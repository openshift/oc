apiVersion: v1
items:
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: d656f31b697c2671aac38bbe46d9e5b22d27ae90
    creationTimestamp: "2024-11-20T22:36:29Z"
    generation: 2
    labels:
      machineconfiguration.openshift.io/role: master
    name: 00-master
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: ControllerConfig
      name: machine-config-controller
      uid: b0288238-f89e-41ca-ad96-dc8692409c40
    resourceVersion: "46502"
    uid: 403e2cee-7df7-4d27-8e64-164b66a735fb
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0ANM_DEVICES_DIR%3D%2Frun%2FNetworkManager%2Fdevices%0ANM_RUN_CONN_DIR%3D%2Frun%2FNetworkManager%2Fsystem-connections%0ANM_ETC_CONN_DIR%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A%0Alogger%20-t%20nm-clean-initrd-state%20%22Cleaning%20network%20activation%20state%20generated%20by%20dracut...%22%0Alogger%20-t%20nm-clean-initrd-state%20%22To%20disable%2C%20remove%20%2Fvar%2Flib%2Fmco%2Fnm-clean-initrd-state%22%0A%0Aif%20%5B%20!%20-e%20%22%24NM_DEVICES_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_RUN_CONN_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_ETC_CONN_DIR%22%20%5D%3B%20then%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22There%20is%20no%20network%20activation%20state%20to%20clean%22%0A%20%20exit%0Afi%0A%0A%23%20Some%20deployments%20require%20an%20active%20network%20early%20in%20the%20boot%20process.%20To%0A%23%20achieve%20this%2C%20dracut%20runs%20specific%20NetworkManager%20modules.%20This%20results%20in%0A%23%20NetworkManager%20keyfiles%20being%20generated%20(either%20default%20or%20from%20ip%20kernel%0A%23%20arguments)%20and%20activated.%20This%20activation%20generates%20state%20that%20makes%20those%0A%23%20profiles%20to%20be%20re-activated%20by%20the%20NetworkManager%20service%20later%20in%20the%0A%23%20boot%20process.%20And%20this%20has%20the%20effect%20that%20other%20profiles%20deployed%20by%20the%0A%23%20user%20for%20the%20same%20set%20of%20devices%20are%20ignored.%0A%0A%23%20Most%20of%20the%20time%20this%20is%20the%20desired%20behavior.%20The%20exception%20to%20this%20rule%0A%23%20is%20when%20the%20user%20wants%20to%20run%20the%20boot%20process%20with%20a%20different%20network%0A%23%20setup%20than%20the%20real%20root%20which%20is%20usually%20related%20to%20the%20fact%20that%0A%23%20generating%20images%20with%20customized%20kernel%20arguments%20is%20a%20complication%20in%0A%23%20the%20deployment%20pipeline.%0A%0A%23%20This%20need%20has%20been%20exacerbated%20by%20past%20NetworkManager%20bugs%20that%20activated%0A%23%20the%20network%20on%20boot%20when%20it%20was%20not%20really%20needed.%20Most%20notably%20when%20ip%0A%23%20kernel%20argument%20is%20present%2C%20something%20that%20the%20baremetal%20installer%20adds%20by%0A%23%20default.%0A%0A%23%20The%20intention%20here%20is%20to%20remove%20the%20state%20that%20was%20generated%20with%20the%0A%23%20activation%20of%20those%20profiles%20during%20dracut%20execution.%20Then%20when%0A%23%20NetworkManager%20service%20runs%2C%20the%20profiles%20generated%20by%20dracut%2C%20along%20with%0A%23%20other%20profiles%20configured%20by%20the%20user%2C%20are%20evaluated%20towards%20finding%20the%0A%23%20most%20appropriate%20profile%20to%20connect%20a%20device%20with.%20As%20a%20precaution%2C%20clean%0A%23%20state%20only%20for%20devices%20that%3A%0A%23%20-%20have%20been%20activated%20with%20a%20default%20profile%20(assume%20that%20a%20non-default%0A%23%20%20%20configuration%20expresses%20intention%20by%20user%20to%20run%20with%20it%20permanently)%0A%23%20-%20have%20a%20specific%20configured%20profile%20set%20to%20auto-connect%20(if%20there%20is%20no%0A%23%20%20%20alternate%20configured%20profile%20for%20a%20device%20it%20makes%20no%20sense%20to%0A%23%20%20%20de-activate%20anything)%0A%23%0A%23%20Although%20this%20can%20theoretically%20happen%20on%20any%20deployment%20type%2C%20need%20has%0A%23%20mostly%20come%20from%20IPI%20bare%20metal%20deployments.%20For%20the%20time%20being%2C%20this%0A%23%20should%20be%20opt-in%20in%20any%20other%20deploment%20type.%0A%23%0A%23%20There%20is%20an%20RFE%20filed%20against%20NM%20that%20once%20implemented%20would%20make%20this%0A%23%20script%20unnecessary%3A%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D2089707%0A%0Afor%20device%20in%20%22%24%7BNM_DEVICES_DIR%7D%22%2F*%3B%20do%0A%20%20if%20%5B%20!%20-e%20%22%24device%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20the%20device%20file%20name%20is%20the%20ifindex%0A%20%20ifindex%3D%24(basename%20%22%24device%22)%0A%20%20%0A%20%20%23%20get%20the%20interface%20name%20by%20ifindex%0A%20%20ifname%3D%24(ip%20-j%20link%20show%20%7C%20jq%20-r%20%22.%5B%5D%20%7C%20select(.ifindex%20%3D%3D%20%24%7Bifindex%7D)%20%7C%20.ifname%20%2F%2F%20empty%22)%0A%0A%20%20%23%20no%20interface%20name%20found%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20get%20the%20uuid%20of%20the%20profile%20the%20device%20has%20been%20activated%20with%0A%20%20active_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bdevice%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Econnection-uuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24device%22)%0A%0A%20%20%23%20the%20device%20was%20not%20activated%20with%20any%20profile%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24active_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20generated%20profile%20by%20uuid%0A%20%20for%20profile%20in%20%22%24%7BNM_RUN_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20generated_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24active_profile_uuid%22%20%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20generated%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24active_profile_uuid%22%20!%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20check%20that%20it%20is%20not%20specific%20for%20the%20device%2C%20otherwise%20ignore%0A%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24profile_ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20profile%20not%20generated%20by%20nm-initrd-generator%2C%20ignore%0A%20%20%23%20only%20check%20it%20if%20the%20key%20is%20set%20(from%20NM%201.32.4)%0A%20%20origin%3D%24(sed%20-nr%20'%2F%5E%5C%5Buser%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eorg.freedesktop.NetworkManager.origin%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24origin%22%20%5D%20%26%26%20%5B%20%22%24origin%22%20!%3D%20%22nm-initrd-generator%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20configured%20profile%20by%20name%20with%20auto-connect%20set%0A%20%20for%20profile%20in%20%22%24%7BNM_ETC_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20autoconnect%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eautoconnect%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24profile_ifname%22%20%3D%20%22%24ifname%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20configured%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24profile_ifname%22%20!%3D%20%22%24ifname%22%20%5D%20%7C%7C%20%5B%20%22%24autoconnect%22%20%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20configured_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20activated%20with%20default%20generated%20profile%20%24generated_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20has%20different%20configured%20specific%20profile%20%24configured_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%3A%20removing%20state...%22%0A%20%20%0A%20%20%23%20NM%20can%20still%20generate%20internal%20profiles%20from%20the%20IP%20address%0A%20%20%23%20configuration%20of%20devices%2C%20so%20flush%20addresses%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Flushing%20IP%20addresses%20from%20%24ifname%22%0A%20%20ip%20addr%20flush%20%22%24ifname%22%0A%20%20ip%20-6%20addr%20flush%20%22%24ifname%22%0A%0A%20%20%23%20remove%20device%20state%20file%20to%20prevent%20NM%20to%20unilaterally%20connect%20with%20the%0A%20%20%23%20latest%20activated%20profile%20without%20evaluating%20other%20profiles%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Removing%20%24device%22%0A%20%20rm%20-f%20--%20%22%24device%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nm-clean-initrd-state.sh
        - contents:
            source: data:,%5Bconnection%5D%0Aipv6.dhcp-duid%3Dll%0Aipv6.dhcp-iaid%3Dmac%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/01-ipv6.conf
        - contents:
            source: data:,%5Bmain%5D%0Aplugins%3Dkeyfile%2Cifcfg-rh%0A%5Bkeyfile%5D%0Apath%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/20-keyfiles.conf
        - contents:
            source: data:,
          mode: 384
          overwrite: true
          path: /etc/pki/ca-trust/source/anchors/openshift-config-user-ca-bundle.crt
        - contents:
            source: data:,KUBERNETES_SERVICE_HOST%3D'api-int.ci-ln-hz4dqct-76ef8.aws-2.ci.openshift.org'%0AKUBERNETES_SERVICE_PORT%3D'6443'%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/apiserver-url.env
        - contents:
            source: data:,%23%20This%20file%20is%20managed%20by%20machine-config-operator.%0A%23%20Suppress%20audit%20rules%20which%20always%20trigger%20for%20container%0A%23%20workloads%2C%20as%20they%20spam%20the%20audit%20log.%20%20Workloads%20are%20expected%0A%23%20to%20be%20dynamic%2C%20and%20the%20networking%20stack%20uses%20iptables.%0A-a%20exclude%2Calways%20-F%20msgtype%3DNETFILTER_CFG%0A%23%20The%20default%20bridged%20networking%20enables%20promiscuous%20on%20the%20veth%0A%23%20device.%20%20Ideally%2C%20we'd%20teach%20audit%20to%20ignore%20only%20veth%20devices%2C%0A%23%20since%20one%20might%20legitimately%20care%20about%20promiscuous%20on%20real%20physical%0A%23%20devices.%20%20But%20we%20can't%20currently%20differentiate.%0A-a%20exclude%2Calways%20-F%20msgtype%3DANOM_PROMISCUOUS%0A
          mode: 420
          overwrite: true
          path: /etc/audit/rules.d/mco-audit-quiet-containers.rules
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20It%20has%20been%20observed%20that%20the%20kernel%20enables%20ESP%20offloads%20of%20bond%0A%23%20devices%20in%20active%2Fbackup%20mode%20even%20if%20slaves%20apparently%20don't%20support%0A%23%20it.%20It's%20unclear%20if%20this%20is%20expected%20behavior%20but%20we%20have%20had%20problems%0A%23%20with%20the%20resulting%20configuration%20in%20vsphere.%20So%20set%20ESP%20offload%20features%0A%23%20off%20in%20bond%20devices%20if%20they%20are%20off%20in%20slave%20devices%20for%20the%20time%20being.%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FRHEL-58811%0A%0Aif%20%5B%5B%20%22%242%22%20!%3D%20%22up%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24DEVICE_IFACE%22)%0A%0Aif%20%5B%5B%20%22%24driver%22%20!%3D%20%22bond%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Abond%3D%22%24DEVICE_IFACE%22%0Afor%20feature%20in%20tx-esp-segmentation%20esp-hw-offload%20esp-tx-csum-hw-offload%3B%20do%0A%0A%20%20if%20ethtool%20-k%20%22%24bond%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%23%20already%20disabled%2C%20nothing%20to%20do%0A%20%20%20%20continue%0A%20%20fi%0A%20%20%0A%20%20for%20slave%20in%20%24(nmcli%20-g%20BOND.SLAVES%20dev%20show%20%22%24DEVICE_IFACE%22)%3B%20do%0A%0A%20%20%20%20if%20!%20ethtool%20-k%20%22%24slave%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%20%20%23%20enabled%20in%20slave%2C%20nothing%20to%20do%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20logger%20-t%20bond-esp-offload%20-s%20%22Bond%20link%20%24slave%20has%20%24feature%20off%2C%20setting%20master%20%24DEVICE_IFACE%20%24feature%20off%22%0A%20%20%20%20ethtool%20-K%20%22%24bond%22%20%22%24feature%22%20off%0A%0A%20%20%20%20break%0A%20%20done%0Adone%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-bond-esp-offload
        - contents:
            source: data:,r%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F80-openshift-network.conf%0Ar%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F10-ovn-kubernetes.conf%0Ad%20%2Frun%2Fmultus%2Fcni%2Fnet.d%2F%200755%20root%20root%20-%20-%0AD%20%2Fvar%2Flib%2Fcni%2Fnetworks%2Fopenshift-sdn%2F%200755%20root%20root%20-%20-%0A
          mode: 420
          overwrite: true
          path: /etc/tmpfiles.d/cleanup-cni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Skipping%20configure-ovs%20due%20to%20manual%20network%20configuration%22%0A%20%20exit%200%0Afi%0A%0A%23%20This%20file%20is%20not%20needed%20anymore%20in%204.7%2B%2C%20but%20when%20rolling%20back%20to%204.6%0A%23%20the%20ovs%20pod%20needs%20it%20to%20know%20ovs%20is%20running%20on%20the%20host.%0Atouch%20%2Fvar%2Frun%2Fovs-config-executed%0A%0A%23%20These%20are%20well%20knwon%20NM%20default%20paths%0ANM_CONN_ETC_PATH%3D%22%2Fetc%2FNetworkManager%2Fsystem-connections%22%0ANM_CONN_RUN_PATH%3D%22%2Frun%2FNetworkManager%2Fsystem-connections%22%0A%0A%23%20This%20is%20the%20path%20where%20NM%20is%20known%20to%20be%20configured%20to%20store%20user%20keyfiles%20%0ANM_CONN_CONF_PATH%3D%22%24NM_CONN_ETC_PATH%22%0A%0A%23%20This%20is%20where%20we%20want%20our%20keyfiles%20to%20finally%20reside.%20configure-ovs%0A%23%20operates%20with%20temporary%20keyfiles%20in%20NM_CONN_RUN_PATH%20and%20then%20as%20a%20last%0A%23%20step%20moves%20those%20keyfiles%20to%20NM_CONN_SET_PATH%20if%20it%20is%20a%20different%20path%0A%23%20(not%20by%20default).%20This%20mitigates%20hard%20interruptions%20(SIGKILL%2C%20hard%20reboot)%0A%23%20of%20configure-ovs%20leaving%20the%20machine%20with%20a%20half-baked%20set%20of%20keyfiles%0A%23%20that%20might%20prevent%20machine%20networking%20from%20working%20correctly.%0ANM_CONN_SET_PATH%3D%22%24%7BNM_CONN_SET_PATH%3A-%24NM_CONN_RUN_PATH%7D%22%0A%0AMANAGED_NM_CONN_SUFFIX%3D%22-slave-ovs-clone%22%0A%23%20Workaround%20to%20ensure%20OVS%20is%20installed%20due%20to%20bug%20in%20systemd%20Requires%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1888017%0Acopy_nm_conn_files()%20%7B%0A%20%20local%20dst_path%3D%22%241%22%0A%20%20for%20src%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20src_path%3D%24(dirname%20%22%24src%22)%0A%20%20%20%20file%3D%24(basename%20%22%24src%22)%0A%20%20%20%20if%20%5B%20-f%20%22%24src_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%24dst_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20elif%20!%20cmp%20--silent%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20updated%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20-f%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it's%20equal%20at%20destination%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it%20does%20not%20exist%20at%20source%22%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0Aupdate_nm_conn_files_base()%20%7B%0A%20%20base_path%3D%24%7B1%7D%0A%20%20bridge_name%3D%24%7B2%7D%0A%20%20port_name%3D%24%7B3%7D%0A%20%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%20%20%23%20In%20RHEL7%20files%20in%20%2F%7Betc%2Crun%7D%2FNetworkManager%2Fsystem-connections%20end%20without%20the%20suffix%20'.nmconnection'%2C%20whereas%20in%20RHCOS%20they%20end%20with%20the%20suffix.%0A%20%20MANAGED_NM_CONN_FILES%3D(%24(echo%20%22%24%7Bbase_path%7D%22%2F%7B%22%24bridge_name%22%2C%22%24ovs_interface%22%2C%22%24ovs_port%22%2C%22%24bridge_interface_name%22%2C%22%24default_port_name%22%7D%7B%2C.nmconnection%7D))%0A%20%20shopt%20-s%20nullglob%0A%20%20MANAGED_NM_CONN_FILES%2B%3D(%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D.nmconnection%20%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D)%0A%20%20shopt%20-u%20nullglob%0A%7D%0A%0Aupdate_nm_conn_run_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_RUN_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_set_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_SET_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0A%23%20Move%20and%20reload%20keyfiles%20at%20their%20final%20destination%0Aset_nm_conn_files()%20%7B%0A%20%20if%20%5B%20%22%24NM_CONN_RUN_PATH%22%20!%3D%20%22%24NM_CONN_SET_PATH%22%20%5D%3B%20then%0A%20%20%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%20%20%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%0A%20%20%20%20%23%20reload%20keyfiles%0A%20%20%20%20nmcli%20connection%20reload%0A%20%20fi%0A%7D%0A%0A%23%20Used%20to%20remove%20files%20managed%20by%20configure-ovs%20and%20temporary%20leftover%20files%20from%20network%20manager%0Arm_nm_conn_files()%20%7B%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20rm%20-f%20%22%24file%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20file%20%24file%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20fi%0A%20%20done%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20for%20temp%20in%20%24(compgen%20-G%20%22%24%7Bfile%7D.*%22)%3B%20do%0A%20%20%20%20%20%20rm%20-f%20%22%24temp%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20temporary%20file%20%24temp%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20done%0A%20%20done%0A%7D%0A%0A%23%20Used%20to%20clone%20a%20slave%20connection%20by%20uuid%2C%20returns%20new%20name%0Aclone_slave_connection()%20%7B%0A%20%20local%20uuid%3D%22%241%22%0A%20%20local%20old_name%0A%20%20old_name%3D%22%24(nmcli%20-g%20connection.id%20connection%20show%20uuid%20%22%24uuid%22)%22%0A%20%20local%20new_name%3D%22%24%7Bold_name%7D%24%7BMANAGED_NM_CONN_SUFFIX%7D%22%0A%20%20if%20nmcli%20connection%20show%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20existing%20ovs%20slave%20%24%7Bnew_name%7D%20connection%20profile%20file%20found%2C%20overwriting...%22%20%3E%262%0A%20%20%20%20nmcli%20connection%20delete%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%0A%20%20fi%0A%20%20clone_nm_conn%20%24uuid%20%22%24%7Bnew_name%7D%22%0A%20%20echo%20%22%24%7Bnew_name%7D%22%0A%7D%0A%0A%23%20Used%20to%20replace%20an%20old%20master%20connection%20uuid%20with%20a%20new%20one%20on%20all%20connections%0Areplace_connection_master()%20%7B%0A%20%20local%20old%3D%22%241%22%0A%20%20local%20new%3D%22%242%22%0A%20%20for%20conn_uuid%20in%20%24(nmcli%20-g%20UUID%20connection%20show)%20%3B%20do%0A%20%20%20%20if%20%5B%20%22%24(nmcli%20-g%20connection.master%20connection%20show%20uuid%20%22%24conn_uuid%22)%22%20!%3D%20%22%24old%22%20%5D%3B%20then%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20local%20autoconnect%3D%24(nmcli%20-g%20connection.autoconnect%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20!%3D%20%22activated%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Assume%20that%20slave%20profiles%20intended%20to%20be%20used%20are%20those%20that%20are%3A%0A%20%20%20%20%20%20%23%20-%20active%0A%20%20%20%20%20%20%23%20-%20or%20inactive%20(which%20might%20be%20due%20to%20link%20being%20down)%20but%20to%20be%20autoconnected.%0A%20%20%20%20%20%20%23%20Otherwise%2C%20ignore%20them.%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20make%20changes%20for%20slave%20profiles%20in%20a%20new%20clone%0A%20%20%20%20local%20new_name%0A%20%20%20%20new_name%3D%24(clone_slave_connection%20%24conn_uuid)%0A%0A%20%20%20%20mod_nm_conn%20%22%24new_name%22%20connection.master%20%22%24new%22%20connection.autoconnect-priority%20100%20connection.autoconnect%20no%20%0A%20%20%20%20echo%20%22Replaced%20master%20%24old%20with%20%24new%20for%20slave%20profile%20%24new_name%22%0A%20%20done%0A%7D%0A%0A%23%20when%20creating%20the%20bridge%2C%20we%20use%20a%20value%20lower%20than%20NM's%20ethernet%20device%20default%20route%20metric%0A%23%20(we%20pick%2048%20and%2049%20to%20be%20lower%20than%20anything%20that%20NM%20chooses%20by%20default)%0ABRIDGE_METRIC%3D%2248%22%0ABRIDGE1_METRIC%3D%2249%22%0A%23%20Given%20an%20interface%2C%20generates%20NM%20configuration%20to%20add%20to%20an%20OVS%20bridge%0Aconvert_to_bridge()%20%7B%0A%20%20local%20iface%3D%24%7B1%7D%0A%20%20local%20bridge_name%3D%24%7B2%7D%0A%20%20local%20port_name%3D%24%7B3%7D%0A%20%20local%20bridge_metric%3D%24%7B4%7D%0A%20%20local%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20local%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20local%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20local%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%0A%20%20if%20%5B%20%22%24iface%22%20%3D%20%22%24bridge_name%22%20%5D%3B%20then%0A%20%20%20%20%23%20handle%20vlans%20and%20bonds%20etc%20if%20they%20have%20already%20been%0A%20%20%20%20%23%20configured%20via%20nm%20key%20files%20and%20br-ex%20is%20already%20up%0A%20%20%20%20ifaces%3D%24(ovs-vsctl%20list-ifaces%20%24%7Biface%7D)%0A%20%20%20%20for%20intf%20in%20%24ifaces%3B%20do%20configure_driver_options%20%24intf%3B%20done%0A%20%20%20%20echo%20%22Networking%20already%20configured%20and%20up%20for%20%24%7Bbridge-name%7D!%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20flag%20to%20reload%20NM%20to%20account%20for%20all%20the%20configuration%20changes%0A%20%20%23%20going%20forward%0A%20%20nm_config_changed%3D1%0A%0A%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20Unable%20to%20find%20default%20gateway%20interface%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20%23%20find%20the%20MAC%20from%20OVS%20config%20or%20the%20default%20interface%20to%20use%20for%20OVS%20internal%20port%0A%20%20%23%20this%20prevents%20us%20from%20getting%20a%20different%20DHCP%20lease%20and%20dropping%20connection%0A%20%20if%20!%20iface_mac%3D%24(%3C%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface%7D%2Faddress%22)%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MAC%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20echo%20%22MAC%20address%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mac%7D%22%0A%0A%20%20%23%20find%20MTU%20from%20original%20iface%0A%20%20iface_mtu%3D%24(ip%20link%20show%20%22%24iface%22%20%7C%20awk%20'%7Bprint%20%245%3B%20exit%7D')%0A%20%20if%20%5B%5B%20-z%20%22%24iface_mtu%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MTU%2C%20defaulting%20to%201500%22%0A%20%20%20%20iface_mtu%3D1500%0A%20%20else%0A%20%20%20%20echo%20%22MTU%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mtu%7D%22%0A%20%20fi%0A%0A%20%20%23%20store%20old%20conn%20for%20later%0A%20%20old_conn%3D%24(nmcli%20--fields%20UUID%2CDEVICE%20conn%20show%20--active%20%7C%20awk%20%22%2F%5Cs%24%7Biface%7D%5Cs*%5C%24%2F%20%7Bprint%20%5C%241%7D%22)%0A%0A%20%20if%20%5B%5B%20-z%20%22%24old_conn%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20cannot%20find%20connection%20for%20interface%3A%20%24%7Biface%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20create%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24bridge_name%22%20type%20ovs-bridge%20conn.interface%20%22%24bridge_name%22%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20%23%20find%20default%20port%20to%20add%20to%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24default_port_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%24%7Biface%7D%0A%20%20%20%20add_nm_conn%20%22%24default_port_name%22%20type%20ovs-port%20conn.interface%20%24%7Biface%7D%20master%20%22%24bridge_name%22%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_port%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24ovs_port%22%20type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24bridge_name%22%0A%20%20fi%0A%0A%20%20extra_phys_args%3D()%0A%20%20%23%20check%20if%20this%20interface%20is%20a%20vlan%2C%20bond%2C%20team%2C%20or%20ethernet%20type%0A%20%20if%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22vlan%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dvlan%0A%20%20%20%20vlan_id%3D%24(nmcli%20--get-values%20vlan.id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_id%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20vlan.parent%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_parent%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_parent%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20nmcli%20connection%20show%20uuid%20%22%24vlan_parent%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20%20%20%23%20if%20the%20VLAN%20connection%20is%20configured%20with%20a%20connection%20UUID%20as%20parent%2C%20we%20need%20to%20find%20the%20underlying%20device%0A%20%20%20%20%20%20%23%20and%20create%20the%20bridge%20against%20it%2C%20as%20the%20parent%20connection%20can%20be%20replaced%20by%20another%20bridge.%0A%20%20%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20GENERAL.DEVICES%20conn%20show%20uuid%20%24%7Bvlan_parent%7D)%0A%20%20%20%20fi%0A%0A%20%20%20%20extra_phys_args%3D(%20dev%20%22%24%7Bvlan_parent%7D%22%20id%20%22%24%7Bvlan_id%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbond%0A%20%20%20%20%23%20check%20bond%20options%0A%20%20%20%20bond_opts%3D%24(nmcli%20--get-values%20bond.options%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24bond_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20bond.options%20%22%24%7Bbond_opts%7D%22%20)%0A%20%20%20%20%20%20MODE_REGEX%3D%22(%5E%7C%2C)mode%3Dactive-backup(%2C%7C%24)%22%0A%20%20%20%20%20%20MAC_REGEX%3D%22(%5E%7C%2C)fail_over_mac%3D(1%7Cactive%7C2%7Cfollow)(%2C%7C%24)%22%0A%20%20%20%20%20%20if%20%5B%5B%20%24bond_opts%20%3D~%20%24MODE_REGEX%20%5D%5D%20%26%26%20%5B%5B%20%24bond_opts%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22team%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dteam%0A%20%20%20%20%23%20check%20team%20config%20options%0A%20%20%20%20team_config_opts%3D%24(nmcli%20--get-values%20team.config%20-e%20no%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24team_config_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20team.config%20is%20json%2C%20remove%20spaces%20to%20avoid%20problems%20later%20on%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20team.config%20%22%24%7Bteam_config_opts%2F%2F%5B%5B%3Aspace%3A%5D%5D%2F%7D%22%20)%0A%20%20%20%20%20%20team_mode%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.name%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20team_mac_policy%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.hwaddr_policy%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20MAC_REGEX%3D%22(by_active%7Conly_active)%22%0A%20%20%20%20%20%20if%20%5B%20%22%24team_mode%22%20%3D%20%22activebackup%22%20%5D%20%26%26%20%5B%5B%20%22%24team_mac_policy%22%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22tun%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dtun%0A%20%20%20%20tun_mode%3D%24(nmcli%20--get-values%20tun.mode%20-e%20no%20connection%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20extra_phys_args%2B%3D(%20tun.mode%20%22%24%7Btun_mode%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bridge%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbridge%0A%20%20else%0A%20%20%20%20iface_type%3D802-3-ethernet%0A%20%20fi%0A%0A%20%20if%20%5B%20!%20%22%24%7Bclone_mac%3A-%7D%22%20%3D%20%220%22%20%5D%3B%20then%0A%20%20%20%20%23%20In%20active-backup%20link%20aggregation%2C%20with%20fail_over_mac%20mode%20enabled%2C%0A%20%20%20%20%23%20cloning%20the%20mac%20address%20is%20not%20supported.%20It%20is%20possible%20then%20that%0A%20%20%20%20%23%20br-ex%20has%20a%20different%20mac%20address%20than%20the%20bond%20which%20might%20be%0A%20%20%20%20%23%20troublesome%20on%20some%20platforms%20where%20the%20nic%20won't%20accept%20packets%20with%0A%20%20%20%20%23%20a%20different%20destination%20mac.%20But%20nobody%20has%20complained%20so%20far%20so%20go%20on%0A%20%20%20%20%23%20with%20what%20we%20got.%20%0A%20%20%20%20%0A%20%20%20%20%23%20Do%20set%20it%20though%20for%20other%20link%20aggregation%20configurations%20where%20the%0A%20%20%20%20%23%20mac%20address%20would%20otherwise%20depend%20on%20enslave%20order%20for%20which%20we%20have%0A%20%20%20%20%23%20no%20control%20going%20forward.%0A%20%20%20%20extra_phys_args%2B%3D(%20802-3-ethernet.cloned-mac-address%20%22%24%7Biface_mac%7D%22%20)%0A%20%20fi%0A%0A%20%20%23%20use%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%20instead%20of%20%24%7Bextra_phys_args%5B%40%5D%7D%20to%20be%20compatible%20with%20bash%204.2%20in%20RHEL7.9%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_interface_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%24%7Biface%7D%0A%20%20%20%20ovs_default_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24default_port_name%22)%0A%20%20%20%20add_nm_conn%20%22%24bridge_interface_name%22%20type%20%24%7Biface_type%7D%20conn.interface%20%24%7Biface%7D%20master%20%22%24ovs_default_port_conn%22%20%5C%0A%20%20%20%20%20%20slave-type%20ovs-port%20connection.autoconnect-priority%20100%20connection.autoconnect-slaves%201%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20%20%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%0A%20%20fi%0A%0A%20%20%23%20Get%20the%20new%20connection%20uuids%0A%20%20new_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24bridge_interface_name%22)%0A%20%20ovs_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24ovs_port%22)%0A%0A%20%20%23%20Update%20connections%20with%20master%20property%20set%20to%20use%20the%20new%20connection%0A%20%20replace_connection_master%20%24old_conn%20%24new_conn%0A%20%20replace_connection_master%20%24iface%20%24new_conn%0A%0A%20%20ipv4_method%3D%24(nmcli%20-g%20ipv4.method%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_method%3D%24(nmcli%20-g%20ipv6.method%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20ipv4_addresses%3D%24(nmcli%20-g%20ipv4.addresses%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_addresses%3D%24(nmcli%20-g%20ipv6.addresses%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20%23%20Warn%20about%20an%20invalid%20MTU%20that%20will%20most%20likely%20fail%20in%20one%20way%20or%0A%20%20%23%20another%0A%20%20if%20%5B%20%24%7Biface_mtu%7D%20-lt%201280%20%5D%20%26%26%20%5B%20%22%24%7Bipv6_method%7D%22%20!%3D%20%22disabled%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20MTU%20%24%7Biface_mtu%7D%20is%20lower%20than%20the%20minimum%20required%20of%201280%20for%20IPv6%22%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_interface%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%22%24bridge_name%22%0A%20%20%20%20%23%20Clone%20the%20connection%20in%20case%20the%20method%20is%20manual%20or%20in%20case%20the%20an%20address%20is%20set%20(DHCP%20%2B%20static%20IP)%0A%20%20%20%20if%20%5B%20%22%24%7Bipv4_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv4_addresses%7D%22%20!%3D%20%22%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_addresses%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Static%20IP%20addressing%20detected%20on%20default%20gateway%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%23%20clone%20the%20old%20connection%20to%20get%20the%20address%20settings%0A%20%20%20%20%20%20%23%20prefer%20cloning%20vs%20copying%20the%20connection%20file%20to%20avoid%20problems%20with%20selinux%0A%20%20%20%20%20%20clone_nm_conn%20%22%24%7Bold_conn%7D%22%20%22%24%7Bovs_interface%7D%22%0A%20%20%20%20%20%20shopt%20-s%20nullglob%0A%20%20%20%20%20%20new_conn_files%3D(%24%7BNM_CONN_RUN_PATH%7D%2F%22%24%7Bovs_interface%7D%22*)%0A%20%20%20%20%20%20shopt%20-u%20nullglob%0A%20%20%20%20%20%20if%20%5B%20%24%7B%23new_conn_files%5B%40%5D%7D%20-ne%201%20%5D%20%7C%7C%20%5B%20!%20-f%20%22%24%7Bnew_conn_files%5B0%5D%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20could%20not%20find%20%24%7Bovs_interface%7D%20conn%20file%20after%20cloning%20from%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20new_conn_file%3D%22%24%7Bnew_conn_files%5B0%5D%7D%22%0A%0A%20%20%20%20%20%20%23%20modify%20the%20connection%20type%20directly%20because%20it%20can't%20be%20modified%0A%20%20%20%20%20%20%23%20through%20nmcli%0A%20%20%20%20%20%20sed%20-i%20'%2F%5E%5C%5Bconnection%5C%5D%24%2F%2C%2F%5E%5C%5B%2F%20s%2F%5Etype%3D.*%24%2Ftype%3Dovs-interface%2F'%20%24%7Bnew_conn_file%7D%0A%0A%20%20%20%20%20%20%23%20modify%20some%20more%20settings%20through%20nmcli%0A%20%20%20%20%20%20mod_nm_conn%20%22%24%7Bovs_interface%7D%22%20conn.interface%20%22%24bridge_name%22%20%5C%0A%20%20%20%20%20%20%20%20connection.multi-connect%20%22%22%20connection.autoconnect%20no%20%5C%0A%20%20%20%20%20%20%20%20connection.master%20%22%24ovs_port_conn%22%20connection.slave-type%20ovs-port%20%5C%0A%20%20%20%20%20%20%20%20ovs-interface.type%20internal%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%0A%0A%20%20%20%20%20%20echo%20%22Loaded%20new%20%24ovs_interface%20connection%20file%3A%20%24%7Bnew_conn_file%7D%22%0A%20%20%20%20else%0A%20%20%20%20%20%20extra_if_brex_args%3D%22%22%0A%20%20%20%20%20%20%23%20check%20if%20interface%20had%20ipv4%2Fipv6%20addresses%20assigned%0A%20%20%20%20%20%20num_ipv4_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ipv4_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20IPV6%20should%20have%20at%20least%20a%20link%20local%20address.%20Check%20for%20more%20than%201%20to%20see%20if%20there%20is%20an%0A%20%20%20%20%20%20%23%20assigned%20address.%0A%20%20%20%20%20%20num_ip6_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet6%5C%22%20and%20.scope%20!%3D%20%5C%22link%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ip6_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20check%20for%20dhcp%20client%20ids%0A%20%20%20%20%20%20dhcp_client_id%3D%24(nmcli%20--get-values%20ipv4.dhcp-client-id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.dhcp-client-id%20%24%7Bdhcp_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20dhcp6_client_id%3D%24(nmcli%20--get-values%20ipv6.dhcp-duid%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp6_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.dhcp-duid%20%24%7Bdhcp6_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20ipv6_addr_gen_mode%3D%24(nmcli%20--get-values%20ipv6.addr-gen-mode%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24ipv6_addr_gen_mode%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.addr-gen-mode%20%24%7Bipv6_addr_gen_mode%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20add_nm_conn%20%22%24ovs_interface%22%20type%20ovs-interface%20slave-type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24ovs_port_conn%22%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.method%20%22%24%7Bipv4_method%7D%22%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20ipv6.method%20%22%24%7Bipv6_method%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20%24%7Bextra_if_brex_args%7D%0A%20%20%20%20fi%0A%20%20fi%0A%0A%20%20configure_driver_options%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20remove%20a%20bridge%0Aremove_ovn_bridges()%20%7B%0A%20%20bridge_name%3D%24%7B1%7D%0A%20%20port_name%3D%24%7B2%7D%0A%0A%20%20%23%20Remove%20the%20keyfiles%20from%20known%20configuration%20paths%0A%20%20update_nm_conn_run_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20update_nm_conn_set_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%0A%20%20%23%20NetworkManager%20will%20not%20remove%20%24%7Bbridge_name%7D%20if%20it%20has%20the%20patch%20port%20created%20by%20ovn-kubernetes%0A%20%20%23%20so%20remove%20explicitly%0A%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%24%7Bbridge_name%7D%0A%7D%0A%0A%23%20Removes%20any%20previous%20ovs%20configuration%0Aremove_all_ovn_bridges()%20%7B%0A%20%20echo%20%22Reverting%20any%20previous%20OVS%20configuration%22%0A%20%20%0A%20%20remove_ovn_bridges%20br-ex%20phys0%0A%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%0A%20%20echo%20%22OVS%20configuration%20successfully%20reverted%22%0A%7D%0A%0A%23%20Reloads%20NM%20NetworkManager%20profiles%20if%20any%20configuration%20change%20was%20done.%0A%23%20Accepts%20a%20list%20of%20devices%20that%20should%20be%20re-connect%20after%20reload.%0Areload_profiles_nm()%20%7B%0A%20%20if%20%5B%20%24%7Bnm_config_changed%3A-0%7D%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%23%20no%20config%20was%20changed%2C%20no%20need%20to%20reload%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20reload%20profiles%0A%20%20nmcli%20connection%20reload%0A%0A%20%20%23%20precautionary%20sleep%20of%2010s%20(default%20timeout%20of%20NM%20to%20bring%20down%20devices)%0A%20%20sleep%2010%0A%0A%20%20%23%20After%20reload%2C%20devices%20that%20were%20already%20connected%20should%20connect%20again%0A%20%20%23%20if%20any%20profile%20is%20available.%20If%20no%20profile%20is%20available%2C%20a%20device%20can%0A%20%20%23%20remain%20disconnected%20and%20we%20have%20to%20explicitly%20connect%20it%20so%20that%20a%0A%20%20%23%20profile%20is%20generated.%20This%20can%20happen%20for%20physical%20devices%20but%20should%0A%20%20%23%20not%20happen%20for%20software%20devices%20as%20those%20always%20require%20a%20profile.%0A%20%20for%20dev%20in%20%24%40%3B%20do%0A%20%20%20%20%23%20Only%20attempt%20to%20connect%20a%20disconnected%20device%0A%20%20%20%20local%20connected_state%3D%24(nmcli%20-g%20GENERAL.STATE%20device%20show%20%22%24dev%22%20%7C%7C%20echo%20%22%22)%0A%20%20%20%20if%20%5B%5B%20%22%24connected_state%22%20%3D~%20%22disconnected%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%23%20keep%20track%20if%20a%20profile%20by%20the%20same%20name%20as%20the%20device%20existed%20%0A%20%20%20%20%20%20%23%20before%20we%20attempt%20activation%0A%20%20%20%20%20%20local%20named_profile_existed%3D%24(%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%5D%20%7C%7C%20%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22%20%5D%20%26%26%20echo%20%22yes%22)%0A%20%20%20%20%20%20%0A%20%20%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20connect%20device%20%24dev%22%0A%20%20%20%20%20%20%20%20%20%20nmcli%20device%20connect%20%22%24dev%22%20%26%26%20break%0A%20%20%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%23%20if%20a%20profile%20did%20not%20exist%20before%20but%20does%20now%2C%20it%20was%20generated%0A%20%20%20%20%20%20%23%20but%20we%20want%20it%20to%20be%20ephemeral%2C%20so%20move%20it%20back%20to%20%2Frun%0A%20%20%20%20%20%20if%20%5B%20!%20%22%24named_profile_existed%22%20%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20MANAGED_NM_CONN_FILES%3D(%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22)%0A%20%20%20%20%20%20%20%20copy_nm_conn_files%20%22%24%7BNM_CONN_RUN_PATH%7D%22%0A%20%20%20%20%20%20%20%20rm_nm_conn_files%0A%20%20%20%20%20%20%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20might%20have%20been%20moved%0A%20%20%20%20%20%20%20%20nmcli%20connection%20reload%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20echo%20%22Waiting%20for%20interface%20%24dev%20to%20activate...%22%0A%20%20%20%20if%20!%20timeout%2060%20bash%20-c%20%22while%20!%20nmcli%20-g%20DEVICE%2CSTATE%20c%20%7C%20grep%20%22'%22'%22%24dev%22%3Aactivated'%22'%22%3B%20do%20sleep%205%3B%20done%22%3B%20then%0A%20%20%20%20%20%20echo%20%22WARNING%3A%20%24dev%20did%20not%20activate%22%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20nm_config_changed%3D0%0A%7D%0A%0A%23%20Removes%20all%20configuration%20and%20reloads%20NM%20if%20necessary%0Arollback_nm()%20%7B%0A%20%20phys0%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20phys1%3D%24(get_bridge_physical_interface%20ovs-if-phys1)%0A%20%20%0A%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20remove_all_ovn_bridges%0A%20%20%0A%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20were%20removed%0A%20%20reload_profiles_nm%20%22%24phys0%22%20%22%24phys1%22%0A%7D%0A%0A%23%20Add%20a%20temporary%20deactivated%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20folowed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20add%60%0Aadd_nm_conn()%20%7B%0A%20%20%23%20Use%20%60save%20no%60%20to%20add%20a%20temporary%20profile%0A%20%20nmcli%20c%20add%20save%20no%20con-name%20%22%24%40%22%20connection.autoconnect%20no%0A%7D%0A%0A%23%20Modify%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20followed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20modify%60%0Amod_nm_conn()%20%7B%0A%20%20%23%20the%20easiest%20thing%20to%20do%20here%20would%20be%20to%20use%20%60nmcli%20c%20mod%20--temporary%60%0A%20%20%23%20but%20there%20is%20a%20bug%20in%20selinux%20profiles%20that%20denies%20NM%20from%20performing%0A%20%20%23%20the%20operation%0A%20%20local%20dst_path%3D%24%7BNM_CONN_RUN_PATH%7D%2F%241.nmconnection%0A%20%20local%20src_path%0A%20%20src_path%3D%24(mktemp)%0A%20%20shift%0A%20%20cat%20%22%24dst_path%22%20%3E%20%22%24src_path%22%0A%20%20rm%20-f%20%22%24dst_path%22%0A%20%20nmcli%20--offline%20c%20mod%20%22%24%40%22%20%3C%20%22%24src_path%22%20%3E%20%22%24dst_path%22%0A%20%20rm%20-f%20%22%24src_path%22%0A%20%20chmod%20600%20%22%24dst_path%22%0A%20%20nmcli%20c%20load%20%22%24dst_path%22%0A%7D%0A%0A%23%20Clone%20to%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20to%20clone%2C%20second%20argument%20is%20the%20clone%20name%0Aclone_nm_conn()%20%7B%0A%20%20%23%20clone%20as%20temporary%20so%20that%20it%20is%20generated%20in%20NM_CONN_RUN_PATH%0A%20%20nmcli%20connection%20clone%20--temporary%20%22%241%22%20%22%242%22%20%26%3E%20%2Fdev%2Fnull%0A%7D%0A%0A%23%20Activates%20an%20ordered%20set%20of%20NM%20connection%20profiles%0Aactivate_nm_connections()%20%7B%0A%20%20local%20connections%3D(%22%24%40%22)%0A%0A%20%20%23%20We%20want%20autoconnect%20set%20for%20our%20cloned%20slave%20profiles%20so%20that%20they%20are%0A%20%20%23%20used%20over%20the%20original%20profiles%20if%20implicitly%20re-activated%20with%20other%0A%20%20%23%20dependant%20profiles.%20Otherwise%20if%20a%20slave%20activates%20with%20an%20old%20profile%2C%0A%20%20%23%20the%20old%20master%20profile%20might%20activate%20as%20well%2C%20interfering%20and%20causing%0A%20%20%23%20further%20activations%20to%20fail.%0A%20%20%23%20Slave%20interfaces%20should%20already%20be%20active%20so%20setting%20autoconnect%20here%0A%20%20%23%20won't%20implicitly%20activate%20them%20but%20there%20is%20an%20edge%20case%20where%20a%20slave%0A%20%20%23%20might%20be%20inactive%20(link%20down%20for%20example)%20and%20in%20that%20case%20setting%0A%20%20%23%20autoconnect%20will%20cause%20an%20implicit%20activation.%20This%20is%20not%20necessarily%20a%0A%20%20%23%20problem%20and%20hopefully%20we%20can%20make%20sure%20everything%20is%20activated%20as%20we%0A%20%20%23%20want%20next.%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20Activate%20all%20connections%20and%20fail%20if%20activation%20fails%0A%20%20%23%20For%20slave%20connections%20-%20for%20as%20long%20as%20at%20least%20one%20slave%20that%20belongs%20to%20a%20bond%2Fteam%0A%20%20%23%20comes%20up%2C%20we%20should%20not%20fail%0A%20%20declare%20-A%20master_interfaces%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%23%20Get%20the%20slave%20type%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20local%20is_slave%3Dfalse%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20is_slave%3Dtrue%0A%20%20%20%20fi%20%0A%0A%20%20%20%20%23%20For%20slave%20interfaces%2C%20initialize%20the%20master%20interface%20to%20false%20if%20the%20key%20is%20not%20yet%20in%20the%20array%0A%20%20%20%20local%20master_interface%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20master_interface%3D%24(nmcli%20-g%20connection.master%20connection%20show%20%22%24conn%22)%0A%20%20%20%20%20%20if%20!%20%5B%5B%20-v%20%22master_interfaces%5B%24master_interface%5D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dfalse%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Do%20not%20activate%20interfaces%20that%20are%20already%20active%0A%20%20%20%20%23%20But%20set%20the%20entry%20in%20master_interfaces%20to%20true%20if%20this%20is%20a%20slave%0A%20%20%20%20%23%20Also%20set%20autoconnect%20to%20yes%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20%3D%3D%20%22activated%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Connection%20%24conn%20already%20activated%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%24master_interface%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Activate%20all%20interfaces%20that%20are%20not%20yet%20active%0A%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20bring%20up%20connection%20%24conn%22%0A%20%20%20%20%20%20nmcli%20conn%20up%20%22%24conn%22%20%26%26%20s%3D0%20%26%26%20break%20%7C%7C%20s%3D%24%3F%0A%20%20%20%20%20%20sleep%205%0A%20%20%20%20done%0A%20%20%20%20if%20%5B%20%24s%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Brought%20up%20connection%20%24conn%20successfully%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20elif%20!%20%24is_slave%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20connection%20%24conn%20after%20%24i%20attempts%22%0A%20%20%20%20%20%20return%20%24s%0A%20%20%20%20fi%0A%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20done%0A%20%20%23%20Check%20that%20all%20master%20interfaces%20report%20at%20least%20a%20single%20active%20slave%0A%20%20%23%20Note%3A%20associative%20arrays%20require%20an%20exclamation%20mark%20when%20looping%0A%20%20for%20i%20in%20%22%24%7B!master_interfaces%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20!%20%24%7Bmaster_interfaces%5B%22%24i%22%5D%7D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20any%20slave%20interface%20for%20master%20interface%3A%20%24i%22%0A%20%20%20%20%20%20%20%20return%201%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24iface%0A%23%20Writes%20content%20of%20%24iface%20into%20%24iface_default_hint_file%0Awrite_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%242%22%0A%0A%20%20echo%20%22%24%7Biface%7D%22%20%3E%7C%20%22%24%7Biface_default_hint_file%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%0A%23%20Returns%20the%20stored%20interface%20default%20hint%20if%20the%20hint%20is%20non-empty%2C%0A%23%20not%20br-ex%2C%20not%20br-ex1%20and%20if%20the%20interface%20can%20be%20found%20in%20%2Fsys%2Fclass%2Fnet%0Aget_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%241%0A%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%3B%20then%0A%20%20%20%20local%20iface_default_hint%3D%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex1%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20-d%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface_default_hint%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%22%0A%7D%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0A%23%20This%20function%20waits%20for%20ip%20address%20of%20br-ex%20to%20be%20bindable%20only%20in%20case%20of%20ipv6%0A%23%20This%20is%20workaround%20for%20OCPBUGS-673%20as%20it%20will%20not%20allow%20starting%20crio%0A%23%20before%20address%20is%20bindable%0Atry_to_bind_ipv6_address()%20%7B%0A%20%20%23%20Retry%20for%201%20minute%0A%20%20retries%3D60%0A%20%20until%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20do%0A%20%20%20%20ip%3D%24(ip%20-6%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(.ifname%3D%3D%5C%22br-ex%5C%22)%20%7C%20.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20.local)%22)%0A%20%20%20%20if%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22No%20ipv6%20ip%20to%20bind%20was%20found%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20sleep%201%0A%20%20%20%20((%20retries--%20))%0A%20%20done%0A%20%20if%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Failed%20to%20bind%20ip%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%7D%0A%0A%23%20Get%20interface%20that%20matches%20ip%20from%20node%20ip%20hint%20file%0A%23%20in%20case%20file%20not%20exists%20return%20nothing%20and%0A%23%20fallback%20to%20default%20interface%20search%20flow%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge%3D%22%242%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)%20and%20.ifname!%3D%5C%22br-ex1%5C%22%20and%20.ifname!%3D%5C%22%24%7Bextra_bridge%7D%5C%22))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20fi%0A%7D%0A%0A%23%20Accepts%20parameters%20%24bridge_interface%20(e.g.%20ovs-port-phys0)%0A%23%20Returns%20the%20physical%20interface%20name%20if%20%24bridge_interface%20exists%2C%20%22%22%20otherwise%0Aget_bridge_physical_interface()%20%7B%0A%20%20local%20bridge_interface%3D%22%241%22%0A%20%20local%20physical_interface%3D%22%22%0A%20%20physical_interface%3D%24(nmcli%20-g%20connection.interface-name%20conn%20show%20%22%24%7Bbridge_interface%7D%22%202%3E%2Fdev%2Fnull%20%7C%7C%20echo%20%22%22)%0A%20%20echo%20%22%24%7Bphysical_interface%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24extra_bridge_file%2C%20%24ip_hint_file%2C%20%24default_bridge_file%0A%23%20Determines%20the%20interface%20to%20be%20used%20for%20br-ex.%20Order%20of%20priority%20is%3A%0A%23%201.%20Use%20the%20user%20specified%20interface%20if%20provided%20in%20the%20default%20bridge%20file%0A%23%202.%20Use%20the%20node%20IP%20hint%20interface%0A%23%203.%20Use%20the%20previously%20selected%20interface%0A%23%204.%20Use%20the%20interface%20detected%20as%20default%20gateway%0A%23%0A%23%20Read%20%24default_bridge_file%20and%20return%20the%20contained%20interface.%20Otherwise%2C%0A%23%20read%20%24ip_hint_file%20and%20return%20the%20interface%20that%20matches%20this%20ip.%20Otherwise%2C%0A%23%20if%20the%20default%20interface%20is%20br-ex%2C%20use%20that%20and%20return.%0A%23%20If%20the%20default%20interface%20is%20not%20br-ex%3A%0A%23%20Check%20if%20there%20is%20a%20valid%20hint%20inside%20%24iface_default_hint_file.%20If%20so%2C%20use%20that%20hint.%0A%23%20If%20there%20is%20no%20valid%20hint%2C%20use%20the%20default%20interface%20that%20we%20found%20during%20the%20step%0A%23%20earlier.%0A%23%20Never%20use%20the%20interface%20that%20is%20provided%20inside%20%24extra_bridge_file%20for%20br-ex1.%0A%23%20Never%20use%20br-ex1.%0A%23%20Write%20the%20default%20interface%20to%20%24iface_default_hint_file%0Aget_default_bridge_interface()%20%7B%0A%20%20local%20iface%3D%22%22%0A%20%20local%20counter%3D0%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge_file%3D%22%242%22%0A%20%20local%20ip_hint_file%3D%22%243%22%0A%20%20local%20default_bridge_file%3D%22%244%22%0A%20%20local%20extra_bridge%3D%22%22%0A%0A%20%20if%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%3B%20then%0A%20%20%20%20extra_bridge%3D%24(cat%20%24%7Bextra_bridge_file%7D)%0A%20%20fi%0A%0A%20%20%23%20try%20to%20use%20user%20specified%20file%20first%0A%20%20if%20%5B%20-f%20%22%24default_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20iface%3D%24(cat%20%22%24%7Bdefault_bridge_file%7D%22)%0A%20%20%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20User%20specified%20bridge%20file%20detected%20without%20any%20data%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20if%20node%20ip%20was%20set%2C%20we%20should%20search%20for%20interface%20that%20matches%20it%0A%20%20iface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bextra_bridge%7D%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20find%20default%20interface%0A%20%20%23%20the%20default%20interface%20might%20be%20br-ex%2C%20so%20check%20this%20before%20looking%20at%20the%20hint%0A%20%20while%20%5B%20%24%7Bcounter%7D%20-lt%2012%20%5D%3B%20do%0A%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20sleep%205%0A%20%20done%0A%0A%20%20%23%20if%20the%20default%20interface%20does%20not%20point%20out%20of%20br-ex%20or%20br-ex1%0A%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20%23%20determine%20if%20an%20interface%20default%20hint%20exists%20from%20a%20previous%20run%0A%20%20%20%20%23%20and%20if%20the%20interface%20has%20a%20valid%20default%20route%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%24%7Biface%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20start%20wherever%20count%20left%20off%20in%20the%20previous%20loop%0A%20%20%20%20%20%20%23%20allow%20this%20for%20one%20more%20iteration%20than%20the%20previous%20loop%0A%20%20%20%20%20%20while%20%5B%20%24%7Bcounter%7D%20-le%2012%20%5D%3B%20do%0A%20%20%20%20%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20-6%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%20%20%20%20fi%0A%20%20%20%20%23%20store%20what%20was%20determined%20was%20the%20(new)%20default%20interface%20inside%0A%20%20%20%20%23%20the%20default%20hint%20file%20for%20future%20reference%0A%20%20%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Biface%7D%22%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20print%20network%20state%0Aprint_state()%20%7B%0A%20%20echo%20%22Current%20device%2C%20connection%2C%20interface%20and%20routing%20state%3A%22%0A%20%20nmcli%20-g%20all%20device%20%7C%20grep%20-v%20unmanaged%0A%20%20nmcli%20-g%20all%20connection%0A%20%20ip%20-d%20address%20show%0A%20%20ip%20route%20show%0A%20%20ip%20-6%20route%20show%0A%7D%0A%0A%23%20Setup%20an%20exit%20trap%20to%20rollback%20on%20error%0Ahandle_exit()%20%7B%0A%20%20e%3D%24%3F%0A%20%20tdir%3D%24(mktemp%20-u%20-d%20-t%20%22configure-ovs-%24(date%20%2B%25Y-%25m-%25d-%25H-%25M-%25S)-XXXXXXXXXX%22)%0A%20%20%0A%20%20if%20%5B%20%24e%20-eq%200%20%5D%3B%20then%0A%20%20%20%20print_state%0A%20%20%20%20%23%20remove%20previous%20troubleshooting%20information%0A%20%20%20%20rm%20-rf%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%0A%20%20echo%20%22ERROR%3A%20configure-ovs%20exited%20with%20error%3A%20%24e%22%0A%20%20print_state%0A%0A%20%20%23%20remove%20previous%20troubleshooting%20information%20except%20the%20oldest%20one%0A%20%20mapfile%20-t%20tdirs%20%3C%20%3C(compgen%20-G%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22)%0A%20%20unset%20-v%20%22tdirs%5B0%5D%22%0A%20%20for%20dir%20in%20%22%24%7Btdirs%5B%40%5D%7D%22%3B%20do%20rm%20-rf%20%22%24dir%22%3B%20done%0A%0A%20%20%23%20copy%20configuration%20to%20tmp%20for%20troubleshooting%0A%20%20mkdir%20-p%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20echo%20%22Copied%20OVS%20configuration%20to%20%24tdir%20for%20troubleshooting%22%0A%0A%20%20%23%20attempt%20to%20restore%20the%20previous%20network%20state%0A%20%20echo%20%22Attempting%20to%20restore%20previous%20configuration...%22%0A%20%20rollback_nm%0A%20%20print_state%0A%0A%20%20exit%20%24e%0A%7D%0A%0A%23%20Setup%20a%20signal%20trap%20to%20rollback%0Ahandle_termination()%20%7B%0A%20%20echo%20%22WARNING%3A%20configure-ovs%20has%20been%20requested%20to%20terminate%2C%20quitting...%22%0A%20%20%0A%20%20%23%20by%20exiting%20with%20an%20error%20we%20will%20cleanup%20after%20ourselves%20in%20a%0A%20%20%23%20subsequent%20call%20to%20handle_exit%0A%20%20exit%201%0A%7D%0A%0A%23%20main%20function%0Aconfigure_ovs()%20%7B%0A%20%20set%20-eu%0A%0A%20%20%23%20setup%20traps%20to%20handle%20signals%20and%20other%20abnormal%20exits%0A%20%20trap%20'handle_termination'%20TERM%20INT%0A%20%20trap%20'handle_exit'%20EXIT%0A%0A%20%20%23%20this%20flag%20tracks%20if%20any%20config%20change%20was%20made%0A%20%20nm_config_changed%3D0%0A%0A%20%20%23%20Check%20that%20we%20are%20provided%20a%20valid%20NM%20connection%20path%0A%20%20if%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_CONF_PATH%22%20%5D%20%26%26%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_RUN_PATH%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Error%3A%20Incorrect%20NM%20connection%20path%3A%20%24NM_CONN_SET_PATH%20is%20not%20%24NM_CONN_CONF_PATH%20nor%20%24NM_CONN_RUN_PATH%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0A%20%20if%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0A%20%20fi%0A%0A%20%20if%20!%20rpm%20-qa%20%7C%20grep%20-q%20openvswitch%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20Openvswitch%20package%20is%20not%20installed!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20print%20initial%20state%0A%20%20print_state%0A%0A%20%20if%20%5B%20%22%241%22%20%3D%3D%20%22OVNKubernetes%22%20%5D%3B%20then%0A%20%20%20%20%23%20Configures%20NICs%20onto%20OVS%20bridge%20%22br-ex%22%0A%20%20%20%20%23%20Configuration%20is%20either%20auto-detected%20or%20provided%20through%20a%20config%20file%20written%20already%20in%20Network%20Manager%0A%20%20%20%20%23%20key%20files%20under%20%2Fetc%2FNetworkManager%2Fsystem-connections%2F%0A%20%20%20%20%23%20Managing%20key%20files%20is%20outside%20of%20the%20scope%20of%20this%20script%0A%0A%20%20%20%20%23%20if%20the%20interface%20is%20of%20type%20vmxnet3%20add%20multicast%20capability%20for%20that%20driver%0A%20%20%20%20%23%20History%3A%20BZ%3A1854355%0A%20%20%20%20function%20configure_driver_options%20%7B%0A%20%20%20%20%20%20intf%3D%241%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Device%20file%20doesn't%20exist%2C%20skipping%20setting%20multicast%20mode%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20driver%3D%24(cat%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%7C%20grep%20DRIVER%20%7C%20awk%20-F%20%22%3D%22%20'%7Bprint%20%242%7D')%0A%20%20%20%20%20%20%20%20echo%20%22Driver%20name%20is%22%20%24driver%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24driver%22%20%3D%20%22vmxnet3%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20ip%20link%20set%20dev%20%22%24%7Bintf%7D%22%20allmulticast%20on%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20fi%0A%20%20%20%20%7D%0A%0A%20%20%20%20ovnk_config_dir%3D'%2Fetc%2Fovnk'%0A%20%20%20%20ovnk_var_dir%3D'%2Fvar%2Flib%2Fovnk'%0A%20%20%20%20extra_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fextra_bridge%22%0A%20%20%20%20iface_default_hint_file%3D%22%24%7Bovnk_var_dir%7D%2Fiface_default_hint%22%0A%20%20%20%20ip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%20%20%20%20%23%20explicitly%20specify%20which%20interface%20should%20be%20used%20with%20the%20default%20bridge%0A%20%20%20%20default_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fdefault_bridge%22%0A%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_config_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_config_dir%7D%22%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_var_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_var_dir%7D%22%0A%0A%20%20%20%20%23%20For%20upgrade%20scenarios%2C%20make%20sure%20that%20we%20stabilize%20what%20we%20already%20configured%0A%20%20%20%20%23%20before.%20If%20we%20do%20not%20have%20a%20valid%20interface%20hint%2C%20find%20the%20physical%20interface%0A%20%20%20%20%23%20that's%20attached%20to%20ovs-if-phys0.%0A%20%20%20%20%23%20If%20we%20find%20such%20an%20interface%2C%20write%20it%20to%20the%20hint%20file.%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20current_interface%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20%20%20%20%20if%20%5B%20%22%24%7Bcurrent_interface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bcurrent_interface%7D%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20delete%20iface_default_hint_file%20if%20it%20has%20the%20same%20content%20as%20extra_bridge_file%0A%20%20%20%20%23%20in%20that%20case%2C%20we%20must%20also%20force%20a%20reconfiguration%20of%20our%20network%20interfaces%0A%20%20%20%20%23%20to%20make%20sure%20that%20we%20reconcile%20this%20conflict%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20%22%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%22%20%3D%3D%20%22%24(cat%20%22%24%7Bextra_bridge_file%7D%22)%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint_file%7D%20and%20%24%7Bextra_bridge_file%7D%20share%20the%20same%20content%22%0A%20%20%20%20%20%20echo%20%22Deleting%20file%20%24%7Biface_default_hint_file%7D%20to%20choose%20a%20different%20interface%22%0A%20%20%20%20%20%20rm%20-f%20%22%24%7Biface_default_hint_file%7D%22%0A%20%20%20%20%20%20rm%20-f%20%2Frun%2Fconfigure-ovs-boot-done%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20on%20every%20boot%20we%20rollback%20and%20generate%20the%20configuration%20again%2C%20to%20take%0A%20%20%20%20%23%20in%20any%20changes%20that%20have%20possibly%20been%20applied%20in%20the%20standard%0A%20%20%20%20%23%20configuration%20sources%0A%20%20%20%20if%20%5B%20!%20-f%20%2Frun%2Fconfigure-ovs-boot-done%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Running%20on%20boot%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20print_state%0A%20%20%20%20fi%0A%20%20%20%20touch%20%2Frun%2Fconfigure-ovs-boot-done%0A%0A%20%20%20%20iface%3D%24(get_default_bridge_interface%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bextra_bridge_file%7D%22%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bdefault_bridge_file%7D%22)%0A%0A%20%20%20%20if%20%5B%20%22%24iface%22%20!%3D%20%22br-ex%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Specified%20interface%20is%20not%20br-ex.%0A%20%20%20%20%20%20%23%20Some%20deployments%20use%20a%20temporary%20solution%20where%20br-ex%20is%20moved%20out%20from%20the%20default%20gateway%20interface%0A%20%20%20%20%20%20%23%20and%20bound%20to%20a%20different%20nic%20(https%3A%2F%2Fgithub.com%2Ftrozet%2Fopenshift-ovn-migration).%0A%20%20%20%20%20%20%23%20This%20is%20now%20supported%20through%20an%20extra%20bridge%20if%20requested.%20If%20that%20is%20the%20case%2C%20we%20rollback.%0A%20%20%20%20%20%20%23%20We%20also%20rollback%20if%20it%20looks%20like%20we%20need%20to%20configure%20things%2C%20just%20in%20case%20there%20are%20any%20leftovers%0A%20%20%20%20%20%20%23%20from%20previous%20attempts.%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%7C%7C%20%5B%20-z%20%22%24(nmcli%20connection%20show%20--active%20br-ex%202%3E%20%2Fdev%2Fnull)%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Bridge%20br-ex%20is%20not%20active%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20%20%20print_state%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20convert_to_bridge%20%22%24iface%22%20%22br-ex%22%20%22phys0%22%20%22%24%7BBRIDGE_METRIC%7D%22%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20configure%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(!%20nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20!%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20interface%3D%24(head%20-n%201%20%24extra_bridge_file)%0A%20%20%20%20%20%20convert_to_bridge%20%22%24interface%22%20%22br-ex1%22%20%22phys1%22%20%22%24%7BBRIDGE1_METRIC%7D%22%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20remove%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20!%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20openshift-sdn%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0A%20%20%20%20%23%20Make%20sure%20everything%20is%20activated.%20Do%20it%20in%20a%20specific%20order%3A%0A%20%20%20%20%23%20-%20activate%20br-ex%20first%2C%20due%20to%20autoconnect-slaves%20this%20will%20also%0A%20%20%20%20%23%20%20%20activate%20ovs-port-br-ex%2C%20ovs-port-phys0%20and%20ovs-if-phys0.%20It%20is%0A%20%20%20%20%23%20%20%20important%20that%20ovs-if-phys0%20activates%20with%20br-ex%20to%20avoid%20the%0A%20%20%20%20%23%20%20%20ovs-if-phys0%20profile%20being%20overridden%20with%20a%20profile%20generated%20from%0A%20%20%20%20%23%20%20%20kargs.%20The%20activation%20of%20ovs-if-phys0%2C%20if%20a%20bond%2C%20might%20cause%20the%0A%20%20%20%20%23%20%20%20slaves%20to%20re-activate%2C%20but%20it%20should%20be%20with%20our%20profiles%20since%20they%0A%20%20%20%20%23%20%20%20have%20higher%20priority%0A%20%20%20%20%23%20-%20make%20sure%20that%20ovs-if-phys0%20and%20its%20slaves%2C%20if%20any%2C%20are%20activated.%0A%20%20%20%20%23%20-%20finally%20activate%20ovs-if-br-ex%20which%20holds%20the%20IP%20configuration.%0A%20%20%20%20connections%3D(br-ex%20ovs-if-phys0)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(br-ex1%20ovs-if-phys1)%0A%20%20%20%20fi%0A%20%20%20%20while%20IFS%3D%20read%20-r%20connection%3B%20do%0A%20%20%20%20%20%20if%20%5B%5B%20%24connection%20%3D%3D%20*%22%24MANAGED_NM_CONN_SUFFIX%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20connections%2B%3D(%22%24connection%22)%0A%20%20%20%20%20%20fi%0A%20%20%20%20done%20%3C%20%3C(nmcli%20-g%20NAME%20c)%0A%20%20%20%20connections%2B%3D(ovs-if-br-ex)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(ovs-if-br-ex1)%0A%20%20%20%20fi%0A%20%20%20%20activate_nm_connections%20%22%24%7Bconnections%5B%40%5D%7D%22%0A%20%20%20%20try_to_bind_ipv6_address%0A%20%20%20%20set_nm_conn_files%0A%20%20elif%20%5B%20%22%241%22%20%3D%3D%20%22OpenShiftSDN%22%20%5D%3B%20then%0A%20%20%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20%20%20rollback_nm%0A%20%20%20%20%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20ovn-kubernetes%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-int%20--%20--if-exists%20del-br%20br-local%0A%20%20fi%0A%7D%0A%0A%23%20Retry%20configure_ovs%20until%20it%20succeeds.%0A%23%20By%20default%2C%20retry%20every%2015%20minutes%20to%20give%20enough%20time%20to%20gather%0A%23%20troubleshooting%20information%20in%20between.%20Note%20that%20configure_ovs%20has%20other%0A%23%20internal%20retry%20mechanisms.%20This%20retry%20is%20intended%20to%20give%20some%0A%23%20self-healing%20capabilities%20to%20temporary%20but%20not%20necessarily%20short-lived%0A%23%20infrastructure%20problems.%0ARETRY%3D%22%24%7BRETRY-15m%7D%22%0Awhile%20true%3B%20do%0A%0A%20%20%23%20Disable%20retries%20if%20termination%20signal%20is%20received.%20Note%20that%20systemd%0A%20%20%23%20sends%20the%20signals%20to%20all%20processes%20in%20the%20group%20by%20default%20so%20we%20expect%0A%20%20%23%20configure_ovs%20to%20get%20its%20own%20signals.%0A%20%20trap%20'echo%20%22WARNING%3A%20termination%20requested%2C%20disabling%20retries%22%3B%20RETRY%3D%22%22'%20INT%20TERM%0A%20%20%0A%20%20%23%20Run%20configure_ovs%20in%20a%20sub-shell.%20%0A%20%20(%20configure_ovs%20%22%24%40%22%20)%0A%20%20e%3D%24%3F%0A%0A%20%20%23%20Handle%20signals%20while%20we%20sleep%0A%20%20trap%20'handle_termination'%20INT%20TERM%0A%20%20%0A%20%20%23%20Exit%20if%20succesful%20and%20not%20configured%20to%20retry%0A%20%20%5B%20%22%24e%22%20-eq%200%20%5D%20%7C%7C%20%5B%20-z%20%22%24RETRY%22%20%5D%20%26%26%20exit%20%22%24e%22%0A%20%20%0A%20%20echo%20%22configure-ovs%20failed%2C%20will%20retry%20after%20%24RETRY%22%0A%20%20%23%20flag%20that%20a%20retry%20has%20happened%0A%20%20touch%20%2Ftmp%2Fconfigure-ovs-retry%0A%20%20sleep%20%22%24RETRY%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ovs.sh
        - contents:
            source: data:,%23%20This%20file%20is%20generated%20by%20the%20Machine%20Config%20Operator's%20containerruntimeconfig%20controller.%0A%23%0A%23%20storage.conf%20is%20the%20configuration%20file%20for%20all%20tools%0A%23%20that%20share%20the%20containers%2Fstorage%20libraries%0A%23%20See%20man%205%20containers-storage.conf%20for%20more%20information%0A%23%20The%20%22container%20storage%22%20table%20contains%20all%20of%20the%20server%20options.%0A%5Bstorage%5D%0A%0A%23%20Default%20Storage%20Driver%0Adriver%20%3D%20%22overlay%22%0A%0A%23%20Temporary%20storage%20location%0Arunroot%20%3D%20%22%2Fvar%2Frun%2Fcontainers%2Fstorage%22%0A%0A%23%20Primary%20Read%2FWrite%20location%20of%20container%20storage%0Agraphroot%20%3D%20%22%2Fvar%2Flib%2Fcontainers%2Fstorage%22%0A%0A%5Bstorage.options%5D%0A%23%20Storage%20options%20to%20be%20passed%20to%20underlying%20storage%20drivers%0A%0A%23%20AdditionalImageStores%20is%20used%20to%20pass%20paths%20to%20additional%20Read%2FOnly%20image%20stores%0A%23%20Must%20be%20comma%20separated%20list.%0Aadditionalimagestores%20%3D%20%5B%0A%5D%0A%0A%23%20Size%20is%20used%20to%20set%20a%20maximum%20size%20of%20the%20container%20image.%20%20Only%20supported%20by%0A%23%20certain%20container%20storage%20drivers.%0Asize%20%3D%20%22%22%0A%0A%23%20Remap-UIDs%2FGIDs%20is%20the%20mapping%20from%20UIDs%2FGIDs%20as%20they%20should%20appear%20inside%20of%0A%23%20a%20container%2C%20to%20UIDs%2FGIDs%20as%20they%20should%20appear%20outside%20of%20the%20container%2C%20and%0A%23%20the%20length%20of%20the%20range%20of%20UIDs%2FGIDs.%20%20Additional%20mapped%20sets%20can%20be%20listed%0A%23%20and%20will%20be%20heeded%20by%20libraries%2C%20but%20there%20are%20limits%20to%20the%20number%20of%0A%23%20mappings%20which%20the%20kernel%20will%20allow%20when%20you%20later%20attempt%20to%20run%20a%0A%23%20container.%0A%23%0A%23%20remap-uids%20%3D%200%3A1668442479%3A65536%0A%23%20remap-gids%20%3D%200%3A1668442479%3A65536%0A%0A%23%20Remap-User%2FGroup%20is%20a%20name%20which%20can%20be%20used%20to%20look%20up%20one%20or%20more%20UID%2FGID%0A%23%20ranges%20in%20the%20%2Fetc%2Fsubuid%20or%20%2Fetc%2Fsubgid%20file.%20%20Mappings%20are%20set%20up%20starting%0A%23%20with%20an%20in-container%20ID%20of%200%20and%20the%20a%20host-level%20ID%20taken%20from%20the%20lowest%0A%23%20range%20that%20matches%20the%20specified%20name%2C%20and%20using%20the%20length%20of%20that%20range.%0A%23%20Additional%20ranges%20are%20then%20assigned%2C%20using%20the%20ranges%20which%20specify%20the%0A%23%20lowest%20host-level%20IDs%20first%2C%20to%20the%20lowest%20not-yet-mapped%20container-level%20ID%2C%0A%23%20until%20all%20of%20the%20entries%20have%20been%20used%20for%20maps.%0A%23%0A%23%20remap-user%20%3D%20%22storage%22%0A%23%20remap-group%20%3D%20%22storage%22%0A%0A%5Bstorage.options.overlay%5D%0A%23%20Storage%20Options%20for%20overlay%0A%0A%23%20Do%20not%20create%20a%20PRIVATE%20bind%20mount%20on%20the%20home%20directory.%0Askip_mount_home%20%3D%20%22true%22%0A%0A%5Bstorage.options.thinpool%5D%0A%23%20Storage%20Options%20for%20thinpool%0A%0A%23%20autoextend_percent%20determines%20the%20amount%20by%20which%20pool%20needs%20to%20be%0A%23%20grown.%20This%20is%20specified%20in%20terms%20of%20%25%20of%20pool%20size.%20So%20a%20value%20of%2020%20means%0A%23%20that%20when%20threshold%20is%20hit%2C%20pool%20will%20be%20grown%20by%2020%25%20of%20existing%0A%23%20pool%20size.%0A%23%20autoextend_percent%20%3D%20%2220%22%0A%0A%23%20autoextend_threshold%20determines%20the%20pool%20extension%20threshold%20in%20terms%0A%23%20of%20percentage%20of%20pool%20size.%20For%20example%2C%20if%20threshold%20is%2060%2C%20that%20means%20when%0A%23%20pool%20is%2060%25%20full%2C%20threshold%20has%20been%20hit.%0A%23%20autoextend_threshold%20%3D%20%2280%22%0A%0A%23%20basesize%20specifies%20the%20size%20to%20use%20when%20creating%20the%20base%20device%2C%20which%0A%23%20limits%20the%20size%20of%20images%20and%20containers.%0A%23%20basesize%20%3D%20%2210G%22%0A%0A%23%20blocksize%20specifies%20a%20custom%20blocksize%20to%20use%20for%20the%20thin%20pool.%0A%23%20blocksize%3D%2264k%22%0A%0A%23%20directlvm_device%20specifies%20a%20custom%20block%20storage%20device%20to%20use%20for%20the%0A%23%20thin%20pool.%20Required%20if%20you%20setup%20devicemapper%0A%23%20directlvm_device%20%3D%20%22%22%0A%0A%23%20directlvm_device_force%20wipes%20device%20even%20if%20device%20already%20has%20a%20filesystem%0A%23%20directlvm_device_force%20%3D%20%22True%22%0A%0A%23%20fs%20specifies%20the%20filesystem%20type%20to%20use%20for%20the%20base%20device.%0A%23%20fs%3D%22xfs%22%0A%0A%23%20log_level%20sets%20the%20log%20level%20of%20devicemapper.%0A%23%200%3A%20LogLevelSuppress%200%20(Default)%0A%23%202%3A%20LogLevelFatal%0A%23%203%3A%20LogLevelErr%0A%23%204%3A%20LogLevelWarn%0A%23%205%3A%20LogLevelNotice%0A%23%206%3A%20LogLevelInfo%0A%23%207%3A%20LogLevelDebug%0A%23%20log_level%20%3D%20%227%22%0A%0A%23%20min_free_space%20specifies%20the%20min%20free%20space%20percent%20in%20a%20thin%20pool%20require%20for%0A%23%20new%20device%20creation%20to%20succeed.%20Valid%20values%20are%20from%200%25%20-%2099%25.%0A%23%20Value%200%25%20disables%0A%23%20min_free_space%20%3D%20%2210%25%22%0A%0A%23%20mkfsarg%20specifies%20extra%20mkfs%20arguments%20to%20be%20used%20when%20creating%20the%20base%0A%23%20device.%0A%23%20mkfsarg%20%3D%20%22%22%0A%0A%23%20mountopt%20specifies%20extra%20mount%20options%20used%20when%20mounting%20the%20thin%20devices.%0A%23%20mountopt%20%3D%20%22%22%0A%0A%23%20use_deferred_removal%20Marking%20device%20for%20deferred%20removal%0A%23%20use_deferred_removal%20%3D%20%22True%22%0A%0A%23%20use_deferred_deletion%20Marking%20device%20for%20deferred%20deletion%0A%23%20use_deferred_deletion%20%3D%20%22True%22%0A%0A%23%20xfs_nospace_max_retries%20specifies%20the%20maximum%20number%20of%20retries%20XFS%20should%0A%23%20attempt%20to%20complete%20IO%20when%20ENOSPC%20(no%20space)%20error%20is%20returned%20by%0A%23%20underlying%20storage%20device.%0A%23%20xfs_nospace_max_retries%20%3D%20%220%22%0A
          mode: 420
          overwrite: true
          path: /etc/containers/storage.conf
        - contents:
            source: data:,apiVersion%3A%20kubelet.config.k8s.io%2Fv1%0Akind%3A%20CredentialProviderConfig%0Aproviders%3A%0A%20%20-%20name%3A%20ecr-credential-provider%0A%20%20%20%20matchImages%3A%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.*.amazonaws.com%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.*.amazonaws.com.cn%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr-fips.*.amazonaws.com%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.us-iso-east-1.c2s.ic.gov%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.us-isob-east-1.sc2s.sgov.gov%22%0A%20%20%20%20defaultCacheDuration%3A%20%2212h%22%0A%20%20%20%20apiVersion%3A%20credentialprovider.kubelet.k8s.io%2Fv1%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/credential-providers/ecr-credential-provider.yaml
        - contents:
            source: data:,%23%20Proxy%20environment%20variables%20will%20be%20populated%20in%20this%20file.%20Properly%0A%23%20url%20encoded%20passwords%20with%20special%20characters%20will%20use%20'%25%3CHEX%3E%3CHEX%3E'.%0A%23%20Systemd%20requires%20that%20any%20%25%20used%20in%20a%20password%20be%20represented%20as%0A%23%20%25%25%20in%20a%20unit%20file%20since%20%25%20is%20a%20prefix%20for%20macros%3B%20this%20restriction%20does%20not%0A%23%20apply%20for%20environment%20files.%20Templates%20that%20need%20the%20proxy%20set%20should%20use%0A%23%20'EnvironmentFile%3D%2Fetc%2Fmco%2Fproxy.env'.%0A
          mode: 420
          overwrite: true
          path: /etc/mco/proxy.env
        - contents:
            source: data:,%5BManager%5D%0ADefaultEnvironment%3DGODEBUG%3Dx509ignoreCN%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/10-default-env-godebug.conf
        - contents:
            source: data:,%23%20Force-load%20legacy%20iptables%20so%20it%20is%20usable%20from%20pod%20network%20namespaces%0Aip_tables%0A
          mode: 420
          overwrite: true
          path: /etc/modules-load.d/iptables.conf
        - contents:
            source: data:,NODE_SIZING_ENABLED%3Dfalse%0ASYSTEM_RESERVED_MEMORY%3D1Gi%0ASYSTEM_RESERVED_CPU%3D500m%0ASYSTEM_RESERVED_ES%3D1Gi
          mode: 420
          overwrite: true
          path: /etc/node-sizing-enabled.env
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%0ANODE_SIZES_ENV%3D%24%7BNODE_SIZES_ENV%3A-%2Fetc%2Fnode-sizing.env%7D%0AVERSION_1%3D1%0AVERSION_2%3D2%0ANODE_AUTO_SIZING_VERSION%3D%24%7BNODE_AUTO_SIZING_VERSION%3A-%24VERSION_2%7D%0ANODE_AUTO_SIZING_VERSION_FILE%3D%24%7BNODE_AUTO_SIZING_VERSION_FILE%3A-%2Fetc%2Fnode-sizing-version.json%7D%0Afunction%20dynamic_memory_sizing%20%7B%0A%20%20%20%20total_memory%3D%24(free%20-g%7Cawk%20'%2F%5EMem%3A%2F%7Bprint%20%242%7D')%0A%20%20%20%20%23%20total_memory%3D8%20test%20the%20recommended%20values%20by%20modifying%20this%20value%0A%20%20%20%20recommended_systemreserved_memory%3D0%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2025%25%20of%20the%20first%204GB%20of%20memory%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24total_memory%200.25%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D1%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2020%25%20of%20the%20next%204GB%20of%20memory%20(up%20to%208GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.20%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%208))%3B%20then%20%23%2010%25%20of%20the%20next%208GB%20of%20memory%20(up%20to%2016GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.10%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-8))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%20112))%3B%20then%20%23%206%25%20of%20the%20next%20112GB%20of%20memory%20(up%20to%20128GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%206.72%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-112))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3E%3D%200))%3B%20then%20%23%202%25%20of%20any%20memory%20above%20128GB%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.02%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20fi%0A%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%7C%20awk%20'%7Bprintf(%22%25d%5Cn%22%2C%241%20%2B%200.5)%7D')%20%23%20Round%20off%20so%20we%20avoid%20float%20conversions%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7Brecommended_systemreserved_memory%7DGi%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_cpu_sizing%20%7B%0A%20%20%20%20total_cpu%3D%24(getconf%20_NPROCESSORS_ONLN)%0A%20%20%20%20if%20%5B%20%22%241%22%20-eq%20%22%24VERSION_1%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%206%25%20of%20the%20first%20core%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24total_cpu%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0.06%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%201%25%20of%20the%20next%20core%20(up%20to%202%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%202))%3B%20then%20%23%200.5%25%20of%20the%20next%202%20cores%20(up%20to%204%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.005%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-2))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3E%3D%200))%3B%20then%20%23%200.25%25%20of%20any%20cores%20above%204%20cores%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.0025%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20%23%20Base%20allocation%20for%201%20CPU%20in%20fractions%20of%20a%20core%20(60%20millicores%20%3D%200.06%20CPU%20core)%0A%20%20%20%20%20%20%20%20base_allocation_fraction%3D0.06%0A%20%20%20%20%20%20%20%20%23%20Increment%20per%20additional%20CPU%20in%20fractions%20of%20a%20core%20(12%20millicores%20%3D%200.012%20CPU%20core)%0A%20%20%20%20%20%20%20%20increment_per_cpu_fraction%3D0.012%0A%20%20%20%20%20%20%20%20if%20((total_cpu%20%3E%201))%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20the%20total%20system-reserved%20CPU%20in%20fractions%2C%20starting%20with%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20and%20adding%20the%20incremental%20fraction%20for%20each%20additional%20CPU%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20base%3D%22%24base_allocation_fraction%22%20-v%20increment%3D%22%24increment_per_cpu_fraction%22%20-v%20cpus%3D%22%24total_cpu%22%20'BEGIN%20%7Bprintf%20%22%25.2f%5Cn%22%2C%20base%20%2B%20increment%20*%20(cpus%20-%201)%7D')%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20a%20single%20CPU%2C%20use%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24base_allocation_fraction%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7Brecommended_systemreserved_cpu%7D%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_ephemeral_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20dynamic_pid_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20set_memory%20%7B%0A%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_cpu%20%7B%0A%20%20%20%20SYSTEM_RESERVED_CPU%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_CPU%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_CPU%3D%22500m%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7BSYSTEM_RESERVED_CPU%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_es%20%7B%0A%20%20%20%20SYSTEM_RESERVED_ES%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_ES%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_ES%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_ES%3D%24%7BSYSTEM_RESERVED_ES%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20dynamic_memory_sizing%0A%20%20%20%20dynamic_cpu_sizing%20%242%0A%20%20%20%20set_es%20%241%0A%20%20%20%20%23dynamic_ephemeral_sizing%0A%20%20%20%20%23dynamic_pid_sizing%0A%7D%0Afunction%20static_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20set_memory%20%241%0A%20%20%20%20set_cpu%20%242%0A%20%20%20%20set_es%20%243%0A%7D%0Afunction%20create_version_file%20%7B%0A%20%20%20%20echo%20%22%7B%5C%22version%5C%22%3A%20%241%7D%22%20%3E%20%242%0A%7D%0Aif%20!%20%5B%20-f%20%24NODE_AUTO_SIZING_VERSION_FILE%20%5D%3B%20then%0A%20%20%20%20create_version_file%20%24NODE_AUTO_SIZING_VERSION%20%24NODE_AUTO_SIZING_VERSION_FILE%0Afi%0Anew_version%3D%24(jq%20.version%20%24NODE_AUTO_SIZING_VERSION_FILE)%0Aif%20%5B%20%241%20%3D%3D%20%22true%22%20%5D%3B%20then%0A%20%20%20%20dynamic_node_sizing%20%244%20%24new_version%0Aelif%20%5B%20%241%20%3D%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20static_node_sizing%20%242%20%243%20%244%0Aelse%0A%20%20%20%20echo%20%22Unrecognized%20command%20line%20option.%20Valid%20options%20are%20%5C%22true%5C%22%20or%20%5C%22false%5C%22%22%0Afi
          mode: 493
          overwrite: true
          path: /usr/local/sbin/dynamic-system-reserved-calc.sh
        - contents:
            source: data:,%23%20Turning%20on%20Accounting%20helps%20track%20down%20performance%20issues.%0A%5BManager%5D%0ADefaultCPUAccounting%3Dyes%0ADefaultMemoryAccounting%3Dyes%0ADefaultBlockIOAccounting%3Dyes%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/kubelet-cgroups.conf
        - contents:
            source: data:,%5BService%5D%0AEnvironment%3D%22KUBELET_LOG_LEVEL%3D2%22%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system/kubelet.service.d/20-logging.conf
        - contents:
            source: data:,%23%20ignore%20known%20SDN-managed%20devices%0A%5Bdevice%5D%0Amatch-device%3Dinterface-name%3Abr-int%3Binterface-name%3Abr-local%3Binterface-name%3Abr-nexthop%3Binterface-name%3Aovn-k8s-*%3Binterface-name%3Ak8s-*%3Binterface-name%3Atun0%3Binterface-name%3Abr0%3Binterface-name%3Apatch-br-*%3Binterface-name%3Abr-ext%3Binterface-name%3Aext-vxlan%3Binterface-name%3Aext%3Binterface-name%3Aint%3Binterface-name%3Avxlan_sys_*%3Binterface-name%3Agenev_sys_*%3Bdriver%3Aveth%0Amanaged%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/sdn.conf
        - contents:
            source: data:,%5Bservice%5D%0Akeep_state_file_after_apply%20%3D%20true%0A
          mode: 420
          overwrite: true
          path: /etc/nmstate/nmstate.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Set%20interface%20ofport_request%20to%20guarantee%20stable%20ofport%20numbers.%20This%20is%20important%20for%20flow%20matches.%0A%23%20Otherwise%2C%20another%20ofport%20number%20is%20assigned%20to%20the%20interface%20on%20every%20restart%20of%20NetworkManager.%0A%23%20This%20script%20will%20build%20an%20associative%20array%20INTERFACE_NAME-%3Eofport_request%20and%20will%20save%20it%20to%20file%20CONFIGURATION_FILE.%0A%23%20When%20an%20interface%20is%20brought%20up%2C%20this%20will%20reuse%20the%20value%20from%20the%20associative%20array%20if%20such%20a%20value%20exists.%0A%23%20Otherwise%2C%20this%20will%20try%20to%20use%20the%20current%20ofport%20value.%20If%20the%20ofport%20value%20is%20already%20reserved%2C%20then%0A%23%20this%20uses%20the%20lowest%20available%20numerical%20value%2C%20instead.%0Aset%20-eux%20-o%20pipefail%0Aif%20%5B%5B%20%22OVNKubernetes%22%20!%3D%20%22OVNKubernetes%22%20%5D%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0AINTERFACE_NAME%3D%241%0AOPERATION%3D%242%0A%0A%23%20Only%20execute%20this%20on%20pre-up%0Aif%20%5B%20%22%24%7BOPERATION%7D%22%20!%3D%20%22pre-up%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0AINTERFACE_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%241%3D%3D%22'%24%7BINTERFACE_NAME%7D'%22%20%26%26%20%242!~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20slave-type.%20If%20this%20is%20not%20an%20ovs-port%2C%20then%20exit%0AINTERFACE_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-port%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20This%20is%20not%20necessarily%20a%20UUID%20(can%20be%20a%20name%20in%20case%20of%20bonds)%20but%20this%20should%20be%20unique%0APORT%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0APORT_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%20(%241%3D%3D%22'%24%7BPORT%7D'%22%20%7C%7C%20%243%3D%3D%22'%24%7BPORT%7D'%22)%20%26%26%20%242~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20slave-type.%20If%20this%20is%20not%20an%20ovs-bridge%2C%20then%20exit%0APORT_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-bridge%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20master.%20If%20it%20doesn't%20have%20any%2C%20assume%20it's%20not%20our%20bridge%0ABRIDGE_ID%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BBRIDGE_ID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20bridge%20name%0ABRIDGE_NAME%3D%24(nmcli%20-t%20-f%20connection.interface-name%20conn%20show%20%22%24%7BBRIDGE_ID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0A%23%20Limit%20this%20to%20br-ex%20and%20br-ex1%20only.%20If%20one%20wanted%20to%20enable%20this%20for%20all%20OVS%20bridges%2C%0A%23%20the%20condition%20would%20be%3A%20if%20%5B%20%22%24BRIDGE_NAME%22%20%3D%3D%20%22%22%20%5D%3B%20then%0Aif%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Make%20sure%20that%20the%20interface%20is%20plugged%20into%20OVS%0A%23%20This%20should%20always%20be%20the%20case%20given%20that%20we%20are%20in%20pre-up%2C%20but%20exit%20gracefully%20in%20the%20odd%20case%20that%20it's%20not%0Aif%20!%20ovs-vsctl%20list%20interface%20%22%24%7BINTERFACE_NAME%7D%22%20%3E%2Fdev%2Fnull%202%3E%261%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0ACONFIGURATION_FILE%3D%22%2Frun%2Fofport_requests.%24%7BBRIDGE_NAME%7D%22%0A%0A%23%20Declare%20a%20new%20associative%20array.%20If%20CONFIGURATION_FILE%20exists%2C%20source%20entries%20from%20there%0Adeclare%20-A%20INTERFACES%0Aif%20%5B%20-f%20%22%24%7BCONFIGURATION_FILE%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Sourcing%20configuration%20file%20'%24%7BCONFIGURATION_FILE%7D'%20with%20contents%3A%22%0A%20%20%20%20cat%20%22%24%7BCONFIGURATION_FILE%7D%22%0A%20%20%20%20source%20%22%24%7BCONFIGURATION_FILE%7D%22%0Afi%0A%0A%23%20get_interface_ofport_request%20will%20return%0A%23%20*%20either%3A%20the%20current%20ofport%20assignment%20for%20the%20port%20if%20no%20interface%20has%20claimed%20this%20ofport%20number%2C%20yet%0A%23%20*%20or%3A%20%20%20%20%20the%20lowest%20available%20free%20ofport%20number%0Afunction%20get_interface_ofport_request()%20%7B%0A%20%20%20%20%23%20Build%20an%20array%20that%20only%20contains%20the%20currently%20reserved%20ofport_requests%0A%20%20%20%20declare%20-A%20ofport_requests%0A%20%20%20%20for%20interface_name%20in%20%22%24%7B!INTERFACES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%20%20%20%20ofport_requests%5B%24%7BINTERFACES%5B%24interface_name%5D%7D%5D%3D%24%7BINTERFACES%5B%24interface_name%5D%7D%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20Get%20the%20current%20ofport%20number%20assignment%0A%20%20%20%20local%20current_ofport%3D%24(ovs-vsctl%20get%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport)%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20still%20free%2C%20use%20it%0A%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24current_ofport%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%24current_ofport%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20not%20free%2C%20return%20the%20lowest%20free%20entry%0A%20%20%20%20i%3D0%0A%20%20%20%20for%20i%20in%20%7B1..65000%7D%3B%20do%0A%20%20%20%20%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24i%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%24i%0A%20%20%20%20%20%20%20%20%20%20%20%20return%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20if%20we%20still%20cannot%20find%20an%20ID%2C%20exit%20with%20an%20error%0A%20%20%20%20echo%20%22Impossible%20to%20find%20an%20ofport%20ID%20for%20interface%20%24%7BINTERFACE_NAME%7D%22%20%3E%262%0A%20%20%20%20exit%201%0A%7D%0A%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20exists%2C%20use%20that%20value%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20does%20not%20exists%2C%20use%20the%20value%20from%20get_interface_ofport_request%0Aif%20!%20%5B%20%22%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20INTERFACES%5B%24INTERFACE_NAME%5D%3D%24(get_interface_ofport_request)%0Afi%0A%23%20Set%20ofport_request%20according%20to%20INTERFACES%5BINTERFACE_NAME%5D%0Aovs-vsctl%20set%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport_request%3D%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%7D%0A%0A%23%20Save%20current%20state%20of%20INTERFACES%20to%20CONFIGURATION_FILE%0Adeclare%20-p%20INTERFACES%20%3E%7C%20%22%24%7BCONFIGURATION_FILE%7D%22%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/pre-up.d/10-ofport-request.sh
        - contents:
            source: data:,%7B%22auths%22%3A%7B%22cloud.openshift.com%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfN2JmN2FjMTAyMDMxNDY1N2EwZjdiMDdiNDNjM2FiZDg6OE1YQ0gyTldMSktPVU9DQk5UNk9NSERPUzc2NkYxTURFTjlXQjhXN0xTTUtDNjk1NjI0N1c1OFUySzFDRUcwVw%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22quay.io%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfN2JmN2FjMTAyMDMxNDY1N2EwZjdiMDdiNDNjM2FiZDg6OE1YQ0gyTldMSktPVU9DQk5UNk9NSERPUzc2NkYxTURFTjlXQjhXN0xTTUtDNjk1NjI0N1c1OFUySzFDRUcwVw%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22registry.ci.openshift.org%22%3A%7B%22auth%22%3A%22c2VydmljZWFjY291bnQ6ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNkluWjBaVmc1TVVkUlpGRjZRME5OWkVWa2JGOXNTSG90YlVSd2EwRlVPR2RzWjJoUVRtMVBkamxLUmpBaWZRLmV5SmhkV1FpT2xzaWFIUjBjSE02THk5amFTMWtkakp1Y0MxdmFXUmpMbk16TG1GdFlYcHZibUYzY3k1amIyMGlYU3dpWlhod0lqb3hOek0wTlRNd05EWXlMQ0pwWVhRaU9qRTNNekl4TVRFeU5qSXNJbWx6Y3lJNkltaDBkSEJ6T2k4dlkya3RaSFl5Ym5BdGIybGtZeTV6TXk1aGJXRjZiMjVoZDNNdVkyOXRJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5STZleUp1WVcxbGMzQmhZMlVpT2lKamFTSXNJbk5sWTNKbGRDSTZleUp1WVcxbElqb2lkRzlyWlc0dFltOTFibVF0YjJKcVpXTjBMVEVpTENKMWFXUWlPaUkxWkRJd1pHUTBNQzFqT1RCaExUUXpNVFl0WVdNd05DMW1OVGczT0RFeVpUVTFZamdpZlN3aWMyVnlkbWxqWldGalkyOTFiblFpT25zaWJtRnRaU0k2SW1sdFlXZGxMWEIxYkd4bGNpSXNJblZwWkNJNkltRTNOMlk1TkdFeUxXVXdOelV0TkRGaU9DMDVPV1JoTFdRMlpEbGtNbUZpTlRGak9TSjlmU3dpYm1KbUlqb3hOek15TVRFeE1qWXlMQ0p6ZFdJaU9pSnplWE4wWlcwNmMyVnlkbWxqWldGalkyOTFiblE2WTJrNmFXMWhaMlV0Y0hWc2JHVnlJbjAuVGFqMktGY1JOV0FIRHJGT0NPQjBhWUJGUTUwVW9FUmdXMWFZYUNTVTQ0NF9jdnpCOFJDamNxR04xdV9jOFRRbFBDNXU0NG5JNklaYTdvU1RnMUh4dE9aQmEyYW5OS0JPMk5UNVF5WEhhX0R5cVJlaUUxb0YtcmphRms2TEJrNWllT1BSWXJHbklpWlJJNkQ2S0kxMmxJVFZQdFBPYUgtaXFuNV9LMXdOcmR4SDhYb2dCdlJ5UlJwRDBLTUxGNkJfeFBzbi1VeHVQQklIbjVRTFlXSkJtOVFMRVlIM0tzZDN2by03Uzc0anlZMkswMUF1OUpwYkFFR3k4Z2lyUDE1YlRnUXJReW1zS1NrbFN6U3BUbEM0MDJxVjNBanVPSjA4eGxrSE5VeXJROFk3dklJWDFBUUVmbHJaaC13ZVcyVy1aNWtnZjFOMXhNVVl6QnplZW5BZF9n%22%7D%2C%22registry.connect.redhat.com%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLWU3NDlmYWFiLTM0ZjktNDg0ZS1hNWQwLTJkNzFhMzgzMTg1MjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSXpORGszTURVMU5URTFObUkwTXpOaFltVmxNRGt5TVRJM09UZzNZV0V5WVNKOS50MUxtR0FhMTQzdnJIWG13RFZVVjNYaWhYa203Vk95bDFLek9kZm9QN0tTd3NqVFpKeUlSN1lKQjNyNGxGN3pVNWMwa0ZyOVYweUtwSFdPRU94clhJekVSaXlfOXkwQzRxbXRDOUhYNjJNVThsdmJtQW9GSXhZbHZXWnREVXVQZWgzSVFqS25CN2FJYlZ6MFJ3SWZWYVZucXFOUzhHbDNFcDRTUjVpNGZmUzE5akJCUnpxdmxBSjF6QkNVWWI3S1ZLTHVGRHJsNjdNNy1rWWwxTUhseTRBN2JVdjVISU5MaEhOdDVfRk5JX3RWbjdQM0RzQkVjcWxkWTd0Y0J4UlNoLTdQbWpzMGJEWm9ZZTZ6by1QY25TeEY0RV94QzF6aGZYYUNpdEU4UVZTUmk2MjhnM1c4WjVQQzc4VFBJWGtvaTBJWG9IX1E4QTd4SDlKaDhsWWhTTnBCaUxHODMyaFNhRUdtYkEtaU5kd3BrTGk0a0oyeTlYWE55ZlNUbU1mRUppUGwyWEI5VXRTT3lva05XU0ZqVk1kZ3l5WFlaUWtTNGh6Ql83VkpzTEh6RHpKaTJGcUZNNE56LW5Qd28zalZ3c3d3YXgzUUZZVUk2YzA5MVZnT0NUdEtpeEJXeTBaVEZyT3hEVDh4ZFRQOXcxY1JoR1N1UzU5WG55c2I2bndDLWQ5ZS11SWZpS2x4dDNZNkJaUkhRYmVUZlRtdGFoMUxOYWhRaXRzclVubVBjZXhnLVFXdzhCS3VENUFwbFc3eFVHcm9Lb1lkSEowVTJtc0ZWcjhZZ2FjVDl1UC1hWGUtTHd0dnJ3ZG1fWGtVdWRMRnFsRklxby1lWTdhVE03Xy1HRk8xWE8xTTIwQWVtSU5oUXJqUkN4TGRJeXlMSU9uOURBZUdYeGc5bUJiWQ%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22registry.redhat.io%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLWU3NDlmYWFiLTM0ZjktNDg0ZS1hNWQwLTJkNzFhMzgzMTg1MjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSXpORGszTURVMU5URTFObUkwTXpOaFltVmxNRGt5TVRJM09UZzNZV0V5WVNKOS50MUxtR0FhMTQzdnJIWG13RFZVVjNYaWhYa203Vk95bDFLek9kZm9QN0tTd3NqVFpKeUlSN1lKQjNyNGxGN3pVNWMwa0ZyOVYweUtwSFdPRU94clhJekVSaXlfOXkwQzRxbXRDOUhYNjJNVThsdmJtQW9GSXhZbHZXWnREVXVQZWgzSVFqS25CN2FJYlZ6MFJ3SWZWYVZucXFOUzhHbDNFcDRTUjVpNGZmUzE5akJCUnpxdmxBSjF6QkNVWWI3S1ZLTHVGRHJsNjdNNy1rWWwxTUhseTRBN2JVdjVISU5MaEhOdDVfRk5JX3RWbjdQM0RzQkVjcWxkWTd0Y0J4UlNoLTdQbWpzMGJEWm9ZZTZ6by1QY25TeEY0RV94QzF6aGZYYUNpdEU4UVZTUmk2MjhnM1c4WjVQQzc4VFBJWGtvaTBJWG9IX1E4QTd4SDlKaDhsWWhTTnBCaUxHODMyaFNhRUdtYkEtaU5kd3BrTGk0a0oyeTlYWE55ZlNUbU1mRUppUGwyWEI5VXRTT3lva05XU0ZqVk1kZ3l5WFlaUWtTNGh6Ql83VkpzTEh6RHpKaTJGcUZNNE56LW5Qd28zalZ3c3d3YXgzUUZZVUk2YzA5MVZnT0NUdEtpeEJXeTBaVEZyT3hEVDh4ZFRQOXcxY1JoR1N1UzU5WG55c2I2bndDLWQ5ZS11SWZpS2x4dDNZNkJaUkhRYmVUZlRtdGFoMUxOYWhRaXRzclVubVBjZXhnLVFXdzhCS3VENUFwbFc3eFVHcm9Lb1lkSEowVTJtc0ZWcjhZZ2FjVDl1UC1hWGUtTHd0dnJ3ZG1fWGtVdWRMRnFsRklxby1lWTdhVE03Xy1HRk8xWE8xTTIwQWVtSU5oUXJqUkN4TGRJeXlMSU9uOURBZUdYeGc5bUJiWQ%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%7D%7D%0A
          mode: 384
          overwrite: true
          path: /var/lib/kubelet/config.json
        - contents:
            source: data:,%23%20Needed%20by%20the%20OpenShift%20SDN.%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1758552%0Anet.ipv4.conf.all.arp_announce%20%3D%202%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/arp.conf
        - contents:
            source: data:,%23%20See%3A%20rhbz%231384746%2C%20OCPBUGS-24012%0Anet.ipv4.neigh.default.gc_thresh1%3D8192%0Anet.ipv4.neigh.default.gc_thresh2%3D32768%0Anet.ipv4.neigh.default.gc_thresh3%3D65536%0Anet.ipv6.neigh.default.gc_thresh1%3D8192%0Anet.ipv6.neigh.default.gc_thresh2%3D32768%0Anet.ipv6.neigh.default.gc_thresh3%3D65536%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/gc-thresh.conf
        - contents:
            source: data:,%0Afs.inotify.max_user_watches%20%3D%2065536%0Afs.inotify.max_user_instances%20%3D%208192%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/inotify.conf
        - contents:
            source: data:,vm.unprivileged_userfaultfd%20%3D%201
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/enable-userfaultfd.conf
        - contents:
            source: data:,%23%20Needed%20for%20OpenShift%20Logging%20(ElasticSearch).%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1793714%0Avm.max_map_count%20%3D%20262144%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/vm-max-map.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%20-o%20pipefail%0A%0ANODEENV%3D%2Fetc%2Fkubernetes%2Fnode.env%0A%0A%23%20This%20can%20be%20removed%201%20release%20after%20it%20merges%20because%20all%20affected%20nodes%0A%23%20will%20have%20upgraded%0ALEGACY_NODEENV%3D%2Fetc%2Fsystemd%2Fsystem%2Fkubelet.service.d%2F20-aws-node-name.conf%0Aif%20%5B%20-e%20%22%24%7BLEGACY_NODEENV%7D%22%20%5D%3B%20then%0A%20%20%20%20%23%20Legacy%20file%20was%20a%20systemd%20stanza%20with%20KUBELET_NODE_NAME%20specified%20in%0A%20%20%20%20%23%20a%20directive%20of%20the%20format%3A%0A%20%20%20%20%23%20%20%20Environment%3D%22KUBELET_NODE_NAME%3Dnode.example.com%22%0A%20%20%20%20%23%20New%20format%20is%20an%20environment%20file.%20The%20following%20extracts%20only%20the%0A%20%20%20%20%23%20contents%20of%20any%20Environment%20directives.%0A%20%20%20%20echo%20%22Migrating%20%24%7BLEGACY_NODEENV%7D%20to%20%24%7BNODEENV%7D%22%0A%20%20%20%20awk%20'match(%240%2C%20%2F%5E%5Cs*Environment%5Cs*%3D%5Cs*%22(.*)%22%5Cs*%24%2F%2C%20value)%20%7B%20print%20value%5B1%5D%20%7D'%20%3C%20%22%24%7BLEGACY_NODEENV%7D%22%20%3E%20%22%24%7BNODEENV%7D%22%0A%20%20%20%20rm%20%22%24%7BLEGACY_NODEENV%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20-e%20%22%24%7BNODEENV%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Not%20replacing%20existing%20%24%7BNODEENV%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20afterburn%20service%20is%20expected%20to%20be%20used%20for%20metadata%20retrival%2C%20see%20respective%20systemd%20unit.%0A%23%20However%2C%20on%20older%20OCP%20boot%20images%20does%20not%20contain%20afterburn%20service%2C%20check%20if%20afterburn%20variables%20are%20there%0A%23%20otherwise%20try%20to%20communicate%20IMDS%20here.%0A%23%20metadata%20related%20afterburn%20doc%3A%20https%3A%2F%2Fcoreos.github.io%2Fafterburn%2Fusage%2Fattributes%2F%0A%0AHOSTNAME%3D%24%7BAFTERBURN_AWS_HOSTNAME%3A-%7D%0Awhile%20%5B%5B%20-z%20%22%24%7BHOSTNAME%7D%22%20%5D%5D%3B%20do%0A%20%20HOSTNAME%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Flocal-hostname)%0A%20%20if%20%5B%5B%20-z%20%22%24%7BHOSTNAME%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Can%20not%20obtain%20hostname%20from%20the%20metadata%20service.%22%201%3E%262%0A%20%20%20%20sleep%205%0A%20%20fi%20%0Adone%0A%0A%23%20For%20compatibility%20with%20the%20AWS%20in-tree%20provider%0A%23%20Set%20node%20name%20to%20be%20instance%20FQDN%20instead%20of%20the%20default%20hostname%0Acat%20%3E%20%22%24%7BNODEENV%7D%22%20%3C%3CEOF%0AKUBELET_NODE_NAME%3D%24%7BHOSTNAME%25%25%20*%7D%0AEOF%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/aws-kubelet-nodename
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%20-o%20pipefail%0A%0ANODECONF%3D%2Fetc%2Fsystemd%2Fsystem%2Fkubelet.service.d%2F20-aws-providerid.conf%0A%0Aif%20%5B%20-e%20%22%24%7BNODECONF%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Not%20replacing%20existing%20%24%7BNODECONF%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20afterburn%20service%20is%20expected%20to%20be%20used%20for%20metadata%20retrival%2C%20see%20respective%20systemd%20unit.%0A%23%20However%2C%20on%20older%20OCP%20boot%20images%20does%20not%20contain%20afterburn%20service%2C%20check%20if%20afterburn%20variables%20are%20there%0A%23%20otherwise%20try%20to%20communicate%20IMDS%20here.%0A%23%20metadata%20related%20afterburn%20doc%3A%20https%3A%2F%2Fcoreos.github.io%2Fafterburn%2Fusage%2Fattributes%2F%0A%0AINSTANCE_ID%3D%24%7BAFTERBURN_AWS_INSTANCE_ID%3A-%7D%0AAVAILABILITY_ZONE%3D%24%7BAFTERBURN_AWS_AVAILABILITY_ZONE%3A-%7D%0Aif%20%5B%5B%20-z%20%22%24%7BINSTANCE_ID%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20-z%20%22%24%7BAVAILABILITY_ZONE%7D%22%20%5D%5D%3B%20then%0A%20%20INSTANCE_ID%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Finstance-id)%0A%20%20AVAILABILITY_ZONE%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Fplacement%2Favailability-zone)%0A%20%20if%20%5B%5B%20-z%20%22%24%7BINSTANCE_ID%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20-z%20%22%24%7BAVAILABILITY_ZONE%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Can%20not%20obtain%20instance-id%20and%20availability%20zone%20info%20from%20the%20metadata%20service.%22%0A%20%20%20%20exit%201%0A%20%20fi%20%0Afi%0A%0A%23%20Due%20to%20a%20potential%20mismatch%20between%20Hostname%20and%20PrivateDNSName%20with%20clusters%20that%20use%20custom%20DHCP%20Option%20Sets%0A%23%20which%20can%20cause%20issues%20in%20cloud%20controller%20manager%20node%20syncing%0A%23%20(see%3A%20https%3A%2F%2Fgithub.com%2Fkubernetes%2Fcloud-provider-aws%2Fissues%2F384)%2C%0A%23%20set%20KUBELET_PROVIDERID%20to%20be%20a%20fully%20qualified%20AWS%20instace%20provider%20id.%0A%23%20This%20new%20variable%20is%20later%20used%20to%20populate%20the%20kubelet's%20%60provider-id%60%20flag%2C%20later%20set%20on%20the%20Node%20.spec%0A%23%20and%20used%20by%20the%20cloud%20controller%20manager's%20node%20controller%20to%20retrieve%20the%20Node's%20backing%20instance.%0Acat%20%3E%20%22%24%7BNODECONF%7D%22%20%3C%3CEOF%0A%5BService%5D%0AEnvironment%3D%22KUBELET_PROVIDERID%3Daws%3A%2F%2F%2F%24%7BAVAILABILITY_ZONE%7D%2F%24%7BINSTANCE_ID%7D%22%0AEOF%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/aws-kubelet-providerid
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20First%2C%20we%20need%20to%20wait%20until%20DHCP%20finishes%20and%20the%20node%20has%20a%20non-%60localhost%60%0A%23%20hostname%20before%20%60kubelet.service%60%20starts.%0A%23%20That's%20the%20%60--wait%60%20argument%20as%20used%20by%20%60node-valid-hostname.service%60.%0A%23%0A%23%20Second%2C%20on%20GCP%20specifically%20we%20truncate%20the%20hostname%20if%20it's%20%3E63%20characters.%0A%23%20That's%20%60gcp-hostname.service%60.%0A%0A%23%20Block%20indefinitely%20until%20the%20host%20gets%20a%20non-localhost%20name.%0A%23%20Note%20node-valid-hostname.service%20uses%20systemd%20to%20abort%20if%20this%20takes%20too%20long.%0Await_localhost()%20%7B%0A%20%20%20%20echo%20%22waiting%20for%20non-localhost%20hostname%20to%20be%20assigned%22%0A%20%20%20%20while%20%5B%5B%20%22%24(%3C%20%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%20%3D~%20(localhost%7Clocalhost.localdomain)%20%5D%5D%3B%0A%20%20%20%20do%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20done%0A%20%20%20%20echo%20%22node%20identified%20as%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%0A%20%20%20%20echo%20%22saving%20hostname%20to%20prevent%20NetworkManager%20from%20ever%20unsetting%20it%22%0A%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_gcp_hostname()%20%7B%0A%20%20%20%20%2Fusr%2Fbin%2Fafterburn%20--provider%20gcp%20--hostname%3D%2Frun%2Fafterburn.hostname%0A%0A%20%20%20%20local%20host_name%3D%24(cat%20%2Frun%2Fafterburn.hostname)%0A%20%20%20%20local%20type_arg%3D%22transient%22%0A%0A%20%20%20%20%23%20%2Fetc%2Fhostname%20is%20used%20for%20static%20hostnames%20and%20is%20authoritative.%0A%20%20%20%20%23%20This%20will%20check%20to%20make%20sure%20that%20the%20static%20hostname%20is%20the%0A%20%20%20%20%23%20less%20than%20or%20equal%20to%2063%20characters%20in%20length.%0A%20%20%20%20if%20%5B%20-f%20%2Fetc%2Fhostname%20%5D%20%26%26%20%5B%20%22%24(cat%20%2Fetc%2Fhostname%20%7C%20wc%20-m)%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20etc_name%3D%22%24(%3C%20%2Fetc%2Fhostname)%22%0A%20%20%20%20%20%20%20%20type_arg%3D%22static%22%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24%7Betc_name%7D%22%20!%3D%20%22%24%7Bhost_name%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%2Fetc%2Fhostname%20is%20set%20to%20%24%7Betc_name%7D%20but%20does%20not%20match%20%24%7Bhost_name%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22using%20%2Fetc%2Fhostname%20as%20the%20authoritative%20name%22%0A%20%20%20%20%20%20%20%20%20%20%20%20host_name%3D%22%24%7Betc_name%7D%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Only%20mutate%20the%20hostname%20if%20the%20length%20is%20longer%20than%2063%20characters.%20The%0A%20%20%20%20%23%20hostname%20will%20be%20the%20lesser%20of%2063%20characters%20after%20the%20first%20dot%20in%20the%0A%20%20%20%20%23%20FQDN.%20%20This%20algorithm%20is%20only%20known%20to%20work%20in%20GCP%2C%20and%20hence%20is%20only%0A%20%20%20%20%23%20executed%20in%20GCP.%0A%20%20%20%20if%20%5B%20%22%24%7B%23host_name%7D%22%20-gt%2063%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20alt_name%3D%24(printf%20%22%24%7Bhost_name%7D%22%20%7C%20cut%20-f1%20-d'.'%20%7C%20cut%20-c%20-63)%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Bhost_name%7D%20is%20longer%20than%2063%20characters%2C%20using%20truncated%20hostname%22%0A%20%20%20%20%20%20%20%20host_name%3D%22%24%7Balt_name%7D%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22setting%20%24%7Btype_arg%7D%20hostname%20to%20%24%7Bhost_name%7D%22%0A%20%20%20%20%2Fbin%2Fhostnamectl%20%22--%24%7Btype_arg%7D%22%20set-hostname%20%22%24%7Bhost_name%7D%22%0A%20%20%20%20exit%200%0A%7D%0A%0Aarg%3D%24%7B1%7D%3B%20shift%3B%0Acase%20%22%24%7Barg%7D%22%20in%0A%20%20%20%20--wait)%20wait_localhost%3B%3B%0A%20%20%20%20--gcp)%20set_gcp_hostname%3B%3B%0A%20%20%20%20*)%20echo%20%22Unhandled%20arg%20%24arg%22%3B%20exit%201%0Aesac%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/mco-hostname
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0Aset%20-eou%20pipefail%0A%0A%23%20context%0Aintapi%3D%24(oc%20get%20infrastructures.config.openshift.io%20cluster%20-o%20%22jsonpath%3D%7B.status.apiServerInternalURI%7D%22)%0Acontext%3D%22%24(oc%20config%20current-context)%22%0A%23%20cluster%0Acluster%3D%22%24(oc%20config%20view%20-o%20%22jsonpath%3D%7B.contexts%5B%3F(%40.name%3D%3D%5C%22%24context%5C%22)%5D.context.cluster%7D%22)%22%0Aserver%3D%22%24(oc%20config%20view%20-o%20%22jsonpath%3D%7B.clusters%5B%3F(%40.name%3D%3D%5C%22%24cluster%5C%22)%5D.cluster.server%7D%22)%22%0A%23%20token%0Aca_crt_data%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20-o%20%22jsonpath%3D%7B.data.ca%5C.crt%7D%22%20%7C%20base64%20--decode)%22%0Anamespace%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20%20-o%20%22jsonpath%3D%7B.data.namespace%7D%22%20%7C%20base64%20--decode)%22%0Atoken%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20-o%20%22jsonpath%3D%7B.data.token%7D%22%20%7C%20base64%20--decode)%22%0A%0Aexport%20KUBECONFIG%3D%22%24(mktemp)%22%0Akubectl%20config%20set-credentials%20%22kubelet%22%20--token%3D%22%24token%22%20%3E%2Fdev%2Fnull%0Aca_crt%3D%22%24(mktemp)%22%3B%20echo%20%22%24ca_crt_data%22%20%3E%20%24ca_crt%0Akubectl%20config%20set-cluster%20%24cluster%20--server%3D%22%24intapi%22%20--certificate-authority%3D%22%24ca_crt%22%20--embed-certs%20%3E%2Fdev%2Fnull%0Akubectl%20config%20set-context%20kubelet%20--cluster%3D%22%24cluster%22%20--user%3D%22kubelet%22%20%3E%2Fdev%2Fnull%0Akubectl%20config%20use-context%20kubelet%20%3E%2Fdev%2Fnull%0Acat%20%22%24KUBECONFIG%22%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/recover-kubeconfig.sh
        - contents:
            source: data:,
          mode: 493
          overwrite: true
          path: /etc/kubernetes/kubelet-plugins/volume/exec/.dummy
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1941714%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1935539%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1987108%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22vmxnet3%22%20%5D%5D%3B%20then%0A%20%20logger%20-s%20%2299-vsphere-disable-tx-udp-tnl%20triggered%20by%20%24%7B2%7D%20on%20device%20%24%7BDEVICE_IFACE%7D.%22%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-csum-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksum-ip-generic%20off%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-vsphere-disable-tx-udp-tnl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0Aif%20%5B%20!%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20%23%20No%20need%20to%20do%20this%20if%20no%20NMState%20configuration%20was%20applied%0A%20%20exit%200%0Afi%0A%0A%23%20This%20logic%20is%20borrowed%20from%20configure-ovs.sh%0A%23%20TODO%3A%20Find%20a%20platform-agnostic%20way%20to%20do%20this.%20It%20won't%20work%20on%20platforms%20where%0A%23%20nodeip-configuration%20is%20not%20used.%0Aip%3D%24(cat%20%2Frun%2Fnodeip-configuration%2Fprimary-ip)%0Aif%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20echo%20%22No%20ip%20to%20bind%20was%20found%22%0A%20%20exit%201%0Afi%0Awhile%20%3A%0Ado%0A%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%20%20sleep%2010%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-primary-ip.sh
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Cleans NetworkManager state generated by dracut
            # Removal of this file signals firstboot completion
            ConditionPathExists=!/etc/ignition-machine-config-encapsulated.json
            # This is opt-in for some deployment types, and opt-out for others.
            ConditionPathExists=/var/lib/mco/nm-clean-initrd-state
            Wants=network-pre.target
            Before=network-pre.target

            [Service]
            Type=oneshot
            # Remove any existing state possibly generated NM run by dracut. We want NM to
            # consider all profiles autoconnect priority when it starts instead of
            # remembering which profile was a device activated with when NM is run by
            # dracut.
            ExecStart=/usr/local/bin/nm-clean-initrd-state.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: NetworkManager-clean-initrd-state.service
        - contents: |
            [Unit]
            Description=Fetch kubelet node name from AWS Metadata

            # Run afterburn service for collect info from metadata server
            # see: https://coreos.github.io/afterburn/usage/attributes/
            # Not required due to OCP 4.1 boot image does not contain afterburn service
            # see: https://issues.redhat.com/browse/OCPBUGS-7559
            Wants=afterburn.service
            After=afterburn.service

            # Wait for NetworkManager to report it's online
            After=NetworkManager-wait-online.service
            # Run before kubelet
            Before=kubelet-dependencies.target

            [Service]
            # Mark afterburn environment file optional, due to it is possible that afterburn service was not executed
            EnvironmentFile=-/run/metadata/afterburn
            ExecStart=/usr/local/bin/aws-kubelet-nodename
            Type=oneshot

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: aws-kubelet-nodename.service
        - contents: |
            [Unit]
            Description=Fetch kubelet provider id from AWS Metadata

            # Run afterburn service for collect info from metadata server
            # see: https://coreos.github.io/afterburn/usage/attributes/
            # Not required due to OCP 4.1 boot image does not contain afterburn service
            # see: https://issues.redhat.com/browse/OCPBUGS-7559
            Wants=afterburn.service
            After=afterburn.service

            # Wait for NetworkManager to report it's online
            After=NetworkManager-wait-online.service
            # Run before kubelet
            Before=kubelet-dependencies.target

            [Service]
            # Mark afterburn environment file optional, due to it is possible that afterburn service was not executed
            EnvironmentFile=-/run/metadata/afterburn
            ExecStart=/usr/local/bin/aws-kubelet-providerid
            Type=oneshot

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: aws-kubelet-providerid.service
        - dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="ENABLE_PROFILE_UNIX_SOCKET=true"
            name: 10-mco-profile-unix-socket.conf
          - contents: |
              [Unit]
              After=kubelet-dependencies.target
              Requires=kubelet-dependencies.target
            name: 05-mco-ordering.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: crio.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: docker.socket
        - contents: |
            [Unit]
            Description=The firstboot OS update has completed
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target

            [Install]
            WantedBy=default.target
          enabled: true
          name: firstboot-osupdate.target
        - contents: |
            [Unit]
            Description=Dynamically sets the system reserved for the kubelet
            Wants=network-online.target
            After=network-online.target firstboot-osupdate.target
            Before=kubelet-dependencies.target

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            RemainAfterExit=yes
            EnvironmentFile=/etc/node-sizing-enabled.env
            ExecStart=/bin/bash /usr/local/sbin/dynamic-system-reserved-calc.sh ${NODE_SIZING_ENABLED} ${SYSTEM_RESERVED_MEMORY} ${SYSTEM_RESERVED_CPU} ${SYSTEM_RESERVED_ES}
            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: kubelet-auto-node-size.service
        - contents: |
            [Unit]
            Description=Dependencies necessary to run kubelet
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target network-online.target
            Wants=NetworkManager-wait-online.service crio-wipe.service
            Wants=rpc-statd.service chrony-wait.service
          name: kubelet-dependencies.target
        - dropins:
          - contents: |
              [Service]
              EnvironmentFile=/etc/kubernetes/node.env
            name: 20-node-env.conf
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: kubelet.service
        - contents: |
            [Unit]
            Description=Manages a mount namespace for kubernetes-specific mounts

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            RuntimeDirectory=kubens
            Environment=RUNTIME_DIRECTORY=%t/kubens
            Environment=BIND_POINT=%t/kubens/mnt
            Environment=ENVFILE=%t/kubens/env

            # Set up the runtime directory as an unbindable mountpoint
            ExecStartPre=bash -c "findmnt ${RUNTIME_DIRECTORY} || mount --make-unbindable --bind ${RUNTIME_DIRECTORY} ${RUNTIME_DIRECTORY}"
            # Ensure the bind point exists
            ExecStartPre=touch ${BIND_POINT}
            # Use 'unshare' to create the new mountpoint, then 'mount --make-rshared' so it cascades internally
            ExecStart=unshare --mount=${BIND_POINT} --propagation slave mount --make-rshared /
            # Finally, set an env pointer for ease-of-use
            ExecStartPost=bash -c 'echo "KUBENSMNT=${BIND_POINT}" > "${ENVFILE}"'

            # On stop, a recursive unmount cleans up the namespace and bind-mounted unbindable parent directory
            ExecStop=umount -R ${RUNTIME_DIRECTORY}

            [Install]
            WantedBy=multi-user.target
          enabled: false
          name: kubens.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Firstboot
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # Removal of this file signals firstboot completion
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            After=machine-config-daemon-pull.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            # Disable existing repos (if any) so that OS extensions would use embedded RPMs only
            ExecStartPre=-/usr/bin/sh -c "sed -i 's/enabled=1/enabled=0/' /etc/yum.repos.d/*.repo"
            # Run this via podman because we want to use the nmstatectl binary in our container
            ExecStart=/usr/bin/podman run --rm --privileged --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:787a505ca594b0a727549353c503dec9233a9d3c2dcd6b64e3de5f998892a1d5' firstboot-complete-machineconfig --persist-nics
            ExecStart=/usr/bin/podman run --rm --privileged --pid=host --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:787a505ca594b0a727549353c503dec9233a9d3c2dcd6b64e3de5f998892a1d5' firstboot-complete-machineconfig
            [Install]
            RequiredBy=firstboot-osupdate.target
          enabled: true
          name: machine-config-daemon-firstboot.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Pull
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # This "stamp file" is unlinked when we complete
            # machine-config-daemon-firstboot.service
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            # Run after crio-wipe so the pulled MCD image is protected against a corrupted storage from a forced shutdown
            Wants=crio-wipe.service NetworkManager-wait-online.service
            After=crio-wipe.service NetworkManager-wait-online.service network.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStart=/bin/sh -c "while ! /usr/bin/podman pull --authfile=/var/lib/kubelet/config.json 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:787a505ca594b0a727549353c503dec9233a9d3c2dcd6b64e3de5f998892a1d5'; do sleep 1; done"
            [Install]
            RequiredBy=machine-config-daemon-firstboot.service
          enabled: true
          name: machine-config-daemon-pull.service
        - contents: |
            [Unit]
            Description=Wait for a non-localhost hostname
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            User=root
            ExecStart=/usr/local/bin/mco-hostname --wait

            # Wait up to 5min for the node to get a non-localhost name
            TimeoutSec=300

            [Install]
            # TODO: Change this to RequiredBy after we fix https://github.com/openshift/machine-config-operator/pull/3865#issuecomment-1746963115
            WantedBy=kubelet-dependencies.target
          enabled: true
          name: node-valid-hostname.service
        - contents: |
            [Unit]
            Description=Writes IP address configuration so that kubelet and crio services select a valid node IP
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service firstboot-osupdate.target
            Before=kubelet-dependencies.target ovs-configuration.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/bin/podman run --rm \
              --authfile /var/lib/kubelet/config.json \
              --net=host \
              --security-opt label=disable \
              --volume /etc/systemd/system:/etc/systemd/system \
              --volume /run/nodeip-configuration:/run/nodeip-configuration \
              quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:02a7419d80a103e656c25a8d7573106a62e8e4a41508c758387db7e13801d89c \
              node-ip \
              set \
              --retry-on-failure \
              --network-type OVNKubernetes \
              ${NODEIP_HINT:-${KUBELET_NODEIP_HINT:-}}; \
              do \
              sleep 5; \
              done"
            ExecStart=/bin/systemctl daemon-reload
            ExecStartPre=/bin/mkdir -p /run/nodeip-configuration
            StandardOutput=journal+console
            StandardError=journal+console

            EnvironmentFile=-/etc/default/nodeip-configuration

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: false
          name: nodeip-configuration.service
        - enabled: true
          name: openvswitch.service
        - contents: |
            [Unit]
            # Kdump will generate it's initramfs based on the running state when kdump.service run
            # If OVS has already run, the kdump fails to gather a working network config,
            # which prevent network log exports, sush as SSH.
            # See https://issues.redhat.com/browse/OCPBUGS-28239
            After=kdump.service
            Description=Configures OVS with proper host networking configuration
            # This service is used to move a physical NIC into OVS and reconfigure OVS to use the host IP
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=firstboot-osupdate.target
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service nmstate.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            ExecStart=/usr/local/bin/configure-ovs.sh OVNKubernetes
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: ovs-configuration.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /var/lib/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /etc/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /run/openvswitch'
              ExecStartPost=-/usr/bin/ovs-appctl vlog/set syslog:info
              ExecReload=-/usr/bin/ovs-appctl vlog/set syslog:info
            name: 10-ovs-vswitchd-restart.conf
          name: ovs-vswitchd.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
            name: 10-ovsdb-restart.conf
          enabled: true
          name: ovsdb-server.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          name: pivot.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              # See https://github.com/openshift/machine-config-operator/issues/1897
              [Service]
              Nice=10
              IOSchedulingClass=best-effort
              IOSchedulingPriority=6
            name: mco-controlplane-nice.conf
          name: rpm-ostreed.service
        - contents: |
            [Unit]
            Description=Ensure primary IP is assigned and usable
            Requires=nmstate.service
            After=nmstate.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/wait-for-primary-ip.sh; \
              do \
              sleep 10; \
              done"
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: wait-for-primary-ip.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: zincati.service
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:ad394c1a0b0cc7d37e2bc632f795f9140ca3f68bc0f2ca2895b83125c61a7d2e
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: d656f31b697c2671aac38bbe46d9e5b22d27ae90
    creationTimestamp: "2024-11-20T22:36:29Z"
    generation: 2
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 00-worker
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: ControllerConfig
      name: machine-config-controller
      uid: b0288238-f89e-41ca-ad96-dc8692409c40
    resourceVersion: "46503"
    uid: 9884dad6-f287-440f-8894-853fdee752da
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0ANM_DEVICES_DIR%3D%2Frun%2FNetworkManager%2Fdevices%0ANM_RUN_CONN_DIR%3D%2Frun%2FNetworkManager%2Fsystem-connections%0ANM_ETC_CONN_DIR%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A%0Alogger%20-t%20nm-clean-initrd-state%20%22Cleaning%20network%20activation%20state%20generated%20by%20dracut...%22%0Alogger%20-t%20nm-clean-initrd-state%20%22To%20disable%2C%20remove%20%2Fvar%2Flib%2Fmco%2Fnm-clean-initrd-state%22%0A%0Aif%20%5B%20!%20-e%20%22%24NM_DEVICES_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_RUN_CONN_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_ETC_CONN_DIR%22%20%5D%3B%20then%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22There%20is%20no%20network%20activation%20state%20to%20clean%22%0A%20%20exit%0Afi%0A%0A%23%20Some%20deployments%20require%20an%20active%20network%20early%20in%20the%20boot%20process.%20To%0A%23%20achieve%20this%2C%20dracut%20runs%20specific%20NetworkManager%20modules.%20This%20results%20in%0A%23%20NetworkManager%20keyfiles%20being%20generated%20(either%20default%20or%20from%20ip%20kernel%0A%23%20arguments)%20and%20activated.%20This%20activation%20generates%20state%20that%20makes%20those%0A%23%20profiles%20to%20be%20re-activated%20by%20the%20NetworkManager%20service%20later%20in%20the%0A%23%20boot%20process.%20And%20this%20has%20the%20effect%20that%20other%20profiles%20deployed%20by%20the%0A%23%20user%20for%20the%20same%20set%20of%20devices%20are%20ignored.%0A%0A%23%20Most%20of%20the%20time%20this%20is%20the%20desired%20behavior.%20The%20exception%20to%20this%20rule%0A%23%20is%20when%20the%20user%20wants%20to%20run%20the%20boot%20process%20with%20a%20different%20network%0A%23%20setup%20than%20the%20real%20root%20which%20is%20usually%20related%20to%20the%20fact%20that%0A%23%20generating%20images%20with%20customized%20kernel%20arguments%20is%20a%20complication%20in%0A%23%20the%20deployment%20pipeline.%0A%0A%23%20This%20need%20has%20been%20exacerbated%20by%20past%20NetworkManager%20bugs%20that%20activated%0A%23%20the%20network%20on%20boot%20when%20it%20was%20not%20really%20needed.%20Most%20notably%20when%20ip%0A%23%20kernel%20argument%20is%20present%2C%20something%20that%20the%20baremetal%20installer%20adds%20by%0A%23%20default.%0A%0A%23%20The%20intention%20here%20is%20to%20remove%20the%20state%20that%20was%20generated%20with%20the%0A%23%20activation%20of%20those%20profiles%20during%20dracut%20execution.%20Then%20when%0A%23%20NetworkManager%20service%20runs%2C%20the%20profiles%20generated%20by%20dracut%2C%20along%20with%0A%23%20other%20profiles%20configured%20by%20the%20user%2C%20are%20evaluated%20towards%20finding%20the%0A%23%20most%20appropriate%20profile%20to%20connect%20a%20device%20with.%20As%20a%20precaution%2C%20clean%0A%23%20state%20only%20for%20devices%20that%3A%0A%23%20-%20have%20been%20activated%20with%20a%20default%20profile%20(assume%20that%20a%20non-default%0A%23%20%20%20configuration%20expresses%20intention%20by%20user%20to%20run%20with%20it%20permanently)%0A%23%20-%20have%20a%20specific%20configured%20profile%20set%20to%20auto-connect%20(if%20there%20is%20no%0A%23%20%20%20alternate%20configured%20profile%20for%20a%20device%20it%20makes%20no%20sense%20to%0A%23%20%20%20de-activate%20anything)%0A%23%0A%23%20Although%20this%20can%20theoretically%20happen%20on%20any%20deployment%20type%2C%20need%20has%0A%23%20mostly%20come%20from%20IPI%20bare%20metal%20deployments.%20For%20the%20time%20being%2C%20this%0A%23%20should%20be%20opt-in%20in%20any%20other%20deploment%20type.%0A%23%0A%23%20There%20is%20an%20RFE%20filed%20against%20NM%20that%20once%20implemented%20would%20make%20this%0A%23%20script%20unnecessary%3A%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D2089707%0A%0Afor%20device%20in%20%22%24%7BNM_DEVICES_DIR%7D%22%2F*%3B%20do%0A%20%20if%20%5B%20!%20-e%20%22%24device%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20the%20device%20file%20name%20is%20the%20ifindex%0A%20%20ifindex%3D%24(basename%20%22%24device%22)%0A%20%20%0A%20%20%23%20get%20the%20interface%20name%20by%20ifindex%0A%20%20ifname%3D%24(ip%20-j%20link%20show%20%7C%20jq%20-r%20%22.%5B%5D%20%7C%20select(.ifindex%20%3D%3D%20%24%7Bifindex%7D)%20%7C%20.ifname%20%2F%2F%20empty%22)%0A%0A%20%20%23%20no%20interface%20name%20found%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20get%20the%20uuid%20of%20the%20profile%20the%20device%20has%20been%20activated%20with%0A%20%20active_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bdevice%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Econnection-uuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24device%22)%0A%0A%20%20%23%20the%20device%20was%20not%20activated%20with%20any%20profile%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24active_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20generated%20profile%20by%20uuid%0A%20%20for%20profile%20in%20%22%24%7BNM_RUN_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20generated_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24active_profile_uuid%22%20%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20generated%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24active_profile_uuid%22%20!%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20check%20that%20it%20is%20not%20specific%20for%20the%20device%2C%20otherwise%20ignore%0A%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24profile_ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20profile%20not%20generated%20by%20nm-initrd-generator%2C%20ignore%0A%20%20%23%20only%20check%20it%20if%20the%20key%20is%20set%20(from%20NM%201.32.4)%0A%20%20origin%3D%24(sed%20-nr%20'%2F%5E%5C%5Buser%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eorg.freedesktop.NetworkManager.origin%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24origin%22%20%5D%20%26%26%20%5B%20%22%24origin%22%20!%3D%20%22nm-initrd-generator%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20configured%20profile%20by%20name%20with%20auto-connect%20set%0A%20%20for%20profile%20in%20%22%24%7BNM_ETC_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20autoconnect%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eautoconnect%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24profile_ifname%22%20%3D%20%22%24ifname%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20configured%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24profile_ifname%22%20!%3D%20%22%24ifname%22%20%5D%20%7C%7C%20%5B%20%22%24autoconnect%22%20%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20configured_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20activated%20with%20default%20generated%20profile%20%24generated_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20has%20different%20configured%20specific%20profile%20%24configured_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%3A%20removing%20state...%22%0A%20%20%0A%20%20%23%20NM%20can%20still%20generate%20internal%20profiles%20from%20the%20IP%20address%0A%20%20%23%20configuration%20of%20devices%2C%20so%20flush%20addresses%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Flushing%20IP%20addresses%20from%20%24ifname%22%0A%20%20ip%20addr%20flush%20%22%24ifname%22%0A%20%20ip%20-6%20addr%20flush%20%22%24ifname%22%0A%0A%20%20%23%20remove%20device%20state%20file%20to%20prevent%20NM%20to%20unilaterally%20connect%20with%20the%0A%20%20%23%20latest%20activated%20profile%20without%20evaluating%20other%20profiles%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Removing%20%24device%22%0A%20%20rm%20-f%20--%20%22%24device%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nm-clean-initrd-state.sh
        - contents:
            source: data:,%5Bconnection%5D%0Aipv6.dhcp-duid%3Dll%0Aipv6.dhcp-iaid%3Dmac%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/01-ipv6.conf
        - contents:
            source: data:,%5Bmain%5D%0Aplugins%3Dkeyfile%2Cifcfg-rh%0A%5Bkeyfile%5D%0Apath%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/20-keyfiles.conf
        - contents:
            source: data:,
          mode: 384
          overwrite: true
          path: /etc/pki/ca-trust/source/anchors/openshift-config-user-ca-bundle.crt
        - contents:
            source: data:,KUBERNETES_SERVICE_HOST%3D'api-int.ci-ln-hz4dqct-76ef8.aws-2.ci.openshift.org'%0AKUBERNETES_SERVICE_PORT%3D'6443'%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/apiserver-url.env
        - contents:
            source: data:,%23%20This%20file%20is%20managed%20by%20machine-config-operator.%0A%23%20Suppress%20audit%20rules%20which%20always%20trigger%20for%20container%0A%23%20workloads%2C%20as%20they%20spam%20the%20audit%20log.%20%20Workloads%20are%20expected%0A%23%20to%20be%20dynamic%2C%20and%20the%20networking%20stack%20uses%20iptables.%0A-a%20exclude%2Calways%20-F%20msgtype%3DNETFILTER_CFG%0A%23%20The%20default%20bridged%20networking%20enables%20promiscuous%20on%20the%20veth%0A%23%20device.%20%20Ideally%2C%20we'd%20teach%20audit%20to%20ignore%20only%20veth%20devices%2C%0A%23%20since%20one%20might%20legitimately%20care%20about%20promiscuous%20on%20real%20physical%0A%23%20devices.%20%20But%20we%20can't%20currently%20differentiate.%0A-a%20exclude%2Calways%20-F%20msgtype%3DANOM_PROMISCUOUS%0A
          mode: 420
          overwrite: true
          path: /etc/audit/rules.d/mco-audit-quiet-containers.rules
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20It%20has%20been%20observed%20that%20the%20kernel%20enables%20ESP%20offloads%20of%20bond%0A%23%20devices%20in%20active%2Fbackup%20mode%20even%20if%20slaves%20apparently%20don't%20support%0A%23%20it.%20It's%20unclear%20if%20this%20is%20expected%20behavior%20but%20we%20have%20had%20problems%0A%23%20with%20the%20resulting%20configuration%20in%20vsphere.%20So%20set%20ESP%20offload%20features%0A%23%20off%20in%20bond%20devices%20if%20they%20are%20off%20in%20slave%20devices%20for%20the%20time%20being.%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FRHEL-58811%0A%0Aif%20%5B%5B%20%22%242%22%20!%3D%20%22up%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24DEVICE_IFACE%22)%0A%0Aif%20%5B%5B%20%22%24driver%22%20!%3D%20%22bond%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Abond%3D%22%24DEVICE_IFACE%22%0Afor%20feature%20in%20tx-esp-segmentation%20esp-hw-offload%20esp-tx-csum-hw-offload%3B%20do%0A%0A%20%20if%20ethtool%20-k%20%22%24bond%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%23%20already%20disabled%2C%20nothing%20to%20do%0A%20%20%20%20continue%0A%20%20fi%0A%20%20%0A%20%20for%20slave%20in%20%24(nmcli%20-g%20BOND.SLAVES%20dev%20show%20%22%24DEVICE_IFACE%22)%3B%20do%0A%0A%20%20%20%20if%20!%20ethtool%20-k%20%22%24slave%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%20%20%23%20enabled%20in%20slave%2C%20nothing%20to%20do%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20logger%20-t%20bond-esp-offload%20-s%20%22Bond%20link%20%24slave%20has%20%24feature%20off%2C%20setting%20master%20%24DEVICE_IFACE%20%24feature%20off%22%0A%20%20%20%20ethtool%20-K%20%22%24bond%22%20%22%24feature%22%20off%0A%0A%20%20%20%20break%0A%20%20done%0Adone%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-bond-esp-offload
        - contents:
            source: data:,r%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F80-openshift-network.conf%0Ar%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F10-ovn-kubernetes.conf%0Ad%20%2Frun%2Fmultus%2Fcni%2Fnet.d%2F%200755%20root%20root%20-%20-%0AD%20%2Fvar%2Flib%2Fcni%2Fnetworks%2Fopenshift-sdn%2F%200755%20root%20root%20-%20-%0A
          mode: 420
          overwrite: true
          path: /etc/tmpfiles.d/cleanup-cni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Skipping%20configure-ovs%20due%20to%20manual%20network%20configuration%22%0A%20%20exit%200%0Afi%0A%0A%23%20This%20file%20is%20not%20needed%20anymore%20in%204.7%2B%2C%20but%20when%20rolling%20back%20to%204.6%0A%23%20the%20ovs%20pod%20needs%20it%20to%20know%20ovs%20is%20running%20on%20the%20host.%0Atouch%20%2Fvar%2Frun%2Fovs-config-executed%0A%0A%23%20These%20are%20well%20knwon%20NM%20default%20paths%0ANM_CONN_ETC_PATH%3D%22%2Fetc%2FNetworkManager%2Fsystem-connections%22%0ANM_CONN_RUN_PATH%3D%22%2Frun%2FNetworkManager%2Fsystem-connections%22%0A%0A%23%20This%20is%20the%20path%20where%20NM%20is%20known%20to%20be%20configured%20to%20store%20user%20keyfiles%20%0ANM_CONN_CONF_PATH%3D%22%24NM_CONN_ETC_PATH%22%0A%0A%23%20This%20is%20where%20we%20want%20our%20keyfiles%20to%20finally%20reside.%20configure-ovs%0A%23%20operates%20with%20temporary%20keyfiles%20in%20NM_CONN_RUN_PATH%20and%20then%20as%20a%20last%0A%23%20step%20moves%20those%20keyfiles%20to%20NM_CONN_SET_PATH%20if%20it%20is%20a%20different%20path%0A%23%20(not%20by%20default).%20This%20mitigates%20hard%20interruptions%20(SIGKILL%2C%20hard%20reboot)%0A%23%20of%20configure-ovs%20leaving%20the%20machine%20with%20a%20half-baked%20set%20of%20keyfiles%0A%23%20that%20might%20prevent%20machine%20networking%20from%20working%20correctly.%0ANM_CONN_SET_PATH%3D%22%24%7BNM_CONN_SET_PATH%3A-%24NM_CONN_RUN_PATH%7D%22%0A%0AMANAGED_NM_CONN_SUFFIX%3D%22-slave-ovs-clone%22%0A%23%20Workaround%20to%20ensure%20OVS%20is%20installed%20due%20to%20bug%20in%20systemd%20Requires%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1888017%0Acopy_nm_conn_files()%20%7B%0A%20%20local%20dst_path%3D%22%241%22%0A%20%20for%20src%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20src_path%3D%24(dirname%20%22%24src%22)%0A%20%20%20%20file%3D%24(basename%20%22%24src%22)%0A%20%20%20%20if%20%5B%20-f%20%22%24src_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%24dst_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20elif%20!%20cmp%20--silent%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20updated%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20-f%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it's%20equal%20at%20destination%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it%20does%20not%20exist%20at%20source%22%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0Aupdate_nm_conn_files_base()%20%7B%0A%20%20base_path%3D%24%7B1%7D%0A%20%20bridge_name%3D%24%7B2%7D%0A%20%20port_name%3D%24%7B3%7D%0A%20%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%20%20%23%20In%20RHEL7%20files%20in%20%2F%7Betc%2Crun%7D%2FNetworkManager%2Fsystem-connections%20end%20without%20the%20suffix%20'.nmconnection'%2C%20whereas%20in%20RHCOS%20they%20end%20with%20the%20suffix.%0A%20%20MANAGED_NM_CONN_FILES%3D(%24(echo%20%22%24%7Bbase_path%7D%22%2F%7B%22%24bridge_name%22%2C%22%24ovs_interface%22%2C%22%24ovs_port%22%2C%22%24bridge_interface_name%22%2C%22%24default_port_name%22%7D%7B%2C.nmconnection%7D))%0A%20%20shopt%20-s%20nullglob%0A%20%20MANAGED_NM_CONN_FILES%2B%3D(%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D.nmconnection%20%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D)%0A%20%20shopt%20-u%20nullglob%0A%7D%0A%0Aupdate_nm_conn_run_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_RUN_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_set_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_SET_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0A%23%20Move%20and%20reload%20keyfiles%20at%20their%20final%20destination%0Aset_nm_conn_files()%20%7B%0A%20%20if%20%5B%20%22%24NM_CONN_RUN_PATH%22%20!%3D%20%22%24NM_CONN_SET_PATH%22%20%5D%3B%20then%0A%20%20%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%20%20%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%0A%20%20%20%20%23%20reload%20keyfiles%0A%20%20%20%20nmcli%20connection%20reload%0A%20%20fi%0A%7D%0A%0A%23%20Used%20to%20remove%20files%20managed%20by%20configure-ovs%20and%20temporary%20leftover%20files%20from%20network%20manager%0Arm_nm_conn_files()%20%7B%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20rm%20-f%20%22%24file%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20file%20%24file%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20fi%0A%20%20done%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20for%20temp%20in%20%24(compgen%20-G%20%22%24%7Bfile%7D.*%22)%3B%20do%0A%20%20%20%20%20%20rm%20-f%20%22%24temp%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20temporary%20file%20%24temp%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20done%0A%20%20done%0A%7D%0A%0A%23%20Used%20to%20clone%20a%20slave%20connection%20by%20uuid%2C%20returns%20new%20name%0Aclone_slave_connection()%20%7B%0A%20%20local%20uuid%3D%22%241%22%0A%20%20local%20old_name%0A%20%20old_name%3D%22%24(nmcli%20-g%20connection.id%20connection%20show%20uuid%20%22%24uuid%22)%22%0A%20%20local%20new_name%3D%22%24%7Bold_name%7D%24%7BMANAGED_NM_CONN_SUFFIX%7D%22%0A%20%20if%20nmcli%20connection%20show%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20existing%20ovs%20slave%20%24%7Bnew_name%7D%20connection%20profile%20file%20found%2C%20overwriting...%22%20%3E%262%0A%20%20%20%20nmcli%20connection%20delete%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%0A%20%20fi%0A%20%20clone_nm_conn%20%24uuid%20%22%24%7Bnew_name%7D%22%0A%20%20echo%20%22%24%7Bnew_name%7D%22%0A%7D%0A%0A%23%20Used%20to%20replace%20an%20old%20master%20connection%20uuid%20with%20a%20new%20one%20on%20all%20connections%0Areplace_connection_master()%20%7B%0A%20%20local%20old%3D%22%241%22%0A%20%20local%20new%3D%22%242%22%0A%20%20for%20conn_uuid%20in%20%24(nmcli%20-g%20UUID%20connection%20show)%20%3B%20do%0A%20%20%20%20if%20%5B%20%22%24(nmcli%20-g%20connection.master%20connection%20show%20uuid%20%22%24conn_uuid%22)%22%20!%3D%20%22%24old%22%20%5D%3B%20then%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20local%20autoconnect%3D%24(nmcli%20-g%20connection.autoconnect%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20!%3D%20%22activated%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Assume%20that%20slave%20profiles%20intended%20to%20be%20used%20are%20those%20that%20are%3A%0A%20%20%20%20%20%20%23%20-%20active%0A%20%20%20%20%20%20%23%20-%20or%20inactive%20(which%20might%20be%20due%20to%20link%20being%20down)%20but%20to%20be%20autoconnected.%0A%20%20%20%20%20%20%23%20Otherwise%2C%20ignore%20them.%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20make%20changes%20for%20slave%20profiles%20in%20a%20new%20clone%0A%20%20%20%20local%20new_name%0A%20%20%20%20new_name%3D%24(clone_slave_connection%20%24conn_uuid)%0A%0A%20%20%20%20mod_nm_conn%20%22%24new_name%22%20connection.master%20%22%24new%22%20connection.autoconnect-priority%20100%20connection.autoconnect%20no%20%0A%20%20%20%20echo%20%22Replaced%20master%20%24old%20with%20%24new%20for%20slave%20profile%20%24new_name%22%0A%20%20done%0A%7D%0A%0A%23%20when%20creating%20the%20bridge%2C%20we%20use%20a%20value%20lower%20than%20NM's%20ethernet%20device%20default%20route%20metric%0A%23%20(we%20pick%2048%20and%2049%20to%20be%20lower%20than%20anything%20that%20NM%20chooses%20by%20default)%0ABRIDGE_METRIC%3D%2248%22%0ABRIDGE1_METRIC%3D%2249%22%0A%23%20Given%20an%20interface%2C%20generates%20NM%20configuration%20to%20add%20to%20an%20OVS%20bridge%0Aconvert_to_bridge()%20%7B%0A%20%20local%20iface%3D%24%7B1%7D%0A%20%20local%20bridge_name%3D%24%7B2%7D%0A%20%20local%20port_name%3D%24%7B3%7D%0A%20%20local%20bridge_metric%3D%24%7B4%7D%0A%20%20local%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20local%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20local%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20local%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%0A%20%20if%20%5B%20%22%24iface%22%20%3D%20%22%24bridge_name%22%20%5D%3B%20then%0A%20%20%20%20%23%20handle%20vlans%20and%20bonds%20etc%20if%20they%20have%20already%20been%0A%20%20%20%20%23%20configured%20via%20nm%20key%20files%20and%20br-ex%20is%20already%20up%0A%20%20%20%20ifaces%3D%24(ovs-vsctl%20list-ifaces%20%24%7Biface%7D)%0A%20%20%20%20for%20intf%20in%20%24ifaces%3B%20do%20configure_driver_options%20%24intf%3B%20done%0A%20%20%20%20echo%20%22Networking%20already%20configured%20and%20up%20for%20%24%7Bbridge-name%7D!%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20flag%20to%20reload%20NM%20to%20account%20for%20all%20the%20configuration%20changes%0A%20%20%23%20going%20forward%0A%20%20nm_config_changed%3D1%0A%0A%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20Unable%20to%20find%20default%20gateway%20interface%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20%23%20find%20the%20MAC%20from%20OVS%20config%20or%20the%20default%20interface%20to%20use%20for%20OVS%20internal%20port%0A%20%20%23%20this%20prevents%20us%20from%20getting%20a%20different%20DHCP%20lease%20and%20dropping%20connection%0A%20%20if%20!%20iface_mac%3D%24(%3C%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface%7D%2Faddress%22)%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MAC%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20echo%20%22MAC%20address%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mac%7D%22%0A%0A%20%20%23%20find%20MTU%20from%20original%20iface%0A%20%20iface_mtu%3D%24(ip%20link%20show%20%22%24iface%22%20%7C%20awk%20'%7Bprint%20%245%3B%20exit%7D')%0A%20%20if%20%5B%5B%20-z%20%22%24iface_mtu%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MTU%2C%20defaulting%20to%201500%22%0A%20%20%20%20iface_mtu%3D1500%0A%20%20else%0A%20%20%20%20echo%20%22MTU%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mtu%7D%22%0A%20%20fi%0A%0A%20%20%23%20store%20old%20conn%20for%20later%0A%20%20old_conn%3D%24(nmcli%20--fields%20UUID%2CDEVICE%20conn%20show%20--active%20%7C%20awk%20%22%2F%5Cs%24%7Biface%7D%5Cs*%5C%24%2F%20%7Bprint%20%5C%241%7D%22)%0A%0A%20%20if%20%5B%5B%20-z%20%22%24old_conn%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20cannot%20find%20connection%20for%20interface%3A%20%24%7Biface%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20create%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24bridge_name%22%20type%20ovs-bridge%20conn.interface%20%22%24bridge_name%22%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20%23%20find%20default%20port%20to%20add%20to%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24default_port_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%24%7Biface%7D%0A%20%20%20%20add_nm_conn%20%22%24default_port_name%22%20type%20ovs-port%20conn.interface%20%24%7Biface%7D%20master%20%22%24bridge_name%22%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_port%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24ovs_port%22%20type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24bridge_name%22%0A%20%20fi%0A%0A%20%20extra_phys_args%3D()%0A%20%20%23%20check%20if%20this%20interface%20is%20a%20vlan%2C%20bond%2C%20team%2C%20or%20ethernet%20type%0A%20%20if%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22vlan%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dvlan%0A%20%20%20%20vlan_id%3D%24(nmcli%20--get-values%20vlan.id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_id%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20vlan.parent%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_parent%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_parent%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20nmcli%20connection%20show%20uuid%20%22%24vlan_parent%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20%20%20%23%20if%20the%20VLAN%20connection%20is%20configured%20with%20a%20connection%20UUID%20as%20parent%2C%20we%20need%20to%20find%20the%20underlying%20device%0A%20%20%20%20%20%20%23%20and%20create%20the%20bridge%20against%20it%2C%20as%20the%20parent%20connection%20can%20be%20replaced%20by%20another%20bridge.%0A%20%20%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20GENERAL.DEVICES%20conn%20show%20uuid%20%24%7Bvlan_parent%7D)%0A%20%20%20%20fi%0A%0A%20%20%20%20extra_phys_args%3D(%20dev%20%22%24%7Bvlan_parent%7D%22%20id%20%22%24%7Bvlan_id%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbond%0A%20%20%20%20%23%20check%20bond%20options%0A%20%20%20%20bond_opts%3D%24(nmcli%20--get-values%20bond.options%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24bond_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20bond.options%20%22%24%7Bbond_opts%7D%22%20)%0A%20%20%20%20%20%20MODE_REGEX%3D%22(%5E%7C%2C)mode%3Dactive-backup(%2C%7C%24)%22%0A%20%20%20%20%20%20MAC_REGEX%3D%22(%5E%7C%2C)fail_over_mac%3D(1%7Cactive%7C2%7Cfollow)(%2C%7C%24)%22%0A%20%20%20%20%20%20if%20%5B%5B%20%24bond_opts%20%3D~%20%24MODE_REGEX%20%5D%5D%20%26%26%20%5B%5B%20%24bond_opts%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22team%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dteam%0A%20%20%20%20%23%20check%20team%20config%20options%0A%20%20%20%20team_config_opts%3D%24(nmcli%20--get-values%20team.config%20-e%20no%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24team_config_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20team.config%20is%20json%2C%20remove%20spaces%20to%20avoid%20problems%20later%20on%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20team.config%20%22%24%7Bteam_config_opts%2F%2F%5B%5B%3Aspace%3A%5D%5D%2F%7D%22%20)%0A%20%20%20%20%20%20team_mode%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.name%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20team_mac_policy%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.hwaddr_policy%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20MAC_REGEX%3D%22(by_active%7Conly_active)%22%0A%20%20%20%20%20%20if%20%5B%20%22%24team_mode%22%20%3D%20%22activebackup%22%20%5D%20%26%26%20%5B%5B%20%22%24team_mac_policy%22%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22tun%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dtun%0A%20%20%20%20tun_mode%3D%24(nmcli%20--get-values%20tun.mode%20-e%20no%20connection%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20extra_phys_args%2B%3D(%20tun.mode%20%22%24%7Btun_mode%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bridge%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbridge%0A%20%20else%0A%20%20%20%20iface_type%3D802-3-ethernet%0A%20%20fi%0A%0A%20%20if%20%5B%20!%20%22%24%7Bclone_mac%3A-%7D%22%20%3D%20%220%22%20%5D%3B%20then%0A%20%20%20%20%23%20In%20active-backup%20link%20aggregation%2C%20with%20fail_over_mac%20mode%20enabled%2C%0A%20%20%20%20%23%20cloning%20the%20mac%20address%20is%20not%20supported.%20It%20is%20possible%20then%20that%0A%20%20%20%20%23%20br-ex%20has%20a%20different%20mac%20address%20than%20the%20bond%20which%20might%20be%0A%20%20%20%20%23%20troublesome%20on%20some%20platforms%20where%20the%20nic%20won't%20accept%20packets%20with%0A%20%20%20%20%23%20a%20different%20destination%20mac.%20But%20nobody%20has%20complained%20so%20far%20so%20go%20on%0A%20%20%20%20%23%20with%20what%20we%20got.%20%0A%20%20%20%20%0A%20%20%20%20%23%20Do%20set%20it%20though%20for%20other%20link%20aggregation%20configurations%20where%20the%0A%20%20%20%20%23%20mac%20address%20would%20otherwise%20depend%20on%20enslave%20order%20for%20which%20we%20have%0A%20%20%20%20%23%20no%20control%20going%20forward.%0A%20%20%20%20extra_phys_args%2B%3D(%20802-3-ethernet.cloned-mac-address%20%22%24%7Biface_mac%7D%22%20)%0A%20%20fi%0A%0A%20%20%23%20use%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%20instead%20of%20%24%7Bextra_phys_args%5B%40%5D%7D%20to%20be%20compatible%20with%20bash%204.2%20in%20RHEL7.9%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_interface_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%24%7Biface%7D%0A%20%20%20%20ovs_default_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24default_port_name%22)%0A%20%20%20%20add_nm_conn%20%22%24bridge_interface_name%22%20type%20%24%7Biface_type%7D%20conn.interface%20%24%7Biface%7D%20master%20%22%24ovs_default_port_conn%22%20%5C%0A%20%20%20%20%20%20slave-type%20ovs-port%20connection.autoconnect-priority%20100%20connection.autoconnect-slaves%201%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20%20%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%0A%20%20fi%0A%0A%20%20%23%20Get%20the%20new%20connection%20uuids%0A%20%20new_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24bridge_interface_name%22)%0A%20%20ovs_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24ovs_port%22)%0A%0A%20%20%23%20Update%20connections%20with%20master%20property%20set%20to%20use%20the%20new%20connection%0A%20%20replace_connection_master%20%24old_conn%20%24new_conn%0A%20%20replace_connection_master%20%24iface%20%24new_conn%0A%0A%20%20ipv4_method%3D%24(nmcli%20-g%20ipv4.method%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_method%3D%24(nmcli%20-g%20ipv6.method%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20ipv4_addresses%3D%24(nmcli%20-g%20ipv4.addresses%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_addresses%3D%24(nmcli%20-g%20ipv6.addresses%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20%23%20Warn%20about%20an%20invalid%20MTU%20that%20will%20most%20likely%20fail%20in%20one%20way%20or%0A%20%20%23%20another%0A%20%20if%20%5B%20%24%7Biface_mtu%7D%20-lt%201280%20%5D%20%26%26%20%5B%20%22%24%7Bipv6_method%7D%22%20!%3D%20%22disabled%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20MTU%20%24%7Biface_mtu%7D%20is%20lower%20than%20the%20minimum%20required%20of%201280%20for%20IPv6%22%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_interface%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%22%24bridge_name%22%0A%20%20%20%20%23%20Clone%20the%20connection%20in%20case%20the%20method%20is%20manual%20or%20in%20case%20the%20an%20address%20is%20set%20(DHCP%20%2B%20static%20IP)%0A%20%20%20%20if%20%5B%20%22%24%7Bipv4_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv4_addresses%7D%22%20!%3D%20%22%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_addresses%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Static%20IP%20addressing%20detected%20on%20default%20gateway%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%23%20clone%20the%20old%20connection%20to%20get%20the%20address%20settings%0A%20%20%20%20%20%20%23%20prefer%20cloning%20vs%20copying%20the%20connection%20file%20to%20avoid%20problems%20with%20selinux%0A%20%20%20%20%20%20clone_nm_conn%20%22%24%7Bold_conn%7D%22%20%22%24%7Bovs_interface%7D%22%0A%20%20%20%20%20%20shopt%20-s%20nullglob%0A%20%20%20%20%20%20new_conn_files%3D(%24%7BNM_CONN_RUN_PATH%7D%2F%22%24%7Bovs_interface%7D%22*)%0A%20%20%20%20%20%20shopt%20-u%20nullglob%0A%20%20%20%20%20%20if%20%5B%20%24%7B%23new_conn_files%5B%40%5D%7D%20-ne%201%20%5D%20%7C%7C%20%5B%20!%20-f%20%22%24%7Bnew_conn_files%5B0%5D%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20could%20not%20find%20%24%7Bovs_interface%7D%20conn%20file%20after%20cloning%20from%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20new_conn_file%3D%22%24%7Bnew_conn_files%5B0%5D%7D%22%0A%0A%20%20%20%20%20%20%23%20modify%20the%20connection%20type%20directly%20because%20it%20can't%20be%20modified%0A%20%20%20%20%20%20%23%20through%20nmcli%0A%20%20%20%20%20%20sed%20-i%20'%2F%5E%5C%5Bconnection%5C%5D%24%2F%2C%2F%5E%5C%5B%2F%20s%2F%5Etype%3D.*%24%2Ftype%3Dovs-interface%2F'%20%24%7Bnew_conn_file%7D%0A%0A%20%20%20%20%20%20%23%20modify%20some%20more%20settings%20through%20nmcli%0A%20%20%20%20%20%20mod_nm_conn%20%22%24%7Bovs_interface%7D%22%20conn.interface%20%22%24bridge_name%22%20%5C%0A%20%20%20%20%20%20%20%20connection.multi-connect%20%22%22%20connection.autoconnect%20no%20%5C%0A%20%20%20%20%20%20%20%20connection.master%20%22%24ovs_port_conn%22%20connection.slave-type%20ovs-port%20%5C%0A%20%20%20%20%20%20%20%20ovs-interface.type%20internal%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%0A%0A%20%20%20%20%20%20echo%20%22Loaded%20new%20%24ovs_interface%20connection%20file%3A%20%24%7Bnew_conn_file%7D%22%0A%20%20%20%20else%0A%20%20%20%20%20%20extra_if_brex_args%3D%22%22%0A%20%20%20%20%20%20%23%20check%20if%20interface%20had%20ipv4%2Fipv6%20addresses%20assigned%0A%20%20%20%20%20%20num_ipv4_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ipv4_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20IPV6%20should%20have%20at%20least%20a%20link%20local%20address.%20Check%20for%20more%20than%201%20to%20see%20if%20there%20is%20an%0A%20%20%20%20%20%20%23%20assigned%20address.%0A%20%20%20%20%20%20num_ip6_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet6%5C%22%20and%20.scope%20!%3D%20%5C%22link%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ip6_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20check%20for%20dhcp%20client%20ids%0A%20%20%20%20%20%20dhcp_client_id%3D%24(nmcli%20--get-values%20ipv4.dhcp-client-id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.dhcp-client-id%20%24%7Bdhcp_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20dhcp6_client_id%3D%24(nmcli%20--get-values%20ipv6.dhcp-duid%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp6_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.dhcp-duid%20%24%7Bdhcp6_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20ipv6_addr_gen_mode%3D%24(nmcli%20--get-values%20ipv6.addr-gen-mode%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24ipv6_addr_gen_mode%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.addr-gen-mode%20%24%7Bipv6_addr_gen_mode%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20add_nm_conn%20%22%24ovs_interface%22%20type%20ovs-interface%20slave-type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24ovs_port_conn%22%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.method%20%22%24%7Bipv4_method%7D%22%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20ipv6.method%20%22%24%7Bipv6_method%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20%24%7Bextra_if_brex_args%7D%0A%20%20%20%20fi%0A%20%20fi%0A%0A%20%20configure_driver_options%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20remove%20a%20bridge%0Aremove_ovn_bridges()%20%7B%0A%20%20bridge_name%3D%24%7B1%7D%0A%20%20port_name%3D%24%7B2%7D%0A%0A%20%20%23%20Remove%20the%20keyfiles%20from%20known%20configuration%20paths%0A%20%20update_nm_conn_run_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20update_nm_conn_set_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%0A%20%20%23%20NetworkManager%20will%20not%20remove%20%24%7Bbridge_name%7D%20if%20it%20has%20the%20patch%20port%20created%20by%20ovn-kubernetes%0A%20%20%23%20so%20remove%20explicitly%0A%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%24%7Bbridge_name%7D%0A%7D%0A%0A%23%20Removes%20any%20previous%20ovs%20configuration%0Aremove_all_ovn_bridges()%20%7B%0A%20%20echo%20%22Reverting%20any%20previous%20OVS%20configuration%22%0A%20%20%0A%20%20remove_ovn_bridges%20br-ex%20phys0%0A%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%0A%20%20echo%20%22OVS%20configuration%20successfully%20reverted%22%0A%7D%0A%0A%23%20Reloads%20NM%20NetworkManager%20profiles%20if%20any%20configuration%20change%20was%20done.%0A%23%20Accepts%20a%20list%20of%20devices%20that%20should%20be%20re-connect%20after%20reload.%0Areload_profiles_nm()%20%7B%0A%20%20if%20%5B%20%24%7Bnm_config_changed%3A-0%7D%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%23%20no%20config%20was%20changed%2C%20no%20need%20to%20reload%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20reload%20profiles%0A%20%20nmcli%20connection%20reload%0A%0A%20%20%23%20precautionary%20sleep%20of%2010s%20(default%20timeout%20of%20NM%20to%20bring%20down%20devices)%0A%20%20sleep%2010%0A%0A%20%20%23%20After%20reload%2C%20devices%20that%20were%20already%20connected%20should%20connect%20again%0A%20%20%23%20if%20any%20profile%20is%20available.%20If%20no%20profile%20is%20available%2C%20a%20device%20can%0A%20%20%23%20remain%20disconnected%20and%20we%20have%20to%20explicitly%20connect%20it%20so%20that%20a%0A%20%20%23%20profile%20is%20generated.%20This%20can%20happen%20for%20physical%20devices%20but%20should%0A%20%20%23%20not%20happen%20for%20software%20devices%20as%20those%20always%20require%20a%20profile.%0A%20%20for%20dev%20in%20%24%40%3B%20do%0A%20%20%20%20%23%20Only%20attempt%20to%20connect%20a%20disconnected%20device%0A%20%20%20%20local%20connected_state%3D%24(nmcli%20-g%20GENERAL.STATE%20device%20show%20%22%24dev%22%20%7C%7C%20echo%20%22%22)%0A%20%20%20%20if%20%5B%5B%20%22%24connected_state%22%20%3D~%20%22disconnected%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%23%20keep%20track%20if%20a%20profile%20by%20the%20same%20name%20as%20the%20device%20existed%20%0A%20%20%20%20%20%20%23%20before%20we%20attempt%20activation%0A%20%20%20%20%20%20local%20named_profile_existed%3D%24(%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%5D%20%7C%7C%20%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22%20%5D%20%26%26%20echo%20%22yes%22)%0A%20%20%20%20%20%20%0A%20%20%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20connect%20device%20%24dev%22%0A%20%20%20%20%20%20%20%20%20%20nmcli%20device%20connect%20%22%24dev%22%20%26%26%20break%0A%20%20%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%23%20if%20a%20profile%20did%20not%20exist%20before%20but%20does%20now%2C%20it%20was%20generated%0A%20%20%20%20%20%20%23%20but%20we%20want%20it%20to%20be%20ephemeral%2C%20so%20move%20it%20back%20to%20%2Frun%0A%20%20%20%20%20%20if%20%5B%20!%20%22%24named_profile_existed%22%20%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20MANAGED_NM_CONN_FILES%3D(%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22)%0A%20%20%20%20%20%20%20%20copy_nm_conn_files%20%22%24%7BNM_CONN_RUN_PATH%7D%22%0A%20%20%20%20%20%20%20%20rm_nm_conn_files%0A%20%20%20%20%20%20%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20might%20have%20been%20moved%0A%20%20%20%20%20%20%20%20nmcli%20connection%20reload%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20echo%20%22Waiting%20for%20interface%20%24dev%20to%20activate...%22%0A%20%20%20%20if%20!%20timeout%2060%20bash%20-c%20%22while%20!%20nmcli%20-g%20DEVICE%2CSTATE%20c%20%7C%20grep%20%22'%22'%22%24dev%22%3Aactivated'%22'%22%3B%20do%20sleep%205%3B%20done%22%3B%20then%0A%20%20%20%20%20%20echo%20%22WARNING%3A%20%24dev%20did%20not%20activate%22%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20nm_config_changed%3D0%0A%7D%0A%0A%23%20Removes%20all%20configuration%20and%20reloads%20NM%20if%20necessary%0Arollback_nm()%20%7B%0A%20%20phys0%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20phys1%3D%24(get_bridge_physical_interface%20ovs-if-phys1)%0A%20%20%0A%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20remove_all_ovn_bridges%0A%20%20%0A%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20were%20removed%0A%20%20reload_profiles_nm%20%22%24phys0%22%20%22%24phys1%22%0A%7D%0A%0A%23%20Add%20a%20temporary%20deactivated%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20folowed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20add%60%0Aadd_nm_conn()%20%7B%0A%20%20%23%20Use%20%60save%20no%60%20to%20add%20a%20temporary%20profile%0A%20%20nmcli%20c%20add%20save%20no%20con-name%20%22%24%40%22%20connection.autoconnect%20no%0A%7D%0A%0A%23%20Modify%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20followed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20modify%60%0Amod_nm_conn()%20%7B%0A%20%20%23%20the%20easiest%20thing%20to%20do%20here%20would%20be%20to%20use%20%60nmcli%20c%20mod%20--temporary%60%0A%20%20%23%20but%20there%20is%20a%20bug%20in%20selinux%20profiles%20that%20denies%20NM%20from%20performing%0A%20%20%23%20the%20operation%0A%20%20local%20dst_path%3D%24%7BNM_CONN_RUN_PATH%7D%2F%241.nmconnection%0A%20%20local%20src_path%0A%20%20src_path%3D%24(mktemp)%0A%20%20shift%0A%20%20cat%20%22%24dst_path%22%20%3E%20%22%24src_path%22%0A%20%20rm%20-f%20%22%24dst_path%22%0A%20%20nmcli%20--offline%20c%20mod%20%22%24%40%22%20%3C%20%22%24src_path%22%20%3E%20%22%24dst_path%22%0A%20%20rm%20-f%20%22%24src_path%22%0A%20%20chmod%20600%20%22%24dst_path%22%0A%20%20nmcli%20c%20load%20%22%24dst_path%22%0A%7D%0A%0A%23%20Clone%20to%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20to%20clone%2C%20second%20argument%20is%20the%20clone%20name%0Aclone_nm_conn()%20%7B%0A%20%20%23%20clone%20as%20temporary%20so%20that%20it%20is%20generated%20in%20NM_CONN_RUN_PATH%0A%20%20nmcli%20connection%20clone%20--temporary%20%22%241%22%20%22%242%22%20%26%3E%20%2Fdev%2Fnull%0A%7D%0A%0A%23%20Activates%20an%20ordered%20set%20of%20NM%20connection%20profiles%0Aactivate_nm_connections()%20%7B%0A%20%20local%20connections%3D(%22%24%40%22)%0A%0A%20%20%23%20We%20want%20autoconnect%20set%20for%20our%20cloned%20slave%20profiles%20so%20that%20they%20are%0A%20%20%23%20used%20over%20the%20original%20profiles%20if%20implicitly%20re-activated%20with%20other%0A%20%20%23%20dependant%20profiles.%20Otherwise%20if%20a%20slave%20activates%20with%20an%20old%20profile%2C%0A%20%20%23%20the%20old%20master%20profile%20might%20activate%20as%20well%2C%20interfering%20and%20causing%0A%20%20%23%20further%20activations%20to%20fail.%0A%20%20%23%20Slave%20interfaces%20should%20already%20be%20active%20so%20setting%20autoconnect%20here%0A%20%20%23%20won't%20implicitly%20activate%20them%20but%20there%20is%20an%20edge%20case%20where%20a%20slave%0A%20%20%23%20might%20be%20inactive%20(link%20down%20for%20example)%20and%20in%20that%20case%20setting%0A%20%20%23%20autoconnect%20will%20cause%20an%20implicit%20activation.%20This%20is%20not%20necessarily%20a%0A%20%20%23%20problem%20and%20hopefully%20we%20can%20make%20sure%20everything%20is%20activated%20as%20we%0A%20%20%23%20want%20next.%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20Activate%20all%20connections%20and%20fail%20if%20activation%20fails%0A%20%20%23%20For%20slave%20connections%20-%20for%20as%20long%20as%20at%20least%20one%20slave%20that%20belongs%20to%20a%20bond%2Fteam%0A%20%20%23%20comes%20up%2C%20we%20should%20not%20fail%0A%20%20declare%20-A%20master_interfaces%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%23%20Get%20the%20slave%20type%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20local%20is_slave%3Dfalse%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20is_slave%3Dtrue%0A%20%20%20%20fi%20%0A%0A%20%20%20%20%23%20For%20slave%20interfaces%2C%20initialize%20the%20master%20interface%20to%20false%20if%20the%20key%20is%20not%20yet%20in%20the%20array%0A%20%20%20%20local%20master_interface%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20master_interface%3D%24(nmcli%20-g%20connection.master%20connection%20show%20%22%24conn%22)%0A%20%20%20%20%20%20if%20!%20%5B%5B%20-v%20%22master_interfaces%5B%24master_interface%5D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dfalse%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Do%20not%20activate%20interfaces%20that%20are%20already%20active%0A%20%20%20%20%23%20But%20set%20the%20entry%20in%20master_interfaces%20to%20true%20if%20this%20is%20a%20slave%0A%20%20%20%20%23%20Also%20set%20autoconnect%20to%20yes%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20%3D%3D%20%22activated%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Connection%20%24conn%20already%20activated%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%24master_interface%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Activate%20all%20interfaces%20that%20are%20not%20yet%20active%0A%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20bring%20up%20connection%20%24conn%22%0A%20%20%20%20%20%20nmcli%20conn%20up%20%22%24conn%22%20%26%26%20s%3D0%20%26%26%20break%20%7C%7C%20s%3D%24%3F%0A%20%20%20%20%20%20sleep%205%0A%20%20%20%20done%0A%20%20%20%20if%20%5B%20%24s%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Brought%20up%20connection%20%24conn%20successfully%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20elif%20!%20%24is_slave%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20connection%20%24conn%20after%20%24i%20attempts%22%0A%20%20%20%20%20%20return%20%24s%0A%20%20%20%20fi%0A%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20done%0A%20%20%23%20Check%20that%20all%20master%20interfaces%20report%20at%20least%20a%20single%20active%20slave%0A%20%20%23%20Note%3A%20associative%20arrays%20require%20an%20exclamation%20mark%20when%20looping%0A%20%20for%20i%20in%20%22%24%7B!master_interfaces%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20!%20%24%7Bmaster_interfaces%5B%22%24i%22%5D%7D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20any%20slave%20interface%20for%20master%20interface%3A%20%24i%22%0A%20%20%20%20%20%20%20%20return%201%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24iface%0A%23%20Writes%20content%20of%20%24iface%20into%20%24iface_default_hint_file%0Awrite_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%242%22%0A%0A%20%20echo%20%22%24%7Biface%7D%22%20%3E%7C%20%22%24%7Biface_default_hint_file%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%0A%23%20Returns%20the%20stored%20interface%20default%20hint%20if%20the%20hint%20is%20non-empty%2C%0A%23%20not%20br-ex%2C%20not%20br-ex1%20and%20if%20the%20interface%20can%20be%20found%20in%20%2Fsys%2Fclass%2Fnet%0Aget_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%241%0A%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%3B%20then%0A%20%20%20%20local%20iface_default_hint%3D%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex1%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20-d%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface_default_hint%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%22%0A%7D%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0A%23%20This%20function%20waits%20for%20ip%20address%20of%20br-ex%20to%20be%20bindable%20only%20in%20case%20of%20ipv6%0A%23%20This%20is%20workaround%20for%20OCPBUGS-673%20as%20it%20will%20not%20allow%20starting%20crio%0A%23%20before%20address%20is%20bindable%0Atry_to_bind_ipv6_address()%20%7B%0A%20%20%23%20Retry%20for%201%20minute%0A%20%20retries%3D60%0A%20%20until%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20do%0A%20%20%20%20ip%3D%24(ip%20-6%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(.ifname%3D%3D%5C%22br-ex%5C%22)%20%7C%20.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20.local)%22)%0A%20%20%20%20if%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22No%20ipv6%20ip%20to%20bind%20was%20found%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20sleep%201%0A%20%20%20%20((%20retries--%20))%0A%20%20done%0A%20%20if%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Failed%20to%20bind%20ip%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%7D%0A%0A%23%20Get%20interface%20that%20matches%20ip%20from%20node%20ip%20hint%20file%0A%23%20in%20case%20file%20not%20exists%20return%20nothing%20and%0A%23%20fallback%20to%20default%20interface%20search%20flow%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge%3D%22%242%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)%20and%20.ifname!%3D%5C%22br-ex1%5C%22%20and%20.ifname!%3D%5C%22%24%7Bextra_bridge%7D%5C%22))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20fi%0A%7D%0A%0A%23%20Accepts%20parameters%20%24bridge_interface%20(e.g.%20ovs-port-phys0)%0A%23%20Returns%20the%20physical%20interface%20name%20if%20%24bridge_interface%20exists%2C%20%22%22%20otherwise%0Aget_bridge_physical_interface()%20%7B%0A%20%20local%20bridge_interface%3D%22%241%22%0A%20%20local%20physical_interface%3D%22%22%0A%20%20physical_interface%3D%24(nmcli%20-g%20connection.interface-name%20conn%20show%20%22%24%7Bbridge_interface%7D%22%202%3E%2Fdev%2Fnull%20%7C%7C%20echo%20%22%22)%0A%20%20echo%20%22%24%7Bphysical_interface%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24extra_bridge_file%2C%20%24ip_hint_file%2C%20%24default_bridge_file%0A%23%20Determines%20the%20interface%20to%20be%20used%20for%20br-ex.%20Order%20of%20priority%20is%3A%0A%23%201.%20Use%20the%20user%20specified%20interface%20if%20provided%20in%20the%20default%20bridge%20file%0A%23%202.%20Use%20the%20node%20IP%20hint%20interface%0A%23%203.%20Use%20the%20previously%20selected%20interface%0A%23%204.%20Use%20the%20interface%20detected%20as%20default%20gateway%0A%23%0A%23%20Read%20%24default_bridge_file%20and%20return%20the%20contained%20interface.%20Otherwise%2C%0A%23%20read%20%24ip_hint_file%20and%20return%20the%20interface%20that%20matches%20this%20ip.%20Otherwise%2C%0A%23%20if%20the%20default%20interface%20is%20br-ex%2C%20use%20that%20and%20return.%0A%23%20If%20the%20default%20interface%20is%20not%20br-ex%3A%0A%23%20Check%20if%20there%20is%20a%20valid%20hint%20inside%20%24iface_default_hint_file.%20If%20so%2C%20use%20that%20hint.%0A%23%20If%20there%20is%20no%20valid%20hint%2C%20use%20the%20default%20interface%20that%20we%20found%20during%20the%20step%0A%23%20earlier.%0A%23%20Never%20use%20the%20interface%20that%20is%20provided%20inside%20%24extra_bridge_file%20for%20br-ex1.%0A%23%20Never%20use%20br-ex1.%0A%23%20Write%20the%20default%20interface%20to%20%24iface_default_hint_file%0Aget_default_bridge_interface()%20%7B%0A%20%20local%20iface%3D%22%22%0A%20%20local%20counter%3D0%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge_file%3D%22%242%22%0A%20%20local%20ip_hint_file%3D%22%243%22%0A%20%20local%20default_bridge_file%3D%22%244%22%0A%20%20local%20extra_bridge%3D%22%22%0A%0A%20%20if%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%3B%20then%0A%20%20%20%20extra_bridge%3D%24(cat%20%24%7Bextra_bridge_file%7D)%0A%20%20fi%0A%0A%20%20%23%20try%20to%20use%20user%20specified%20file%20first%0A%20%20if%20%5B%20-f%20%22%24default_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20iface%3D%24(cat%20%22%24%7Bdefault_bridge_file%7D%22)%0A%20%20%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20User%20specified%20bridge%20file%20detected%20without%20any%20data%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20if%20node%20ip%20was%20set%2C%20we%20should%20search%20for%20interface%20that%20matches%20it%0A%20%20iface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bextra_bridge%7D%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20find%20default%20interface%0A%20%20%23%20the%20default%20interface%20might%20be%20br-ex%2C%20so%20check%20this%20before%20looking%20at%20the%20hint%0A%20%20while%20%5B%20%24%7Bcounter%7D%20-lt%2012%20%5D%3B%20do%0A%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20sleep%205%0A%20%20done%0A%0A%20%20%23%20if%20the%20default%20interface%20does%20not%20point%20out%20of%20br-ex%20or%20br-ex1%0A%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20%23%20determine%20if%20an%20interface%20default%20hint%20exists%20from%20a%20previous%20run%0A%20%20%20%20%23%20and%20if%20the%20interface%20has%20a%20valid%20default%20route%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%24%7Biface%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20start%20wherever%20count%20left%20off%20in%20the%20previous%20loop%0A%20%20%20%20%20%20%23%20allow%20this%20for%20one%20more%20iteration%20than%20the%20previous%20loop%0A%20%20%20%20%20%20while%20%5B%20%24%7Bcounter%7D%20-le%2012%20%5D%3B%20do%0A%20%20%20%20%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20-6%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%20%20%20%20fi%0A%20%20%20%20%23%20store%20what%20was%20determined%20was%20the%20(new)%20default%20interface%20inside%0A%20%20%20%20%23%20the%20default%20hint%20file%20for%20future%20reference%0A%20%20%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Biface%7D%22%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20print%20network%20state%0Aprint_state()%20%7B%0A%20%20echo%20%22Current%20device%2C%20connection%2C%20interface%20and%20routing%20state%3A%22%0A%20%20nmcli%20-g%20all%20device%20%7C%20grep%20-v%20unmanaged%0A%20%20nmcli%20-g%20all%20connection%0A%20%20ip%20-d%20address%20show%0A%20%20ip%20route%20show%0A%20%20ip%20-6%20route%20show%0A%7D%0A%0A%23%20Setup%20an%20exit%20trap%20to%20rollback%20on%20error%0Ahandle_exit()%20%7B%0A%20%20e%3D%24%3F%0A%20%20tdir%3D%24(mktemp%20-u%20-d%20-t%20%22configure-ovs-%24(date%20%2B%25Y-%25m-%25d-%25H-%25M-%25S)-XXXXXXXXXX%22)%0A%20%20%0A%20%20if%20%5B%20%24e%20-eq%200%20%5D%3B%20then%0A%20%20%20%20print_state%0A%20%20%20%20%23%20remove%20previous%20troubleshooting%20information%0A%20%20%20%20rm%20-rf%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%0A%20%20echo%20%22ERROR%3A%20configure-ovs%20exited%20with%20error%3A%20%24e%22%0A%20%20print_state%0A%0A%20%20%23%20remove%20previous%20troubleshooting%20information%20except%20the%20oldest%20one%0A%20%20mapfile%20-t%20tdirs%20%3C%20%3C(compgen%20-G%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22)%0A%20%20unset%20-v%20%22tdirs%5B0%5D%22%0A%20%20for%20dir%20in%20%22%24%7Btdirs%5B%40%5D%7D%22%3B%20do%20rm%20-rf%20%22%24dir%22%3B%20done%0A%0A%20%20%23%20copy%20configuration%20to%20tmp%20for%20troubleshooting%0A%20%20mkdir%20-p%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20echo%20%22Copied%20OVS%20configuration%20to%20%24tdir%20for%20troubleshooting%22%0A%0A%20%20%23%20attempt%20to%20restore%20the%20previous%20network%20state%0A%20%20echo%20%22Attempting%20to%20restore%20previous%20configuration...%22%0A%20%20rollback_nm%0A%20%20print_state%0A%0A%20%20exit%20%24e%0A%7D%0A%0A%23%20Setup%20a%20signal%20trap%20to%20rollback%0Ahandle_termination()%20%7B%0A%20%20echo%20%22WARNING%3A%20configure-ovs%20has%20been%20requested%20to%20terminate%2C%20quitting...%22%0A%20%20%0A%20%20%23%20by%20exiting%20with%20an%20error%20we%20will%20cleanup%20after%20ourselves%20in%20a%0A%20%20%23%20subsequent%20call%20to%20handle_exit%0A%20%20exit%201%0A%7D%0A%0A%23%20main%20function%0Aconfigure_ovs()%20%7B%0A%20%20set%20-eu%0A%0A%20%20%23%20setup%20traps%20to%20handle%20signals%20and%20other%20abnormal%20exits%0A%20%20trap%20'handle_termination'%20TERM%20INT%0A%20%20trap%20'handle_exit'%20EXIT%0A%0A%20%20%23%20this%20flag%20tracks%20if%20any%20config%20change%20was%20made%0A%20%20nm_config_changed%3D0%0A%0A%20%20%23%20Check%20that%20we%20are%20provided%20a%20valid%20NM%20connection%20path%0A%20%20if%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_CONF_PATH%22%20%5D%20%26%26%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_RUN_PATH%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Error%3A%20Incorrect%20NM%20connection%20path%3A%20%24NM_CONN_SET_PATH%20is%20not%20%24NM_CONN_CONF_PATH%20nor%20%24NM_CONN_RUN_PATH%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0A%20%20if%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0A%20%20fi%0A%0A%20%20if%20!%20rpm%20-qa%20%7C%20grep%20-q%20openvswitch%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20Openvswitch%20package%20is%20not%20installed!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20print%20initial%20state%0A%20%20print_state%0A%0A%20%20if%20%5B%20%22%241%22%20%3D%3D%20%22OVNKubernetes%22%20%5D%3B%20then%0A%20%20%20%20%23%20Configures%20NICs%20onto%20OVS%20bridge%20%22br-ex%22%0A%20%20%20%20%23%20Configuration%20is%20either%20auto-detected%20or%20provided%20through%20a%20config%20file%20written%20already%20in%20Network%20Manager%0A%20%20%20%20%23%20key%20files%20under%20%2Fetc%2FNetworkManager%2Fsystem-connections%2F%0A%20%20%20%20%23%20Managing%20key%20files%20is%20outside%20of%20the%20scope%20of%20this%20script%0A%0A%20%20%20%20%23%20if%20the%20interface%20is%20of%20type%20vmxnet3%20add%20multicast%20capability%20for%20that%20driver%0A%20%20%20%20%23%20History%3A%20BZ%3A1854355%0A%20%20%20%20function%20configure_driver_options%20%7B%0A%20%20%20%20%20%20intf%3D%241%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Device%20file%20doesn't%20exist%2C%20skipping%20setting%20multicast%20mode%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20driver%3D%24(cat%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%7C%20grep%20DRIVER%20%7C%20awk%20-F%20%22%3D%22%20'%7Bprint%20%242%7D')%0A%20%20%20%20%20%20%20%20echo%20%22Driver%20name%20is%22%20%24driver%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24driver%22%20%3D%20%22vmxnet3%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20ip%20link%20set%20dev%20%22%24%7Bintf%7D%22%20allmulticast%20on%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20fi%0A%20%20%20%20%7D%0A%0A%20%20%20%20ovnk_config_dir%3D'%2Fetc%2Fovnk'%0A%20%20%20%20ovnk_var_dir%3D'%2Fvar%2Flib%2Fovnk'%0A%20%20%20%20extra_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fextra_bridge%22%0A%20%20%20%20iface_default_hint_file%3D%22%24%7Bovnk_var_dir%7D%2Fiface_default_hint%22%0A%20%20%20%20ip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%20%20%20%20%23%20explicitly%20specify%20which%20interface%20should%20be%20used%20with%20the%20default%20bridge%0A%20%20%20%20default_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fdefault_bridge%22%0A%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_config_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_config_dir%7D%22%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_var_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_var_dir%7D%22%0A%0A%20%20%20%20%23%20For%20upgrade%20scenarios%2C%20make%20sure%20that%20we%20stabilize%20what%20we%20already%20configured%0A%20%20%20%20%23%20before.%20If%20we%20do%20not%20have%20a%20valid%20interface%20hint%2C%20find%20the%20physical%20interface%0A%20%20%20%20%23%20that's%20attached%20to%20ovs-if-phys0.%0A%20%20%20%20%23%20If%20we%20find%20such%20an%20interface%2C%20write%20it%20to%20the%20hint%20file.%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20current_interface%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20%20%20%20%20if%20%5B%20%22%24%7Bcurrent_interface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bcurrent_interface%7D%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20delete%20iface_default_hint_file%20if%20it%20has%20the%20same%20content%20as%20extra_bridge_file%0A%20%20%20%20%23%20in%20that%20case%2C%20we%20must%20also%20force%20a%20reconfiguration%20of%20our%20network%20interfaces%0A%20%20%20%20%23%20to%20make%20sure%20that%20we%20reconcile%20this%20conflict%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20%22%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%22%20%3D%3D%20%22%24(cat%20%22%24%7Bextra_bridge_file%7D%22)%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint_file%7D%20and%20%24%7Bextra_bridge_file%7D%20share%20the%20same%20content%22%0A%20%20%20%20%20%20echo%20%22Deleting%20file%20%24%7Biface_default_hint_file%7D%20to%20choose%20a%20different%20interface%22%0A%20%20%20%20%20%20rm%20-f%20%22%24%7Biface_default_hint_file%7D%22%0A%20%20%20%20%20%20rm%20-f%20%2Frun%2Fconfigure-ovs-boot-done%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20on%20every%20boot%20we%20rollback%20and%20generate%20the%20configuration%20again%2C%20to%20take%0A%20%20%20%20%23%20in%20any%20changes%20that%20have%20possibly%20been%20applied%20in%20the%20standard%0A%20%20%20%20%23%20configuration%20sources%0A%20%20%20%20if%20%5B%20!%20-f%20%2Frun%2Fconfigure-ovs-boot-done%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Running%20on%20boot%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20print_state%0A%20%20%20%20fi%0A%20%20%20%20touch%20%2Frun%2Fconfigure-ovs-boot-done%0A%0A%20%20%20%20iface%3D%24(get_default_bridge_interface%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bextra_bridge_file%7D%22%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bdefault_bridge_file%7D%22)%0A%0A%20%20%20%20if%20%5B%20%22%24iface%22%20!%3D%20%22br-ex%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Specified%20interface%20is%20not%20br-ex.%0A%20%20%20%20%20%20%23%20Some%20deployments%20use%20a%20temporary%20solution%20where%20br-ex%20is%20moved%20out%20from%20the%20default%20gateway%20interface%0A%20%20%20%20%20%20%23%20and%20bound%20to%20a%20different%20nic%20(https%3A%2F%2Fgithub.com%2Ftrozet%2Fopenshift-ovn-migration).%0A%20%20%20%20%20%20%23%20This%20is%20now%20supported%20through%20an%20extra%20bridge%20if%20requested.%20If%20that%20is%20the%20case%2C%20we%20rollback.%0A%20%20%20%20%20%20%23%20We%20also%20rollback%20if%20it%20looks%20like%20we%20need%20to%20configure%20things%2C%20just%20in%20case%20there%20are%20any%20leftovers%0A%20%20%20%20%20%20%23%20from%20previous%20attempts.%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%7C%7C%20%5B%20-z%20%22%24(nmcli%20connection%20show%20--active%20br-ex%202%3E%20%2Fdev%2Fnull)%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Bridge%20br-ex%20is%20not%20active%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20%20%20print_state%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20convert_to_bridge%20%22%24iface%22%20%22br-ex%22%20%22phys0%22%20%22%24%7BBRIDGE_METRIC%7D%22%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20configure%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(!%20nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20!%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20interface%3D%24(head%20-n%201%20%24extra_bridge_file)%0A%20%20%20%20%20%20convert_to_bridge%20%22%24interface%22%20%22br-ex1%22%20%22phys1%22%20%22%24%7BBRIDGE1_METRIC%7D%22%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20remove%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20!%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20openshift-sdn%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0A%20%20%20%20%23%20Make%20sure%20everything%20is%20activated.%20Do%20it%20in%20a%20specific%20order%3A%0A%20%20%20%20%23%20-%20activate%20br-ex%20first%2C%20due%20to%20autoconnect-slaves%20this%20will%20also%0A%20%20%20%20%23%20%20%20activate%20ovs-port-br-ex%2C%20ovs-port-phys0%20and%20ovs-if-phys0.%20It%20is%0A%20%20%20%20%23%20%20%20important%20that%20ovs-if-phys0%20activates%20with%20br-ex%20to%20avoid%20the%0A%20%20%20%20%23%20%20%20ovs-if-phys0%20profile%20being%20overridden%20with%20a%20profile%20generated%20from%0A%20%20%20%20%23%20%20%20kargs.%20The%20activation%20of%20ovs-if-phys0%2C%20if%20a%20bond%2C%20might%20cause%20the%0A%20%20%20%20%23%20%20%20slaves%20to%20re-activate%2C%20but%20it%20should%20be%20with%20our%20profiles%20since%20they%0A%20%20%20%20%23%20%20%20have%20higher%20priority%0A%20%20%20%20%23%20-%20make%20sure%20that%20ovs-if-phys0%20and%20its%20slaves%2C%20if%20any%2C%20are%20activated.%0A%20%20%20%20%23%20-%20finally%20activate%20ovs-if-br-ex%20which%20holds%20the%20IP%20configuration.%0A%20%20%20%20connections%3D(br-ex%20ovs-if-phys0)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(br-ex1%20ovs-if-phys1)%0A%20%20%20%20fi%0A%20%20%20%20while%20IFS%3D%20read%20-r%20connection%3B%20do%0A%20%20%20%20%20%20if%20%5B%5B%20%24connection%20%3D%3D%20*%22%24MANAGED_NM_CONN_SUFFIX%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20connections%2B%3D(%22%24connection%22)%0A%20%20%20%20%20%20fi%0A%20%20%20%20done%20%3C%20%3C(nmcli%20-g%20NAME%20c)%0A%20%20%20%20connections%2B%3D(ovs-if-br-ex)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(ovs-if-br-ex1)%0A%20%20%20%20fi%0A%20%20%20%20activate_nm_connections%20%22%24%7Bconnections%5B%40%5D%7D%22%0A%20%20%20%20try_to_bind_ipv6_address%0A%20%20%20%20set_nm_conn_files%0A%20%20elif%20%5B%20%22%241%22%20%3D%3D%20%22OpenShiftSDN%22%20%5D%3B%20then%0A%20%20%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20%20%20rollback_nm%0A%20%20%20%20%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20ovn-kubernetes%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-int%20--%20--if-exists%20del-br%20br-local%0A%20%20fi%0A%7D%0A%0A%23%20Retry%20configure_ovs%20until%20it%20succeeds.%0A%23%20By%20default%2C%20retry%20every%2015%20minutes%20to%20give%20enough%20time%20to%20gather%0A%23%20troubleshooting%20information%20in%20between.%20Note%20that%20configure_ovs%20has%20other%0A%23%20internal%20retry%20mechanisms.%20This%20retry%20is%20intended%20to%20give%20some%0A%23%20self-healing%20capabilities%20to%20temporary%20but%20not%20necessarily%20short-lived%0A%23%20infrastructure%20problems.%0ARETRY%3D%22%24%7BRETRY-15m%7D%22%0Awhile%20true%3B%20do%0A%0A%20%20%23%20Disable%20retries%20if%20termination%20signal%20is%20received.%20Note%20that%20systemd%0A%20%20%23%20sends%20the%20signals%20to%20all%20processes%20in%20the%20group%20by%20default%20so%20we%20expect%0A%20%20%23%20configure_ovs%20to%20get%20its%20own%20signals.%0A%20%20trap%20'echo%20%22WARNING%3A%20termination%20requested%2C%20disabling%20retries%22%3B%20RETRY%3D%22%22'%20INT%20TERM%0A%20%20%0A%20%20%23%20Run%20configure_ovs%20in%20a%20sub-shell.%20%0A%20%20(%20configure_ovs%20%22%24%40%22%20)%0A%20%20e%3D%24%3F%0A%0A%20%20%23%20Handle%20signals%20while%20we%20sleep%0A%20%20trap%20'handle_termination'%20INT%20TERM%0A%20%20%0A%20%20%23%20Exit%20if%20succesful%20and%20not%20configured%20to%20retry%0A%20%20%5B%20%22%24e%22%20-eq%200%20%5D%20%7C%7C%20%5B%20-z%20%22%24RETRY%22%20%5D%20%26%26%20exit%20%22%24e%22%0A%20%20%0A%20%20echo%20%22configure-ovs%20failed%2C%20will%20retry%20after%20%24RETRY%22%0A%20%20%23%20flag%20that%20a%20retry%20has%20happened%0A%20%20touch%20%2Ftmp%2Fconfigure-ovs-retry%0A%20%20sleep%20%22%24RETRY%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ovs.sh
        - contents:
            source: data:,%23%20This%20file%20is%20generated%20by%20the%20Machine%20Config%20Operator's%20containerruntimeconfig%20controller.%0A%23%0A%23%20storage.conf%20is%20the%20configuration%20file%20for%20all%20tools%0A%23%20that%20share%20the%20containers%2Fstorage%20libraries%0A%23%20See%20man%205%20containers-storage.conf%20for%20more%20information%0A%23%20The%20%22container%20storage%22%20table%20contains%20all%20of%20the%20server%20options.%0A%5Bstorage%5D%0A%0A%23%20Default%20Storage%20Driver%0Adriver%20%3D%20%22overlay%22%0A%0A%23%20Temporary%20storage%20location%0Arunroot%20%3D%20%22%2Fvar%2Frun%2Fcontainers%2Fstorage%22%0A%0A%23%20Primary%20Read%2FWrite%20location%20of%20container%20storage%0Agraphroot%20%3D%20%22%2Fvar%2Flib%2Fcontainers%2Fstorage%22%0A%0A%5Bstorage.options%5D%0A%23%20Storage%20options%20to%20be%20passed%20to%20underlying%20storage%20drivers%0A%0A%23%20AdditionalImageStores%20is%20used%20to%20pass%20paths%20to%20additional%20Read%2FOnly%20image%20stores%0A%23%20Must%20be%20comma%20separated%20list.%0Aadditionalimagestores%20%3D%20%5B%0A%5D%0A%0A%23%20Size%20is%20used%20to%20set%20a%20maximum%20size%20of%20the%20container%20image.%20%20Only%20supported%20by%0A%23%20certain%20container%20storage%20drivers.%0Asize%20%3D%20%22%22%0A%0A%23%20Remap-UIDs%2FGIDs%20is%20the%20mapping%20from%20UIDs%2FGIDs%20as%20they%20should%20appear%20inside%20of%0A%23%20a%20container%2C%20to%20UIDs%2FGIDs%20as%20they%20should%20appear%20outside%20of%20the%20container%2C%20and%0A%23%20the%20length%20of%20the%20range%20of%20UIDs%2FGIDs.%20%20Additional%20mapped%20sets%20can%20be%20listed%0A%23%20and%20will%20be%20heeded%20by%20libraries%2C%20but%20there%20are%20limits%20to%20the%20number%20of%0A%23%20mappings%20which%20the%20kernel%20will%20allow%20when%20you%20later%20attempt%20to%20run%20a%0A%23%20container.%0A%23%0A%23%20remap-uids%20%3D%200%3A1668442479%3A65536%0A%23%20remap-gids%20%3D%200%3A1668442479%3A65536%0A%0A%23%20Remap-User%2FGroup%20is%20a%20name%20which%20can%20be%20used%20to%20look%20up%20one%20or%20more%20UID%2FGID%0A%23%20ranges%20in%20the%20%2Fetc%2Fsubuid%20or%20%2Fetc%2Fsubgid%20file.%20%20Mappings%20are%20set%20up%20starting%0A%23%20with%20an%20in-container%20ID%20of%200%20and%20the%20a%20host-level%20ID%20taken%20from%20the%20lowest%0A%23%20range%20that%20matches%20the%20specified%20name%2C%20and%20using%20the%20length%20of%20that%20range.%0A%23%20Additional%20ranges%20are%20then%20assigned%2C%20using%20the%20ranges%20which%20specify%20the%0A%23%20lowest%20host-level%20IDs%20first%2C%20to%20the%20lowest%20not-yet-mapped%20container-level%20ID%2C%0A%23%20until%20all%20of%20the%20entries%20have%20been%20used%20for%20maps.%0A%23%0A%23%20remap-user%20%3D%20%22storage%22%0A%23%20remap-group%20%3D%20%22storage%22%0A%0A%5Bstorage.options.overlay%5D%0A%23%20Storage%20Options%20for%20overlay%0A%0A%23%20Do%20not%20create%20a%20PRIVATE%20bind%20mount%20on%20the%20home%20directory.%0Askip_mount_home%20%3D%20%22true%22%0A%0A%5Bstorage.options.thinpool%5D%0A%23%20Storage%20Options%20for%20thinpool%0A%0A%23%20autoextend_percent%20determines%20the%20amount%20by%20which%20pool%20needs%20to%20be%0A%23%20grown.%20This%20is%20specified%20in%20terms%20of%20%25%20of%20pool%20size.%20So%20a%20value%20of%2020%20means%0A%23%20that%20when%20threshold%20is%20hit%2C%20pool%20will%20be%20grown%20by%2020%25%20of%20existing%0A%23%20pool%20size.%0A%23%20autoextend_percent%20%3D%20%2220%22%0A%0A%23%20autoextend_threshold%20determines%20the%20pool%20extension%20threshold%20in%20terms%0A%23%20of%20percentage%20of%20pool%20size.%20For%20example%2C%20if%20threshold%20is%2060%2C%20that%20means%20when%0A%23%20pool%20is%2060%25%20full%2C%20threshold%20has%20been%20hit.%0A%23%20autoextend_threshold%20%3D%20%2280%22%0A%0A%23%20basesize%20specifies%20the%20size%20to%20use%20when%20creating%20the%20base%20device%2C%20which%0A%23%20limits%20the%20size%20of%20images%20and%20containers.%0A%23%20basesize%20%3D%20%2210G%22%0A%0A%23%20blocksize%20specifies%20a%20custom%20blocksize%20to%20use%20for%20the%20thin%20pool.%0A%23%20blocksize%3D%2264k%22%0A%0A%23%20directlvm_device%20specifies%20a%20custom%20block%20storage%20device%20to%20use%20for%20the%0A%23%20thin%20pool.%20Required%20if%20you%20setup%20devicemapper%0A%23%20directlvm_device%20%3D%20%22%22%0A%0A%23%20directlvm_device_force%20wipes%20device%20even%20if%20device%20already%20has%20a%20filesystem%0A%23%20directlvm_device_force%20%3D%20%22True%22%0A%0A%23%20fs%20specifies%20the%20filesystem%20type%20to%20use%20for%20the%20base%20device.%0A%23%20fs%3D%22xfs%22%0A%0A%23%20log_level%20sets%20the%20log%20level%20of%20devicemapper.%0A%23%200%3A%20LogLevelSuppress%200%20(Default)%0A%23%202%3A%20LogLevelFatal%0A%23%203%3A%20LogLevelErr%0A%23%204%3A%20LogLevelWarn%0A%23%205%3A%20LogLevelNotice%0A%23%206%3A%20LogLevelInfo%0A%23%207%3A%20LogLevelDebug%0A%23%20log_level%20%3D%20%227%22%0A%0A%23%20min_free_space%20specifies%20the%20min%20free%20space%20percent%20in%20a%20thin%20pool%20require%20for%0A%23%20new%20device%20creation%20to%20succeed.%20Valid%20values%20are%20from%200%25%20-%2099%25.%0A%23%20Value%200%25%20disables%0A%23%20min_free_space%20%3D%20%2210%25%22%0A%0A%23%20mkfsarg%20specifies%20extra%20mkfs%20arguments%20to%20be%20used%20when%20creating%20the%20base%0A%23%20device.%0A%23%20mkfsarg%20%3D%20%22%22%0A%0A%23%20mountopt%20specifies%20extra%20mount%20options%20used%20when%20mounting%20the%20thin%20devices.%0A%23%20mountopt%20%3D%20%22%22%0A%0A%23%20use_deferred_removal%20Marking%20device%20for%20deferred%20removal%0A%23%20use_deferred_removal%20%3D%20%22True%22%0A%0A%23%20use_deferred_deletion%20Marking%20device%20for%20deferred%20deletion%0A%23%20use_deferred_deletion%20%3D%20%22True%22%0A%0A%23%20xfs_nospace_max_retries%20specifies%20the%20maximum%20number%20of%20retries%20XFS%20should%0A%23%20attempt%20to%20complete%20IO%20when%20ENOSPC%20(no%20space)%20error%20is%20returned%20by%0A%23%20underlying%20storage%20device.%0A%23%20xfs_nospace_max_retries%20%3D%20%220%22%0A
          mode: 420
          overwrite: true
          path: /etc/containers/storage.conf
        - contents:
            source: data:,apiVersion%3A%20kubelet.config.k8s.io%2Fv1%0Akind%3A%20CredentialProviderConfig%0Aproviders%3A%0A%20%20-%20name%3A%20ecr-credential-provider%0A%20%20%20%20matchImages%3A%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.*.amazonaws.com%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.*.amazonaws.com.cn%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr-fips.*.amazonaws.com%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.us-iso-east-1.c2s.ic.gov%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.us-isob-east-1.sc2s.sgov.gov%22%0A%20%20%20%20defaultCacheDuration%3A%20%2212h%22%0A%20%20%20%20apiVersion%3A%20credentialprovider.kubelet.k8s.io%2Fv1%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/credential-providers/ecr-credential-provider.yaml
        - contents:
            source: data:,%23%20Proxy%20environment%20variables%20will%20be%20populated%20in%20this%20file.%20Properly%0A%23%20url%20encoded%20passwords%20with%20special%20characters%20will%20use%20'%25%3CHEX%3E%3CHEX%3E'.%0A%23%20Systemd%20requires%20that%20any%20%25%20used%20in%20a%20password%20be%20represented%20as%0A%23%20%25%25%20in%20a%20unit%20file%20since%20%25%20is%20a%20prefix%20for%20macros%3B%20this%20restriction%20does%20not%0A%23%20apply%20for%20environment%20files.%20Templates%20that%20need%20the%20proxy%20set%20should%20use%0A%23%20'EnvironmentFile%3D%2Fetc%2Fmco%2Fproxy.env'.%0A
          mode: 420
          overwrite: true
          path: /etc/mco/proxy.env
        - contents:
            source: data:,%5BManager%5D%0ADefaultEnvironment%3DGODEBUG%3Dx509ignoreCN%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/10-default-env-godebug.conf
        - contents:
            source: data:,%23%20Force-load%20legacy%20iptables%20so%20it%20is%20usable%20from%20pod%20network%20namespaces%0Aip_tables%0A
          mode: 420
          overwrite: true
          path: /etc/modules-load.d/iptables.conf
        - contents:
            source: data:,NODE_SIZING_ENABLED%3Dfalse%0ASYSTEM_RESERVED_MEMORY%3D1Gi%0ASYSTEM_RESERVED_CPU%3D500m%0ASYSTEM_RESERVED_ES%3D1Gi
          mode: 420
          overwrite: true
          path: /etc/node-sizing-enabled.env
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%0ANODE_SIZES_ENV%3D%24%7BNODE_SIZES_ENV%3A-%2Fetc%2Fnode-sizing.env%7D%0AVERSION_1%3D1%0AVERSION_2%3D2%0ANODE_AUTO_SIZING_VERSION%3D%24%7BNODE_AUTO_SIZING_VERSION%3A-%24VERSION_2%7D%0ANODE_AUTO_SIZING_VERSION_FILE%3D%24%7BNODE_AUTO_SIZING_VERSION_FILE%3A-%2Fetc%2Fnode-sizing-version.json%7D%0Afunction%20dynamic_memory_sizing%20%7B%0A%20%20%20%20total_memory%3D%24(free%20-g%7Cawk%20'%2F%5EMem%3A%2F%7Bprint%20%242%7D')%0A%20%20%20%20%23%20total_memory%3D8%20test%20the%20recommended%20values%20by%20modifying%20this%20value%0A%20%20%20%20recommended_systemreserved_memory%3D0%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2025%25%20of%20the%20first%204GB%20of%20memory%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24total_memory%200.25%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D1%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2020%25%20of%20the%20next%204GB%20of%20memory%20(up%20to%208GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.20%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%208))%3B%20then%20%23%2010%25%20of%20the%20next%208GB%20of%20memory%20(up%20to%2016GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.10%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-8))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%20112))%3B%20then%20%23%206%25%20of%20the%20next%20112GB%20of%20memory%20(up%20to%20128GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%206.72%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-112))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3E%3D%200))%3B%20then%20%23%202%25%20of%20any%20memory%20above%20128GB%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.02%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20fi%0A%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%7C%20awk%20'%7Bprintf(%22%25d%5Cn%22%2C%241%20%2B%200.5)%7D')%20%23%20Round%20off%20so%20we%20avoid%20float%20conversions%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7Brecommended_systemreserved_memory%7DGi%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_cpu_sizing%20%7B%0A%20%20%20%20total_cpu%3D%24(getconf%20_NPROCESSORS_ONLN)%0A%20%20%20%20if%20%5B%20%22%241%22%20-eq%20%22%24VERSION_1%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%206%25%20of%20the%20first%20core%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24total_cpu%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0.06%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%201%25%20of%20the%20next%20core%20(up%20to%202%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%202))%3B%20then%20%23%200.5%25%20of%20the%20next%202%20cores%20(up%20to%204%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.005%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-2))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3E%3D%200))%3B%20then%20%23%200.25%25%20of%20any%20cores%20above%204%20cores%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.0025%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20%23%20Base%20allocation%20for%201%20CPU%20in%20fractions%20of%20a%20core%20(60%20millicores%20%3D%200.06%20CPU%20core)%0A%20%20%20%20%20%20%20%20base_allocation_fraction%3D0.06%0A%20%20%20%20%20%20%20%20%23%20Increment%20per%20additional%20CPU%20in%20fractions%20of%20a%20core%20(12%20millicores%20%3D%200.012%20CPU%20core)%0A%20%20%20%20%20%20%20%20increment_per_cpu_fraction%3D0.012%0A%20%20%20%20%20%20%20%20if%20((total_cpu%20%3E%201))%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20the%20total%20system-reserved%20CPU%20in%20fractions%2C%20starting%20with%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20and%20adding%20the%20incremental%20fraction%20for%20each%20additional%20CPU%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20base%3D%22%24base_allocation_fraction%22%20-v%20increment%3D%22%24increment_per_cpu_fraction%22%20-v%20cpus%3D%22%24total_cpu%22%20'BEGIN%20%7Bprintf%20%22%25.2f%5Cn%22%2C%20base%20%2B%20increment%20*%20(cpus%20-%201)%7D')%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20a%20single%20CPU%2C%20use%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24base_allocation_fraction%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7Brecommended_systemreserved_cpu%7D%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_ephemeral_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20dynamic_pid_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20set_memory%20%7B%0A%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_cpu%20%7B%0A%20%20%20%20SYSTEM_RESERVED_CPU%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_CPU%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_CPU%3D%22500m%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7BSYSTEM_RESERVED_CPU%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_es%20%7B%0A%20%20%20%20SYSTEM_RESERVED_ES%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_ES%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_ES%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_ES%3D%24%7BSYSTEM_RESERVED_ES%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20dynamic_memory_sizing%0A%20%20%20%20dynamic_cpu_sizing%20%242%0A%20%20%20%20set_es%20%241%0A%20%20%20%20%23dynamic_ephemeral_sizing%0A%20%20%20%20%23dynamic_pid_sizing%0A%7D%0Afunction%20static_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20set_memory%20%241%0A%20%20%20%20set_cpu%20%242%0A%20%20%20%20set_es%20%243%0A%7D%0Afunction%20create_version_file%20%7B%0A%20%20%20%20echo%20%22%7B%5C%22version%5C%22%3A%20%241%7D%22%20%3E%20%242%0A%7D%0Aif%20!%20%5B%20-f%20%24NODE_AUTO_SIZING_VERSION_FILE%20%5D%3B%20then%0A%20%20%20%20create_version_file%20%24NODE_AUTO_SIZING_VERSION%20%24NODE_AUTO_SIZING_VERSION_FILE%0Afi%0Anew_version%3D%24(jq%20.version%20%24NODE_AUTO_SIZING_VERSION_FILE)%0Aif%20%5B%20%241%20%3D%3D%20%22true%22%20%5D%3B%20then%0A%20%20%20%20dynamic_node_sizing%20%244%20%24new_version%0Aelif%20%5B%20%241%20%3D%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20static_node_sizing%20%242%20%243%20%244%0Aelse%0A%20%20%20%20echo%20%22Unrecognized%20command%20line%20option.%20Valid%20options%20are%20%5C%22true%5C%22%20or%20%5C%22false%5C%22%22%0Afi
          mode: 493
          overwrite: true
          path: /usr/local/sbin/dynamic-system-reserved-calc.sh
        - contents:
            source: data:,%23%20Turning%20on%20Accounting%20helps%20track%20down%20performance%20issues.%0A%5BManager%5D%0ADefaultCPUAccounting%3Dyes%0ADefaultMemoryAccounting%3Dyes%0ADefaultBlockIOAccounting%3Dyes%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/kubelet-cgroups.conf
        - contents:
            source: data:,%5BService%5D%0AEnvironment%3D%22KUBELET_LOG_LEVEL%3D2%22%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system/kubelet.service.d/20-logging.conf
        - contents:
            source: data:,%23%20ignore%20known%20SDN-managed%20devices%0A%5Bdevice%5D%0Amatch-device%3Dinterface-name%3Abr-int%3Binterface-name%3Abr-local%3Binterface-name%3Abr-nexthop%3Binterface-name%3Aovn-k8s-*%3Binterface-name%3Ak8s-*%3Binterface-name%3Atun0%3Binterface-name%3Abr0%3Binterface-name%3Apatch-br-*%3Binterface-name%3Abr-ext%3Binterface-name%3Aext-vxlan%3Binterface-name%3Aext%3Binterface-name%3Aint%3Binterface-name%3Avxlan_sys_*%3Binterface-name%3Agenev_sys_*%3Bdriver%3Aveth%0Amanaged%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/sdn.conf
        - contents:
            source: data:,%5Bservice%5D%0Akeep_state_file_after_apply%20%3D%20true%0A
          mode: 420
          overwrite: true
          path: /etc/nmstate/nmstate.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Set%20interface%20ofport_request%20to%20guarantee%20stable%20ofport%20numbers.%20This%20is%20important%20for%20flow%20matches.%0A%23%20Otherwise%2C%20another%20ofport%20number%20is%20assigned%20to%20the%20interface%20on%20every%20restart%20of%20NetworkManager.%0A%23%20This%20script%20will%20build%20an%20associative%20array%20INTERFACE_NAME-%3Eofport_request%20and%20will%20save%20it%20to%20file%20CONFIGURATION_FILE.%0A%23%20When%20an%20interface%20is%20brought%20up%2C%20this%20will%20reuse%20the%20value%20from%20the%20associative%20array%20if%20such%20a%20value%20exists.%0A%23%20Otherwise%2C%20this%20will%20try%20to%20use%20the%20current%20ofport%20value.%20If%20the%20ofport%20value%20is%20already%20reserved%2C%20then%0A%23%20this%20uses%20the%20lowest%20available%20numerical%20value%2C%20instead.%0Aset%20-eux%20-o%20pipefail%0Aif%20%5B%5B%20%22OVNKubernetes%22%20!%3D%20%22OVNKubernetes%22%20%5D%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0AINTERFACE_NAME%3D%241%0AOPERATION%3D%242%0A%0A%23%20Only%20execute%20this%20on%20pre-up%0Aif%20%5B%20%22%24%7BOPERATION%7D%22%20!%3D%20%22pre-up%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0AINTERFACE_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%241%3D%3D%22'%24%7BINTERFACE_NAME%7D'%22%20%26%26%20%242!~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20slave-type.%20If%20this%20is%20not%20an%20ovs-port%2C%20then%20exit%0AINTERFACE_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-port%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20This%20is%20not%20necessarily%20a%20UUID%20(can%20be%20a%20name%20in%20case%20of%20bonds)%20but%20this%20should%20be%20unique%0APORT%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0APORT_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%20(%241%3D%3D%22'%24%7BPORT%7D'%22%20%7C%7C%20%243%3D%3D%22'%24%7BPORT%7D'%22)%20%26%26%20%242~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20slave-type.%20If%20this%20is%20not%20an%20ovs-bridge%2C%20then%20exit%0APORT_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-bridge%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20master.%20If%20it%20doesn't%20have%20any%2C%20assume%20it's%20not%20our%20bridge%0ABRIDGE_ID%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BBRIDGE_ID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20bridge%20name%0ABRIDGE_NAME%3D%24(nmcli%20-t%20-f%20connection.interface-name%20conn%20show%20%22%24%7BBRIDGE_ID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0A%23%20Limit%20this%20to%20br-ex%20and%20br-ex1%20only.%20If%20one%20wanted%20to%20enable%20this%20for%20all%20OVS%20bridges%2C%0A%23%20the%20condition%20would%20be%3A%20if%20%5B%20%22%24BRIDGE_NAME%22%20%3D%3D%20%22%22%20%5D%3B%20then%0Aif%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Make%20sure%20that%20the%20interface%20is%20plugged%20into%20OVS%0A%23%20This%20should%20always%20be%20the%20case%20given%20that%20we%20are%20in%20pre-up%2C%20but%20exit%20gracefully%20in%20the%20odd%20case%20that%20it's%20not%0Aif%20!%20ovs-vsctl%20list%20interface%20%22%24%7BINTERFACE_NAME%7D%22%20%3E%2Fdev%2Fnull%202%3E%261%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0ACONFIGURATION_FILE%3D%22%2Frun%2Fofport_requests.%24%7BBRIDGE_NAME%7D%22%0A%0A%23%20Declare%20a%20new%20associative%20array.%20If%20CONFIGURATION_FILE%20exists%2C%20source%20entries%20from%20there%0Adeclare%20-A%20INTERFACES%0Aif%20%5B%20-f%20%22%24%7BCONFIGURATION_FILE%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Sourcing%20configuration%20file%20'%24%7BCONFIGURATION_FILE%7D'%20with%20contents%3A%22%0A%20%20%20%20cat%20%22%24%7BCONFIGURATION_FILE%7D%22%0A%20%20%20%20source%20%22%24%7BCONFIGURATION_FILE%7D%22%0Afi%0A%0A%23%20get_interface_ofport_request%20will%20return%0A%23%20*%20either%3A%20the%20current%20ofport%20assignment%20for%20the%20port%20if%20no%20interface%20has%20claimed%20this%20ofport%20number%2C%20yet%0A%23%20*%20or%3A%20%20%20%20%20the%20lowest%20available%20free%20ofport%20number%0Afunction%20get_interface_ofport_request()%20%7B%0A%20%20%20%20%23%20Build%20an%20array%20that%20only%20contains%20the%20currently%20reserved%20ofport_requests%0A%20%20%20%20declare%20-A%20ofport_requests%0A%20%20%20%20for%20interface_name%20in%20%22%24%7B!INTERFACES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%20%20%20%20ofport_requests%5B%24%7BINTERFACES%5B%24interface_name%5D%7D%5D%3D%24%7BINTERFACES%5B%24interface_name%5D%7D%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20Get%20the%20current%20ofport%20number%20assignment%0A%20%20%20%20local%20current_ofport%3D%24(ovs-vsctl%20get%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport)%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20still%20free%2C%20use%20it%0A%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24current_ofport%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%24current_ofport%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20not%20free%2C%20return%20the%20lowest%20free%20entry%0A%20%20%20%20i%3D0%0A%20%20%20%20for%20i%20in%20%7B1..65000%7D%3B%20do%0A%20%20%20%20%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24i%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%24i%0A%20%20%20%20%20%20%20%20%20%20%20%20return%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20if%20we%20still%20cannot%20find%20an%20ID%2C%20exit%20with%20an%20error%0A%20%20%20%20echo%20%22Impossible%20to%20find%20an%20ofport%20ID%20for%20interface%20%24%7BINTERFACE_NAME%7D%22%20%3E%262%0A%20%20%20%20exit%201%0A%7D%0A%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20exists%2C%20use%20that%20value%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20does%20not%20exists%2C%20use%20the%20value%20from%20get_interface_ofport_request%0Aif%20!%20%5B%20%22%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20INTERFACES%5B%24INTERFACE_NAME%5D%3D%24(get_interface_ofport_request)%0Afi%0A%23%20Set%20ofport_request%20according%20to%20INTERFACES%5BINTERFACE_NAME%5D%0Aovs-vsctl%20set%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport_request%3D%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%7D%0A%0A%23%20Save%20current%20state%20of%20INTERFACES%20to%20CONFIGURATION_FILE%0Adeclare%20-p%20INTERFACES%20%3E%7C%20%22%24%7BCONFIGURATION_FILE%7D%22%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/pre-up.d/10-ofport-request.sh
        - contents:
            source: data:,%7B%22auths%22%3A%7B%22cloud.openshift.com%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfN2JmN2FjMTAyMDMxNDY1N2EwZjdiMDdiNDNjM2FiZDg6OE1YQ0gyTldMSktPVU9DQk5UNk9NSERPUzc2NkYxTURFTjlXQjhXN0xTTUtDNjk1NjI0N1c1OFUySzFDRUcwVw%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22quay.io%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfN2JmN2FjMTAyMDMxNDY1N2EwZjdiMDdiNDNjM2FiZDg6OE1YQ0gyTldMSktPVU9DQk5UNk9NSERPUzc2NkYxTURFTjlXQjhXN0xTTUtDNjk1NjI0N1c1OFUySzFDRUcwVw%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22registry.ci.openshift.org%22%3A%7B%22auth%22%3A%22c2VydmljZWFjY291bnQ6ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNkluWjBaVmc1TVVkUlpGRjZRME5OWkVWa2JGOXNTSG90YlVSd2EwRlVPR2RzWjJoUVRtMVBkamxLUmpBaWZRLmV5SmhkV1FpT2xzaWFIUjBjSE02THk5amFTMWtkakp1Y0MxdmFXUmpMbk16TG1GdFlYcHZibUYzY3k1amIyMGlYU3dpWlhod0lqb3hOek0wTlRNd05EWXlMQ0pwWVhRaU9qRTNNekl4TVRFeU5qSXNJbWx6Y3lJNkltaDBkSEJ6T2k4dlkya3RaSFl5Ym5BdGIybGtZeTV6TXk1aGJXRjZiMjVoZDNNdVkyOXRJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5STZleUp1WVcxbGMzQmhZMlVpT2lKamFTSXNJbk5sWTNKbGRDSTZleUp1WVcxbElqb2lkRzlyWlc0dFltOTFibVF0YjJKcVpXTjBMVEVpTENKMWFXUWlPaUkxWkRJd1pHUTBNQzFqT1RCaExUUXpNVFl0WVdNd05DMW1OVGczT0RFeVpUVTFZamdpZlN3aWMyVnlkbWxqWldGalkyOTFiblFpT25zaWJtRnRaU0k2SW1sdFlXZGxMWEIxYkd4bGNpSXNJblZwWkNJNkltRTNOMlk1TkdFeUxXVXdOelV0TkRGaU9DMDVPV1JoTFdRMlpEbGtNbUZpTlRGak9TSjlmU3dpYm1KbUlqb3hOek15TVRFeE1qWXlMQ0p6ZFdJaU9pSnplWE4wWlcwNmMyVnlkbWxqWldGalkyOTFiblE2WTJrNmFXMWhaMlV0Y0hWc2JHVnlJbjAuVGFqMktGY1JOV0FIRHJGT0NPQjBhWUJGUTUwVW9FUmdXMWFZYUNTVTQ0NF9jdnpCOFJDamNxR04xdV9jOFRRbFBDNXU0NG5JNklaYTdvU1RnMUh4dE9aQmEyYW5OS0JPMk5UNVF5WEhhX0R5cVJlaUUxb0YtcmphRms2TEJrNWllT1BSWXJHbklpWlJJNkQ2S0kxMmxJVFZQdFBPYUgtaXFuNV9LMXdOcmR4SDhYb2dCdlJ5UlJwRDBLTUxGNkJfeFBzbi1VeHVQQklIbjVRTFlXSkJtOVFMRVlIM0tzZDN2by03Uzc0anlZMkswMUF1OUpwYkFFR3k4Z2lyUDE1YlRnUXJReW1zS1NrbFN6U3BUbEM0MDJxVjNBanVPSjA4eGxrSE5VeXJROFk3dklJWDFBUUVmbHJaaC13ZVcyVy1aNWtnZjFOMXhNVVl6QnplZW5BZF9n%22%7D%2C%22registry.connect.redhat.com%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLWU3NDlmYWFiLTM0ZjktNDg0ZS1hNWQwLTJkNzFhMzgzMTg1MjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSXpORGszTURVMU5URTFObUkwTXpOaFltVmxNRGt5TVRJM09UZzNZV0V5WVNKOS50MUxtR0FhMTQzdnJIWG13RFZVVjNYaWhYa203Vk95bDFLek9kZm9QN0tTd3NqVFpKeUlSN1lKQjNyNGxGN3pVNWMwa0ZyOVYweUtwSFdPRU94clhJekVSaXlfOXkwQzRxbXRDOUhYNjJNVThsdmJtQW9GSXhZbHZXWnREVXVQZWgzSVFqS25CN2FJYlZ6MFJ3SWZWYVZucXFOUzhHbDNFcDRTUjVpNGZmUzE5akJCUnpxdmxBSjF6QkNVWWI3S1ZLTHVGRHJsNjdNNy1rWWwxTUhseTRBN2JVdjVISU5MaEhOdDVfRk5JX3RWbjdQM0RzQkVjcWxkWTd0Y0J4UlNoLTdQbWpzMGJEWm9ZZTZ6by1QY25TeEY0RV94QzF6aGZYYUNpdEU4UVZTUmk2MjhnM1c4WjVQQzc4VFBJWGtvaTBJWG9IX1E4QTd4SDlKaDhsWWhTTnBCaUxHODMyaFNhRUdtYkEtaU5kd3BrTGk0a0oyeTlYWE55ZlNUbU1mRUppUGwyWEI5VXRTT3lva05XU0ZqVk1kZ3l5WFlaUWtTNGh6Ql83VkpzTEh6RHpKaTJGcUZNNE56LW5Qd28zalZ3c3d3YXgzUUZZVUk2YzA5MVZnT0NUdEtpeEJXeTBaVEZyT3hEVDh4ZFRQOXcxY1JoR1N1UzU5WG55c2I2bndDLWQ5ZS11SWZpS2x4dDNZNkJaUkhRYmVUZlRtdGFoMUxOYWhRaXRzclVubVBjZXhnLVFXdzhCS3VENUFwbFc3eFVHcm9Lb1lkSEowVTJtc0ZWcjhZZ2FjVDl1UC1hWGUtTHd0dnJ3ZG1fWGtVdWRMRnFsRklxby1lWTdhVE03Xy1HRk8xWE8xTTIwQWVtSU5oUXJqUkN4TGRJeXlMSU9uOURBZUdYeGc5bUJiWQ%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22registry.redhat.io%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLWU3NDlmYWFiLTM0ZjktNDg0ZS1hNWQwLTJkNzFhMzgzMTg1MjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSXpORGszTURVMU5URTFObUkwTXpOaFltVmxNRGt5TVRJM09UZzNZV0V5WVNKOS50MUxtR0FhMTQzdnJIWG13RFZVVjNYaWhYa203Vk95bDFLek9kZm9QN0tTd3NqVFpKeUlSN1lKQjNyNGxGN3pVNWMwa0ZyOVYweUtwSFdPRU94clhJekVSaXlfOXkwQzRxbXRDOUhYNjJNVThsdmJtQW9GSXhZbHZXWnREVXVQZWgzSVFqS25CN2FJYlZ6MFJ3SWZWYVZucXFOUzhHbDNFcDRTUjVpNGZmUzE5akJCUnpxdmxBSjF6QkNVWWI3S1ZLTHVGRHJsNjdNNy1rWWwxTUhseTRBN2JVdjVISU5MaEhOdDVfRk5JX3RWbjdQM0RzQkVjcWxkWTd0Y0J4UlNoLTdQbWpzMGJEWm9ZZTZ6by1QY25TeEY0RV94QzF6aGZYYUNpdEU4UVZTUmk2MjhnM1c4WjVQQzc4VFBJWGtvaTBJWG9IX1E4QTd4SDlKaDhsWWhTTnBCaUxHODMyaFNhRUdtYkEtaU5kd3BrTGk0a0oyeTlYWE55ZlNUbU1mRUppUGwyWEI5VXRTT3lva05XU0ZqVk1kZ3l5WFlaUWtTNGh6Ql83VkpzTEh6RHpKaTJGcUZNNE56LW5Qd28zalZ3c3d3YXgzUUZZVUk2YzA5MVZnT0NUdEtpeEJXeTBaVEZyT3hEVDh4ZFRQOXcxY1JoR1N1UzU5WG55c2I2bndDLWQ5ZS11SWZpS2x4dDNZNkJaUkhRYmVUZlRtdGFoMUxOYWhRaXRzclVubVBjZXhnLVFXdzhCS3VENUFwbFc3eFVHcm9Lb1lkSEowVTJtc0ZWcjhZZ2FjVDl1UC1hWGUtTHd0dnJ3ZG1fWGtVdWRMRnFsRklxby1lWTdhVE03Xy1HRk8xWE8xTTIwQWVtSU5oUXJqUkN4TGRJeXlMSU9uOURBZUdYeGc5bUJiWQ%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%7D%7D%0A
          mode: 384
          overwrite: true
          path: /var/lib/kubelet/config.json
        - contents:
            source: data:,%23%20Needed%20by%20the%20OpenShift%20SDN.%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1758552%0Anet.ipv4.conf.all.arp_announce%20%3D%202%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/arp.conf
        - contents:
            source: data:,%23%20See%3A%20rhbz%231384746%2C%20OCPBUGS-24012%0Anet.ipv4.neigh.default.gc_thresh1%3D8192%0Anet.ipv4.neigh.default.gc_thresh2%3D32768%0Anet.ipv4.neigh.default.gc_thresh3%3D65536%0Anet.ipv6.neigh.default.gc_thresh1%3D8192%0Anet.ipv6.neigh.default.gc_thresh2%3D32768%0Anet.ipv6.neigh.default.gc_thresh3%3D65536%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/gc-thresh.conf
        - contents:
            source: data:,%0Afs.inotify.max_user_watches%20%3D%2065536%0Afs.inotify.max_user_instances%20%3D%208192%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/inotify.conf
        - contents:
            source: data:,vm.unprivileged_userfaultfd%20%3D%201
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/enable-userfaultfd.conf
        - contents:
            source: data:,%23%20Needed%20for%20OpenShift%20Logging%20(ElasticSearch).%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1793714%0Avm.max_map_count%20%3D%20262144%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/vm-max-map.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%20-o%20pipefail%0A%0ANODEENV%3D%2Fetc%2Fkubernetes%2Fnode.env%0A%0A%23%20This%20can%20be%20removed%201%20release%20after%20it%20merges%20because%20all%20affected%20nodes%0A%23%20will%20have%20upgraded%0ALEGACY_NODEENV%3D%2Fetc%2Fsystemd%2Fsystem%2Fkubelet.service.d%2F20-aws-node-name.conf%0Aif%20%5B%20-e%20%22%24%7BLEGACY_NODEENV%7D%22%20%5D%3B%20then%0A%20%20%20%20%23%20Legacy%20file%20was%20a%20systemd%20stanza%20with%20KUBELET_NODE_NAME%20specified%20in%0A%20%20%20%20%23%20a%20directive%20of%20the%20format%3A%0A%20%20%20%20%23%20%20%20Environment%3D%22KUBELET_NODE_NAME%3Dnode.example.com%22%0A%20%20%20%20%23%20New%20format%20is%20an%20environment%20file.%20The%20following%20extracts%20only%20the%0A%20%20%20%20%23%20contents%20of%20any%20Environment%20directives.%0A%20%20%20%20echo%20%22Migrating%20%24%7BLEGACY_NODEENV%7D%20to%20%24%7BNODEENV%7D%22%0A%20%20%20%20awk%20'match(%240%2C%20%2F%5E%5Cs*Environment%5Cs*%3D%5Cs*%22(.*)%22%5Cs*%24%2F%2C%20value)%20%7B%20print%20value%5B1%5D%20%7D'%20%3C%20%22%24%7BLEGACY_NODEENV%7D%22%20%3E%20%22%24%7BNODEENV%7D%22%0A%20%20%20%20rm%20%22%24%7BLEGACY_NODEENV%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20-e%20%22%24%7BNODEENV%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Not%20replacing%20existing%20%24%7BNODEENV%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20afterburn%20service%20is%20expected%20to%20be%20used%20for%20metadata%20retrival%2C%20see%20respective%20systemd%20unit.%0A%23%20However%2C%20on%20older%20OCP%20boot%20images%20does%20not%20contain%20afterburn%20service%2C%20check%20if%20afterburn%20variables%20are%20there%0A%23%20otherwise%20try%20to%20communicate%20IMDS%20here.%0A%23%20metadata%20related%20afterburn%20doc%3A%20https%3A%2F%2Fcoreos.github.io%2Fafterburn%2Fusage%2Fattributes%2F%0A%0AHOSTNAME%3D%24%7BAFTERBURN_AWS_HOSTNAME%3A-%7D%0Awhile%20%5B%5B%20-z%20%22%24%7BHOSTNAME%7D%22%20%5D%5D%3B%20do%0A%20%20HOSTNAME%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Flocal-hostname)%0A%20%20if%20%5B%5B%20-z%20%22%24%7BHOSTNAME%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Can%20not%20obtain%20hostname%20from%20the%20metadata%20service.%22%201%3E%262%0A%20%20%20%20sleep%205%0A%20%20fi%20%0Adone%0A%0A%23%20For%20compatibility%20with%20the%20AWS%20in-tree%20provider%0A%23%20Set%20node%20name%20to%20be%20instance%20FQDN%20instead%20of%20the%20default%20hostname%0Acat%20%3E%20%22%24%7BNODEENV%7D%22%20%3C%3CEOF%0AKUBELET_NODE_NAME%3D%24%7BHOSTNAME%25%25%20*%7D%0AEOF%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/aws-kubelet-nodename
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%20-o%20pipefail%0A%0ANODECONF%3D%2Fetc%2Fsystemd%2Fsystem%2Fkubelet.service.d%2F20-aws-providerid.conf%0A%0Aif%20%5B%20-e%20%22%24%7BNODECONF%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Not%20replacing%20existing%20%24%7BNODECONF%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20afterburn%20service%20is%20expected%20to%20be%20used%20for%20metadata%20retrival%2C%20see%20respective%20systemd%20unit.%0A%23%20However%2C%20on%20older%20OCP%20boot%20images%20does%20not%20contain%20afterburn%20service%2C%20check%20if%20afterburn%20variables%20are%20there%0A%23%20otherwise%20try%20to%20communicate%20IMDS%20here.%0A%23%20metadata%20related%20afterburn%20doc%3A%20https%3A%2F%2Fcoreos.github.io%2Fafterburn%2Fusage%2Fattributes%2F%0A%0AINSTANCE_ID%3D%24%7BAFTERBURN_AWS_INSTANCE_ID%3A-%7D%0AAVAILABILITY_ZONE%3D%24%7BAFTERBURN_AWS_AVAILABILITY_ZONE%3A-%7D%0Aif%20%5B%5B%20-z%20%22%24%7BINSTANCE_ID%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20-z%20%22%24%7BAVAILABILITY_ZONE%7D%22%20%5D%5D%3B%20then%0A%20%20INSTANCE_ID%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Finstance-id)%0A%20%20AVAILABILITY_ZONE%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Fplacement%2Favailability-zone)%0A%20%20if%20%5B%5B%20-z%20%22%24%7BINSTANCE_ID%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20-z%20%22%24%7BAVAILABILITY_ZONE%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Can%20not%20obtain%20instance-id%20and%20availability%20zone%20info%20from%20the%20metadata%20service.%22%0A%20%20%20%20exit%201%0A%20%20fi%20%0Afi%0A%0A%23%20Due%20to%20a%20potential%20mismatch%20between%20Hostname%20and%20PrivateDNSName%20with%20clusters%20that%20use%20custom%20DHCP%20Option%20Sets%0A%23%20which%20can%20cause%20issues%20in%20cloud%20controller%20manager%20node%20syncing%0A%23%20(see%3A%20https%3A%2F%2Fgithub.com%2Fkubernetes%2Fcloud-provider-aws%2Fissues%2F384)%2C%0A%23%20set%20KUBELET_PROVIDERID%20to%20be%20a%20fully%20qualified%20AWS%20instace%20provider%20id.%0A%23%20This%20new%20variable%20is%20later%20used%20to%20populate%20the%20kubelet's%20%60provider-id%60%20flag%2C%20later%20set%20on%20the%20Node%20.spec%0A%23%20and%20used%20by%20the%20cloud%20controller%20manager's%20node%20controller%20to%20retrieve%20the%20Node's%20backing%20instance.%0Acat%20%3E%20%22%24%7BNODECONF%7D%22%20%3C%3CEOF%0A%5BService%5D%0AEnvironment%3D%22KUBELET_PROVIDERID%3Daws%3A%2F%2F%2F%24%7BAVAILABILITY_ZONE%7D%2F%24%7BINSTANCE_ID%7D%22%0AEOF%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/aws-kubelet-providerid
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20First%2C%20we%20need%20to%20wait%20until%20DHCP%20finishes%20and%20the%20node%20has%20a%20non-%60localhost%60%0A%23%20hostname%20before%20%60kubelet.service%60%20starts.%0A%23%20That's%20the%20%60--wait%60%20argument%20as%20used%20by%20%60node-valid-hostname.service%60.%0A%23%0A%23%20Second%2C%20on%20GCP%20specifically%20we%20truncate%20the%20hostname%20if%20it's%20%3E63%20characters.%0A%23%20That's%20%60gcp-hostname.service%60.%0A%0A%23%20Block%20indefinitely%20until%20the%20host%20gets%20a%20non-localhost%20name.%0A%23%20Note%20node-valid-hostname.service%20uses%20systemd%20to%20abort%20if%20this%20takes%20too%20long.%0Await_localhost()%20%7B%0A%20%20%20%20echo%20%22waiting%20for%20non-localhost%20hostname%20to%20be%20assigned%22%0A%20%20%20%20while%20%5B%5B%20%22%24(%3C%20%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%20%3D~%20(localhost%7Clocalhost.localdomain)%20%5D%5D%3B%0A%20%20%20%20do%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20done%0A%20%20%20%20echo%20%22node%20identified%20as%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%0A%20%20%20%20echo%20%22saving%20hostname%20to%20prevent%20NetworkManager%20from%20ever%20unsetting%20it%22%0A%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_gcp_hostname()%20%7B%0A%20%20%20%20%2Fusr%2Fbin%2Fafterburn%20--provider%20gcp%20--hostname%3D%2Frun%2Fafterburn.hostname%0A%0A%20%20%20%20local%20host_name%3D%24(cat%20%2Frun%2Fafterburn.hostname)%0A%20%20%20%20local%20type_arg%3D%22transient%22%0A%0A%20%20%20%20%23%20%2Fetc%2Fhostname%20is%20used%20for%20static%20hostnames%20and%20is%20authoritative.%0A%20%20%20%20%23%20This%20will%20check%20to%20make%20sure%20that%20the%20static%20hostname%20is%20the%0A%20%20%20%20%23%20less%20than%20or%20equal%20to%2063%20characters%20in%20length.%0A%20%20%20%20if%20%5B%20-f%20%2Fetc%2Fhostname%20%5D%20%26%26%20%5B%20%22%24(cat%20%2Fetc%2Fhostname%20%7C%20wc%20-m)%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20etc_name%3D%22%24(%3C%20%2Fetc%2Fhostname)%22%0A%20%20%20%20%20%20%20%20type_arg%3D%22static%22%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24%7Betc_name%7D%22%20!%3D%20%22%24%7Bhost_name%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%2Fetc%2Fhostname%20is%20set%20to%20%24%7Betc_name%7D%20but%20does%20not%20match%20%24%7Bhost_name%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22using%20%2Fetc%2Fhostname%20as%20the%20authoritative%20name%22%0A%20%20%20%20%20%20%20%20%20%20%20%20host_name%3D%22%24%7Betc_name%7D%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Only%20mutate%20the%20hostname%20if%20the%20length%20is%20longer%20than%2063%20characters.%20The%0A%20%20%20%20%23%20hostname%20will%20be%20the%20lesser%20of%2063%20characters%20after%20the%20first%20dot%20in%20the%0A%20%20%20%20%23%20FQDN.%20%20This%20algorithm%20is%20only%20known%20to%20work%20in%20GCP%2C%20and%20hence%20is%20only%0A%20%20%20%20%23%20executed%20in%20GCP.%0A%20%20%20%20if%20%5B%20%22%24%7B%23host_name%7D%22%20-gt%2063%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20alt_name%3D%24(printf%20%22%24%7Bhost_name%7D%22%20%7C%20cut%20-f1%20-d'.'%20%7C%20cut%20-c%20-63)%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Bhost_name%7D%20is%20longer%20than%2063%20characters%2C%20using%20truncated%20hostname%22%0A%20%20%20%20%20%20%20%20host_name%3D%22%24%7Balt_name%7D%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22setting%20%24%7Btype_arg%7D%20hostname%20to%20%24%7Bhost_name%7D%22%0A%20%20%20%20%2Fbin%2Fhostnamectl%20%22--%24%7Btype_arg%7D%22%20set-hostname%20%22%24%7Bhost_name%7D%22%0A%20%20%20%20exit%200%0A%7D%0A%0Aarg%3D%24%7B1%7D%3B%20shift%3B%0Acase%20%22%24%7Barg%7D%22%20in%0A%20%20%20%20--wait)%20wait_localhost%3B%3B%0A%20%20%20%20--gcp)%20set_gcp_hostname%3B%3B%0A%20%20%20%20*)%20echo%20%22Unhandled%20arg%20%24arg%22%3B%20exit%201%0Aesac%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/mco-hostname
        - contents:
            source: data:,
          mode: 493
          overwrite: true
          path: /etc/kubernetes/kubelet-plugins/volume/exec/.dummy
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1941714%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1935539%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1987108%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22vmxnet3%22%20%5D%5D%3B%20then%0A%20%20logger%20-s%20%2299-vsphere-disable-tx-udp-tnl%20triggered%20by%20%24%7B2%7D%20on%20device%20%24%7BDEVICE_IFACE%7D.%22%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-csum-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksum-ip-generic%20off%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-vsphere-disable-tx-udp-tnl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0Aif%20%5B%20!%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20%23%20No%20need%20to%20do%20this%20if%20no%20NMState%20configuration%20was%20applied%0A%20%20exit%200%0Afi%0A%0A%23%20This%20logic%20is%20borrowed%20from%20configure-ovs.sh%0A%23%20TODO%3A%20Find%20a%20platform-agnostic%20way%20to%20do%20this.%20It%20won't%20work%20on%20platforms%20where%0A%23%20nodeip-configuration%20is%20not%20used.%0Aip%3D%24(cat%20%2Frun%2Fnodeip-configuration%2Fprimary-ip)%0Aif%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20echo%20%22No%20ip%20to%20bind%20was%20found%22%0A%20%20exit%201%0Afi%0Awhile%20%3A%0Ado%0A%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%20%20sleep%2010%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-primary-ip.sh
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Cleans NetworkManager state generated by dracut
            # Removal of this file signals firstboot completion
            ConditionPathExists=!/etc/ignition-machine-config-encapsulated.json
            # This is opt-in for some deployment types, and opt-out for others.
            ConditionPathExists=/var/lib/mco/nm-clean-initrd-state
            Wants=network-pre.target
            Before=network-pre.target

            [Service]
            Type=oneshot
            # Remove any existing state possibly generated NM run by dracut. We want NM to
            # consider all profiles autoconnect priority when it starts instead of
            # remembering which profile was a device activated with when NM is run by
            # dracut.
            ExecStart=/usr/local/bin/nm-clean-initrd-state.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: NetworkManager-clean-initrd-state.service
        - contents: |
            [Unit]
            Description=Fetch kubelet node name from AWS Metadata

            # Run afterburn service for collect info from metadata server
            # see: https://coreos.github.io/afterburn/usage/attributes/
            # Not required due to OCP 4.1 boot image does not contain afterburn service
            # see: https://issues.redhat.com/browse/OCPBUGS-7559
            Wants=afterburn.service
            After=afterburn.service

            # Wait for NetworkManager to report it's online
            After=NetworkManager-wait-online.service
            # Run before kubelet
            Before=kubelet-dependencies.target

            [Service]
            # Mark afterburn environment file optional, due to it is possible that afterburn service was not executed
            EnvironmentFile=-/run/metadata/afterburn
            ExecStart=/usr/local/bin/aws-kubelet-nodename
            Type=oneshot

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: aws-kubelet-nodename.service
        - contents: |
            [Unit]
            Description=Fetch kubelet provider id from AWS Metadata

            # Run afterburn service for collect info from metadata server
            # see: https://coreos.github.io/afterburn/usage/attributes/
            # Not required due to OCP 4.1 boot image does not contain afterburn service
            # see: https://issues.redhat.com/browse/OCPBUGS-7559
            Wants=afterburn.service
            After=afterburn.service

            # Wait for NetworkManager to report it's online
            After=NetworkManager-wait-online.service
            # Run before kubelet
            Before=kubelet-dependencies.target

            [Service]
            # Mark afterburn environment file optional, due to it is possible that afterburn service was not executed
            EnvironmentFile=-/run/metadata/afterburn
            ExecStart=/usr/local/bin/aws-kubelet-providerid
            Type=oneshot

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: aws-kubelet-providerid.service
        - dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="ENABLE_PROFILE_UNIX_SOCKET=true"
            name: 10-mco-profile-unix-socket.conf
          - contents: |
              [Unit]
              After=kubelet-dependencies.target
              Requires=kubelet-dependencies.target
            name: 05-mco-ordering.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: crio.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: docker.socket
        - contents: |
            [Unit]
            Description=The firstboot OS update has completed
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target

            [Install]
            WantedBy=default.target
          enabled: true
          name: firstboot-osupdate.target
        - contents: |
            [Unit]
            Description=Dynamically sets the system reserved for the kubelet
            Wants=network-online.target
            After=network-online.target firstboot-osupdate.target
            Before=kubelet-dependencies.target

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            RemainAfterExit=yes
            EnvironmentFile=/etc/node-sizing-enabled.env
            ExecStart=/bin/bash /usr/local/sbin/dynamic-system-reserved-calc.sh ${NODE_SIZING_ENABLED} ${SYSTEM_RESERVED_MEMORY} ${SYSTEM_RESERVED_CPU} ${SYSTEM_RESERVED_ES}
            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: kubelet-auto-node-size.service
        - contents: |
            [Unit]
            Description=Dependencies necessary to run kubelet
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target network-online.target
            Wants=NetworkManager-wait-online.service crio-wipe.service
            Wants=rpc-statd.service chrony-wait.service
          name: kubelet-dependencies.target
        - dropins:
          - contents: |
              [Service]
              EnvironmentFile=/etc/kubernetes/node.env
            name: 20-node-env.conf
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: kubelet.service
        - contents: |
            [Unit]
            Description=Manages a mount namespace for kubernetes-specific mounts

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            RuntimeDirectory=kubens
            Environment=RUNTIME_DIRECTORY=%t/kubens
            Environment=BIND_POINT=%t/kubens/mnt
            Environment=ENVFILE=%t/kubens/env

            # Set up the runtime directory as an unbindable mountpoint
            ExecStartPre=bash -c "findmnt ${RUNTIME_DIRECTORY} || mount --make-unbindable --bind ${RUNTIME_DIRECTORY} ${RUNTIME_DIRECTORY}"
            # Ensure the bind point exists
            ExecStartPre=touch ${BIND_POINT}
            # Use 'unshare' to create the new mountpoint, then 'mount --make-rshared' so it cascades internally
            ExecStart=unshare --mount=${BIND_POINT} --propagation slave mount --make-rshared /
            # Finally, set an env pointer for ease-of-use
            ExecStartPost=bash -c 'echo "KUBENSMNT=${BIND_POINT}" > "${ENVFILE}"'

            # On stop, a recursive unmount cleans up the namespace and bind-mounted unbindable parent directory
            ExecStop=umount -R ${RUNTIME_DIRECTORY}

            [Install]
            WantedBy=multi-user.target
          enabled: false
          name: kubens.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Firstboot
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # Removal of this file signals firstboot completion
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            After=machine-config-daemon-pull.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            # Disable existing repos (if any) so that OS extensions would use embedded RPMs only
            ExecStartPre=-/usr/bin/sh -c "sed -i 's/enabled=1/enabled=0/' /etc/yum.repos.d/*.repo"
            # Run this via podman because we want to use the nmstatectl binary in our container
            ExecStart=/usr/bin/podman run --rm --privileged --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:787a505ca594b0a727549353c503dec9233a9d3c2dcd6b64e3de5f998892a1d5' firstboot-complete-machineconfig --persist-nics
            ExecStart=/usr/bin/podman run --rm --privileged --pid=host --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:787a505ca594b0a727549353c503dec9233a9d3c2dcd6b64e3de5f998892a1d5' firstboot-complete-machineconfig
            [Install]
            RequiredBy=firstboot-osupdate.target
          enabled: true
          name: machine-config-daemon-firstboot.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Pull
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # This "stamp file" is unlinked when we complete
            # machine-config-daemon-firstboot.service
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            # Run after crio-wipe so the pulled MCD image is protected against a corrupted storage from a forced shutdown
            Wants=crio-wipe.service NetworkManager-wait-online.service
            After=crio-wipe.service NetworkManager-wait-online.service network.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStart=/bin/sh -c "while ! /usr/bin/podman pull --authfile=/var/lib/kubelet/config.json 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:787a505ca594b0a727549353c503dec9233a9d3c2dcd6b64e3de5f998892a1d5'; do sleep 1; done"
            [Install]
            RequiredBy=machine-config-daemon-firstboot.service
          enabled: true
          name: machine-config-daemon-pull.service
        - contents: |
            [Unit]
            Description=Wait for a non-localhost hostname
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            User=root
            ExecStart=/usr/local/bin/mco-hostname --wait

            # Wait up to 5min for the node to get a non-localhost name
            TimeoutSec=300

            [Install]
            # TODO: Change this to RequiredBy after we fix https://github.com/openshift/machine-config-operator/pull/3865#issuecomment-1746963115
            WantedBy=kubelet-dependencies.target
          enabled: true
          name: node-valid-hostname.service
        - contents: |
            [Unit]
            Description=Writes IP address configuration so that kubelet and crio services select a valid node IP
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service firstboot-osupdate.target
            Before=kubelet-dependencies.target ovs-configuration.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/bin/podman run --rm \
              --authfile /var/lib/kubelet/config.json \
              --net=host \
              --security-opt label=disable \
              --volume /etc/systemd/system:/etc/systemd/system \
              --volume /run/nodeip-configuration:/run/nodeip-configuration \
              quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:02a7419d80a103e656c25a8d7573106a62e8e4a41508c758387db7e13801d89c \
              node-ip \
              set \
              --retry-on-failure \
              --network-type OVNKubernetes \
              ${NODEIP_HINT:-${KUBELET_NODEIP_HINT:-}}; \
              do \
              sleep 5; \
              done"
            ExecStart=/bin/systemctl daemon-reload
            ExecStartPre=/bin/mkdir -p /run/nodeip-configuration
            StandardOutput=journal+console
            StandardError=journal+console

            EnvironmentFile=-/etc/default/nodeip-configuration

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: false
          name: nodeip-configuration.service
        - enabled: true
          name: openvswitch.service
        - contents: |
            [Unit]
            # Kdump will generate it's initramfs based on the running state when kdump.service run
            # If OVS has already run, the kdump fails to gather a working network config,
            # which prevent network log exports, sush as SSH.
            # See https://issues.redhat.com/browse/OCPBUGS-28239
            After=kdump.service
            Description=Configures OVS with proper host networking configuration
            # This service is used to move a physical NIC into OVS and reconfigure OVS to use the host IP
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=firstboot-osupdate.target
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service nmstate.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            ExecStart=/usr/local/bin/configure-ovs.sh OVNKubernetes
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: ovs-configuration.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /var/lib/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /etc/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /run/openvswitch'
              ExecStartPost=-/usr/bin/ovs-appctl vlog/set syslog:info
              ExecReload=-/usr/bin/ovs-appctl vlog/set syslog:info
            name: 10-ovs-vswitchd-restart.conf
          name: ovs-vswitchd.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
            name: 10-ovsdb-restart.conf
          enabled: true
          name: ovsdb-server.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          name: pivot.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          name: rpm-ostreed.service
        - contents: |
            [Unit]
            Description=Ensure primary IP is assigned and usable
            Requires=nmstate.service
            After=nmstate.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/wait-for-primary-ip.sh; \
              do \
              sleep 10; \
              done"
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: wait-for-primary-ip.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: zincati.service
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:ad394c1a0b0cc7d37e2bc632f795f9140ca3f68bc0f2ca2895b83125c61a7d2e
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: d656f31b697c2671aac38bbe46d9e5b22d27ae90
    creationTimestamp: "2024-11-20T22:36:29Z"
    generation: 2
    labels:
      machineconfiguration.openshift.io/role: master
    name: 01-master-container-runtime
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: ControllerConfig
      name: machine-config-controller
      uid: b0288238-f89e-41ca-ad96-dc8692409c40
    resourceVersion: "46507"
    uid: 18072756-8db5-4971-9ec6-b0cdd071c537
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            source: data:,unqualified-search-registries%20%3D%20%5B'registry.access.redhat.com'%2C%20'docker.io'%5D%0A
          mode: 420
          overwrite: true
          path: /etc/containers/registries.conf
        - contents:
            source: data:,%5Bcrio%5D%0Ainternal_wipe%20%3D%20true%0Ainternal_repair%20%3D%20true%0A%0A%5Bcrio.api%5D%0Astream_address%20%3D%20%22127.0.0.1%22%0Astream_port%20%3D%20%220%22%0A%0A%5Bcrio.runtime%5D%0Aselinux%20%3D%20true%0Aconmon%20%3D%20%22%22%0Aconmon_cgroup%20%3D%20%22pod%22%0Adefault_env%20%3D%20%5B%0A%20%20%20%20%22NSS_SDB_USE_CACHE%3Dno%22%2C%0A%5D%0Adefault_runtime%20%3D%20%22crun%22%0Alog_level%20%3D%20%22info%22%0Acgroup_manager%20%3D%20%22systemd%22%0Adefault_sysctls%20%3D%20%5B%0A%20%20%20%20%22net.ipv4.ping_group_range%3D0%202147483647%22%2C%0A%5D%0Ahooks_dir%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Frun%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Fusr%2Fshare%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%5D%0Amanage_ns_lifecycle%20%3D%20true%0Aabsent_mount_sources_to_reject%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fhostname%22%2C%0A%5D%0Adrop_infra_ctr%20%3D%20true%0A%0A%5Bcrio.runtime.runtimes.runc%5D%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%0A%5Bcrio.runtime.runtimes.crun%5D%0Aruntime_root%20%3D%20%22%2Frun%2Fcrun%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%23%20Based%20on%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcrun%2Fblob%2F27d7dd3a0%2FREADME.md%3Fplain%3D1%23L48%0Acontainer_min_memory%20%3D%20%22512KiB%22%0A%0A%5Bcrio.runtime.workloads.openshift-builder%5D%0Aactivation_annotation%20%3D%20%22io.openshift.builder%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%22io.kubernetes.cri-o.userns-mode%22%2C%0A%20%20%22io.kubernetes.cri-o.Devices%22%0A%5D%0A%5Bcrio.runtime.workloads.openshift-builder.resources%5D%0A%0A%5Bcrio.image%5D%0Aglobal_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_image%20%3D%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A8c3c9719ba85ce692f2462e653d82d154bd958dc57c236d6bc0a8092bb6b2080%22%0Apause_image_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_command%20%3D%20%22%2Fusr%2Fbin%2Fpod%22%0A%0A%5Bcrio.network%5D%0Anetwork_dir%20%3D%20%22%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F%22%0Aplugin_dirs%20%3D%20%5B%0A%20%20%20%20%22%2Fvar%2Flib%2Fcni%2Fbin%22%2C%0A%20%20%20%20%22%2Fusr%2Flibexec%2Fcni%22%2C%0A%5D%0A%0A%5Bcrio.metrics%5D%0Aenable_metrics%20%3D%20true%0Ametrics_host%20%3D%20%22127.0.0.1%22%0Ametrics_port%20%3D%209537%0Ametrics_collectors%20%3D%20%5B%0A%20%20%22operations%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_total%22%0A%20%20%22operations_latency_microseconds_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds_total%22%0A%20%20%22operations_latency_microseconds%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds%22%0A%20%20%22operations_errors%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_errors_total%22%0A%20%20%22image_pulls_layer_size%22%2C%0A%20%20%22containers_oom_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22containers_oom_count_total%22%0A%20%20%22containers_oom%22%2C%0A%20%20%23%20Drop%20metrics%20with%20excessive%20label%20cardinality.%0A%20%20%23%20%22image_pulls_by_digest%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name_skipped%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_skipped_bytes_total%22%0A%20%20%23%20%22image_pulls_failures%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_failure_total%22%0A%20%20%23%20%22image_pulls_successes%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_success_total%22%0A%20%20%23%20%22image_layer_reuse%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_layer_reuse_total%22%0A%20%20%22operations_total%22%2C%0A%20%20%22operations_latency_seconds_total%22%2C%0A%20%20%22operations_latency_seconds%22%2C%0A%20%20%22operations_errors_total%22%2C%0A%20%20%22image_pulls_bytes_total%22%2C%0A%20%20%22image_pulls_skipped_bytes_total%22%2C%0A%20%20%22image_pulls_success_total%22%2C%0A%20%20%22image_pulls_failure_total%22%2C%0A%20%20%22image_layer_reuse_total%22%2C%0A%20%20%22containers_oom_count_total%22%2C%0A%20%20%22processes_defunct%22%0A%5D%0A
          mode: 420
          overwrite: true
          path: /etc/crio/crio.conf.d/00-default
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D
          mode: 420
          overwrite: true
          path: /etc/containers/policy.json
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:ad394c1a0b0cc7d37e2bc632f795f9140ca3f68bc0f2ca2895b83125c61a7d2e
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: d656f31b697c2671aac38bbe46d9e5b22d27ae90
    creationTimestamp: "2024-11-20T22:36:29Z"
    generation: 2
    labels:
      machineconfiguration.openshift.io/role: master
    name: 01-master-kubelet
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: ControllerConfig
      name: machine-config-controller
      uid: b0288238-f89e-41ca-ad96-dc8692409c40
    resourceVersion: "46508"
    uid: e099696d-0e0d-4b67-8ee7-35d1a22d79e7
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            source: data:,%5BGlobal%5D
          mode: 420
          overwrite: true
          path: /etc/kubernetes/cloud.conf
        - contents:
            source: data:,authorization%3A%0A%20%20static%3A%0A%20%20%20%20-%20resourceRequest%3A%20false%0A%20%20%20%20%20%20path%3A%20%2Fmetrics%0A%20%20%20%20%20%20verb%3A%20get%0A%20%20%20%20%20%20user%3A%0A%20%20%20%20%20%20%20%20name%3A%20system%3Aserviceaccount%3Aopenshift-monitoring%3Aprometheus-k8s
          mode: 420
          overwrite: true
          path: /etc/kubernetes/crio-metrics-proxy.cfg
        - contents:
            source: data:,apiVersion%3A%20v1%0Akind%3A%20Pod%0Ametadata%3A%0A%20%20name%3A%20kube-rbac-proxy-crio%0A%20%20namespace%3A%20openshift-machine-config-operator%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20etc-kube%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20hostNetwork%3A%20true%0A%20%20priorityClassName%3A%20system-cluster-critical%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20setup%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ae6c78ecf5ff15391d335577ffca87563ddd533727e52cf08217038a579f70dd9%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20command%3A%20%5B'%2Fbin%2Fbash'%2C%20'-ec'%5D%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20echo%20-n%20%22Waiting%20for%20kubelet%20key%20and%20certificate%20to%20be%20available%22%0A%20%20%20%20%20%20while%20%5B%20-n%20%22%24(test%20-e%20%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem)%22%20%5D%20%3B%20do%0A%20%20%20%20%20%20%20%20echo%20-n%20%22.%22%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20%20%20%20%20((%20tries%20%2B%3D%201%20))%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20%22%24%7Btries%7D%22%20-gt%2010%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Timed%20out%20waiting%20for%20kubelet%20key%20and%20cert.%22%0A%20%20%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20done%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20%20%20%20%20cpu%3A%205m%0A%20%20containers%3A%0A%20%20-%20name%3A%20kube-rbac-proxy-crio%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ae6c78ecf5ff15391d335577ffca87563ddd533727e52cf08217038a579f70dd9%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20ports%3A%0A%20%20%20%20-%20containerPort%3A%209637%0A%20%20%20%20args%3A%0A%20%20%20%20-%20--secure-listen-address%3D%3A9637%0A%20%20%20%20-%20--config-file%3D%2Fetc%2Fkubernetes%2Fcrio-metrics-proxy.cfg%0A%20%20%20%20-%20--client-ca-file%3D%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20%20%20-%20--logtostderr%3Dtrue%0A%20%20%20%20-%20--kubeconfig%3D%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%0A%20%20%20%20-%20--tls-cipher-suites%3DTLS_AES_128_GCM_SHA256%2CTLS_AES_256_GCM_SHA384%2CTLS_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%20%0A%20%20%20%20-%20--tls-min-version%3DVersionTLS12%0A%20%20%20%20-%20--upstream%3Dhttp%3A%2F%2F127.0.0.1%3A9537%0A%20%20%20%20-%20--tls-cert-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20-%20--tls-private-key-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%2020m%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20etc-kube%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/criometricsproxy.yaml
        - contents:
            source: data:,kind%3A%20KubeletConfiguration%0AapiVersion%3A%20kubelet.config.k8s.io%2Fv1beta1%0Aauthentication%3A%0A%20%20x509%3A%0A%20%20%20%20clientCAFile%3A%20%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20anonymous%3A%0A%20%20%20%20enabled%3A%20false%0AcgroupDriver%3A%20systemd%0AcgroupRoot%3A%20%2F%0AclusterDNS%3A%0A%20%20-%20172.30.0.10%0AclusterDomain%3A%20cluster.local%0AcontainerLogMaxSize%3A%2050Mi%0AenableSystemLogQuery%3A%20true%0AmaxPods%3A%20250%0AkubeAPIQPS%3A%2050%0AkubeAPIBurst%3A%20100%0ApodPidsLimit%3A%204096%0AprotectKernelDefaults%3A%20true%0ArotateCertificates%3A%20true%0AserializeImagePulls%3A%20false%0AstaticPodPath%3A%20%2Fetc%2Fkubernetes%2Fmanifests%0AsystemCgroups%3A%20%2Fsystem.slice%0AnodeStatusUpdateFrequency%3A%2010s%0AnodeStatusReportFrequency%3A%205m%0AserverTLSBootstrap%3A%20true%0AtlsMinVersion%3A%20VersionTLS12%0AtlsCipherSuites%3A%0A%20%20%20%20-%20TLS_AES_128_GCM_SHA256%0A%20%20%20%20-%20TLS_AES_256_GCM_SHA384%0A%20%20%20%20-%20TLS_CHACHA20_POLY1305_SHA256%0A%20%20%20%20-%20TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%0A%20%20%20%20-%20TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%0A%20%20%20%20-%20TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%0A%20%20%20%20-%20TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%0A%20%20%20%20-%20TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%0A%20%20%20%20-%20TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
        - contents:
            source: data:,%23!%2Fbin%2Fsh%0Aif%20%5B%20-x%20%2Fusr%2Fbin%2Fkubensenter%20%5D%3B%20then%0A%20%20exec%20%2Fusr%2Fbin%2Fkubensenter%20%22%24%40%22%0Aelse%0A%20%20exec%20%22%24%40%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/kubenswrapper
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet After Reboot Cleanup
            Before=kubelet.service

            [Service]
            Type=oneshot
            ExecStart=/bin/rm -f /var/lib/kubelet/cpu_manager_state
            ExecStart=/bin/rm -f /var/lib/kubelet/memory_manager_state
            ExecStart=-/bin/rm -f /var/lib/kubelet/dra_manager_state

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet-cleanup.service
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet
            Requires=crio.service kubelet-dependencies.target
            After=kubelet-dependencies.target
            After=ostree-finalize-staged.service

            [Service]
            Type=notify
            ExecStartPre=/bin/mkdir --parents /etc/kubernetes/manifests
            ExecStartPre=-/usr/sbin/restorecon -rv /var/lib/kubelet/ /usr/local/bin/kubenswrapper /usr/bin/kubensenter
            Environment="KUBELET_NODE_IP=0.0.0.0"
            EnvironmentFile=/etc/os-release
            EnvironmentFile=-/etc/kubernetes/kubelet-workaround
            EnvironmentFile=-/etc/kubernetes/kubelet-env
            EnvironmentFile=/etc/node-sizing.env

            ExecStart=/usr/local/bin/kubenswrapper \
                /usr/bin/kubelet \
                  --config=/etc/kubernetes/kubelet.conf \
                  --bootstrap-kubeconfig=/etc/kubernetes/kubeconfig \
                  --kubeconfig=/var/lib/kubelet/kubeconfig \
                  --container-runtime-endpoint=/var/run/crio/crio.sock \
                  --runtime-cgroups=/system.slice/crio.service \
                  --node-labels=node-role.kubernetes.io/control-plane,node-role.kubernetes.io/master,node.openshift.io/os_id=${ID} \
                  --node-ip=${KUBELET_NODE_IP} \
                  --minimum-container-ttl-duration=6m0s \
                  --cloud-provider=external \
                  --volume-plugin-dir=/etc/kubernetes/kubelet-plugins/volume/exec \
                  --image-credential-provider-bin-dir=/usr/libexec/kubelet-image-credential-provider-plugins --image-credential-provider-config=/etc/kubernetes/credential-providers/ecr-credential-provider.yaml \
                  --hostname-override=${KUBELET_NODE_NAME} \
                  --provider-id=${KUBELET_PROVIDERID} \
                  --register-with-taints=node-role.kubernetes.io/master=:NoSchedule \
                  --pod-infra-container-image=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8c3c9719ba85ce692f2462e653d82d154bd958dc57c236d6bc0a8092bb6b2080 \
                  --system-reserved=cpu=${SYSTEM_RESERVED_CPU},memory=${SYSTEM_RESERVED_MEMORY},ephemeral-storage=${SYSTEM_RESERVED_ES} \
                  --v=${KUBELET_LOG_LEVEL}

            Restart=always
            RestartSec=10

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet.service
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:ad394c1a0b0cc7d37e2bc632f795f9140ca3f68bc0f2ca2895b83125c61a7d2e
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: d656f31b697c2671aac38bbe46d9e5b22d27ae90
    creationTimestamp: "2024-11-20T22:36:29Z"
    generation: 2
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 01-worker-container-runtime
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: ControllerConfig
      name: machine-config-controller
      uid: b0288238-f89e-41ca-ad96-dc8692409c40
    resourceVersion: "46509"
    uid: 241b311d-75b2-4f01-ae9a-ff95d8db3167
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            source: data:,unqualified-search-registries%20%3D%20%5B'registry.access.redhat.com'%2C%20'docker.io'%5D%0A
          mode: 420
          overwrite: true
          path: /etc/containers/registries.conf
        - contents:
            source: data:,%5Bcrio%5D%0Ainternal_wipe%20%3D%20true%0Ainternal_repair%20%3D%20true%0A%0A%5Bcrio.api%5D%0Astream_address%20%3D%20%22127.0.0.1%22%0Astream_port%20%3D%20%220%22%0A%0A%5Bcrio.runtime%5D%0Aselinux%20%3D%20true%0Aconmon%20%3D%20%22%22%0Aconmon_cgroup%20%3D%20%22pod%22%0Adefault_env%20%3D%20%5B%0A%20%20%20%20%22NSS_SDB_USE_CACHE%3Dno%22%2C%0A%5D%0Alog_level%20%3D%20%22info%22%0Acgroup_manager%20%3D%20%22systemd%22%0Adefault_sysctls%20%3D%20%5B%0A%20%20%20%20%22net.ipv4.ping_group_range%3D0%202147483647%22%2C%0A%5D%0Adefault_runtime%20%3D%20%22crun%22%0Ahooks_dir%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Frun%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Fusr%2Fshare%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%5D%0Amanage_ns_lifecycle%20%3D%20true%0Aabsent_mount_sources_to_reject%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fhostname%22%2C%0A%5D%0Adrop_infra_ctr%20%3D%20true%0A%0A%5Bcrio.runtime.runtimes.runc%5D%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%0A%5Bcrio.runtime.runtimes.crun%5D%0Aruntime_root%20%3D%20%22%2Frun%2Fcrun%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%23%20Based%20on%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcrun%2Fblob%2F27d7dd3a0%2FREADME.md%3Fplain%3D1%23L48%0Acontainer_min_memory%20%3D%20%22512KiB%22%0A%0A%5Bcrio.runtime.workloads.openshift-builder%5D%0Aactivation_annotation%20%3D%20%22io.openshift.builder%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%22io.kubernetes.cri-o.userns-mode%22%2C%0A%20%20%22io.kubernetes.cri-o.Devices%22%0A%5D%0A%5Bcrio.runtime.workloads.openshift-builder.resources%5D%0A%0A%5Bcrio.image%5D%0Aglobal_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_image%20%3D%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A8c3c9719ba85ce692f2462e653d82d154bd958dc57c236d6bc0a8092bb6b2080%22%0Apause_image_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_command%20%3D%20%22%2Fusr%2Fbin%2Fpod%22%0A%0A%5Bcrio.network%5D%0Anetwork_dir%20%3D%20%22%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F%22%0Aplugin_dirs%20%3D%20%5B%0A%20%20%20%20%22%2Fvar%2Flib%2Fcni%2Fbin%22%2C%0A%20%20%20%20%22%2Fusr%2Flibexec%2Fcni%22%2C%0A%5D%0A%0A%5Bcrio.metrics%5D%0Aenable_metrics%20%3D%20true%0Ametrics_host%20%3D%20%22127.0.0.1%22%0Ametrics_port%20%3D%209537%0Ametrics_collectors%20%3D%20%5B%0A%20%20%22operations%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_total%22%0A%20%20%22operations_latency_microseconds_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds_total%22%0A%20%20%22operations_latency_microseconds%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds%22%0A%20%20%22operations_errors%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_errors_total%22%0A%20%20%22image_pulls_layer_size%22%2C%0A%20%20%22containers_oom_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22containers_oom_count_total%22%0A%20%20%22containers_oom%22%2C%0A%20%20%23%20Drop%20metrics%20with%20excessive%20label%20cardinality.%0A%20%20%23%20%22image_pulls_by_digest%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name_skipped%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_skipped_bytes_total%22%0A%20%20%23%20%22image_pulls_failures%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_failure_total%22%0A%20%20%23%20%22image_pulls_successes%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_success_total%22%0A%20%20%23%20%22image_layer_reuse%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_layer_reuse_total%22%0A%20%20%22operations_total%22%2C%0A%20%20%22operations_latency_seconds_total%22%2C%0A%20%20%22operations_latency_seconds%22%2C%0A%20%20%22operations_errors_total%22%2C%0A%20%20%22image_pulls_bytes_total%22%2C%0A%20%20%22image_pulls_skipped_bytes_total%22%2C%0A%20%20%22image_pulls_success_total%22%2C%0A%20%20%22image_pulls_failure_total%22%2C%0A%20%20%22image_layer_reuse_total%22%2C%0A%20%20%22containers_oom_count_total%22%2C%0A%20%20%22processes_defunct%22%0A%5D%0A
          mode: 420
          overwrite: true
          path: /etc/crio/crio.conf.d/00-default
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D
          mode: 420
          overwrite: true
          path: /etc/containers/policy.json
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:ad394c1a0b0cc7d37e2bc632f795f9140ca3f68bc0f2ca2895b83125c61a7d2e
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: d656f31b697c2671aac38bbe46d9e5b22d27ae90
    creationTimestamp: "2024-11-20T22:36:29Z"
    generation: 2
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 01-worker-kubelet
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: ControllerConfig
      name: machine-config-controller
      uid: b0288238-f89e-41ca-ad96-dc8692409c40
    resourceVersion: "46513"
    uid: 0c056b28-f915-4b0f-8a55-a5504ea2bf12
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            source: data:,%5BGlobal%5D
          mode: 420
          overwrite: true
          path: /etc/kubernetes/cloud.conf
        - contents:
            source: data:,authorization%3A%0A%20%20static%3A%0A%20%20%20%20-%20resourceRequest%3A%20false%0A%20%20%20%20%20%20path%3A%20%2Fmetrics%0A%20%20%20%20%20%20verb%3A%20get%0A%20%20%20%20%20%20user%3A%0A%20%20%20%20%20%20%20%20name%3A%20system%3Aserviceaccount%3Aopenshift-monitoring%3Aprometheus-k8s
          mode: 420
          overwrite: true
          path: /etc/kubernetes/crio-metrics-proxy.cfg
        - contents:
            source: data:,apiVersion%3A%20v1%0Akind%3A%20Pod%0Ametadata%3A%0A%20%20name%3A%20kube-rbac-proxy-crio%0A%20%20namespace%3A%20openshift-machine-config-operator%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20etc-kube%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20hostNetwork%3A%20true%0A%20%20priorityClassName%3A%20system-cluster-critical%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20setup%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ae6c78ecf5ff15391d335577ffca87563ddd533727e52cf08217038a579f70dd9%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20command%3A%20%5B'%2Fbin%2Fbash'%2C%20'-ec'%5D%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20echo%20-n%20%22Waiting%20for%20kubelet%20key%20and%20certificate%20to%20be%20available%22%0A%20%20%20%20%20%20while%20%5B%20-n%20%22%24(test%20-e%20%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem)%22%20%5D%20%3B%20do%0A%20%20%20%20%20%20%20%20echo%20-n%20%22.%22%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20%20%20%20%20((%20tries%20%2B%3D%201%20))%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20%22%24%7Btries%7D%22%20-gt%2010%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Timed%20out%20waiting%20for%20kubelet%20key%20and%20cert.%22%0A%20%20%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20done%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20%20%20%20%20cpu%3A%205m%0A%20%20containers%3A%0A%20%20-%20name%3A%20kube-rbac-proxy-crio%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ae6c78ecf5ff15391d335577ffca87563ddd533727e52cf08217038a579f70dd9%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20ports%3A%0A%20%20%20%20-%20containerPort%3A%209637%0A%20%20%20%20args%3A%0A%20%20%20%20-%20--secure-listen-address%3D%3A9637%0A%20%20%20%20-%20--config-file%3D%2Fetc%2Fkubernetes%2Fcrio-metrics-proxy.cfg%0A%20%20%20%20-%20--client-ca-file%3D%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20%20%20-%20--logtostderr%3Dtrue%0A%20%20%20%20-%20--kubeconfig%3D%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%0A%20%20%20%20-%20--tls-cipher-suites%3DTLS_AES_128_GCM_SHA256%2CTLS_AES_256_GCM_SHA384%2CTLS_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%20%0A%20%20%20%20-%20--tls-min-version%3DVersionTLS12%0A%20%20%20%20-%20--upstream%3Dhttp%3A%2F%2F127.0.0.1%3A9537%0A%20%20%20%20-%20--tls-cert-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20-%20--tls-private-key-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%2020m%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20etc-kube%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/criometricsproxy.yaml
        - contents:
            source: data:,kind%3A%20KubeletConfiguration%0AapiVersion%3A%20kubelet.config.k8s.io%2Fv1beta1%0Aauthentication%3A%0A%20%20x509%3A%0A%20%20%20%20clientCAFile%3A%20%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20anonymous%3A%0A%20%20%20%20enabled%3A%20false%0AcgroupDriver%3A%20systemd%0AcgroupRoot%3A%20%2F%0AclusterDNS%3A%0A%20%20-%20172.30.0.10%0AclusterDomain%3A%20cluster.local%0AcontainerLogMaxSize%3A%2050Mi%0AenableSystemLogQuery%3A%20true%0AmaxPods%3A%20250%0AkubeAPIQPS%3A%2050%0AkubeAPIBurst%3A%20100%0ApodPidsLimit%3A%204096%0AprotectKernelDefaults%3A%20true%0ArotateCertificates%3A%20true%0AserializeImagePulls%3A%20false%0AstaticPodPath%3A%20%2Fetc%2Fkubernetes%2Fmanifests%0AsystemCgroups%3A%20%2Fsystem.slice%0AnodeStatusUpdateFrequency%3A%2010s%0AnodeStatusReportFrequency%3A%205m%0AserverTLSBootstrap%3A%20true%0AtlsMinVersion%3A%20VersionTLS12%0AtlsCipherSuites%3A%0A%20%20%20%20-%20TLS_AES_128_GCM_SHA256%0A%20%20%20%20-%20TLS_AES_256_GCM_SHA384%0A%20%20%20%20-%20TLS_CHACHA20_POLY1305_SHA256%0A%20%20%20%20-%20TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%0A%20%20%20%20-%20TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%0A%20%20%20%20-%20TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%0A%20%20%20%20-%20TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%0A%20%20%20%20-%20TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%0A%20%20%20%20-%20TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
        - contents:
            source: data:,%23!%2Fbin%2Fsh%0Aif%20%5B%20-x%20%2Fusr%2Fbin%2Fkubensenter%20%5D%3B%20then%0A%20%20exec%20%2Fusr%2Fbin%2Fkubensenter%20%22%24%40%22%0Aelse%0A%20%20exec%20%22%24%40%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/kubenswrapper
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet After Reboot Cleanup
            Before=kubelet.service

            [Service]
            Type=oneshot
            ExecStart=/bin/rm -f /var/lib/kubelet/cpu_manager_state
            ExecStart=/bin/rm -f /var/lib/kubelet/memory_manager_state
            ExecStart=-/bin/rm -f /var/lib/kubelet/dra_manager_state

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet-cleanup.service
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet
            Requires=crio.service kubelet-dependencies.target
            After=kubelet-dependencies.target
            After=ostree-finalize-staged.service

            [Service]
            Type=notify
            ExecStartPre=/bin/mkdir --parents /etc/kubernetes/manifests
            ExecStartPre=-/usr/sbin/restorecon -rv /var/lib/kubelet/ /usr/local/bin/kubenswrapper /usr/bin/kubensenter
            Environment="KUBELET_NODE_IP=0.0.0.0"
            EnvironmentFile=/etc/os-release
            EnvironmentFile=-/etc/kubernetes/kubelet-workaround
            EnvironmentFile=-/etc/kubernetes/kubelet-env
            EnvironmentFile=/etc/node-sizing.env

            ExecStart=/usr/local/bin/kubenswrapper \
                /usr/bin/kubelet \
                  --config=/etc/kubernetes/kubelet.conf \
                  --bootstrap-kubeconfig=/etc/kubernetes/kubeconfig \
                  --kubeconfig=/var/lib/kubelet/kubeconfig \
                  --container-runtime-endpoint=/var/run/crio/crio.sock \
                  --runtime-cgroups=/system.slice/crio.service \
                  --node-labels=node-role.kubernetes.io/worker,node.openshift.io/os_id=${ID} \
                  --node-ip=${KUBELET_NODE_IP} \
                  --minimum-container-ttl-duration=6m0s \
                  --volume-plugin-dir=/etc/kubernetes/kubelet-plugins/volume/exec \
                  --cloud-provider=external \
                  --image-credential-provider-bin-dir=/usr/libexec/kubelet-image-credential-provider-plugins --image-credential-provider-config=/etc/kubernetes/credential-providers/ecr-credential-provider.yaml \
                  --hostname-override=${KUBELET_NODE_NAME} \
                  --provider-id=${KUBELET_PROVIDERID} \
                  --pod-infra-container-image=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8c3c9719ba85ce692f2462e653d82d154bd958dc57c236d6bc0a8092bb6b2080 \
                  --system-reserved=cpu=${SYSTEM_RESERVED_CPU},memory=${SYSTEM_RESERVED_MEMORY},ephemeral-storage=${SYSTEM_RESERVED_ES} \
                  --v=${KUBELET_LOG_LEVEL}

            Restart=always
            RestartSec=10

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet.service
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:ad394c1a0b0cc7d37e2bc632f795f9140ca3f68bc0f2ca2895b83125c61a7d2e
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: d656f31b697c2671aac38bbe46d9e5b22d27ae90
    creationTimestamp: "2024-11-20T22:36:29Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: master
    name: 97-master-generated-kubelet
    resourceVersion: "10106"
    uid: f76065ff-13f9-403e-adb2-5dad8ff0073c
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,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
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
    fips: false
    kernelArguments:
    - systemd.unified_cgroup_hierarchy=1
    - cgroup_no_v1="all"
    - psi=0
    kernelType: ""
    osImageURL: ""
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: d656f31b697c2671aac38bbe46d9e5b22d27ae90
    creationTimestamp: "2024-11-20T22:36:30Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 97-worker-generated-kubelet
    resourceVersion: "10137"
    uid: a9576134-6cf5-4278-820a-5ad25eadb46e
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,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
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
    fips: false
    kernelArguments:
    - systemd.unified_cgroup_hierarchy=1
    - cgroup_no_v1="all"
    - psi=0
    kernelType: ""
    osImageURL: ""
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: d656f31b697c2671aac38bbe46d9e5b22d27ae90
    creationTimestamp: "2024-11-20T22:36:29Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: master
    name: 98-master-generated-kubelet
    resourceVersion: "10082"
    uid: 889cadc1-d989-4ea7-81e0-0927e8ba8eb3
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,YXBpVmVyc2lvbjoga3ViZWxldC5jb25maWcuazhzLmlvL3YxYmV0YTEKYXV0aGVudGljYXRpb246CiAgYW5vbnltb3VzOgogICAgZW5hYmxlZDogZmFsc2UKICB3ZWJob29rOgogICAgY2FjaGVUVEw6IDBzCiAgeDUwOToKICAgIGNsaWVudENBRmlsZTogL2V0Yy9rdWJlcm5ldGVzL2t1YmVsZXQtY2EuY3J0CmF1dGhvcml6YXRpb246CiAgd2ViaG9vazoKICAgIGNhY2hlQXV0aG9yaXplZFRUTDogMHMKICAgIGNhY2hlVW5hdXRob3JpemVkVFRMOiAwcwpjZ3JvdXBEcml2ZXI6IHN5c3RlbWQKY2dyb3VwUm9vdDogLwpjbHVzdGVyRE5TOgotIDE3Mi4zMC4wLjEwCmNsdXN0ZXJEb21haW46IGNsdXN0ZXIubG9jYWwKY29udGFpbmVyTG9nTWF4U2l6ZTogNTBNaQpjb250YWluZXJSdW50aW1lRW5kcG9pbnQ6ICIiCmNwdU1hbmFnZXJSZWNvbmNpbGVQZXJpb2Q6IDBzCmVuYWJsZVN5c3RlbUxvZ1F1ZXJ5OiB0cnVlCmV2aWN0aW9uUHJlc3N1cmVUcmFuc2l0aW9uUGVyaW9kOiAwcwpmZWF0dXJlR2F0ZXM6CiAgQVdTQ2x1c3Rlckhvc3RlZEROUzogZmFsc2UKICBBV1NFRlNEcml2ZXJWb2x1bWVNZXRyaWNzOiB0cnVlCiAgQWRkaXRpb25hbFJvdXRpbmdDYXBhYmlsaXRpZXM6IGZhbHNlCiAgQWRtaW5OZXR3b3JrUG9saWN5OiB0cnVlCiAgQWxpYmFiYVBsYXRmb3JtOiB0cnVlCiAgQXV0b21hdGVkRXRjZEJhY2t1cDogZmFsc2UKICBBenVyZVdvcmtsb2FkSWRlbnRpdHk6IHRydWUKICBCYXJlTWV0YWxMb2FkQmFsYW5jZXI6IHRydWUKICBCb290Y05vZGVNYW5hZ2VtZW50OiBmYWxzZQogIEJ1aWxkQ1NJVm9sdW1lczogdHJ1ZQogIENTSURyaXZlclNoYXJlZFJlc291cmNlOiBmYWxzZQogIENodW5rU2l6ZU1pQjogdHJ1ZQogIENsb3VkRHVhbFN0YWNrTm9kZUlQczogdHJ1ZQogIENsdXN0ZXJBUElJbnN0YWxsOiBmYWxzZQogIENsdXN0ZXJBUElJbnN0YWxsSUJNQ2xvdWQ6IGZhbHNlCiAgQ2x1c3Rlck1vbml0b3JpbmdDb25maWc6IGZhbHNlCiAgRE5TTmFtZVJlc29sdmVyOiBmYWxzZQogIERpc2FibGVLdWJlbGV0Q2xvdWRDcmVkZW50aWFsUHJvdmlkZXJzOiB0cnVlCiAgRHluYW1pY1Jlc291cmNlQWxsb2NhdGlvbjogZmFsc2UKICBFdGNkQmFja2VuZFF1b3RhOiBmYWxzZQogIEV2ZW50ZWRQTEVHOiBmYWxzZQogIEV4YW1wbGU6IGZhbHNlCiAgRXh0ZXJuYWxPSURDOiBmYWxzZQogIEdDUENsdXN0ZXJIb3N0ZWRETlM6IGZhbHNlCiAgR0NQTGFiZWxzVGFnczogdHJ1ZQogIEdhdGV3YXlBUEk6IGZhbHNlCiAgSGFyZHdhcmVTcGVlZDogdHJ1ZQogIEltYWdlU3RyZWFtSW1wb3J0TW9kZTogZmFsc2UKICBJbmdyZXNzQ29udHJvbGxlckR5bmFtaWNDb25maWd1cmF0aW9uTWFuYWdlcjogZmFsc2UKICBJbmdyZXNzQ29udHJvbGxlckxCU3VibmV0c0FXUzogdHJ1ZQogIEluc2lnaHRzQ29uZmlnOiBmYWxzZQogIEluc2lnaHRzQ29uZmlnQVBJOiBmYWxzZQogIEluc2lnaHRzT25EZW1hbmREYXRhR2F0aGVyOiBmYWxzZQogIEluc2lnaHRzUnVudGltZUV4dHJhY3RvcjogZmFsc2UKICBLTVN2MTogdHJ1ZQogIE1hY2hpbmVBUElNaWdyYXRpb246IGZhbHNlCiAgTWFjaGluZUFQSU9wZXJhdG9yRGlzYWJsZU1hY2hpbmVIZWFsdGhDaGVja0NvbnRyb2xsZXI6IGZhbHNlCiAgTWFjaGluZUFQSVByb3ZpZGVyT3BlblN0YWNrOiBmYWxzZQogIE1hY2hpbmVDb25maWdOb2RlczogZmFsc2UKICBNYW5hZ2VkQm9vdEltYWdlczogdHJ1ZQogIE1hbmFnZWRCb290SW1hZ2VzQVdTOiBmYWxzZQogIE1heFVuYXZhaWxhYmxlU3RhdGVmdWxTZXQ6IGZhbHNlCiAgTWV0cmljc0NvbGxlY3Rpb25Qcm9maWxlczogZmFsc2UKICBNaXhlZENQVXNBbGxvY2F0aW9uOiBmYWxzZQogIE11bHRpQXJjaEluc3RhbGxBV1M6IHRydWUKICBNdWx0aUFyY2hJbnN0YWxsQXp1cmU6IGZhbHNlCiAgTXVsdGlBcmNoSW5zdGFsbEdDUDogdHJ1ZQogIE5ldHdvcmtEaWFnbm9zdGljc0NvbmZpZzogdHJ1ZQogIE5ldHdvcmtMaXZlTWlncmF0aW9uOiB0cnVlCiAgTmV0d29ya1NlZ21lbnRhdGlvbjogZmFsc2UKICBOZXdPTE06IGZhbHNlCiAgTm9kZURpc3J1cHRpb25Qb2xpY3k6IHRydWUKICBOb2RlU3dhcDogZmFsc2UKICBPVk5PYnNlcnZhYmlsaXR5OiBmYWxzZQogIE9uQ2x1c3RlckJ1aWxkOiBmYWxzZQogIE9wZW5TaGlmdFBvZFNlY3VyaXR5QWRtaXNzaW9uOiB0cnVlCiAgUGVyc2lzdGVudElQc0ZvclZpcnR1YWxpemF0aW9uOiBmYWxzZQogIFBpbm5lZEltYWdlczogZmFsc2UKICBQbGF0Zm9ybU9wZXJhdG9yczogZmFsc2UKICBQcml2YXRlSG9zdGVkWm9uZUFXUzogdHJ1ZQogIFByb2NNb3VudFR5cGU6IGZhbHNlCiAgUm91dGVBZHZlcnRpc2VtZW50czogZmFsc2UKICBSb3V0ZUV4dGVybmFsQ2VydGlmaWNhdGU6IGZhbHNlCiAgU2VydmljZUFjY291bnRUb2tlbk5vZGVCaW5kaW5nOiBmYWxzZQogIFNldEVJUEZvck5MQkluZ3Jlc3NDb250cm9sbGVyOiB0cnVlCiAgU2lnbmF0dXJlU3RvcmVzOiBmYWxzZQogIFNpZ3N0b3JlSW1hZ2VWZXJpZmljYXRpb246IGZhbHNlCiAgVHJhbnNsYXRlU3RyZWFtQ2xvc2VXZWJzb2NrZXRSZXF1ZXN0czogZmFsc2UKICBVcGdyYWRlU3RhdHVzOiBmYWxzZQogIFVzZXJOYW1lc3BhY2VzUG9kU2VjdXJpdHlTdGFuZGFyZHM6IGZhbHNlCiAgVXNlck5hbWVzcGFjZXNTdXBwb3J0OiBmYWxzZQogIFZTcGhlcmVDb250cm9sUGxhbmVNYWNoaW5lU2V0OiB0cnVlCiAgVlNwaGVyZURyaXZlckNvbmZpZ3VyYXRpb246IHRydWUKICBWU3BoZXJlTXVsdGlOZXR3b3JrczogZmFsc2UKICBWU3BoZXJlTXVsdGlWQ2VudGVyczogZmFsc2UKICBWU3BoZXJlU3RhdGljSVBzOiB0cnVlCiAgVmFsaWRhdGluZ0FkbWlzc2lvblBvbGljeTogdHJ1ZQogIFZvbHVtZUdyb3VwU25hcHNob3Q6IGZhbHNlCmZpbGVDaGVja0ZyZXF1ZW5jeTogMHMKaHR0cENoZWNrRnJlcXVlbmN5OiAwcwppbWFnZU1heGltdW1HQ0FnZTogMHMKaW1hZ2VNaW5pbXVtR0NBZ2U6IDBzCmtpbmQ6IEt1YmVsZXRDb25maWd1cmF0aW9uCmt1YmVBUElCdXJzdDogMTAwCmt1YmVBUElRUFM6IDUwCmxvZ2dpbmc6CiAgZmx1c2hGcmVxdWVuY3k6IDAKICBvcHRpb25zOgogICAganNvbjoKICAgICAgaW5mb0J1ZmZlclNpemU6ICIwIgogICAgdGV4dDoKICAgICAgaW5mb0J1ZmZlclNpemU6ICIwIgogIHZlcmJvc2l0eTogMAptYXhQb2RzOiAyNTAKbWVtb3J5U3dhcDoge30Kbm9kZVN0YXR1c1JlcG9ydEZyZXF1ZW5jeTogNW0wcwpub2RlU3RhdHVzVXBkYXRlRnJlcXVlbmN5OiAxMHMKcG9kUGlkc0xpbWl0OiA0MDk2CnByb3RlY3RLZXJuZWxEZWZhdWx0czogdHJ1ZQpyb3RhdGVDZXJ0aWZpY2F0ZXM6IHRydWUKcnVudGltZVJlcXVlc3RUaW1lb3V0OiAwcwpzZXJpYWxpemVJbWFnZVB1bGxzOiBmYWxzZQpzZXJ2ZXJUTFNCb290c3RyYXA6IHRydWUKc2h1dGRvd25HcmFjZVBlcmlvZDogMHMKc2h1dGRvd25HcmFjZVBlcmlvZENyaXRpY2FsUG9kczogMHMKc3RhdGljUG9kUGF0aDogL2V0Yy9rdWJlcm5ldGVzL21hbmlmZXN0cwpzdHJlYW1pbmdDb25uZWN0aW9uSWRsZVRpbWVvdXQ6IDBzCnN5bmNGcmVxdWVuY3k6IDBzCnN5c3RlbUNncm91cHM6IC9zeXN0ZW0uc2xpY2UKdGxzQ2lwaGVyU3VpdGVzOgotIFRMU19BRVNfMTI4X0dDTV9TSEEyNTYKLSBUTFNfQUVTXzI1Nl9HQ01fU0hBMzg0Ci0gVExTX0NIQUNIQTIwX1BPTFkxMzA1X1NIQTI1NgotIFRMU19FQ0RIRV9FQ0RTQV9XSVRIX0FFU18xMjhfR0NNX1NIQTI1NgotIFRMU19FQ0RIRV9SU0FfV0lUSF9BRVNfMTI4X0dDTV9TSEEyNTYKLSBUTFNfRUNESEVfRUNEU0FfV0lUSF9BRVNfMjU2X0dDTV9TSEEzODQKLSBUTFNfRUNESEVfUlNBX1dJVEhfQUVTXzI1Nl9HQ01fU0hBMzg0Ci0gVExTX0VDREhFX0VDRFNBX1dJVEhfQ0hBQ0hBMjBfUE9MWTEzMDVfU0hBMjU2Ci0gVExTX0VDREhFX1JTQV9XSVRIX0NIQUNIQTIwX1BPTFkxMzA1X1NIQTI1Ngp0bHNNaW5WZXJzaW9uOiBWZXJzaW9uVExTMTIKdm9sdW1lU3RhdHNBZ2dQZXJpb2Q6IDBzCg==
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: ""
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: d656f31b697c2671aac38bbe46d9e5b22d27ae90
    creationTimestamp: "2024-11-20T22:36:30Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 98-worker-generated-kubelet
    resourceVersion: "10117"
    uid: 3032efa7-1712-480c-83aa-b21f0504098d
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
      storage:
        files:
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,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
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: ""
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: d656f31b697c2671aac38bbe46d9e5b22d27ae90
    creationTimestamp: "2024-11-20T22:36:29Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: master
    name: 99-master-generated-registries
    ownerReferences:
    - apiVersion: config.openshift.io/v1
      kind: Image
      name: cluster
      uid: 8a5a738f-ee13-4ee0-8c75-c37cd1fd70ab
    resourceVersion: "10084"
    uid: 430fd52c-aabe-4860-ba9c-eb10ffe4a68e
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: ""
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    creationTimestamp: "2024-11-20T22:32:45Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: master
    name: 99-master-ssh
    resourceVersion: "2009"
    uid: 9c3fe4de-874c-4d05-8f08-690c11056ff2
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.2.0
      passwd:
        users:
        - name: core
          sshAuthorizedKeys:
          - |
            ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDLume21au7DO1U53hRBlP0FdJPJ85QEsm/ahjj3t9ZHUZkIZIZspYkAu6uahm6JReNnAbo2lDvVaVjq134BooT++WRIhk2X4hv7eUFYpBPaztjrTTG+COqLNJHZKNKa+KzRDEDk/TDsBSOgx35qZdC4l2VnJOkFXxGKMC/N4cW+NBJCdEOOz56LodPHmmIM1I0U97tuHkplw4+vMrAh8DgjoaxpijBlGOnVo3fD95EoG4D+d3RkOSsB3AsrkdyZa+A703NvSuIcofbOvXz5tBeKVlgpSyXUKywtKPr7J8UnWy3/ajGTDuY+kY/447Y+n1T5aU/iD8Xk2LTBhIZ7Z7SilYYWgV6Yr+z7DpLUqCBWlggI/Owp8XOaAPRETl3UPxFc4hKkE3cL8eu+Nw25ooUwY4Jikoq+r3WY2FCcVnQL2Rswf7z+pi8q49YaQV0mFGoow036+5f1JA/GvglDZEnKWMH8rwQw0Sw24FG+iC+1Fy6qrKoMFkz2nk4j8lZ368= nmoraiti@localhost.localdomain
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: ""
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: d656f31b697c2671aac38bbe46d9e5b22d27ae90
    creationTimestamp: "2024-11-20T22:36:29Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 99-worker-generated-registries
    ownerReferences:
    - apiVersion: config.openshift.io/v1
      kind: Image
      name: cluster
      uid: 8a5a738f-ee13-4ee0-8c75-c37cd1fd70ab
    resourceVersion: "10093"
    uid: 32a4202c-7e21-4d74-85d4-53e7f410aa8e
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.4.0
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: ""
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    creationTimestamp: "2024-11-20T22:32:46Z"
    generation: 1
    labels:
      machineconfiguration.openshift.io/role: worker
    name: 99-worker-ssh
    resourceVersion: "2040"
    uid: dd4a2ee1-1775-40d6-a7bb-9d1d5b420e99
  spec:
    baseOSExtensionsContainerImage: ""
    config:
      ignition:
        version: 3.2.0
      passwd:
        users:
        - name: core
          sshAuthorizedKeys:
          - |
            ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDLume21au7DO1U53hRBlP0FdJPJ85QEsm/ahjj3t9ZHUZkIZIZspYkAu6uahm6JReNnAbo2lDvVaVjq134BooT++WRIhk2X4hv7eUFYpBPaztjrTTG+COqLNJHZKNKa+KzRDEDk/TDsBSOgx35qZdC4l2VnJOkFXxGKMC/N4cW+NBJCdEOOz56LodPHmmIM1I0U97tuHkplw4+vMrAh8DgjoaxpijBlGOnVo3fD95EoG4D+d3RkOSsB3AsrkdyZa+A703NvSuIcofbOvXz5tBeKVlgpSyXUKywtKPr7J8UnWy3/ajGTDuY+kY/447Y+n1T5aU/iD8Xk2LTBhIZ7Z7SilYYWgV6Yr+z7DpLUqCBWlggI/Owp8XOaAPRETl3UPxFc4hKkE3cL8eu+Nw25ooUwY4Jikoq+r3WY2FCcVnQL2Rswf7z+pi8q49YaQV0mFGoow036+5f1JA/GvglDZEnKWMH8rwQw0Sw24FG+iC+1Fy6qrKoMFkz2nk4j8lZ368= nmoraiti@localhost.localdomain
    fips: false
    kernelArguments: null
    kernelType: ""
    osImageURL: ""
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: d656f31b697c2671aac38bbe46d9e5b22d27ae90
      machineconfiguration.openshift.io/release-image-version: 4.18.0-ec.3
    creationTimestamp: "2024-11-20T23:24:40Z"
    generation: 1
    name: rendered-master-1f718b5bc3667e49797e9a47d9f48725
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: MachineConfigPool
      name: master
      uid: 8cbf0d60-4f8f-4dfc-932a-7172d44d6e89
    resourceVersion: "46712"
    uid: af472560-687d-4ce6-a84e-409f7538a973
  spec:
    baseOSExtensionsContainerImage: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f135a14056f31c9c21782ac194f527e358d59a67e20ccf75f08706cc68c8c980
    config:
      ignition:
        version: 3.4.0
      passwd:
        users:
        - name: core
          sshAuthorizedKeys:
          - |
            ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDLume21au7DO1U53hRBlP0FdJPJ85QEsm/ahjj3t9ZHUZkIZIZspYkAu6uahm6JReNnAbo2lDvVaVjq134BooT++WRIhk2X4hv7eUFYpBPaztjrTTG+COqLNJHZKNKa+KzRDEDk/TDsBSOgx35qZdC4l2VnJOkFXxGKMC/N4cW+NBJCdEOOz56LodPHmmIM1I0U97tuHkplw4+vMrAh8DgjoaxpijBlGOnVo3fD95EoG4D+d3RkOSsB3AsrkdyZa+A703NvSuIcofbOvXz5tBeKVlgpSyXUKywtKPr7J8UnWy3/ajGTDuY+kY/447Y+n1T5aU/iD8Xk2LTBhIZ7Z7SilYYWgV6Yr+z7DpLUqCBWlggI/Owp8XOaAPRETl3UPxFc4hKkE3cL8eu+Nw25ooUwY4Jikoq+r3WY2FCcVnQL2Rswf7z+pi8q49YaQV0mFGoow036+5f1JA/GvglDZEnKWMH8rwQw0Sw24FG+iC+1Fy6qrKoMFkz2nk4j8lZ368= nmoraiti@localhost.localdomain
      storage:
        files:
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0ANM_DEVICES_DIR%3D%2Frun%2FNetworkManager%2Fdevices%0ANM_RUN_CONN_DIR%3D%2Frun%2FNetworkManager%2Fsystem-connections%0ANM_ETC_CONN_DIR%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A%0Alogger%20-t%20nm-clean-initrd-state%20%22Cleaning%20network%20activation%20state%20generated%20by%20dracut...%22%0Alogger%20-t%20nm-clean-initrd-state%20%22To%20disable%2C%20remove%20%2Fvar%2Flib%2Fmco%2Fnm-clean-initrd-state%22%0A%0Aif%20%5B%20!%20-e%20%22%24NM_DEVICES_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_RUN_CONN_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_ETC_CONN_DIR%22%20%5D%3B%20then%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22There%20is%20no%20network%20activation%20state%20to%20clean%22%0A%20%20exit%0Afi%0A%0A%23%20Some%20deployments%20require%20an%20active%20network%20early%20in%20the%20boot%20process.%20To%0A%23%20achieve%20this%2C%20dracut%20runs%20specific%20NetworkManager%20modules.%20This%20results%20in%0A%23%20NetworkManager%20keyfiles%20being%20generated%20(either%20default%20or%20from%20ip%20kernel%0A%23%20arguments)%20and%20activated.%20This%20activation%20generates%20state%20that%20makes%20those%0A%23%20profiles%20to%20be%20re-activated%20by%20the%20NetworkManager%20service%20later%20in%20the%0A%23%20boot%20process.%20And%20this%20has%20the%20effect%20that%20other%20profiles%20deployed%20by%20the%0A%23%20user%20for%20the%20same%20set%20of%20devices%20are%20ignored.%0A%0A%23%20Most%20of%20the%20time%20this%20is%20the%20desired%20behavior.%20The%20exception%20to%20this%20rule%0A%23%20is%20when%20the%20user%20wants%20to%20run%20the%20boot%20process%20with%20a%20different%20network%0A%23%20setup%20than%20the%20real%20root%20which%20is%20usually%20related%20to%20the%20fact%20that%0A%23%20generating%20images%20with%20customized%20kernel%20arguments%20is%20a%20complication%20in%0A%23%20the%20deployment%20pipeline.%0A%0A%23%20This%20need%20has%20been%20exacerbated%20by%20past%20NetworkManager%20bugs%20that%20activated%0A%23%20the%20network%20on%20boot%20when%20it%20was%20not%20really%20needed.%20Most%20notably%20when%20ip%0A%23%20kernel%20argument%20is%20present%2C%20something%20that%20the%20baremetal%20installer%20adds%20by%0A%23%20default.%0A%0A%23%20The%20intention%20here%20is%20to%20remove%20the%20state%20that%20was%20generated%20with%20the%0A%23%20activation%20of%20those%20profiles%20during%20dracut%20execution.%20Then%20when%0A%23%20NetworkManager%20service%20runs%2C%20the%20profiles%20generated%20by%20dracut%2C%20along%20with%0A%23%20other%20profiles%20configured%20by%20the%20user%2C%20are%20evaluated%20towards%20finding%20the%0A%23%20most%20appropriate%20profile%20to%20connect%20a%20device%20with.%20As%20a%20precaution%2C%20clean%0A%23%20state%20only%20for%20devices%20that%3A%0A%23%20-%20have%20been%20activated%20with%20a%20default%20profile%20(assume%20that%20a%20non-default%0A%23%20%20%20configuration%20expresses%20intention%20by%20user%20to%20run%20with%20it%20permanently)%0A%23%20-%20have%20a%20specific%20configured%20profile%20set%20to%20auto-connect%20(if%20there%20is%20no%0A%23%20%20%20alternate%20configured%20profile%20for%20a%20device%20it%20makes%20no%20sense%20to%0A%23%20%20%20de-activate%20anything)%0A%23%0A%23%20Although%20this%20can%20theoretically%20happen%20on%20any%20deployment%20type%2C%20need%20has%0A%23%20mostly%20come%20from%20IPI%20bare%20metal%20deployments.%20For%20the%20time%20being%2C%20this%0A%23%20should%20be%20opt-in%20in%20any%20other%20deploment%20type.%0A%23%0A%23%20There%20is%20an%20RFE%20filed%20against%20NM%20that%20once%20implemented%20would%20make%20this%0A%23%20script%20unnecessary%3A%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D2089707%0A%0Afor%20device%20in%20%22%24%7BNM_DEVICES_DIR%7D%22%2F*%3B%20do%0A%20%20if%20%5B%20!%20-e%20%22%24device%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20the%20device%20file%20name%20is%20the%20ifindex%0A%20%20ifindex%3D%24(basename%20%22%24device%22)%0A%20%20%0A%20%20%23%20get%20the%20interface%20name%20by%20ifindex%0A%20%20ifname%3D%24(ip%20-j%20link%20show%20%7C%20jq%20-r%20%22.%5B%5D%20%7C%20select(.ifindex%20%3D%3D%20%24%7Bifindex%7D)%20%7C%20.ifname%20%2F%2F%20empty%22)%0A%0A%20%20%23%20no%20interface%20name%20found%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20get%20the%20uuid%20of%20the%20profile%20the%20device%20has%20been%20activated%20with%0A%20%20active_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bdevice%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Econnection-uuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24device%22)%0A%0A%20%20%23%20the%20device%20was%20not%20activated%20with%20any%20profile%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24active_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20generated%20profile%20by%20uuid%0A%20%20for%20profile%20in%20%22%24%7BNM_RUN_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20generated_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24active_profile_uuid%22%20%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20generated%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24active_profile_uuid%22%20!%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20check%20that%20it%20is%20not%20specific%20for%20the%20device%2C%20otherwise%20ignore%0A%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24profile_ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20profile%20not%20generated%20by%20nm-initrd-generator%2C%20ignore%0A%20%20%23%20only%20check%20it%20if%20the%20key%20is%20set%20(from%20NM%201.32.4)%0A%20%20origin%3D%24(sed%20-nr%20'%2F%5E%5C%5Buser%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eorg.freedesktop.NetworkManager.origin%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24origin%22%20%5D%20%26%26%20%5B%20%22%24origin%22%20!%3D%20%22nm-initrd-generator%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20configured%20profile%20by%20name%20with%20auto-connect%20set%0A%20%20for%20profile%20in%20%22%24%7BNM_ETC_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20autoconnect%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eautoconnect%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24profile_ifname%22%20%3D%20%22%24ifname%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20configured%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24profile_ifname%22%20!%3D%20%22%24ifname%22%20%5D%20%7C%7C%20%5B%20%22%24autoconnect%22%20%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20configured_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20activated%20with%20default%20generated%20profile%20%24generated_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20has%20different%20configured%20specific%20profile%20%24configured_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%3A%20removing%20state...%22%0A%20%20%0A%20%20%23%20NM%20can%20still%20generate%20internal%20profiles%20from%20the%20IP%20address%0A%20%20%23%20configuration%20of%20devices%2C%20so%20flush%20addresses%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Flushing%20IP%20addresses%20from%20%24ifname%22%0A%20%20ip%20addr%20flush%20%22%24ifname%22%0A%20%20ip%20-6%20addr%20flush%20%22%24ifname%22%0A%0A%20%20%23%20remove%20device%20state%20file%20to%20prevent%20NM%20to%20unilaterally%20connect%20with%20the%0A%20%20%23%20latest%20activated%20profile%20without%20evaluating%20other%20profiles%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Removing%20%24device%22%0A%20%20rm%20-f%20--%20%22%24device%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nm-clean-initrd-state.sh
        - contents:
            source: data:,%5Bconnection%5D%0Aipv6.dhcp-duid%3Dll%0Aipv6.dhcp-iaid%3Dmac%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/01-ipv6.conf
        - contents:
            source: data:,%5Bmain%5D%0Aplugins%3Dkeyfile%2Cifcfg-rh%0A%5Bkeyfile%5D%0Apath%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/20-keyfiles.conf
        - contents:
            source: data:,
          mode: 384
          overwrite: true
          path: /etc/pki/ca-trust/source/anchors/openshift-config-user-ca-bundle.crt
        - contents:
            source: data:,KUBERNETES_SERVICE_HOST%3D'api-int.ci-ln-hz4dqct-76ef8.aws-2.ci.openshift.org'%0AKUBERNETES_SERVICE_PORT%3D'6443'%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/apiserver-url.env
        - contents:
            source: data:,%23%20This%20file%20is%20managed%20by%20machine-config-operator.%0A%23%20Suppress%20audit%20rules%20which%20always%20trigger%20for%20container%0A%23%20workloads%2C%20as%20they%20spam%20the%20audit%20log.%20%20Workloads%20are%20expected%0A%23%20to%20be%20dynamic%2C%20and%20the%20networking%20stack%20uses%20iptables.%0A-a%20exclude%2Calways%20-F%20msgtype%3DNETFILTER_CFG%0A%23%20The%20default%20bridged%20networking%20enables%20promiscuous%20on%20the%20veth%0A%23%20device.%20%20Ideally%2C%20we'd%20teach%20audit%20to%20ignore%20only%20veth%20devices%2C%0A%23%20since%20one%20might%20legitimately%20care%20about%20promiscuous%20on%20real%20physical%0A%23%20devices.%20%20But%20we%20can't%20currently%20differentiate.%0A-a%20exclude%2Calways%20-F%20msgtype%3DANOM_PROMISCUOUS%0A
          mode: 420
          overwrite: true
          path: /etc/audit/rules.d/mco-audit-quiet-containers.rules
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20It%20has%20been%20observed%20that%20the%20kernel%20enables%20ESP%20offloads%20of%20bond%0A%23%20devices%20in%20active%2Fbackup%20mode%20even%20if%20slaves%20apparently%20don't%20support%0A%23%20it.%20It's%20unclear%20if%20this%20is%20expected%20behavior%20but%20we%20have%20had%20problems%0A%23%20with%20the%20resulting%20configuration%20in%20vsphere.%20So%20set%20ESP%20offload%20features%0A%23%20off%20in%20bond%20devices%20if%20they%20are%20off%20in%20slave%20devices%20for%20the%20time%20being.%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FRHEL-58811%0A%0Aif%20%5B%5B%20%22%242%22%20!%3D%20%22up%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24DEVICE_IFACE%22)%0A%0Aif%20%5B%5B%20%22%24driver%22%20!%3D%20%22bond%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Abond%3D%22%24DEVICE_IFACE%22%0Afor%20feature%20in%20tx-esp-segmentation%20esp-hw-offload%20esp-tx-csum-hw-offload%3B%20do%0A%0A%20%20if%20ethtool%20-k%20%22%24bond%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%23%20already%20disabled%2C%20nothing%20to%20do%0A%20%20%20%20continue%0A%20%20fi%0A%20%20%0A%20%20for%20slave%20in%20%24(nmcli%20-g%20BOND.SLAVES%20dev%20show%20%22%24DEVICE_IFACE%22)%3B%20do%0A%0A%20%20%20%20if%20!%20ethtool%20-k%20%22%24slave%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%20%20%23%20enabled%20in%20slave%2C%20nothing%20to%20do%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20logger%20-t%20bond-esp-offload%20-s%20%22Bond%20link%20%24slave%20has%20%24feature%20off%2C%20setting%20master%20%24DEVICE_IFACE%20%24feature%20off%22%0A%20%20%20%20ethtool%20-K%20%22%24bond%22%20%22%24feature%22%20off%0A%0A%20%20%20%20break%0A%20%20done%0Adone%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-bond-esp-offload
        - contents:
            source: data:,r%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F80-openshift-network.conf%0Ar%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F10-ovn-kubernetes.conf%0Ad%20%2Frun%2Fmultus%2Fcni%2Fnet.d%2F%200755%20root%20root%20-%20-%0AD%20%2Fvar%2Flib%2Fcni%2Fnetworks%2Fopenshift-sdn%2F%200755%20root%20root%20-%20-%0A
          mode: 420
          overwrite: true
          path: /etc/tmpfiles.d/cleanup-cni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Skipping%20configure-ovs%20due%20to%20manual%20network%20configuration%22%0A%20%20exit%200%0Afi%0A%0A%23%20This%20file%20is%20not%20needed%20anymore%20in%204.7%2B%2C%20but%20when%20rolling%20back%20to%204.6%0A%23%20the%20ovs%20pod%20needs%20it%20to%20know%20ovs%20is%20running%20on%20the%20host.%0Atouch%20%2Fvar%2Frun%2Fovs-config-executed%0A%0A%23%20These%20are%20well%20knwon%20NM%20default%20paths%0ANM_CONN_ETC_PATH%3D%22%2Fetc%2FNetworkManager%2Fsystem-connections%22%0ANM_CONN_RUN_PATH%3D%22%2Frun%2FNetworkManager%2Fsystem-connections%22%0A%0A%23%20This%20is%20the%20path%20where%20NM%20is%20known%20to%20be%20configured%20to%20store%20user%20keyfiles%20%0ANM_CONN_CONF_PATH%3D%22%24NM_CONN_ETC_PATH%22%0A%0A%23%20This%20is%20where%20we%20want%20our%20keyfiles%20to%20finally%20reside.%20configure-ovs%0A%23%20operates%20with%20temporary%20keyfiles%20in%20NM_CONN_RUN_PATH%20and%20then%20as%20a%20last%0A%23%20step%20moves%20those%20keyfiles%20to%20NM_CONN_SET_PATH%20if%20it%20is%20a%20different%20path%0A%23%20(not%20by%20default).%20This%20mitigates%20hard%20interruptions%20(SIGKILL%2C%20hard%20reboot)%0A%23%20of%20configure-ovs%20leaving%20the%20machine%20with%20a%20half-baked%20set%20of%20keyfiles%0A%23%20that%20might%20prevent%20machine%20networking%20from%20working%20correctly.%0ANM_CONN_SET_PATH%3D%22%24%7BNM_CONN_SET_PATH%3A-%24NM_CONN_RUN_PATH%7D%22%0A%0AMANAGED_NM_CONN_SUFFIX%3D%22-slave-ovs-clone%22%0A%23%20Workaround%20to%20ensure%20OVS%20is%20installed%20due%20to%20bug%20in%20systemd%20Requires%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1888017%0Acopy_nm_conn_files()%20%7B%0A%20%20local%20dst_path%3D%22%241%22%0A%20%20for%20src%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20src_path%3D%24(dirname%20%22%24src%22)%0A%20%20%20%20file%3D%24(basename%20%22%24src%22)%0A%20%20%20%20if%20%5B%20-f%20%22%24src_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%24dst_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20elif%20!%20cmp%20--silent%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20updated%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20-f%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it's%20equal%20at%20destination%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it%20does%20not%20exist%20at%20source%22%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0Aupdate_nm_conn_files_base()%20%7B%0A%20%20base_path%3D%24%7B1%7D%0A%20%20bridge_name%3D%24%7B2%7D%0A%20%20port_name%3D%24%7B3%7D%0A%20%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%20%20%23%20In%20RHEL7%20files%20in%20%2F%7Betc%2Crun%7D%2FNetworkManager%2Fsystem-connections%20end%20without%20the%20suffix%20'.nmconnection'%2C%20whereas%20in%20RHCOS%20they%20end%20with%20the%20suffix.%0A%20%20MANAGED_NM_CONN_FILES%3D(%24(echo%20%22%24%7Bbase_path%7D%22%2F%7B%22%24bridge_name%22%2C%22%24ovs_interface%22%2C%22%24ovs_port%22%2C%22%24bridge_interface_name%22%2C%22%24default_port_name%22%7D%7B%2C.nmconnection%7D))%0A%20%20shopt%20-s%20nullglob%0A%20%20MANAGED_NM_CONN_FILES%2B%3D(%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D.nmconnection%20%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D)%0A%20%20shopt%20-u%20nullglob%0A%7D%0A%0Aupdate_nm_conn_run_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_RUN_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_set_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_SET_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0A%23%20Move%20and%20reload%20keyfiles%20at%20their%20final%20destination%0Aset_nm_conn_files()%20%7B%0A%20%20if%20%5B%20%22%24NM_CONN_RUN_PATH%22%20!%3D%20%22%24NM_CONN_SET_PATH%22%20%5D%3B%20then%0A%20%20%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%20%20%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%0A%20%20%20%20%23%20reload%20keyfiles%0A%20%20%20%20nmcli%20connection%20reload%0A%20%20fi%0A%7D%0A%0A%23%20Used%20to%20remove%20files%20managed%20by%20configure-ovs%20and%20temporary%20leftover%20files%20from%20network%20manager%0Arm_nm_conn_files()%20%7B%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20rm%20-f%20%22%24file%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20file%20%24file%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20fi%0A%20%20done%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20for%20temp%20in%20%24(compgen%20-G%20%22%24%7Bfile%7D.*%22)%3B%20do%0A%20%20%20%20%20%20rm%20-f%20%22%24temp%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20temporary%20file%20%24temp%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20done%0A%20%20done%0A%7D%0A%0A%23%20Used%20to%20clone%20a%20slave%20connection%20by%20uuid%2C%20returns%20new%20name%0Aclone_slave_connection()%20%7B%0A%20%20local%20uuid%3D%22%241%22%0A%20%20local%20old_name%0A%20%20old_name%3D%22%24(nmcli%20-g%20connection.id%20connection%20show%20uuid%20%22%24uuid%22)%22%0A%20%20local%20new_name%3D%22%24%7Bold_name%7D%24%7BMANAGED_NM_CONN_SUFFIX%7D%22%0A%20%20if%20nmcli%20connection%20show%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20existing%20ovs%20slave%20%24%7Bnew_name%7D%20connection%20profile%20file%20found%2C%20overwriting...%22%20%3E%262%0A%20%20%20%20nmcli%20connection%20delete%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%0A%20%20fi%0A%20%20clone_nm_conn%20%24uuid%20%22%24%7Bnew_name%7D%22%0A%20%20echo%20%22%24%7Bnew_name%7D%22%0A%7D%0A%0A%23%20Used%20to%20replace%20an%20old%20master%20connection%20uuid%20with%20a%20new%20one%20on%20all%20connections%0Areplace_connection_master()%20%7B%0A%20%20local%20old%3D%22%241%22%0A%20%20local%20new%3D%22%242%22%0A%20%20for%20conn_uuid%20in%20%24(nmcli%20-g%20UUID%20connection%20show)%20%3B%20do%0A%20%20%20%20if%20%5B%20%22%24(nmcli%20-g%20connection.master%20connection%20show%20uuid%20%22%24conn_uuid%22)%22%20!%3D%20%22%24old%22%20%5D%3B%20then%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20local%20autoconnect%3D%24(nmcli%20-g%20connection.autoconnect%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20!%3D%20%22activated%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Assume%20that%20slave%20profiles%20intended%20to%20be%20used%20are%20those%20that%20are%3A%0A%20%20%20%20%20%20%23%20-%20active%0A%20%20%20%20%20%20%23%20-%20or%20inactive%20(which%20might%20be%20due%20to%20link%20being%20down)%20but%20to%20be%20autoconnected.%0A%20%20%20%20%20%20%23%20Otherwise%2C%20ignore%20them.%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20make%20changes%20for%20slave%20profiles%20in%20a%20new%20clone%0A%20%20%20%20local%20new_name%0A%20%20%20%20new_name%3D%24(clone_slave_connection%20%24conn_uuid)%0A%0A%20%20%20%20mod_nm_conn%20%22%24new_name%22%20connection.master%20%22%24new%22%20connection.autoconnect-priority%20100%20connection.autoconnect%20no%20%0A%20%20%20%20echo%20%22Replaced%20master%20%24old%20with%20%24new%20for%20slave%20profile%20%24new_name%22%0A%20%20done%0A%7D%0A%0A%23%20when%20creating%20the%20bridge%2C%20we%20use%20a%20value%20lower%20than%20NM's%20ethernet%20device%20default%20route%20metric%0A%23%20(we%20pick%2048%20and%2049%20to%20be%20lower%20than%20anything%20that%20NM%20chooses%20by%20default)%0ABRIDGE_METRIC%3D%2248%22%0ABRIDGE1_METRIC%3D%2249%22%0A%23%20Given%20an%20interface%2C%20generates%20NM%20configuration%20to%20add%20to%20an%20OVS%20bridge%0Aconvert_to_bridge()%20%7B%0A%20%20local%20iface%3D%24%7B1%7D%0A%20%20local%20bridge_name%3D%24%7B2%7D%0A%20%20local%20port_name%3D%24%7B3%7D%0A%20%20local%20bridge_metric%3D%24%7B4%7D%0A%20%20local%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20local%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20local%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20local%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%0A%20%20if%20%5B%20%22%24iface%22%20%3D%20%22%24bridge_name%22%20%5D%3B%20then%0A%20%20%20%20%23%20handle%20vlans%20and%20bonds%20etc%20if%20they%20have%20already%20been%0A%20%20%20%20%23%20configured%20via%20nm%20key%20files%20and%20br-ex%20is%20already%20up%0A%20%20%20%20ifaces%3D%24(ovs-vsctl%20list-ifaces%20%24%7Biface%7D)%0A%20%20%20%20for%20intf%20in%20%24ifaces%3B%20do%20configure_driver_options%20%24intf%3B%20done%0A%20%20%20%20echo%20%22Networking%20already%20configured%20and%20up%20for%20%24%7Bbridge-name%7D!%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20flag%20to%20reload%20NM%20to%20account%20for%20all%20the%20configuration%20changes%0A%20%20%23%20going%20forward%0A%20%20nm_config_changed%3D1%0A%0A%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20Unable%20to%20find%20default%20gateway%20interface%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20%23%20find%20the%20MAC%20from%20OVS%20config%20or%20the%20default%20interface%20to%20use%20for%20OVS%20internal%20port%0A%20%20%23%20this%20prevents%20us%20from%20getting%20a%20different%20DHCP%20lease%20and%20dropping%20connection%0A%20%20if%20!%20iface_mac%3D%24(%3C%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface%7D%2Faddress%22)%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MAC%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20echo%20%22MAC%20address%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mac%7D%22%0A%0A%20%20%23%20find%20MTU%20from%20original%20iface%0A%20%20iface_mtu%3D%24(ip%20link%20show%20%22%24iface%22%20%7C%20awk%20'%7Bprint%20%245%3B%20exit%7D')%0A%20%20if%20%5B%5B%20-z%20%22%24iface_mtu%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MTU%2C%20defaulting%20to%201500%22%0A%20%20%20%20iface_mtu%3D1500%0A%20%20else%0A%20%20%20%20echo%20%22MTU%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mtu%7D%22%0A%20%20fi%0A%0A%20%20%23%20store%20old%20conn%20for%20later%0A%20%20old_conn%3D%24(nmcli%20--fields%20UUID%2CDEVICE%20conn%20show%20--active%20%7C%20awk%20%22%2F%5Cs%24%7Biface%7D%5Cs*%5C%24%2F%20%7Bprint%20%5C%241%7D%22)%0A%0A%20%20if%20%5B%5B%20-z%20%22%24old_conn%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20cannot%20find%20connection%20for%20interface%3A%20%24%7Biface%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20create%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24bridge_name%22%20type%20ovs-bridge%20conn.interface%20%22%24bridge_name%22%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20%23%20find%20default%20port%20to%20add%20to%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24default_port_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%24%7Biface%7D%0A%20%20%20%20add_nm_conn%20%22%24default_port_name%22%20type%20ovs-port%20conn.interface%20%24%7Biface%7D%20master%20%22%24bridge_name%22%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_port%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24ovs_port%22%20type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24bridge_name%22%0A%20%20fi%0A%0A%20%20extra_phys_args%3D()%0A%20%20%23%20check%20if%20this%20interface%20is%20a%20vlan%2C%20bond%2C%20team%2C%20or%20ethernet%20type%0A%20%20if%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22vlan%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dvlan%0A%20%20%20%20vlan_id%3D%24(nmcli%20--get-values%20vlan.id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_id%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20vlan.parent%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_parent%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_parent%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20nmcli%20connection%20show%20uuid%20%22%24vlan_parent%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20%20%20%23%20if%20the%20VLAN%20connection%20is%20configured%20with%20a%20connection%20UUID%20as%20parent%2C%20we%20need%20to%20find%20the%20underlying%20device%0A%20%20%20%20%20%20%23%20and%20create%20the%20bridge%20against%20it%2C%20as%20the%20parent%20connection%20can%20be%20replaced%20by%20another%20bridge.%0A%20%20%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20GENERAL.DEVICES%20conn%20show%20uuid%20%24%7Bvlan_parent%7D)%0A%20%20%20%20fi%0A%0A%20%20%20%20extra_phys_args%3D(%20dev%20%22%24%7Bvlan_parent%7D%22%20id%20%22%24%7Bvlan_id%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbond%0A%20%20%20%20%23%20check%20bond%20options%0A%20%20%20%20bond_opts%3D%24(nmcli%20--get-values%20bond.options%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24bond_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20bond.options%20%22%24%7Bbond_opts%7D%22%20)%0A%20%20%20%20%20%20MODE_REGEX%3D%22(%5E%7C%2C)mode%3Dactive-backup(%2C%7C%24)%22%0A%20%20%20%20%20%20MAC_REGEX%3D%22(%5E%7C%2C)fail_over_mac%3D(1%7Cactive%7C2%7Cfollow)(%2C%7C%24)%22%0A%20%20%20%20%20%20if%20%5B%5B%20%24bond_opts%20%3D~%20%24MODE_REGEX%20%5D%5D%20%26%26%20%5B%5B%20%24bond_opts%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22team%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dteam%0A%20%20%20%20%23%20check%20team%20config%20options%0A%20%20%20%20team_config_opts%3D%24(nmcli%20--get-values%20team.config%20-e%20no%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24team_config_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20team.config%20is%20json%2C%20remove%20spaces%20to%20avoid%20problems%20later%20on%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20team.config%20%22%24%7Bteam_config_opts%2F%2F%5B%5B%3Aspace%3A%5D%5D%2F%7D%22%20)%0A%20%20%20%20%20%20team_mode%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.name%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20team_mac_policy%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.hwaddr_policy%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20MAC_REGEX%3D%22(by_active%7Conly_active)%22%0A%20%20%20%20%20%20if%20%5B%20%22%24team_mode%22%20%3D%20%22activebackup%22%20%5D%20%26%26%20%5B%5B%20%22%24team_mac_policy%22%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22tun%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dtun%0A%20%20%20%20tun_mode%3D%24(nmcli%20--get-values%20tun.mode%20-e%20no%20connection%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20extra_phys_args%2B%3D(%20tun.mode%20%22%24%7Btun_mode%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bridge%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbridge%0A%20%20else%0A%20%20%20%20iface_type%3D802-3-ethernet%0A%20%20fi%0A%0A%20%20if%20%5B%20!%20%22%24%7Bclone_mac%3A-%7D%22%20%3D%20%220%22%20%5D%3B%20then%0A%20%20%20%20%23%20In%20active-backup%20link%20aggregation%2C%20with%20fail_over_mac%20mode%20enabled%2C%0A%20%20%20%20%23%20cloning%20the%20mac%20address%20is%20not%20supported.%20It%20is%20possible%20then%20that%0A%20%20%20%20%23%20br-ex%20has%20a%20different%20mac%20address%20than%20the%20bond%20which%20might%20be%0A%20%20%20%20%23%20troublesome%20on%20some%20platforms%20where%20the%20nic%20won't%20accept%20packets%20with%0A%20%20%20%20%23%20a%20different%20destination%20mac.%20But%20nobody%20has%20complained%20so%20far%20so%20go%20on%0A%20%20%20%20%23%20with%20what%20we%20got.%20%0A%20%20%20%20%0A%20%20%20%20%23%20Do%20set%20it%20though%20for%20other%20link%20aggregation%20configurations%20where%20the%0A%20%20%20%20%23%20mac%20address%20would%20otherwise%20depend%20on%20enslave%20order%20for%20which%20we%20have%0A%20%20%20%20%23%20no%20control%20going%20forward.%0A%20%20%20%20extra_phys_args%2B%3D(%20802-3-ethernet.cloned-mac-address%20%22%24%7Biface_mac%7D%22%20)%0A%20%20fi%0A%0A%20%20%23%20use%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%20instead%20of%20%24%7Bextra_phys_args%5B%40%5D%7D%20to%20be%20compatible%20with%20bash%204.2%20in%20RHEL7.9%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_interface_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%24%7Biface%7D%0A%20%20%20%20ovs_default_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24default_port_name%22)%0A%20%20%20%20add_nm_conn%20%22%24bridge_interface_name%22%20type%20%24%7Biface_type%7D%20conn.interface%20%24%7Biface%7D%20master%20%22%24ovs_default_port_conn%22%20%5C%0A%20%20%20%20%20%20slave-type%20ovs-port%20connection.autoconnect-priority%20100%20connection.autoconnect-slaves%201%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20%20%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%0A%20%20fi%0A%0A%20%20%23%20Get%20the%20new%20connection%20uuids%0A%20%20new_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24bridge_interface_name%22)%0A%20%20ovs_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24ovs_port%22)%0A%0A%20%20%23%20Update%20connections%20with%20master%20property%20set%20to%20use%20the%20new%20connection%0A%20%20replace_connection_master%20%24old_conn%20%24new_conn%0A%20%20replace_connection_master%20%24iface%20%24new_conn%0A%0A%20%20ipv4_method%3D%24(nmcli%20-g%20ipv4.method%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_method%3D%24(nmcli%20-g%20ipv6.method%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20ipv4_addresses%3D%24(nmcli%20-g%20ipv4.addresses%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_addresses%3D%24(nmcli%20-g%20ipv6.addresses%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20%23%20Warn%20about%20an%20invalid%20MTU%20that%20will%20most%20likely%20fail%20in%20one%20way%20or%0A%20%20%23%20another%0A%20%20if%20%5B%20%24%7Biface_mtu%7D%20-lt%201280%20%5D%20%26%26%20%5B%20%22%24%7Bipv6_method%7D%22%20!%3D%20%22disabled%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20MTU%20%24%7Biface_mtu%7D%20is%20lower%20than%20the%20minimum%20required%20of%201280%20for%20IPv6%22%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_interface%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%22%24bridge_name%22%0A%20%20%20%20%23%20Clone%20the%20connection%20in%20case%20the%20method%20is%20manual%20or%20in%20case%20the%20an%20address%20is%20set%20(DHCP%20%2B%20static%20IP)%0A%20%20%20%20if%20%5B%20%22%24%7Bipv4_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv4_addresses%7D%22%20!%3D%20%22%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_addresses%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Static%20IP%20addressing%20detected%20on%20default%20gateway%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%23%20clone%20the%20old%20connection%20to%20get%20the%20address%20settings%0A%20%20%20%20%20%20%23%20prefer%20cloning%20vs%20copying%20the%20connection%20file%20to%20avoid%20problems%20with%20selinux%0A%20%20%20%20%20%20clone_nm_conn%20%22%24%7Bold_conn%7D%22%20%22%24%7Bovs_interface%7D%22%0A%20%20%20%20%20%20shopt%20-s%20nullglob%0A%20%20%20%20%20%20new_conn_files%3D(%24%7BNM_CONN_RUN_PATH%7D%2F%22%24%7Bovs_interface%7D%22*)%0A%20%20%20%20%20%20shopt%20-u%20nullglob%0A%20%20%20%20%20%20if%20%5B%20%24%7B%23new_conn_files%5B%40%5D%7D%20-ne%201%20%5D%20%7C%7C%20%5B%20!%20-f%20%22%24%7Bnew_conn_files%5B0%5D%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20could%20not%20find%20%24%7Bovs_interface%7D%20conn%20file%20after%20cloning%20from%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20new_conn_file%3D%22%24%7Bnew_conn_files%5B0%5D%7D%22%0A%0A%20%20%20%20%20%20%23%20modify%20the%20connection%20type%20directly%20because%20it%20can't%20be%20modified%0A%20%20%20%20%20%20%23%20through%20nmcli%0A%20%20%20%20%20%20sed%20-i%20'%2F%5E%5C%5Bconnection%5C%5D%24%2F%2C%2F%5E%5C%5B%2F%20s%2F%5Etype%3D.*%24%2Ftype%3Dovs-interface%2F'%20%24%7Bnew_conn_file%7D%0A%0A%20%20%20%20%20%20%23%20modify%20some%20more%20settings%20through%20nmcli%0A%20%20%20%20%20%20mod_nm_conn%20%22%24%7Bovs_interface%7D%22%20conn.interface%20%22%24bridge_name%22%20%5C%0A%20%20%20%20%20%20%20%20connection.multi-connect%20%22%22%20connection.autoconnect%20no%20%5C%0A%20%20%20%20%20%20%20%20connection.master%20%22%24ovs_port_conn%22%20connection.slave-type%20ovs-port%20%5C%0A%20%20%20%20%20%20%20%20ovs-interface.type%20internal%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%0A%0A%20%20%20%20%20%20echo%20%22Loaded%20new%20%24ovs_interface%20connection%20file%3A%20%24%7Bnew_conn_file%7D%22%0A%20%20%20%20else%0A%20%20%20%20%20%20extra_if_brex_args%3D%22%22%0A%20%20%20%20%20%20%23%20check%20if%20interface%20had%20ipv4%2Fipv6%20addresses%20assigned%0A%20%20%20%20%20%20num_ipv4_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ipv4_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20IPV6%20should%20have%20at%20least%20a%20link%20local%20address.%20Check%20for%20more%20than%201%20to%20see%20if%20there%20is%20an%0A%20%20%20%20%20%20%23%20assigned%20address.%0A%20%20%20%20%20%20num_ip6_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet6%5C%22%20and%20.scope%20!%3D%20%5C%22link%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ip6_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20check%20for%20dhcp%20client%20ids%0A%20%20%20%20%20%20dhcp_client_id%3D%24(nmcli%20--get-values%20ipv4.dhcp-client-id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.dhcp-client-id%20%24%7Bdhcp_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20dhcp6_client_id%3D%24(nmcli%20--get-values%20ipv6.dhcp-duid%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp6_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.dhcp-duid%20%24%7Bdhcp6_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20ipv6_addr_gen_mode%3D%24(nmcli%20--get-values%20ipv6.addr-gen-mode%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24ipv6_addr_gen_mode%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.addr-gen-mode%20%24%7Bipv6_addr_gen_mode%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20add_nm_conn%20%22%24ovs_interface%22%20type%20ovs-interface%20slave-type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24ovs_port_conn%22%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.method%20%22%24%7Bipv4_method%7D%22%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20ipv6.method%20%22%24%7Bipv6_method%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20%24%7Bextra_if_brex_args%7D%0A%20%20%20%20fi%0A%20%20fi%0A%0A%20%20configure_driver_options%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20remove%20a%20bridge%0Aremove_ovn_bridges()%20%7B%0A%20%20bridge_name%3D%24%7B1%7D%0A%20%20port_name%3D%24%7B2%7D%0A%0A%20%20%23%20Remove%20the%20keyfiles%20from%20known%20configuration%20paths%0A%20%20update_nm_conn_run_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20update_nm_conn_set_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%0A%20%20%23%20NetworkManager%20will%20not%20remove%20%24%7Bbridge_name%7D%20if%20it%20has%20the%20patch%20port%20created%20by%20ovn-kubernetes%0A%20%20%23%20so%20remove%20explicitly%0A%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%24%7Bbridge_name%7D%0A%7D%0A%0A%23%20Removes%20any%20previous%20ovs%20configuration%0Aremove_all_ovn_bridges()%20%7B%0A%20%20echo%20%22Reverting%20any%20previous%20OVS%20configuration%22%0A%20%20%0A%20%20remove_ovn_bridges%20br-ex%20phys0%0A%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%0A%20%20echo%20%22OVS%20configuration%20successfully%20reverted%22%0A%7D%0A%0A%23%20Reloads%20NM%20NetworkManager%20profiles%20if%20any%20configuration%20change%20was%20done.%0A%23%20Accepts%20a%20list%20of%20devices%20that%20should%20be%20re-connect%20after%20reload.%0Areload_profiles_nm()%20%7B%0A%20%20if%20%5B%20%24%7Bnm_config_changed%3A-0%7D%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%23%20no%20config%20was%20changed%2C%20no%20need%20to%20reload%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20reload%20profiles%0A%20%20nmcli%20connection%20reload%0A%0A%20%20%23%20precautionary%20sleep%20of%2010s%20(default%20timeout%20of%20NM%20to%20bring%20down%20devices)%0A%20%20sleep%2010%0A%0A%20%20%23%20After%20reload%2C%20devices%20that%20were%20already%20connected%20should%20connect%20again%0A%20%20%23%20if%20any%20profile%20is%20available.%20If%20no%20profile%20is%20available%2C%20a%20device%20can%0A%20%20%23%20remain%20disconnected%20and%20we%20have%20to%20explicitly%20connect%20it%20so%20that%20a%0A%20%20%23%20profile%20is%20generated.%20This%20can%20happen%20for%20physical%20devices%20but%20should%0A%20%20%23%20not%20happen%20for%20software%20devices%20as%20those%20always%20require%20a%20profile.%0A%20%20for%20dev%20in%20%24%40%3B%20do%0A%20%20%20%20%23%20Only%20attempt%20to%20connect%20a%20disconnected%20device%0A%20%20%20%20local%20connected_state%3D%24(nmcli%20-g%20GENERAL.STATE%20device%20show%20%22%24dev%22%20%7C%7C%20echo%20%22%22)%0A%20%20%20%20if%20%5B%5B%20%22%24connected_state%22%20%3D~%20%22disconnected%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%23%20keep%20track%20if%20a%20profile%20by%20the%20same%20name%20as%20the%20device%20existed%20%0A%20%20%20%20%20%20%23%20before%20we%20attempt%20activation%0A%20%20%20%20%20%20local%20named_profile_existed%3D%24(%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%5D%20%7C%7C%20%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22%20%5D%20%26%26%20echo%20%22yes%22)%0A%20%20%20%20%20%20%0A%20%20%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20connect%20device%20%24dev%22%0A%20%20%20%20%20%20%20%20%20%20nmcli%20device%20connect%20%22%24dev%22%20%26%26%20break%0A%20%20%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%23%20if%20a%20profile%20did%20not%20exist%20before%20but%20does%20now%2C%20it%20was%20generated%0A%20%20%20%20%20%20%23%20but%20we%20want%20it%20to%20be%20ephemeral%2C%20so%20move%20it%20back%20to%20%2Frun%0A%20%20%20%20%20%20if%20%5B%20!%20%22%24named_profile_existed%22%20%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20MANAGED_NM_CONN_FILES%3D(%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22)%0A%20%20%20%20%20%20%20%20copy_nm_conn_files%20%22%24%7BNM_CONN_RUN_PATH%7D%22%0A%20%20%20%20%20%20%20%20rm_nm_conn_files%0A%20%20%20%20%20%20%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20might%20have%20been%20moved%0A%20%20%20%20%20%20%20%20nmcli%20connection%20reload%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20echo%20%22Waiting%20for%20interface%20%24dev%20to%20activate...%22%0A%20%20%20%20if%20!%20timeout%2060%20bash%20-c%20%22while%20!%20nmcli%20-g%20DEVICE%2CSTATE%20c%20%7C%20grep%20%22'%22'%22%24dev%22%3Aactivated'%22'%22%3B%20do%20sleep%205%3B%20done%22%3B%20then%0A%20%20%20%20%20%20echo%20%22WARNING%3A%20%24dev%20did%20not%20activate%22%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20nm_config_changed%3D0%0A%7D%0A%0A%23%20Removes%20all%20configuration%20and%20reloads%20NM%20if%20necessary%0Arollback_nm()%20%7B%0A%20%20phys0%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20phys1%3D%24(get_bridge_physical_interface%20ovs-if-phys1)%0A%20%20%0A%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20remove_all_ovn_bridges%0A%20%20%0A%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20were%20removed%0A%20%20reload_profiles_nm%20%22%24phys0%22%20%22%24phys1%22%0A%7D%0A%0A%23%20Add%20a%20temporary%20deactivated%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20folowed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20add%60%0Aadd_nm_conn()%20%7B%0A%20%20%23%20Use%20%60save%20no%60%20to%20add%20a%20temporary%20profile%0A%20%20nmcli%20c%20add%20save%20no%20con-name%20%22%24%40%22%20connection.autoconnect%20no%0A%7D%0A%0A%23%20Modify%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20followed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20modify%60%0Amod_nm_conn()%20%7B%0A%20%20%23%20the%20easiest%20thing%20to%20do%20here%20would%20be%20to%20use%20%60nmcli%20c%20mod%20--temporary%60%0A%20%20%23%20but%20there%20is%20a%20bug%20in%20selinux%20profiles%20that%20denies%20NM%20from%20performing%0A%20%20%23%20the%20operation%0A%20%20local%20dst_path%3D%24%7BNM_CONN_RUN_PATH%7D%2F%241.nmconnection%0A%20%20local%20src_path%0A%20%20src_path%3D%24(mktemp)%0A%20%20shift%0A%20%20cat%20%22%24dst_path%22%20%3E%20%22%24src_path%22%0A%20%20rm%20-f%20%22%24dst_path%22%0A%20%20nmcli%20--offline%20c%20mod%20%22%24%40%22%20%3C%20%22%24src_path%22%20%3E%20%22%24dst_path%22%0A%20%20rm%20-f%20%22%24src_path%22%0A%20%20chmod%20600%20%22%24dst_path%22%0A%20%20nmcli%20c%20load%20%22%24dst_path%22%0A%7D%0A%0A%23%20Clone%20to%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20to%20clone%2C%20second%20argument%20is%20the%20clone%20name%0Aclone_nm_conn()%20%7B%0A%20%20%23%20clone%20as%20temporary%20so%20that%20it%20is%20generated%20in%20NM_CONN_RUN_PATH%0A%20%20nmcli%20connection%20clone%20--temporary%20%22%241%22%20%22%242%22%20%26%3E%20%2Fdev%2Fnull%0A%7D%0A%0A%23%20Activates%20an%20ordered%20set%20of%20NM%20connection%20profiles%0Aactivate_nm_connections()%20%7B%0A%20%20local%20connections%3D(%22%24%40%22)%0A%0A%20%20%23%20We%20want%20autoconnect%20set%20for%20our%20cloned%20slave%20profiles%20so%20that%20they%20are%0A%20%20%23%20used%20over%20the%20original%20profiles%20if%20implicitly%20re-activated%20with%20other%0A%20%20%23%20dependant%20profiles.%20Otherwise%20if%20a%20slave%20activates%20with%20an%20old%20profile%2C%0A%20%20%23%20the%20old%20master%20profile%20might%20activate%20as%20well%2C%20interfering%20and%20causing%0A%20%20%23%20further%20activations%20to%20fail.%0A%20%20%23%20Slave%20interfaces%20should%20already%20be%20active%20so%20setting%20autoconnect%20here%0A%20%20%23%20won't%20implicitly%20activate%20them%20but%20there%20is%20an%20edge%20case%20where%20a%20slave%0A%20%20%23%20might%20be%20inactive%20(link%20down%20for%20example)%20and%20in%20that%20case%20setting%0A%20%20%23%20autoconnect%20will%20cause%20an%20implicit%20activation.%20This%20is%20not%20necessarily%20a%0A%20%20%23%20problem%20and%20hopefully%20we%20can%20make%20sure%20everything%20is%20activated%20as%20we%0A%20%20%23%20want%20next.%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20Activate%20all%20connections%20and%20fail%20if%20activation%20fails%0A%20%20%23%20For%20slave%20connections%20-%20for%20as%20long%20as%20at%20least%20one%20slave%20that%20belongs%20to%20a%20bond%2Fteam%0A%20%20%23%20comes%20up%2C%20we%20should%20not%20fail%0A%20%20declare%20-A%20master_interfaces%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%23%20Get%20the%20slave%20type%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20local%20is_slave%3Dfalse%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20is_slave%3Dtrue%0A%20%20%20%20fi%20%0A%0A%20%20%20%20%23%20For%20slave%20interfaces%2C%20initialize%20the%20master%20interface%20to%20false%20if%20the%20key%20is%20not%20yet%20in%20the%20array%0A%20%20%20%20local%20master_interface%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20master_interface%3D%24(nmcli%20-g%20connection.master%20connection%20show%20%22%24conn%22)%0A%20%20%20%20%20%20if%20!%20%5B%5B%20-v%20%22master_interfaces%5B%24master_interface%5D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dfalse%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Do%20not%20activate%20interfaces%20that%20are%20already%20active%0A%20%20%20%20%23%20But%20set%20the%20entry%20in%20master_interfaces%20to%20true%20if%20this%20is%20a%20slave%0A%20%20%20%20%23%20Also%20set%20autoconnect%20to%20yes%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20%3D%3D%20%22activated%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Connection%20%24conn%20already%20activated%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%24master_interface%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Activate%20all%20interfaces%20that%20are%20not%20yet%20active%0A%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20bring%20up%20connection%20%24conn%22%0A%20%20%20%20%20%20nmcli%20conn%20up%20%22%24conn%22%20%26%26%20s%3D0%20%26%26%20break%20%7C%7C%20s%3D%24%3F%0A%20%20%20%20%20%20sleep%205%0A%20%20%20%20done%0A%20%20%20%20if%20%5B%20%24s%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Brought%20up%20connection%20%24conn%20successfully%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20elif%20!%20%24is_slave%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20connection%20%24conn%20after%20%24i%20attempts%22%0A%20%20%20%20%20%20return%20%24s%0A%20%20%20%20fi%0A%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20done%0A%20%20%23%20Check%20that%20all%20master%20interfaces%20report%20at%20least%20a%20single%20active%20slave%0A%20%20%23%20Note%3A%20associative%20arrays%20require%20an%20exclamation%20mark%20when%20looping%0A%20%20for%20i%20in%20%22%24%7B!master_interfaces%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20!%20%24%7Bmaster_interfaces%5B%22%24i%22%5D%7D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20any%20slave%20interface%20for%20master%20interface%3A%20%24i%22%0A%20%20%20%20%20%20%20%20return%201%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24iface%0A%23%20Writes%20content%20of%20%24iface%20into%20%24iface_default_hint_file%0Awrite_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%242%22%0A%0A%20%20echo%20%22%24%7Biface%7D%22%20%3E%7C%20%22%24%7Biface_default_hint_file%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%0A%23%20Returns%20the%20stored%20interface%20default%20hint%20if%20the%20hint%20is%20non-empty%2C%0A%23%20not%20br-ex%2C%20not%20br-ex1%20and%20if%20the%20interface%20can%20be%20found%20in%20%2Fsys%2Fclass%2Fnet%0Aget_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%241%0A%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%3B%20then%0A%20%20%20%20local%20iface_default_hint%3D%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex1%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20-d%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface_default_hint%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%22%0A%7D%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0A%23%20This%20function%20waits%20for%20ip%20address%20of%20br-ex%20to%20be%20bindable%20only%20in%20case%20of%20ipv6%0A%23%20This%20is%20workaround%20for%20OCPBUGS-673%20as%20it%20will%20not%20allow%20starting%20crio%0A%23%20before%20address%20is%20bindable%0Atry_to_bind_ipv6_address()%20%7B%0A%20%20%23%20Retry%20for%201%20minute%0A%20%20retries%3D60%0A%20%20until%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20do%0A%20%20%20%20ip%3D%24(ip%20-6%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(.ifname%3D%3D%5C%22br-ex%5C%22)%20%7C%20.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20.local)%22)%0A%20%20%20%20if%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22No%20ipv6%20ip%20to%20bind%20was%20found%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20sleep%201%0A%20%20%20%20((%20retries--%20))%0A%20%20done%0A%20%20if%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Failed%20to%20bind%20ip%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%7D%0A%0A%23%20Get%20interface%20that%20matches%20ip%20from%20node%20ip%20hint%20file%0A%23%20in%20case%20file%20not%20exists%20return%20nothing%20and%0A%23%20fallback%20to%20default%20interface%20search%20flow%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge%3D%22%242%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)%20and%20.ifname!%3D%5C%22br-ex1%5C%22%20and%20.ifname!%3D%5C%22%24%7Bextra_bridge%7D%5C%22))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20fi%0A%7D%0A%0A%23%20Accepts%20parameters%20%24bridge_interface%20(e.g.%20ovs-port-phys0)%0A%23%20Returns%20the%20physical%20interface%20name%20if%20%24bridge_interface%20exists%2C%20%22%22%20otherwise%0Aget_bridge_physical_interface()%20%7B%0A%20%20local%20bridge_interface%3D%22%241%22%0A%20%20local%20physical_interface%3D%22%22%0A%20%20physical_interface%3D%24(nmcli%20-g%20connection.interface-name%20conn%20show%20%22%24%7Bbridge_interface%7D%22%202%3E%2Fdev%2Fnull%20%7C%7C%20echo%20%22%22)%0A%20%20echo%20%22%24%7Bphysical_interface%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24extra_bridge_file%2C%20%24ip_hint_file%2C%20%24default_bridge_file%0A%23%20Determines%20the%20interface%20to%20be%20used%20for%20br-ex.%20Order%20of%20priority%20is%3A%0A%23%201.%20Use%20the%20user%20specified%20interface%20if%20provided%20in%20the%20default%20bridge%20file%0A%23%202.%20Use%20the%20node%20IP%20hint%20interface%0A%23%203.%20Use%20the%20previously%20selected%20interface%0A%23%204.%20Use%20the%20interface%20detected%20as%20default%20gateway%0A%23%0A%23%20Read%20%24default_bridge_file%20and%20return%20the%20contained%20interface.%20Otherwise%2C%0A%23%20read%20%24ip_hint_file%20and%20return%20the%20interface%20that%20matches%20this%20ip.%20Otherwise%2C%0A%23%20if%20the%20default%20interface%20is%20br-ex%2C%20use%20that%20and%20return.%0A%23%20If%20the%20default%20interface%20is%20not%20br-ex%3A%0A%23%20Check%20if%20there%20is%20a%20valid%20hint%20inside%20%24iface_default_hint_file.%20If%20so%2C%20use%20that%20hint.%0A%23%20If%20there%20is%20no%20valid%20hint%2C%20use%20the%20default%20interface%20that%20we%20found%20during%20the%20step%0A%23%20earlier.%0A%23%20Never%20use%20the%20interface%20that%20is%20provided%20inside%20%24extra_bridge_file%20for%20br-ex1.%0A%23%20Never%20use%20br-ex1.%0A%23%20Write%20the%20default%20interface%20to%20%24iface_default_hint_file%0Aget_default_bridge_interface()%20%7B%0A%20%20local%20iface%3D%22%22%0A%20%20local%20counter%3D0%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge_file%3D%22%242%22%0A%20%20local%20ip_hint_file%3D%22%243%22%0A%20%20local%20default_bridge_file%3D%22%244%22%0A%20%20local%20extra_bridge%3D%22%22%0A%0A%20%20if%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%3B%20then%0A%20%20%20%20extra_bridge%3D%24(cat%20%24%7Bextra_bridge_file%7D)%0A%20%20fi%0A%0A%20%20%23%20try%20to%20use%20user%20specified%20file%20first%0A%20%20if%20%5B%20-f%20%22%24default_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20iface%3D%24(cat%20%22%24%7Bdefault_bridge_file%7D%22)%0A%20%20%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20User%20specified%20bridge%20file%20detected%20without%20any%20data%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20if%20node%20ip%20was%20set%2C%20we%20should%20search%20for%20interface%20that%20matches%20it%0A%20%20iface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bextra_bridge%7D%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20find%20default%20interface%0A%20%20%23%20the%20default%20interface%20might%20be%20br-ex%2C%20so%20check%20this%20before%20looking%20at%20the%20hint%0A%20%20while%20%5B%20%24%7Bcounter%7D%20-lt%2012%20%5D%3B%20do%0A%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20sleep%205%0A%20%20done%0A%0A%20%20%23%20if%20the%20default%20interface%20does%20not%20point%20out%20of%20br-ex%20or%20br-ex1%0A%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20%23%20determine%20if%20an%20interface%20default%20hint%20exists%20from%20a%20previous%20run%0A%20%20%20%20%23%20and%20if%20the%20interface%20has%20a%20valid%20default%20route%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%24%7Biface%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20start%20wherever%20count%20left%20off%20in%20the%20previous%20loop%0A%20%20%20%20%20%20%23%20allow%20this%20for%20one%20more%20iteration%20than%20the%20previous%20loop%0A%20%20%20%20%20%20while%20%5B%20%24%7Bcounter%7D%20-le%2012%20%5D%3B%20do%0A%20%20%20%20%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20-6%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%20%20%20%20fi%0A%20%20%20%20%23%20store%20what%20was%20determined%20was%20the%20(new)%20default%20interface%20inside%0A%20%20%20%20%23%20the%20default%20hint%20file%20for%20future%20reference%0A%20%20%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Biface%7D%22%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20print%20network%20state%0Aprint_state()%20%7B%0A%20%20echo%20%22Current%20device%2C%20connection%2C%20interface%20and%20routing%20state%3A%22%0A%20%20nmcli%20-g%20all%20device%20%7C%20grep%20-v%20unmanaged%0A%20%20nmcli%20-g%20all%20connection%0A%20%20ip%20-d%20address%20show%0A%20%20ip%20route%20show%0A%20%20ip%20-6%20route%20show%0A%7D%0A%0A%23%20Setup%20an%20exit%20trap%20to%20rollback%20on%20error%0Ahandle_exit()%20%7B%0A%20%20e%3D%24%3F%0A%20%20tdir%3D%24(mktemp%20-u%20-d%20-t%20%22configure-ovs-%24(date%20%2B%25Y-%25m-%25d-%25H-%25M-%25S)-XXXXXXXXXX%22)%0A%20%20%0A%20%20if%20%5B%20%24e%20-eq%200%20%5D%3B%20then%0A%20%20%20%20print_state%0A%20%20%20%20%23%20remove%20previous%20troubleshooting%20information%0A%20%20%20%20rm%20-rf%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%0A%20%20echo%20%22ERROR%3A%20configure-ovs%20exited%20with%20error%3A%20%24e%22%0A%20%20print_state%0A%0A%20%20%23%20remove%20previous%20troubleshooting%20information%20except%20the%20oldest%20one%0A%20%20mapfile%20-t%20tdirs%20%3C%20%3C(compgen%20-G%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22)%0A%20%20unset%20-v%20%22tdirs%5B0%5D%22%0A%20%20for%20dir%20in%20%22%24%7Btdirs%5B%40%5D%7D%22%3B%20do%20rm%20-rf%20%22%24dir%22%3B%20done%0A%0A%20%20%23%20copy%20configuration%20to%20tmp%20for%20troubleshooting%0A%20%20mkdir%20-p%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20echo%20%22Copied%20OVS%20configuration%20to%20%24tdir%20for%20troubleshooting%22%0A%0A%20%20%23%20attempt%20to%20restore%20the%20previous%20network%20state%0A%20%20echo%20%22Attempting%20to%20restore%20previous%20configuration...%22%0A%20%20rollback_nm%0A%20%20print_state%0A%0A%20%20exit%20%24e%0A%7D%0A%0A%23%20Setup%20a%20signal%20trap%20to%20rollback%0Ahandle_termination()%20%7B%0A%20%20echo%20%22WARNING%3A%20configure-ovs%20has%20been%20requested%20to%20terminate%2C%20quitting...%22%0A%20%20%0A%20%20%23%20by%20exiting%20with%20an%20error%20we%20will%20cleanup%20after%20ourselves%20in%20a%0A%20%20%23%20subsequent%20call%20to%20handle_exit%0A%20%20exit%201%0A%7D%0A%0A%23%20main%20function%0Aconfigure_ovs()%20%7B%0A%20%20set%20-eu%0A%0A%20%20%23%20setup%20traps%20to%20handle%20signals%20and%20other%20abnormal%20exits%0A%20%20trap%20'handle_termination'%20TERM%20INT%0A%20%20trap%20'handle_exit'%20EXIT%0A%0A%20%20%23%20this%20flag%20tracks%20if%20any%20config%20change%20was%20made%0A%20%20nm_config_changed%3D0%0A%0A%20%20%23%20Check%20that%20we%20are%20provided%20a%20valid%20NM%20connection%20path%0A%20%20if%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_CONF_PATH%22%20%5D%20%26%26%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_RUN_PATH%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Error%3A%20Incorrect%20NM%20connection%20path%3A%20%24NM_CONN_SET_PATH%20is%20not%20%24NM_CONN_CONF_PATH%20nor%20%24NM_CONN_RUN_PATH%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0A%20%20if%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0A%20%20fi%0A%0A%20%20if%20!%20rpm%20-qa%20%7C%20grep%20-q%20openvswitch%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20Openvswitch%20package%20is%20not%20installed!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20print%20initial%20state%0A%20%20print_state%0A%0A%20%20if%20%5B%20%22%241%22%20%3D%3D%20%22OVNKubernetes%22%20%5D%3B%20then%0A%20%20%20%20%23%20Configures%20NICs%20onto%20OVS%20bridge%20%22br-ex%22%0A%20%20%20%20%23%20Configuration%20is%20either%20auto-detected%20or%20provided%20through%20a%20config%20file%20written%20already%20in%20Network%20Manager%0A%20%20%20%20%23%20key%20files%20under%20%2Fetc%2FNetworkManager%2Fsystem-connections%2F%0A%20%20%20%20%23%20Managing%20key%20files%20is%20outside%20of%20the%20scope%20of%20this%20script%0A%0A%20%20%20%20%23%20if%20the%20interface%20is%20of%20type%20vmxnet3%20add%20multicast%20capability%20for%20that%20driver%0A%20%20%20%20%23%20History%3A%20BZ%3A1854355%0A%20%20%20%20function%20configure_driver_options%20%7B%0A%20%20%20%20%20%20intf%3D%241%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Device%20file%20doesn't%20exist%2C%20skipping%20setting%20multicast%20mode%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20driver%3D%24(cat%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%7C%20grep%20DRIVER%20%7C%20awk%20-F%20%22%3D%22%20'%7Bprint%20%242%7D')%0A%20%20%20%20%20%20%20%20echo%20%22Driver%20name%20is%22%20%24driver%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24driver%22%20%3D%20%22vmxnet3%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20ip%20link%20set%20dev%20%22%24%7Bintf%7D%22%20allmulticast%20on%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20fi%0A%20%20%20%20%7D%0A%0A%20%20%20%20ovnk_config_dir%3D'%2Fetc%2Fovnk'%0A%20%20%20%20ovnk_var_dir%3D'%2Fvar%2Flib%2Fovnk'%0A%20%20%20%20extra_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fextra_bridge%22%0A%20%20%20%20iface_default_hint_file%3D%22%24%7Bovnk_var_dir%7D%2Fiface_default_hint%22%0A%20%20%20%20ip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%20%20%20%20%23%20explicitly%20specify%20which%20interface%20should%20be%20used%20with%20the%20default%20bridge%0A%20%20%20%20default_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fdefault_bridge%22%0A%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_config_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_config_dir%7D%22%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_var_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_var_dir%7D%22%0A%0A%20%20%20%20%23%20For%20upgrade%20scenarios%2C%20make%20sure%20that%20we%20stabilize%20what%20we%20already%20configured%0A%20%20%20%20%23%20before.%20If%20we%20do%20not%20have%20a%20valid%20interface%20hint%2C%20find%20the%20physical%20interface%0A%20%20%20%20%23%20that's%20attached%20to%20ovs-if-phys0.%0A%20%20%20%20%23%20If%20we%20find%20such%20an%20interface%2C%20write%20it%20to%20the%20hint%20file.%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20current_interface%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20%20%20%20%20if%20%5B%20%22%24%7Bcurrent_interface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bcurrent_interface%7D%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20delete%20iface_default_hint_file%20if%20it%20has%20the%20same%20content%20as%20extra_bridge_file%0A%20%20%20%20%23%20in%20that%20case%2C%20we%20must%20also%20force%20a%20reconfiguration%20of%20our%20network%20interfaces%0A%20%20%20%20%23%20to%20make%20sure%20that%20we%20reconcile%20this%20conflict%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20%22%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%22%20%3D%3D%20%22%24(cat%20%22%24%7Bextra_bridge_file%7D%22)%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint_file%7D%20and%20%24%7Bextra_bridge_file%7D%20share%20the%20same%20content%22%0A%20%20%20%20%20%20echo%20%22Deleting%20file%20%24%7Biface_default_hint_file%7D%20to%20choose%20a%20different%20interface%22%0A%20%20%20%20%20%20rm%20-f%20%22%24%7Biface_default_hint_file%7D%22%0A%20%20%20%20%20%20rm%20-f%20%2Frun%2Fconfigure-ovs-boot-done%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20on%20every%20boot%20we%20rollback%20and%20generate%20the%20configuration%20again%2C%20to%20take%0A%20%20%20%20%23%20in%20any%20changes%20that%20have%20possibly%20been%20applied%20in%20the%20standard%0A%20%20%20%20%23%20configuration%20sources%0A%20%20%20%20if%20%5B%20!%20-f%20%2Frun%2Fconfigure-ovs-boot-done%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Running%20on%20boot%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20print_state%0A%20%20%20%20fi%0A%20%20%20%20touch%20%2Frun%2Fconfigure-ovs-boot-done%0A%0A%20%20%20%20iface%3D%24(get_default_bridge_interface%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bextra_bridge_file%7D%22%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bdefault_bridge_file%7D%22)%0A%0A%20%20%20%20if%20%5B%20%22%24iface%22%20!%3D%20%22br-ex%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Specified%20interface%20is%20not%20br-ex.%0A%20%20%20%20%20%20%23%20Some%20deployments%20use%20a%20temporary%20solution%20where%20br-ex%20is%20moved%20out%20from%20the%20default%20gateway%20interface%0A%20%20%20%20%20%20%23%20and%20bound%20to%20a%20different%20nic%20(https%3A%2F%2Fgithub.com%2Ftrozet%2Fopenshift-ovn-migration).%0A%20%20%20%20%20%20%23%20This%20is%20now%20supported%20through%20an%20extra%20bridge%20if%20requested.%20If%20that%20is%20the%20case%2C%20we%20rollback.%0A%20%20%20%20%20%20%23%20We%20also%20rollback%20if%20it%20looks%20like%20we%20need%20to%20configure%20things%2C%20just%20in%20case%20there%20are%20any%20leftovers%0A%20%20%20%20%20%20%23%20from%20previous%20attempts.%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%7C%7C%20%5B%20-z%20%22%24(nmcli%20connection%20show%20--active%20br-ex%202%3E%20%2Fdev%2Fnull)%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Bridge%20br-ex%20is%20not%20active%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20%20%20print_state%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20convert_to_bridge%20%22%24iface%22%20%22br-ex%22%20%22phys0%22%20%22%24%7BBRIDGE_METRIC%7D%22%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20configure%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(!%20nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20!%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20interface%3D%24(head%20-n%201%20%24extra_bridge_file)%0A%20%20%20%20%20%20convert_to_bridge%20%22%24interface%22%20%22br-ex1%22%20%22phys1%22%20%22%24%7BBRIDGE1_METRIC%7D%22%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20remove%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20!%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20openshift-sdn%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0A%20%20%20%20%23%20Make%20sure%20everything%20is%20activated.%20Do%20it%20in%20a%20specific%20order%3A%0A%20%20%20%20%23%20-%20activate%20br-ex%20first%2C%20due%20to%20autoconnect-slaves%20this%20will%20also%0A%20%20%20%20%23%20%20%20activate%20ovs-port-br-ex%2C%20ovs-port-phys0%20and%20ovs-if-phys0.%20It%20is%0A%20%20%20%20%23%20%20%20important%20that%20ovs-if-phys0%20activates%20with%20br-ex%20to%20avoid%20the%0A%20%20%20%20%23%20%20%20ovs-if-phys0%20profile%20being%20overridden%20with%20a%20profile%20generated%20from%0A%20%20%20%20%23%20%20%20kargs.%20The%20activation%20of%20ovs-if-phys0%2C%20if%20a%20bond%2C%20might%20cause%20the%0A%20%20%20%20%23%20%20%20slaves%20to%20re-activate%2C%20but%20it%20should%20be%20with%20our%20profiles%20since%20they%0A%20%20%20%20%23%20%20%20have%20higher%20priority%0A%20%20%20%20%23%20-%20make%20sure%20that%20ovs-if-phys0%20and%20its%20slaves%2C%20if%20any%2C%20are%20activated.%0A%20%20%20%20%23%20-%20finally%20activate%20ovs-if-br-ex%20which%20holds%20the%20IP%20configuration.%0A%20%20%20%20connections%3D(br-ex%20ovs-if-phys0)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(br-ex1%20ovs-if-phys1)%0A%20%20%20%20fi%0A%20%20%20%20while%20IFS%3D%20read%20-r%20connection%3B%20do%0A%20%20%20%20%20%20if%20%5B%5B%20%24connection%20%3D%3D%20*%22%24MANAGED_NM_CONN_SUFFIX%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20connections%2B%3D(%22%24connection%22)%0A%20%20%20%20%20%20fi%0A%20%20%20%20done%20%3C%20%3C(nmcli%20-g%20NAME%20c)%0A%20%20%20%20connections%2B%3D(ovs-if-br-ex)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(ovs-if-br-ex1)%0A%20%20%20%20fi%0A%20%20%20%20activate_nm_connections%20%22%24%7Bconnections%5B%40%5D%7D%22%0A%20%20%20%20try_to_bind_ipv6_address%0A%20%20%20%20set_nm_conn_files%0A%20%20elif%20%5B%20%22%241%22%20%3D%3D%20%22OpenShiftSDN%22%20%5D%3B%20then%0A%20%20%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20%20%20rollback_nm%0A%20%20%20%20%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20ovn-kubernetes%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-int%20--%20--if-exists%20del-br%20br-local%0A%20%20fi%0A%7D%0A%0A%23%20Retry%20configure_ovs%20until%20it%20succeeds.%0A%23%20By%20default%2C%20retry%20every%2015%20minutes%20to%20give%20enough%20time%20to%20gather%0A%23%20troubleshooting%20information%20in%20between.%20Note%20that%20configure_ovs%20has%20other%0A%23%20internal%20retry%20mechanisms.%20This%20retry%20is%20intended%20to%20give%20some%0A%23%20self-healing%20capabilities%20to%20temporary%20but%20not%20necessarily%20short-lived%0A%23%20infrastructure%20problems.%0ARETRY%3D%22%24%7BRETRY-15m%7D%22%0Awhile%20true%3B%20do%0A%0A%20%20%23%20Disable%20retries%20if%20termination%20signal%20is%20received.%20Note%20that%20systemd%0A%20%20%23%20sends%20the%20signals%20to%20all%20processes%20in%20the%20group%20by%20default%20so%20we%20expect%0A%20%20%23%20configure_ovs%20to%20get%20its%20own%20signals.%0A%20%20trap%20'echo%20%22WARNING%3A%20termination%20requested%2C%20disabling%20retries%22%3B%20RETRY%3D%22%22'%20INT%20TERM%0A%20%20%0A%20%20%23%20Run%20configure_ovs%20in%20a%20sub-shell.%20%0A%20%20(%20configure_ovs%20%22%24%40%22%20)%0A%20%20e%3D%24%3F%0A%0A%20%20%23%20Handle%20signals%20while%20we%20sleep%0A%20%20trap%20'handle_termination'%20INT%20TERM%0A%20%20%0A%20%20%23%20Exit%20if%20succesful%20and%20not%20configured%20to%20retry%0A%20%20%5B%20%22%24e%22%20-eq%200%20%5D%20%7C%7C%20%5B%20-z%20%22%24RETRY%22%20%5D%20%26%26%20exit%20%22%24e%22%0A%20%20%0A%20%20echo%20%22configure-ovs%20failed%2C%20will%20retry%20after%20%24RETRY%22%0A%20%20%23%20flag%20that%20a%20retry%20has%20happened%0A%20%20touch%20%2Ftmp%2Fconfigure-ovs-retry%0A%20%20sleep%20%22%24RETRY%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ovs.sh
        - contents:
            source: data:,%23%20This%20file%20is%20generated%20by%20the%20Machine%20Config%20Operator's%20containerruntimeconfig%20controller.%0A%23%0A%23%20storage.conf%20is%20the%20configuration%20file%20for%20all%20tools%0A%23%20that%20share%20the%20containers%2Fstorage%20libraries%0A%23%20See%20man%205%20containers-storage.conf%20for%20more%20information%0A%23%20The%20%22container%20storage%22%20table%20contains%20all%20of%20the%20server%20options.%0A%5Bstorage%5D%0A%0A%23%20Default%20Storage%20Driver%0Adriver%20%3D%20%22overlay%22%0A%0A%23%20Temporary%20storage%20location%0Arunroot%20%3D%20%22%2Fvar%2Frun%2Fcontainers%2Fstorage%22%0A%0A%23%20Primary%20Read%2FWrite%20location%20of%20container%20storage%0Agraphroot%20%3D%20%22%2Fvar%2Flib%2Fcontainers%2Fstorage%22%0A%0A%5Bstorage.options%5D%0A%23%20Storage%20options%20to%20be%20passed%20to%20underlying%20storage%20drivers%0A%0A%23%20AdditionalImageStores%20is%20used%20to%20pass%20paths%20to%20additional%20Read%2FOnly%20image%20stores%0A%23%20Must%20be%20comma%20separated%20list.%0Aadditionalimagestores%20%3D%20%5B%0A%5D%0A%0A%23%20Size%20is%20used%20to%20set%20a%20maximum%20size%20of%20the%20container%20image.%20%20Only%20supported%20by%0A%23%20certain%20container%20storage%20drivers.%0Asize%20%3D%20%22%22%0A%0A%23%20Remap-UIDs%2FGIDs%20is%20the%20mapping%20from%20UIDs%2FGIDs%20as%20they%20should%20appear%20inside%20of%0A%23%20a%20container%2C%20to%20UIDs%2FGIDs%20as%20they%20should%20appear%20outside%20of%20the%20container%2C%20and%0A%23%20the%20length%20of%20the%20range%20of%20UIDs%2FGIDs.%20%20Additional%20mapped%20sets%20can%20be%20listed%0A%23%20and%20will%20be%20heeded%20by%20libraries%2C%20but%20there%20are%20limits%20to%20the%20number%20of%0A%23%20mappings%20which%20the%20kernel%20will%20allow%20when%20you%20later%20attempt%20to%20run%20a%0A%23%20container.%0A%23%0A%23%20remap-uids%20%3D%200%3A1668442479%3A65536%0A%23%20remap-gids%20%3D%200%3A1668442479%3A65536%0A%0A%23%20Remap-User%2FGroup%20is%20a%20name%20which%20can%20be%20used%20to%20look%20up%20one%20or%20more%20UID%2FGID%0A%23%20ranges%20in%20the%20%2Fetc%2Fsubuid%20or%20%2Fetc%2Fsubgid%20file.%20%20Mappings%20are%20set%20up%20starting%0A%23%20with%20an%20in-container%20ID%20of%200%20and%20the%20a%20host-level%20ID%20taken%20from%20the%20lowest%0A%23%20range%20that%20matches%20the%20specified%20name%2C%20and%20using%20the%20length%20of%20that%20range.%0A%23%20Additional%20ranges%20are%20then%20assigned%2C%20using%20the%20ranges%20which%20specify%20the%0A%23%20lowest%20host-level%20IDs%20first%2C%20to%20the%20lowest%20not-yet-mapped%20container-level%20ID%2C%0A%23%20until%20all%20of%20the%20entries%20have%20been%20used%20for%20maps.%0A%23%0A%23%20remap-user%20%3D%20%22storage%22%0A%23%20remap-group%20%3D%20%22storage%22%0A%0A%5Bstorage.options.overlay%5D%0A%23%20Storage%20Options%20for%20overlay%0A%0A%23%20Do%20not%20create%20a%20PRIVATE%20bind%20mount%20on%20the%20home%20directory.%0Askip_mount_home%20%3D%20%22true%22%0A%0A%5Bstorage.options.thinpool%5D%0A%23%20Storage%20Options%20for%20thinpool%0A%0A%23%20autoextend_percent%20determines%20the%20amount%20by%20which%20pool%20needs%20to%20be%0A%23%20grown.%20This%20is%20specified%20in%20terms%20of%20%25%20of%20pool%20size.%20So%20a%20value%20of%2020%20means%0A%23%20that%20when%20threshold%20is%20hit%2C%20pool%20will%20be%20grown%20by%2020%25%20of%20existing%0A%23%20pool%20size.%0A%23%20autoextend_percent%20%3D%20%2220%22%0A%0A%23%20autoextend_threshold%20determines%20the%20pool%20extension%20threshold%20in%20terms%0A%23%20of%20percentage%20of%20pool%20size.%20For%20example%2C%20if%20threshold%20is%2060%2C%20that%20means%20when%0A%23%20pool%20is%2060%25%20full%2C%20threshold%20has%20been%20hit.%0A%23%20autoextend_threshold%20%3D%20%2280%22%0A%0A%23%20basesize%20specifies%20the%20size%20to%20use%20when%20creating%20the%20base%20device%2C%20which%0A%23%20limits%20the%20size%20of%20images%20and%20containers.%0A%23%20basesize%20%3D%20%2210G%22%0A%0A%23%20blocksize%20specifies%20a%20custom%20blocksize%20to%20use%20for%20the%20thin%20pool.%0A%23%20blocksize%3D%2264k%22%0A%0A%23%20directlvm_device%20specifies%20a%20custom%20block%20storage%20device%20to%20use%20for%20the%0A%23%20thin%20pool.%20Required%20if%20you%20setup%20devicemapper%0A%23%20directlvm_device%20%3D%20%22%22%0A%0A%23%20directlvm_device_force%20wipes%20device%20even%20if%20device%20already%20has%20a%20filesystem%0A%23%20directlvm_device_force%20%3D%20%22True%22%0A%0A%23%20fs%20specifies%20the%20filesystem%20type%20to%20use%20for%20the%20base%20device.%0A%23%20fs%3D%22xfs%22%0A%0A%23%20log_level%20sets%20the%20log%20level%20of%20devicemapper.%0A%23%200%3A%20LogLevelSuppress%200%20(Default)%0A%23%202%3A%20LogLevelFatal%0A%23%203%3A%20LogLevelErr%0A%23%204%3A%20LogLevelWarn%0A%23%205%3A%20LogLevelNotice%0A%23%206%3A%20LogLevelInfo%0A%23%207%3A%20LogLevelDebug%0A%23%20log_level%20%3D%20%227%22%0A%0A%23%20min_free_space%20specifies%20the%20min%20free%20space%20percent%20in%20a%20thin%20pool%20require%20for%0A%23%20new%20device%20creation%20to%20succeed.%20Valid%20values%20are%20from%200%25%20-%2099%25.%0A%23%20Value%200%25%20disables%0A%23%20min_free_space%20%3D%20%2210%25%22%0A%0A%23%20mkfsarg%20specifies%20extra%20mkfs%20arguments%20to%20be%20used%20when%20creating%20the%20base%0A%23%20device.%0A%23%20mkfsarg%20%3D%20%22%22%0A%0A%23%20mountopt%20specifies%20extra%20mount%20options%20used%20when%20mounting%20the%20thin%20devices.%0A%23%20mountopt%20%3D%20%22%22%0A%0A%23%20use_deferred_removal%20Marking%20device%20for%20deferred%20removal%0A%23%20use_deferred_removal%20%3D%20%22True%22%0A%0A%23%20use_deferred_deletion%20Marking%20device%20for%20deferred%20deletion%0A%23%20use_deferred_deletion%20%3D%20%22True%22%0A%0A%23%20xfs_nospace_max_retries%20specifies%20the%20maximum%20number%20of%20retries%20XFS%20should%0A%23%20attempt%20to%20complete%20IO%20when%20ENOSPC%20(no%20space)%20error%20is%20returned%20by%0A%23%20underlying%20storage%20device.%0A%23%20xfs_nospace_max_retries%20%3D%20%220%22%0A
          mode: 420
          overwrite: true
          path: /etc/containers/storage.conf
        - contents:
            source: data:,apiVersion%3A%20kubelet.config.k8s.io%2Fv1%0Akind%3A%20CredentialProviderConfig%0Aproviders%3A%0A%20%20-%20name%3A%20ecr-credential-provider%0A%20%20%20%20matchImages%3A%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.*.amazonaws.com%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.*.amazonaws.com.cn%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr-fips.*.amazonaws.com%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.us-iso-east-1.c2s.ic.gov%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.us-isob-east-1.sc2s.sgov.gov%22%0A%20%20%20%20defaultCacheDuration%3A%20%2212h%22%0A%20%20%20%20apiVersion%3A%20credentialprovider.kubelet.k8s.io%2Fv1%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/credential-providers/ecr-credential-provider.yaml
        - contents:
            source: data:,%23%20Proxy%20environment%20variables%20will%20be%20populated%20in%20this%20file.%20Properly%0A%23%20url%20encoded%20passwords%20with%20special%20characters%20will%20use%20'%25%3CHEX%3E%3CHEX%3E'.%0A%23%20Systemd%20requires%20that%20any%20%25%20used%20in%20a%20password%20be%20represented%20as%0A%23%20%25%25%20in%20a%20unit%20file%20since%20%25%20is%20a%20prefix%20for%20macros%3B%20this%20restriction%20does%20not%0A%23%20apply%20for%20environment%20files.%20Templates%20that%20need%20the%20proxy%20set%20should%20use%0A%23%20'EnvironmentFile%3D%2Fetc%2Fmco%2Fproxy.env'.%0A
          mode: 420
          overwrite: true
          path: /etc/mco/proxy.env
        - contents:
            source: data:,%5BManager%5D%0ADefaultEnvironment%3DGODEBUG%3Dx509ignoreCN%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/10-default-env-godebug.conf
        - contents:
            source: data:,%23%20Force-load%20legacy%20iptables%20so%20it%20is%20usable%20from%20pod%20network%20namespaces%0Aip_tables%0A
          mode: 420
          overwrite: true
          path: /etc/modules-load.d/iptables.conf
        - contents:
            source: data:,NODE_SIZING_ENABLED%3Dfalse%0ASYSTEM_RESERVED_MEMORY%3D1Gi%0ASYSTEM_RESERVED_CPU%3D500m%0ASYSTEM_RESERVED_ES%3D1Gi
          mode: 420
          overwrite: true
          path: /etc/node-sizing-enabled.env
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%0ANODE_SIZES_ENV%3D%24%7BNODE_SIZES_ENV%3A-%2Fetc%2Fnode-sizing.env%7D%0AVERSION_1%3D1%0AVERSION_2%3D2%0ANODE_AUTO_SIZING_VERSION%3D%24%7BNODE_AUTO_SIZING_VERSION%3A-%24VERSION_2%7D%0ANODE_AUTO_SIZING_VERSION_FILE%3D%24%7BNODE_AUTO_SIZING_VERSION_FILE%3A-%2Fetc%2Fnode-sizing-version.json%7D%0Afunction%20dynamic_memory_sizing%20%7B%0A%20%20%20%20total_memory%3D%24(free%20-g%7Cawk%20'%2F%5EMem%3A%2F%7Bprint%20%242%7D')%0A%20%20%20%20%23%20total_memory%3D8%20test%20the%20recommended%20values%20by%20modifying%20this%20value%0A%20%20%20%20recommended_systemreserved_memory%3D0%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2025%25%20of%20the%20first%204GB%20of%20memory%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24total_memory%200.25%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D1%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2020%25%20of%20the%20next%204GB%20of%20memory%20(up%20to%208GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.20%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%208))%3B%20then%20%23%2010%25%20of%20the%20next%208GB%20of%20memory%20(up%20to%2016GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.10%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-8))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%20112))%3B%20then%20%23%206%25%20of%20the%20next%20112GB%20of%20memory%20(up%20to%20128GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%206.72%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-112))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3E%3D%200))%3B%20then%20%23%202%25%20of%20any%20memory%20above%20128GB%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.02%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20fi%0A%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%7C%20awk%20'%7Bprintf(%22%25d%5Cn%22%2C%241%20%2B%200.5)%7D')%20%23%20Round%20off%20so%20we%20avoid%20float%20conversions%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7Brecommended_systemreserved_memory%7DGi%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_cpu_sizing%20%7B%0A%20%20%20%20total_cpu%3D%24(getconf%20_NPROCESSORS_ONLN)%0A%20%20%20%20if%20%5B%20%22%241%22%20-eq%20%22%24VERSION_1%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%206%25%20of%20the%20first%20core%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24total_cpu%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0.06%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%201%25%20of%20the%20next%20core%20(up%20to%202%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%202))%3B%20then%20%23%200.5%25%20of%20the%20next%202%20cores%20(up%20to%204%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.005%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-2))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3E%3D%200))%3B%20then%20%23%200.25%25%20of%20any%20cores%20above%204%20cores%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.0025%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20%23%20Base%20allocation%20for%201%20CPU%20in%20fractions%20of%20a%20core%20(60%20millicores%20%3D%200.06%20CPU%20core)%0A%20%20%20%20%20%20%20%20base_allocation_fraction%3D0.06%0A%20%20%20%20%20%20%20%20%23%20Increment%20per%20additional%20CPU%20in%20fractions%20of%20a%20core%20(12%20millicores%20%3D%200.012%20CPU%20core)%0A%20%20%20%20%20%20%20%20increment_per_cpu_fraction%3D0.012%0A%20%20%20%20%20%20%20%20if%20((total_cpu%20%3E%201))%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20the%20total%20system-reserved%20CPU%20in%20fractions%2C%20starting%20with%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20and%20adding%20the%20incremental%20fraction%20for%20each%20additional%20CPU%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20base%3D%22%24base_allocation_fraction%22%20-v%20increment%3D%22%24increment_per_cpu_fraction%22%20-v%20cpus%3D%22%24total_cpu%22%20'BEGIN%20%7Bprintf%20%22%25.2f%5Cn%22%2C%20base%20%2B%20increment%20*%20(cpus%20-%201)%7D')%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20a%20single%20CPU%2C%20use%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24base_allocation_fraction%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7Brecommended_systemreserved_cpu%7D%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_ephemeral_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20dynamic_pid_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20set_memory%20%7B%0A%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_cpu%20%7B%0A%20%20%20%20SYSTEM_RESERVED_CPU%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_CPU%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_CPU%3D%22500m%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7BSYSTEM_RESERVED_CPU%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_es%20%7B%0A%20%20%20%20SYSTEM_RESERVED_ES%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_ES%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_ES%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_ES%3D%24%7BSYSTEM_RESERVED_ES%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20dynamic_memory_sizing%0A%20%20%20%20dynamic_cpu_sizing%20%242%0A%20%20%20%20set_es%20%241%0A%20%20%20%20%23dynamic_ephemeral_sizing%0A%20%20%20%20%23dynamic_pid_sizing%0A%7D%0Afunction%20static_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20set_memory%20%241%0A%20%20%20%20set_cpu%20%242%0A%20%20%20%20set_es%20%243%0A%7D%0Afunction%20create_version_file%20%7B%0A%20%20%20%20echo%20%22%7B%5C%22version%5C%22%3A%20%241%7D%22%20%3E%20%242%0A%7D%0Aif%20!%20%5B%20-f%20%24NODE_AUTO_SIZING_VERSION_FILE%20%5D%3B%20then%0A%20%20%20%20create_version_file%20%24NODE_AUTO_SIZING_VERSION%20%24NODE_AUTO_SIZING_VERSION_FILE%0Afi%0Anew_version%3D%24(jq%20.version%20%24NODE_AUTO_SIZING_VERSION_FILE)%0Aif%20%5B%20%241%20%3D%3D%20%22true%22%20%5D%3B%20then%0A%20%20%20%20dynamic_node_sizing%20%244%20%24new_version%0Aelif%20%5B%20%241%20%3D%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20static_node_sizing%20%242%20%243%20%244%0Aelse%0A%20%20%20%20echo%20%22Unrecognized%20command%20line%20option.%20Valid%20options%20are%20%5C%22true%5C%22%20or%20%5C%22false%5C%22%22%0Afi
          mode: 493
          overwrite: true
          path: /usr/local/sbin/dynamic-system-reserved-calc.sh
        - contents:
            source: data:,%23%20Turning%20on%20Accounting%20helps%20track%20down%20performance%20issues.%0A%5BManager%5D%0ADefaultCPUAccounting%3Dyes%0ADefaultMemoryAccounting%3Dyes%0ADefaultBlockIOAccounting%3Dyes%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/kubelet-cgroups.conf
        - contents:
            source: data:,%5BService%5D%0AEnvironment%3D%22KUBELET_LOG_LEVEL%3D2%22%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system/kubelet.service.d/20-logging.conf
        - contents:
            source: data:,%23%20ignore%20known%20SDN-managed%20devices%0A%5Bdevice%5D%0Amatch-device%3Dinterface-name%3Abr-int%3Binterface-name%3Abr-local%3Binterface-name%3Abr-nexthop%3Binterface-name%3Aovn-k8s-*%3Binterface-name%3Ak8s-*%3Binterface-name%3Atun0%3Binterface-name%3Abr0%3Binterface-name%3Apatch-br-*%3Binterface-name%3Abr-ext%3Binterface-name%3Aext-vxlan%3Binterface-name%3Aext%3Binterface-name%3Aint%3Binterface-name%3Avxlan_sys_*%3Binterface-name%3Agenev_sys_*%3Bdriver%3Aveth%0Amanaged%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/sdn.conf
        - contents:
            source: data:,%5Bservice%5D%0Akeep_state_file_after_apply%20%3D%20true%0A
          mode: 420
          overwrite: true
          path: /etc/nmstate/nmstate.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Set%20interface%20ofport_request%20to%20guarantee%20stable%20ofport%20numbers.%20This%20is%20important%20for%20flow%20matches.%0A%23%20Otherwise%2C%20another%20ofport%20number%20is%20assigned%20to%20the%20interface%20on%20every%20restart%20of%20NetworkManager.%0A%23%20This%20script%20will%20build%20an%20associative%20array%20INTERFACE_NAME-%3Eofport_request%20and%20will%20save%20it%20to%20file%20CONFIGURATION_FILE.%0A%23%20When%20an%20interface%20is%20brought%20up%2C%20this%20will%20reuse%20the%20value%20from%20the%20associative%20array%20if%20such%20a%20value%20exists.%0A%23%20Otherwise%2C%20this%20will%20try%20to%20use%20the%20current%20ofport%20value.%20If%20the%20ofport%20value%20is%20already%20reserved%2C%20then%0A%23%20this%20uses%20the%20lowest%20available%20numerical%20value%2C%20instead.%0Aset%20-eux%20-o%20pipefail%0Aif%20%5B%5B%20%22OVNKubernetes%22%20!%3D%20%22OVNKubernetes%22%20%5D%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0AINTERFACE_NAME%3D%241%0AOPERATION%3D%242%0A%0A%23%20Only%20execute%20this%20on%20pre-up%0Aif%20%5B%20%22%24%7BOPERATION%7D%22%20!%3D%20%22pre-up%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0AINTERFACE_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%241%3D%3D%22'%24%7BINTERFACE_NAME%7D'%22%20%26%26%20%242!~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20slave-type.%20If%20this%20is%20not%20an%20ovs-port%2C%20then%20exit%0AINTERFACE_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-port%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20This%20is%20not%20necessarily%20a%20UUID%20(can%20be%20a%20name%20in%20case%20of%20bonds)%20but%20this%20should%20be%20unique%0APORT%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0APORT_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%20(%241%3D%3D%22'%24%7BPORT%7D'%22%20%7C%7C%20%243%3D%3D%22'%24%7BPORT%7D'%22)%20%26%26%20%242~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20slave-type.%20If%20this%20is%20not%20an%20ovs-bridge%2C%20then%20exit%0APORT_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-bridge%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20master.%20If%20it%20doesn't%20have%20any%2C%20assume%20it's%20not%20our%20bridge%0ABRIDGE_ID%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BBRIDGE_ID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20bridge%20name%0ABRIDGE_NAME%3D%24(nmcli%20-t%20-f%20connection.interface-name%20conn%20show%20%22%24%7BBRIDGE_ID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0A%23%20Limit%20this%20to%20br-ex%20and%20br-ex1%20only.%20If%20one%20wanted%20to%20enable%20this%20for%20all%20OVS%20bridges%2C%0A%23%20the%20condition%20would%20be%3A%20if%20%5B%20%22%24BRIDGE_NAME%22%20%3D%3D%20%22%22%20%5D%3B%20then%0Aif%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Make%20sure%20that%20the%20interface%20is%20plugged%20into%20OVS%0A%23%20This%20should%20always%20be%20the%20case%20given%20that%20we%20are%20in%20pre-up%2C%20but%20exit%20gracefully%20in%20the%20odd%20case%20that%20it's%20not%0Aif%20!%20ovs-vsctl%20list%20interface%20%22%24%7BINTERFACE_NAME%7D%22%20%3E%2Fdev%2Fnull%202%3E%261%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0ACONFIGURATION_FILE%3D%22%2Frun%2Fofport_requests.%24%7BBRIDGE_NAME%7D%22%0A%0A%23%20Declare%20a%20new%20associative%20array.%20If%20CONFIGURATION_FILE%20exists%2C%20source%20entries%20from%20there%0Adeclare%20-A%20INTERFACES%0Aif%20%5B%20-f%20%22%24%7BCONFIGURATION_FILE%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Sourcing%20configuration%20file%20'%24%7BCONFIGURATION_FILE%7D'%20with%20contents%3A%22%0A%20%20%20%20cat%20%22%24%7BCONFIGURATION_FILE%7D%22%0A%20%20%20%20source%20%22%24%7BCONFIGURATION_FILE%7D%22%0Afi%0A%0A%23%20get_interface_ofport_request%20will%20return%0A%23%20*%20either%3A%20the%20current%20ofport%20assignment%20for%20the%20port%20if%20no%20interface%20has%20claimed%20this%20ofport%20number%2C%20yet%0A%23%20*%20or%3A%20%20%20%20%20the%20lowest%20available%20free%20ofport%20number%0Afunction%20get_interface_ofport_request()%20%7B%0A%20%20%20%20%23%20Build%20an%20array%20that%20only%20contains%20the%20currently%20reserved%20ofport_requests%0A%20%20%20%20declare%20-A%20ofport_requests%0A%20%20%20%20for%20interface_name%20in%20%22%24%7B!INTERFACES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%20%20%20%20ofport_requests%5B%24%7BINTERFACES%5B%24interface_name%5D%7D%5D%3D%24%7BINTERFACES%5B%24interface_name%5D%7D%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20Get%20the%20current%20ofport%20number%20assignment%0A%20%20%20%20local%20current_ofport%3D%24(ovs-vsctl%20get%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport)%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20still%20free%2C%20use%20it%0A%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24current_ofport%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%24current_ofport%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20not%20free%2C%20return%20the%20lowest%20free%20entry%0A%20%20%20%20i%3D0%0A%20%20%20%20for%20i%20in%20%7B1..65000%7D%3B%20do%0A%20%20%20%20%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24i%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%24i%0A%20%20%20%20%20%20%20%20%20%20%20%20return%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20if%20we%20still%20cannot%20find%20an%20ID%2C%20exit%20with%20an%20error%0A%20%20%20%20echo%20%22Impossible%20to%20find%20an%20ofport%20ID%20for%20interface%20%24%7BINTERFACE_NAME%7D%22%20%3E%262%0A%20%20%20%20exit%201%0A%7D%0A%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20exists%2C%20use%20that%20value%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20does%20not%20exists%2C%20use%20the%20value%20from%20get_interface_ofport_request%0Aif%20!%20%5B%20%22%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20INTERFACES%5B%24INTERFACE_NAME%5D%3D%24(get_interface_ofport_request)%0Afi%0A%23%20Set%20ofport_request%20according%20to%20INTERFACES%5BINTERFACE_NAME%5D%0Aovs-vsctl%20set%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport_request%3D%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%7D%0A%0A%23%20Save%20current%20state%20of%20INTERFACES%20to%20CONFIGURATION_FILE%0Adeclare%20-p%20INTERFACES%20%3E%7C%20%22%24%7BCONFIGURATION_FILE%7D%22%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/pre-up.d/10-ofport-request.sh
        - contents:
            source: data:,%7B%22auths%22%3A%7B%22cloud.openshift.com%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfN2JmN2FjMTAyMDMxNDY1N2EwZjdiMDdiNDNjM2FiZDg6OE1YQ0gyTldMSktPVU9DQk5UNk9NSERPUzc2NkYxTURFTjlXQjhXN0xTTUtDNjk1NjI0N1c1OFUySzFDRUcwVw%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22quay.io%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfN2JmN2FjMTAyMDMxNDY1N2EwZjdiMDdiNDNjM2FiZDg6OE1YQ0gyTldMSktPVU9DQk5UNk9NSERPUzc2NkYxTURFTjlXQjhXN0xTTUtDNjk1NjI0N1c1OFUySzFDRUcwVw%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22registry.ci.openshift.org%22%3A%7B%22auth%22%3A%22c2VydmljZWFjY291bnQ6ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNkluWjBaVmc1TVVkUlpGRjZRME5OWkVWa2JGOXNTSG90YlVSd2EwRlVPR2RzWjJoUVRtMVBkamxLUmpBaWZRLmV5SmhkV1FpT2xzaWFIUjBjSE02THk5amFTMWtkakp1Y0MxdmFXUmpMbk16TG1GdFlYcHZibUYzY3k1amIyMGlYU3dpWlhod0lqb3hOek0wTlRNd05EWXlMQ0pwWVhRaU9qRTNNekl4TVRFeU5qSXNJbWx6Y3lJNkltaDBkSEJ6T2k4dlkya3RaSFl5Ym5BdGIybGtZeTV6TXk1aGJXRjZiMjVoZDNNdVkyOXRJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5STZleUp1WVcxbGMzQmhZMlVpT2lKamFTSXNJbk5sWTNKbGRDSTZleUp1WVcxbElqb2lkRzlyWlc0dFltOTFibVF0YjJKcVpXTjBMVEVpTENKMWFXUWlPaUkxWkRJd1pHUTBNQzFqT1RCaExUUXpNVFl0WVdNd05DMW1OVGczT0RFeVpUVTFZamdpZlN3aWMyVnlkbWxqWldGalkyOTFiblFpT25zaWJtRnRaU0k2SW1sdFlXZGxMWEIxYkd4bGNpSXNJblZwWkNJNkltRTNOMlk1TkdFeUxXVXdOelV0TkRGaU9DMDVPV1JoTFdRMlpEbGtNbUZpTlRGak9TSjlmU3dpYm1KbUlqb3hOek15TVRFeE1qWXlMQ0p6ZFdJaU9pSnplWE4wWlcwNmMyVnlkbWxqWldGalkyOTFiblE2WTJrNmFXMWhaMlV0Y0hWc2JHVnlJbjAuVGFqMktGY1JOV0FIRHJGT0NPQjBhWUJGUTUwVW9FUmdXMWFZYUNTVTQ0NF9jdnpCOFJDamNxR04xdV9jOFRRbFBDNXU0NG5JNklaYTdvU1RnMUh4dE9aQmEyYW5OS0JPMk5UNVF5WEhhX0R5cVJlaUUxb0YtcmphRms2TEJrNWllT1BSWXJHbklpWlJJNkQ2S0kxMmxJVFZQdFBPYUgtaXFuNV9LMXdOcmR4SDhYb2dCdlJ5UlJwRDBLTUxGNkJfeFBzbi1VeHVQQklIbjVRTFlXSkJtOVFMRVlIM0tzZDN2by03Uzc0anlZMkswMUF1OUpwYkFFR3k4Z2lyUDE1YlRnUXJReW1zS1NrbFN6U3BUbEM0MDJxVjNBanVPSjA4eGxrSE5VeXJROFk3dklJWDFBUUVmbHJaaC13ZVcyVy1aNWtnZjFOMXhNVVl6QnplZW5BZF9n%22%7D%2C%22registry.connect.redhat.com%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLWU3NDlmYWFiLTM0ZjktNDg0ZS1hNWQwLTJkNzFhMzgzMTg1MjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSXpORGszTURVMU5URTFObUkwTXpOaFltVmxNRGt5TVRJM09UZzNZV0V5WVNKOS50MUxtR0FhMTQzdnJIWG13RFZVVjNYaWhYa203Vk95bDFLek9kZm9QN0tTd3NqVFpKeUlSN1lKQjNyNGxGN3pVNWMwa0ZyOVYweUtwSFdPRU94clhJekVSaXlfOXkwQzRxbXRDOUhYNjJNVThsdmJtQW9GSXhZbHZXWnREVXVQZWgzSVFqS25CN2FJYlZ6MFJ3SWZWYVZucXFOUzhHbDNFcDRTUjVpNGZmUzE5akJCUnpxdmxBSjF6QkNVWWI3S1ZLTHVGRHJsNjdNNy1rWWwxTUhseTRBN2JVdjVISU5MaEhOdDVfRk5JX3RWbjdQM0RzQkVjcWxkWTd0Y0J4UlNoLTdQbWpzMGJEWm9ZZTZ6by1QY25TeEY0RV94QzF6aGZYYUNpdEU4UVZTUmk2MjhnM1c4WjVQQzc4VFBJWGtvaTBJWG9IX1E4QTd4SDlKaDhsWWhTTnBCaUxHODMyaFNhRUdtYkEtaU5kd3BrTGk0a0oyeTlYWE55ZlNUbU1mRUppUGwyWEI5VXRTT3lva05XU0ZqVk1kZ3l5WFlaUWtTNGh6Ql83VkpzTEh6RHpKaTJGcUZNNE56LW5Qd28zalZ3c3d3YXgzUUZZVUk2YzA5MVZnT0NUdEtpeEJXeTBaVEZyT3hEVDh4ZFRQOXcxY1JoR1N1UzU5WG55c2I2bndDLWQ5ZS11SWZpS2x4dDNZNkJaUkhRYmVUZlRtdGFoMUxOYWhRaXRzclVubVBjZXhnLVFXdzhCS3VENUFwbFc3eFVHcm9Lb1lkSEowVTJtc0ZWcjhZZ2FjVDl1UC1hWGUtTHd0dnJ3ZG1fWGtVdWRMRnFsRklxby1lWTdhVE03Xy1HRk8xWE8xTTIwQWVtSU5oUXJqUkN4TGRJeXlMSU9uOURBZUdYeGc5bUJiWQ%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22registry.redhat.io%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLWU3NDlmYWFiLTM0ZjktNDg0ZS1hNWQwLTJkNzFhMzgzMTg1MjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSXpORGszTURVMU5URTFObUkwTXpOaFltVmxNRGt5TVRJM09UZzNZV0V5WVNKOS50MUxtR0FhMTQzdnJIWG13RFZVVjNYaWhYa203Vk95bDFLek9kZm9QN0tTd3NqVFpKeUlSN1lKQjNyNGxGN3pVNWMwa0ZyOVYweUtwSFdPRU94clhJekVSaXlfOXkwQzRxbXRDOUhYNjJNVThsdmJtQW9GSXhZbHZXWnREVXVQZWgzSVFqS25CN2FJYlZ6MFJ3SWZWYVZucXFOUzhHbDNFcDRTUjVpNGZmUzE5akJCUnpxdmxBSjF6QkNVWWI3S1ZLTHVGRHJsNjdNNy1rWWwxTUhseTRBN2JVdjVISU5MaEhOdDVfRk5JX3RWbjdQM0RzQkVjcWxkWTd0Y0J4UlNoLTdQbWpzMGJEWm9ZZTZ6by1QY25TeEY0RV94QzF6aGZYYUNpdEU4UVZTUmk2MjhnM1c4WjVQQzc4VFBJWGtvaTBJWG9IX1E4QTd4SDlKaDhsWWhTTnBCaUxHODMyaFNhRUdtYkEtaU5kd3BrTGk0a0oyeTlYWE55ZlNUbU1mRUppUGwyWEI5VXRTT3lva05XU0ZqVk1kZ3l5WFlaUWtTNGh6Ql83VkpzTEh6RHpKaTJGcUZNNE56LW5Qd28zalZ3c3d3YXgzUUZZVUk2YzA5MVZnT0NUdEtpeEJXeTBaVEZyT3hEVDh4ZFRQOXcxY1JoR1N1UzU5WG55c2I2bndDLWQ5ZS11SWZpS2x4dDNZNkJaUkhRYmVUZlRtdGFoMUxOYWhRaXRzclVubVBjZXhnLVFXdzhCS3VENUFwbFc3eFVHcm9Lb1lkSEowVTJtc0ZWcjhZZ2FjVDl1UC1hWGUtTHd0dnJ3ZG1fWGtVdWRMRnFsRklxby1lWTdhVE03Xy1HRk8xWE8xTTIwQWVtSU5oUXJqUkN4TGRJeXlMSU9uOURBZUdYeGc5bUJiWQ%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%7D%7D%0A
          mode: 384
          overwrite: true
          path: /var/lib/kubelet/config.json
        - contents:
            source: data:,%23%20Needed%20by%20the%20OpenShift%20SDN.%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1758552%0Anet.ipv4.conf.all.arp_announce%20%3D%202%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/arp.conf
        - contents:
            source: data:,%23%20See%3A%20rhbz%231384746%2C%20OCPBUGS-24012%0Anet.ipv4.neigh.default.gc_thresh1%3D8192%0Anet.ipv4.neigh.default.gc_thresh2%3D32768%0Anet.ipv4.neigh.default.gc_thresh3%3D65536%0Anet.ipv6.neigh.default.gc_thresh1%3D8192%0Anet.ipv6.neigh.default.gc_thresh2%3D32768%0Anet.ipv6.neigh.default.gc_thresh3%3D65536%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/gc-thresh.conf
        - contents:
            source: data:,%0Afs.inotify.max_user_watches%20%3D%2065536%0Afs.inotify.max_user_instances%20%3D%208192%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/inotify.conf
        - contents:
            source: data:,vm.unprivileged_userfaultfd%20%3D%201
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/enable-userfaultfd.conf
        - contents:
            source: data:,%23%20Needed%20for%20OpenShift%20Logging%20(ElasticSearch).%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1793714%0Avm.max_map_count%20%3D%20262144%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/vm-max-map.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%20-o%20pipefail%0A%0ANODEENV%3D%2Fetc%2Fkubernetes%2Fnode.env%0A%0A%23%20This%20can%20be%20removed%201%20release%20after%20it%20merges%20because%20all%20affected%20nodes%0A%23%20will%20have%20upgraded%0ALEGACY_NODEENV%3D%2Fetc%2Fsystemd%2Fsystem%2Fkubelet.service.d%2F20-aws-node-name.conf%0Aif%20%5B%20-e%20%22%24%7BLEGACY_NODEENV%7D%22%20%5D%3B%20then%0A%20%20%20%20%23%20Legacy%20file%20was%20a%20systemd%20stanza%20with%20KUBELET_NODE_NAME%20specified%20in%0A%20%20%20%20%23%20a%20directive%20of%20the%20format%3A%0A%20%20%20%20%23%20%20%20Environment%3D%22KUBELET_NODE_NAME%3Dnode.example.com%22%0A%20%20%20%20%23%20New%20format%20is%20an%20environment%20file.%20The%20following%20extracts%20only%20the%0A%20%20%20%20%23%20contents%20of%20any%20Environment%20directives.%0A%20%20%20%20echo%20%22Migrating%20%24%7BLEGACY_NODEENV%7D%20to%20%24%7BNODEENV%7D%22%0A%20%20%20%20awk%20'match(%240%2C%20%2F%5E%5Cs*Environment%5Cs*%3D%5Cs*%22(.*)%22%5Cs*%24%2F%2C%20value)%20%7B%20print%20value%5B1%5D%20%7D'%20%3C%20%22%24%7BLEGACY_NODEENV%7D%22%20%3E%20%22%24%7BNODEENV%7D%22%0A%20%20%20%20rm%20%22%24%7BLEGACY_NODEENV%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20-e%20%22%24%7BNODEENV%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Not%20replacing%20existing%20%24%7BNODEENV%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20afterburn%20service%20is%20expected%20to%20be%20used%20for%20metadata%20retrival%2C%20see%20respective%20systemd%20unit.%0A%23%20However%2C%20on%20older%20OCP%20boot%20images%20does%20not%20contain%20afterburn%20service%2C%20check%20if%20afterburn%20variables%20are%20there%0A%23%20otherwise%20try%20to%20communicate%20IMDS%20here.%0A%23%20metadata%20related%20afterburn%20doc%3A%20https%3A%2F%2Fcoreos.github.io%2Fafterburn%2Fusage%2Fattributes%2F%0A%0AHOSTNAME%3D%24%7BAFTERBURN_AWS_HOSTNAME%3A-%7D%0Awhile%20%5B%5B%20-z%20%22%24%7BHOSTNAME%7D%22%20%5D%5D%3B%20do%0A%20%20HOSTNAME%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Flocal-hostname)%0A%20%20if%20%5B%5B%20-z%20%22%24%7BHOSTNAME%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Can%20not%20obtain%20hostname%20from%20the%20metadata%20service.%22%201%3E%262%0A%20%20%20%20sleep%205%0A%20%20fi%20%0Adone%0A%0A%23%20For%20compatibility%20with%20the%20AWS%20in-tree%20provider%0A%23%20Set%20node%20name%20to%20be%20instance%20FQDN%20instead%20of%20the%20default%20hostname%0Acat%20%3E%20%22%24%7BNODEENV%7D%22%20%3C%3CEOF%0AKUBELET_NODE_NAME%3D%24%7BHOSTNAME%25%25%20*%7D%0AEOF%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/aws-kubelet-nodename
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%20-o%20pipefail%0A%0ANODECONF%3D%2Fetc%2Fsystemd%2Fsystem%2Fkubelet.service.d%2F20-aws-providerid.conf%0A%0Aif%20%5B%20-e%20%22%24%7BNODECONF%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Not%20replacing%20existing%20%24%7BNODECONF%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20afterburn%20service%20is%20expected%20to%20be%20used%20for%20metadata%20retrival%2C%20see%20respective%20systemd%20unit.%0A%23%20However%2C%20on%20older%20OCP%20boot%20images%20does%20not%20contain%20afterburn%20service%2C%20check%20if%20afterburn%20variables%20are%20there%0A%23%20otherwise%20try%20to%20communicate%20IMDS%20here.%0A%23%20metadata%20related%20afterburn%20doc%3A%20https%3A%2F%2Fcoreos.github.io%2Fafterburn%2Fusage%2Fattributes%2F%0A%0AINSTANCE_ID%3D%24%7BAFTERBURN_AWS_INSTANCE_ID%3A-%7D%0AAVAILABILITY_ZONE%3D%24%7BAFTERBURN_AWS_AVAILABILITY_ZONE%3A-%7D%0Aif%20%5B%5B%20-z%20%22%24%7BINSTANCE_ID%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20-z%20%22%24%7BAVAILABILITY_ZONE%7D%22%20%5D%5D%3B%20then%0A%20%20INSTANCE_ID%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Finstance-id)%0A%20%20AVAILABILITY_ZONE%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Fplacement%2Favailability-zone)%0A%20%20if%20%5B%5B%20-z%20%22%24%7BINSTANCE_ID%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20-z%20%22%24%7BAVAILABILITY_ZONE%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Can%20not%20obtain%20instance-id%20and%20availability%20zone%20info%20from%20the%20metadata%20service.%22%0A%20%20%20%20exit%201%0A%20%20fi%20%0Afi%0A%0A%23%20Due%20to%20a%20potential%20mismatch%20between%20Hostname%20and%20PrivateDNSName%20with%20clusters%20that%20use%20custom%20DHCP%20Option%20Sets%0A%23%20which%20can%20cause%20issues%20in%20cloud%20controller%20manager%20node%20syncing%0A%23%20(see%3A%20https%3A%2F%2Fgithub.com%2Fkubernetes%2Fcloud-provider-aws%2Fissues%2F384)%2C%0A%23%20set%20KUBELET_PROVIDERID%20to%20be%20a%20fully%20qualified%20AWS%20instace%20provider%20id.%0A%23%20This%20new%20variable%20is%20later%20used%20to%20populate%20the%20kubelet's%20%60provider-id%60%20flag%2C%20later%20set%20on%20the%20Node%20.spec%0A%23%20and%20used%20by%20the%20cloud%20controller%20manager's%20node%20controller%20to%20retrieve%20the%20Node's%20backing%20instance.%0Acat%20%3E%20%22%24%7BNODECONF%7D%22%20%3C%3CEOF%0A%5BService%5D%0AEnvironment%3D%22KUBELET_PROVIDERID%3Daws%3A%2F%2F%2F%24%7BAVAILABILITY_ZONE%7D%2F%24%7BINSTANCE_ID%7D%22%0AEOF%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/aws-kubelet-providerid
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20First%2C%20we%20need%20to%20wait%20until%20DHCP%20finishes%20and%20the%20node%20has%20a%20non-%60localhost%60%0A%23%20hostname%20before%20%60kubelet.service%60%20starts.%0A%23%20That's%20the%20%60--wait%60%20argument%20as%20used%20by%20%60node-valid-hostname.service%60.%0A%23%0A%23%20Second%2C%20on%20GCP%20specifically%20we%20truncate%20the%20hostname%20if%20it's%20%3E63%20characters.%0A%23%20That's%20%60gcp-hostname.service%60.%0A%0A%23%20Block%20indefinitely%20until%20the%20host%20gets%20a%20non-localhost%20name.%0A%23%20Note%20node-valid-hostname.service%20uses%20systemd%20to%20abort%20if%20this%20takes%20too%20long.%0Await_localhost()%20%7B%0A%20%20%20%20echo%20%22waiting%20for%20non-localhost%20hostname%20to%20be%20assigned%22%0A%20%20%20%20while%20%5B%5B%20%22%24(%3C%20%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%20%3D~%20(localhost%7Clocalhost.localdomain)%20%5D%5D%3B%0A%20%20%20%20do%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20done%0A%20%20%20%20echo%20%22node%20identified%20as%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%0A%20%20%20%20echo%20%22saving%20hostname%20to%20prevent%20NetworkManager%20from%20ever%20unsetting%20it%22%0A%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_gcp_hostname()%20%7B%0A%20%20%20%20%2Fusr%2Fbin%2Fafterburn%20--provider%20gcp%20--hostname%3D%2Frun%2Fafterburn.hostname%0A%0A%20%20%20%20local%20host_name%3D%24(cat%20%2Frun%2Fafterburn.hostname)%0A%20%20%20%20local%20type_arg%3D%22transient%22%0A%0A%20%20%20%20%23%20%2Fetc%2Fhostname%20is%20used%20for%20static%20hostnames%20and%20is%20authoritative.%0A%20%20%20%20%23%20This%20will%20check%20to%20make%20sure%20that%20the%20static%20hostname%20is%20the%0A%20%20%20%20%23%20less%20than%20or%20equal%20to%2063%20characters%20in%20length.%0A%20%20%20%20if%20%5B%20-f%20%2Fetc%2Fhostname%20%5D%20%26%26%20%5B%20%22%24(cat%20%2Fetc%2Fhostname%20%7C%20wc%20-m)%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20etc_name%3D%22%24(%3C%20%2Fetc%2Fhostname)%22%0A%20%20%20%20%20%20%20%20type_arg%3D%22static%22%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24%7Betc_name%7D%22%20!%3D%20%22%24%7Bhost_name%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%2Fetc%2Fhostname%20is%20set%20to%20%24%7Betc_name%7D%20but%20does%20not%20match%20%24%7Bhost_name%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22using%20%2Fetc%2Fhostname%20as%20the%20authoritative%20name%22%0A%20%20%20%20%20%20%20%20%20%20%20%20host_name%3D%22%24%7Betc_name%7D%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Only%20mutate%20the%20hostname%20if%20the%20length%20is%20longer%20than%2063%20characters.%20The%0A%20%20%20%20%23%20hostname%20will%20be%20the%20lesser%20of%2063%20characters%20after%20the%20first%20dot%20in%20the%0A%20%20%20%20%23%20FQDN.%20%20This%20algorithm%20is%20only%20known%20to%20work%20in%20GCP%2C%20and%20hence%20is%20only%0A%20%20%20%20%23%20executed%20in%20GCP.%0A%20%20%20%20if%20%5B%20%22%24%7B%23host_name%7D%22%20-gt%2063%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20alt_name%3D%24(printf%20%22%24%7Bhost_name%7D%22%20%7C%20cut%20-f1%20-d'.'%20%7C%20cut%20-c%20-63)%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Bhost_name%7D%20is%20longer%20than%2063%20characters%2C%20using%20truncated%20hostname%22%0A%20%20%20%20%20%20%20%20host_name%3D%22%24%7Balt_name%7D%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22setting%20%24%7Btype_arg%7D%20hostname%20to%20%24%7Bhost_name%7D%22%0A%20%20%20%20%2Fbin%2Fhostnamectl%20%22--%24%7Btype_arg%7D%22%20set-hostname%20%22%24%7Bhost_name%7D%22%0A%20%20%20%20exit%200%0A%7D%0A%0Aarg%3D%24%7B1%7D%3B%20shift%3B%0Acase%20%22%24%7Barg%7D%22%20in%0A%20%20%20%20--wait)%20wait_localhost%3B%3B%0A%20%20%20%20--gcp)%20set_gcp_hostname%3B%3B%0A%20%20%20%20*)%20echo%20%22Unhandled%20arg%20%24arg%22%3B%20exit%201%0Aesac%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/mco-hostname
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0Aset%20-eou%20pipefail%0A%0A%23%20context%0Aintapi%3D%24(oc%20get%20infrastructures.config.openshift.io%20cluster%20-o%20%22jsonpath%3D%7B.status.apiServerInternalURI%7D%22)%0Acontext%3D%22%24(oc%20config%20current-context)%22%0A%23%20cluster%0Acluster%3D%22%24(oc%20config%20view%20-o%20%22jsonpath%3D%7B.contexts%5B%3F(%40.name%3D%3D%5C%22%24context%5C%22)%5D.context.cluster%7D%22)%22%0Aserver%3D%22%24(oc%20config%20view%20-o%20%22jsonpath%3D%7B.clusters%5B%3F(%40.name%3D%3D%5C%22%24cluster%5C%22)%5D.cluster.server%7D%22)%22%0A%23%20token%0Aca_crt_data%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20-o%20%22jsonpath%3D%7B.data.ca%5C.crt%7D%22%20%7C%20base64%20--decode)%22%0Anamespace%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20%20-o%20%22jsonpath%3D%7B.data.namespace%7D%22%20%7C%20base64%20--decode)%22%0Atoken%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20-o%20%22jsonpath%3D%7B.data.token%7D%22%20%7C%20base64%20--decode)%22%0A%0Aexport%20KUBECONFIG%3D%22%24(mktemp)%22%0Akubectl%20config%20set-credentials%20%22kubelet%22%20--token%3D%22%24token%22%20%3E%2Fdev%2Fnull%0Aca_crt%3D%22%24(mktemp)%22%3B%20echo%20%22%24ca_crt_data%22%20%3E%20%24ca_crt%0Akubectl%20config%20set-cluster%20%24cluster%20--server%3D%22%24intapi%22%20--certificate-authority%3D%22%24ca_crt%22%20--embed-certs%20%3E%2Fdev%2Fnull%0Akubectl%20config%20set-context%20kubelet%20--cluster%3D%22%24cluster%22%20--user%3D%22kubelet%22%20%3E%2Fdev%2Fnull%0Akubectl%20config%20use-context%20kubelet%20%3E%2Fdev%2Fnull%0Acat%20%22%24KUBECONFIG%22%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/recover-kubeconfig.sh
        - contents:
            source: data:,
          mode: 493
          overwrite: true
          path: /etc/kubernetes/kubelet-plugins/volume/exec/.dummy
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1941714%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1935539%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1987108%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22vmxnet3%22%20%5D%5D%3B%20then%0A%20%20logger%20-s%20%2299-vsphere-disable-tx-udp-tnl%20triggered%20by%20%24%7B2%7D%20on%20device%20%24%7BDEVICE_IFACE%7D.%22%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-csum-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksum-ip-generic%20off%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-vsphere-disable-tx-udp-tnl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0Aif%20%5B%20!%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20%23%20No%20need%20to%20do%20this%20if%20no%20NMState%20configuration%20was%20applied%0A%20%20exit%200%0Afi%0A%0A%23%20This%20logic%20is%20borrowed%20from%20configure-ovs.sh%0A%23%20TODO%3A%20Find%20a%20platform-agnostic%20way%20to%20do%20this.%20It%20won't%20work%20on%20platforms%20where%0A%23%20nodeip-configuration%20is%20not%20used.%0Aip%3D%24(cat%20%2Frun%2Fnodeip-configuration%2Fprimary-ip)%0Aif%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20echo%20%22No%20ip%20to%20bind%20was%20found%22%0A%20%20exit%201%0Afi%0Awhile%20%3A%0Ado%0A%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%20%20sleep%2010%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-primary-ip.sh
        - contents:
            source: data:,unqualified-search-registries%20%3D%20%5B'registry.access.redhat.com'%2C%20'docker.io'%5D%0A
          mode: 420
          overwrite: true
          path: /etc/containers/registries.conf
        - contents:
            source: data:,%5Bcrio%5D%0Ainternal_wipe%20%3D%20true%0Ainternal_repair%20%3D%20true%0A%0A%5Bcrio.api%5D%0Astream_address%20%3D%20%22127.0.0.1%22%0Astream_port%20%3D%20%220%22%0A%0A%5Bcrio.runtime%5D%0Aselinux%20%3D%20true%0Aconmon%20%3D%20%22%22%0Aconmon_cgroup%20%3D%20%22pod%22%0Adefault_env%20%3D%20%5B%0A%20%20%20%20%22NSS_SDB_USE_CACHE%3Dno%22%2C%0A%5D%0Adefault_runtime%20%3D%20%22crun%22%0Alog_level%20%3D%20%22info%22%0Acgroup_manager%20%3D%20%22systemd%22%0Adefault_sysctls%20%3D%20%5B%0A%20%20%20%20%22net.ipv4.ping_group_range%3D0%202147483647%22%2C%0A%5D%0Ahooks_dir%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Frun%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Fusr%2Fshare%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%5D%0Amanage_ns_lifecycle%20%3D%20true%0Aabsent_mount_sources_to_reject%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fhostname%22%2C%0A%5D%0Adrop_infra_ctr%20%3D%20true%0A%0A%5Bcrio.runtime.runtimes.runc%5D%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%0A%5Bcrio.runtime.runtimes.crun%5D%0Aruntime_root%20%3D%20%22%2Frun%2Fcrun%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%23%20Based%20on%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcrun%2Fblob%2F27d7dd3a0%2FREADME.md%3Fplain%3D1%23L48%0Acontainer_min_memory%20%3D%20%22512KiB%22%0A%0A%5Bcrio.runtime.workloads.openshift-builder%5D%0Aactivation_annotation%20%3D%20%22io.openshift.builder%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%22io.kubernetes.cri-o.userns-mode%22%2C%0A%20%20%22io.kubernetes.cri-o.Devices%22%0A%5D%0A%5Bcrio.runtime.workloads.openshift-builder.resources%5D%0A%0A%5Bcrio.image%5D%0Aglobal_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_image%20%3D%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A8c3c9719ba85ce692f2462e653d82d154bd958dc57c236d6bc0a8092bb6b2080%22%0Apause_image_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_command%20%3D%20%22%2Fusr%2Fbin%2Fpod%22%0A%0A%5Bcrio.network%5D%0Anetwork_dir%20%3D%20%22%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F%22%0Aplugin_dirs%20%3D%20%5B%0A%20%20%20%20%22%2Fvar%2Flib%2Fcni%2Fbin%22%2C%0A%20%20%20%20%22%2Fusr%2Flibexec%2Fcni%22%2C%0A%5D%0A%0A%5Bcrio.metrics%5D%0Aenable_metrics%20%3D%20true%0Ametrics_host%20%3D%20%22127.0.0.1%22%0Ametrics_port%20%3D%209537%0Ametrics_collectors%20%3D%20%5B%0A%20%20%22operations%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_total%22%0A%20%20%22operations_latency_microseconds_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds_total%22%0A%20%20%22operations_latency_microseconds%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds%22%0A%20%20%22operations_errors%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_errors_total%22%0A%20%20%22image_pulls_layer_size%22%2C%0A%20%20%22containers_oom_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22containers_oom_count_total%22%0A%20%20%22containers_oom%22%2C%0A%20%20%23%20Drop%20metrics%20with%20excessive%20label%20cardinality.%0A%20%20%23%20%22image_pulls_by_digest%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name_skipped%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_skipped_bytes_total%22%0A%20%20%23%20%22image_pulls_failures%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_failure_total%22%0A%20%20%23%20%22image_pulls_successes%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_success_total%22%0A%20%20%23%20%22image_layer_reuse%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_layer_reuse_total%22%0A%20%20%22operations_total%22%2C%0A%20%20%22operations_latency_seconds_total%22%2C%0A%20%20%22operations_latency_seconds%22%2C%0A%20%20%22operations_errors_total%22%2C%0A%20%20%22image_pulls_bytes_total%22%2C%0A%20%20%22image_pulls_skipped_bytes_total%22%2C%0A%20%20%22image_pulls_success_total%22%2C%0A%20%20%22image_pulls_failure_total%22%2C%0A%20%20%22image_layer_reuse_total%22%2C%0A%20%20%22containers_oom_count_total%22%2C%0A%20%20%22processes_defunct%22%0A%5D%0A
          mode: 420
          overwrite: true
          path: /etc/crio/crio.conf.d/00-default
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D
          mode: 420
          overwrite: true
          path: /etc/containers/policy.json
        - contents:
            source: data:,%5BGlobal%5D
          mode: 420
          overwrite: true
          path: /etc/kubernetes/cloud.conf
        - contents:
            source: data:,authorization%3A%0A%20%20static%3A%0A%20%20%20%20-%20resourceRequest%3A%20false%0A%20%20%20%20%20%20path%3A%20%2Fmetrics%0A%20%20%20%20%20%20verb%3A%20get%0A%20%20%20%20%20%20user%3A%0A%20%20%20%20%20%20%20%20name%3A%20system%3Aserviceaccount%3Aopenshift-monitoring%3Aprometheus-k8s
          mode: 420
          overwrite: true
          path: /etc/kubernetes/crio-metrics-proxy.cfg
        - contents:
            source: data:,apiVersion%3A%20v1%0Akind%3A%20Pod%0Ametadata%3A%0A%20%20name%3A%20kube-rbac-proxy-crio%0A%20%20namespace%3A%20openshift-machine-config-operator%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20etc-kube%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20hostNetwork%3A%20true%0A%20%20priorityClassName%3A%20system-cluster-critical%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20setup%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ae6c78ecf5ff15391d335577ffca87563ddd533727e52cf08217038a579f70dd9%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20command%3A%20%5B'%2Fbin%2Fbash'%2C%20'-ec'%5D%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20echo%20-n%20%22Waiting%20for%20kubelet%20key%20and%20certificate%20to%20be%20available%22%0A%20%20%20%20%20%20while%20%5B%20-n%20%22%24(test%20-e%20%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem)%22%20%5D%20%3B%20do%0A%20%20%20%20%20%20%20%20echo%20-n%20%22.%22%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20%20%20%20%20((%20tries%20%2B%3D%201%20))%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20%22%24%7Btries%7D%22%20-gt%2010%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Timed%20out%20waiting%20for%20kubelet%20key%20and%20cert.%22%0A%20%20%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20done%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20%20%20%20%20cpu%3A%205m%0A%20%20containers%3A%0A%20%20-%20name%3A%20kube-rbac-proxy-crio%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ae6c78ecf5ff15391d335577ffca87563ddd533727e52cf08217038a579f70dd9%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20ports%3A%0A%20%20%20%20-%20containerPort%3A%209637%0A%20%20%20%20args%3A%0A%20%20%20%20-%20--secure-listen-address%3D%3A9637%0A%20%20%20%20-%20--config-file%3D%2Fetc%2Fkubernetes%2Fcrio-metrics-proxy.cfg%0A%20%20%20%20-%20--client-ca-file%3D%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20%20%20-%20--logtostderr%3Dtrue%0A%20%20%20%20-%20--kubeconfig%3D%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%0A%20%20%20%20-%20--tls-cipher-suites%3DTLS_AES_128_GCM_SHA256%2CTLS_AES_256_GCM_SHA384%2CTLS_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%20%0A%20%20%20%20-%20--tls-min-version%3DVersionTLS12%0A%20%20%20%20-%20--upstream%3Dhttp%3A%2F%2F127.0.0.1%3A9537%0A%20%20%20%20-%20--tls-cert-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20-%20--tls-private-key-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%2020m%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20etc-kube%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/criometricsproxy.yaml
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,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
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
        - contents:
            source: data:,%23!%2Fbin%2Fsh%0Aif%20%5B%20-x%20%2Fusr%2Fbin%2Fkubensenter%20%5D%3B%20then%0A%20%20exec%20%2Fusr%2Fbin%2Fkubensenter%20%22%24%40%22%0Aelse%0A%20%20exec%20%22%24%40%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/kubenswrapper
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Cleans NetworkManager state generated by dracut
            # Removal of this file signals firstboot completion
            ConditionPathExists=!/etc/ignition-machine-config-encapsulated.json
            # This is opt-in for some deployment types, and opt-out for others.
            ConditionPathExists=/var/lib/mco/nm-clean-initrd-state
            Wants=network-pre.target
            Before=network-pre.target

            [Service]
            Type=oneshot
            # Remove any existing state possibly generated NM run by dracut. We want NM to
            # consider all profiles autoconnect priority when it starts instead of
            # remembering which profile was a device activated with when NM is run by
            # dracut.
            ExecStart=/usr/local/bin/nm-clean-initrd-state.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: NetworkManager-clean-initrd-state.service
        - contents: |
            [Unit]
            Description=Fetch kubelet node name from AWS Metadata

            # Run afterburn service for collect info from metadata server
            # see: https://coreos.github.io/afterburn/usage/attributes/
            # Not required due to OCP 4.1 boot image does not contain afterburn service
            # see: https://issues.redhat.com/browse/OCPBUGS-7559
            Wants=afterburn.service
            After=afterburn.service

            # Wait for NetworkManager to report it's online
            After=NetworkManager-wait-online.service
            # Run before kubelet
            Before=kubelet-dependencies.target

            [Service]
            # Mark afterburn environment file optional, due to it is possible that afterburn service was not executed
            EnvironmentFile=-/run/metadata/afterburn
            ExecStart=/usr/local/bin/aws-kubelet-nodename
            Type=oneshot

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: aws-kubelet-nodename.service
        - contents: |
            [Unit]
            Description=Fetch kubelet provider id from AWS Metadata

            # Run afterburn service for collect info from metadata server
            # see: https://coreos.github.io/afterburn/usage/attributes/
            # Not required due to OCP 4.1 boot image does not contain afterburn service
            # see: https://issues.redhat.com/browse/OCPBUGS-7559
            Wants=afterburn.service
            After=afterburn.service

            # Wait for NetworkManager to report it's online
            After=NetworkManager-wait-online.service
            # Run before kubelet
            Before=kubelet-dependencies.target

            [Service]
            # Mark afterburn environment file optional, due to it is possible that afterburn service was not executed
            EnvironmentFile=-/run/metadata/afterburn
            ExecStart=/usr/local/bin/aws-kubelet-providerid
            Type=oneshot

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: aws-kubelet-providerid.service
        - dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="ENABLE_PROFILE_UNIX_SOCKET=true"
            name: 10-mco-profile-unix-socket.conf
          - contents: |
              [Unit]
              After=kubelet-dependencies.target
              Requires=kubelet-dependencies.target
            name: 05-mco-ordering.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: crio.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: docker.socket
        - contents: |
            [Unit]
            Description=The firstboot OS update has completed
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target

            [Install]
            WantedBy=default.target
          enabled: true
          name: firstboot-osupdate.target
        - contents: |
            [Unit]
            Description=Dynamically sets the system reserved for the kubelet
            Wants=network-online.target
            After=network-online.target firstboot-osupdate.target
            Before=kubelet-dependencies.target

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            RemainAfterExit=yes
            EnvironmentFile=/etc/node-sizing-enabled.env
            ExecStart=/bin/bash /usr/local/sbin/dynamic-system-reserved-calc.sh ${NODE_SIZING_ENABLED} ${SYSTEM_RESERVED_MEMORY} ${SYSTEM_RESERVED_CPU} ${SYSTEM_RESERVED_ES}
            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: kubelet-auto-node-size.service
        - contents: |
            [Unit]
            Description=Dependencies necessary to run kubelet
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target network-online.target
            Wants=NetworkManager-wait-online.service crio-wipe.service
            Wants=rpc-statd.service chrony-wait.service
          name: kubelet-dependencies.target
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet
            Requires=crio.service kubelet-dependencies.target
            After=kubelet-dependencies.target
            After=ostree-finalize-staged.service

            [Service]
            Type=notify
            ExecStartPre=/bin/mkdir --parents /etc/kubernetes/manifests
            ExecStartPre=-/usr/sbin/restorecon -rv /var/lib/kubelet/ /usr/local/bin/kubenswrapper /usr/bin/kubensenter
            Environment="KUBELET_NODE_IP=0.0.0.0"
            EnvironmentFile=/etc/os-release
            EnvironmentFile=-/etc/kubernetes/kubelet-workaround
            EnvironmentFile=-/etc/kubernetes/kubelet-env
            EnvironmentFile=/etc/node-sizing.env

            ExecStart=/usr/local/bin/kubenswrapper \
                /usr/bin/kubelet \
                  --config=/etc/kubernetes/kubelet.conf \
                  --bootstrap-kubeconfig=/etc/kubernetes/kubeconfig \
                  --kubeconfig=/var/lib/kubelet/kubeconfig \
                  --container-runtime-endpoint=/var/run/crio/crio.sock \
                  --runtime-cgroups=/system.slice/crio.service \
                  --node-labels=node-role.kubernetes.io/control-plane,node-role.kubernetes.io/master,node.openshift.io/os_id=${ID} \
                  --node-ip=${KUBELET_NODE_IP} \
                  --minimum-container-ttl-duration=6m0s \
                  --cloud-provider=external \
                  --volume-plugin-dir=/etc/kubernetes/kubelet-plugins/volume/exec \
                  --image-credential-provider-bin-dir=/usr/libexec/kubelet-image-credential-provider-plugins --image-credential-provider-config=/etc/kubernetes/credential-providers/ecr-credential-provider.yaml \
                  --hostname-override=${KUBELET_NODE_NAME} \
                  --provider-id=${KUBELET_PROVIDERID} \
                  --register-with-taints=node-role.kubernetes.io/master=:NoSchedule \
                  --pod-infra-container-image=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8c3c9719ba85ce692f2462e653d82d154bd958dc57c236d6bc0a8092bb6b2080 \
                  --system-reserved=cpu=${SYSTEM_RESERVED_CPU},memory=${SYSTEM_RESERVED_MEMORY},ephemeral-storage=${SYSTEM_RESERVED_ES} \
                  --v=${KUBELET_LOG_LEVEL}

            Restart=always
            RestartSec=10

            [Install]
            WantedBy=multi-user.target
          dropins:
          - contents: |
              [Service]
              EnvironmentFile=/etc/kubernetes/node.env
            name: 20-node-env.conf
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          enabled: true
          name: kubelet.service
        - contents: |
            [Unit]
            Description=Manages a mount namespace for kubernetes-specific mounts

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            RuntimeDirectory=kubens
            Environment=RUNTIME_DIRECTORY=%t/kubens
            Environment=BIND_POINT=%t/kubens/mnt
            Environment=ENVFILE=%t/kubens/env

            # Set up the runtime directory as an unbindable mountpoint
            ExecStartPre=bash -c "findmnt ${RUNTIME_DIRECTORY} || mount --make-unbindable --bind ${RUNTIME_DIRECTORY} ${RUNTIME_DIRECTORY}"
            # Ensure the bind point exists
            ExecStartPre=touch ${BIND_POINT}
            # Use 'unshare' to create the new mountpoint, then 'mount --make-rshared' so it cascades internally
            ExecStart=unshare --mount=${BIND_POINT} --propagation slave mount --make-rshared /
            # Finally, set an env pointer for ease-of-use
            ExecStartPost=bash -c 'echo "KUBENSMNT=${BIND_POINT}" > "${ENVFILE}"'

            # On stop, a recursive unmount cleans up the namespace and bind-mounted unbindable parent directory
            ExecStop=umount -R ${RUNTIME_DIRECTORY}

            [Install]
            WantedBy=multi-user.target
          enabled: false
          name: kubens.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Firstboot
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # Removal of this file signals firstboot completion
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            After=machine-config-daemon-pull.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            # Disable existing repos (if any) so that OS extensions would use embedded RPMs only
            ExecStartPre=-/usr/bin/sh -c "sed -i 's/enabled=1/enabled=0/' /etc/yum.repos.d/*.repo"
            # Run this via podman because we want to use the nmstatectl binary in our container
            ExecStart=/usr/bin/podman run --rm --privileged --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:787a505ca594b0a727549353c503dec9233a9d3c2dcd6b64e3de5f998892a1d5' firstboot-complete-machineconfig --persist-nics
            ExecStart=/usr/bin/podman run --rm --privileged --pid=host --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:787a505ca594b0a727549353c503dec9233a9d3c2dcd6b64e3de5f998892a1d5' firstboot-complete-machineconfig
            [Install]
            RequiredBy=firstboot-osupdate.target
          enabled: true
          name: machine-config-daemon-firstboot.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Pull
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # This "stamp file" is unlinked when we complete
            # machine-config-daemon-firstboot.service
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            # Run after crio-wipe so the pulled MCD image is protected against a corrupted storage from a forced shutdown
            Wants=crio-wipe.service NetworkManager-wait-online.service
            After=crio-wipe.service NetworkManager-wait-online.service network.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStart=/bin/sh -c "while ! /usr/bin/podman pull --authfile=/var/lib/kubelet/config.json 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:787a505ca594b0a727549353c503dec9233a9d3c2dcd6b64e3de5f998892a1d5'; do sleep 1; done"
            [Install]
            RequiredBy=machine-config-daemon-firstboot.service
          enabled: true
          name: machine-config-daemon-pull.service
        - contents: |
            [Unit]
            Description=Wait for a non-localhost hostname
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            User=root
            ExecStart=/usr/local/bin/mco-hostname --wait

            # Wait up to 5min for the node to get a non-localhost name
            TimeoutSec=300

            [Install]
            # TODO: Change this to RequiredBy after we fix https://github.com/openshift/machine-config-operator/pull/3865#issuecomment-1746963115
            WantedBy=kubelet-dependencies.target
          enabled: true
          name: node-valid-hostname.service
        - contents: |
            [Unit]
            Description=Writes IP address configuration so that kubelet and crio services select a valid node IP
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service firstboot-osupdate.target
            Before=kubelet-dependencies.target ovs-configuration.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/bin/podman run --rm \
              --authfile /var/lib/kubelet/config.json \
              --net=host \
              --security-opt label=disable \
              --volume /etc/systemd/system:/etc/systemd/system \
              --volume /run/nodeip-configuration:/run/nodeip-configuration \
              quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:02a7419d80a103e656c25a8d7573106a62e8e4a41508c758387db7e13801d89c \
              node-ip \
              set \
              --retry-on-failure \
              --network-type OVNKubernetes \
              ${NODEIP_HINT:-${KUBELET_NODEIP_HINT:-}}; \
              do \
              sleep 5; \
              done"
            ExecStart=/bin/systemctl daemon-reload
            ExecStartPre=/bin/mkdir -p /run/nodeip-configuration
            StandardOutput=journal+console
            StandardError=journal+console

            EnvironmentFile=-/etc/default/nodeip-configuration

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: false
          name: nodeip-configuration.service
        - enabled: true
          name: openvswitch.service
        - contents: |
            [Unit]
            # Kdump will generate it's initramfs based on the running state when kdump.service run
            # If OVS has already run, the kdump fails to gather a working network config,
            # which prevent network log exports, sush as SSH.
            # See https://issues.redhat.com/browse/OCPBUGS-28239
            After=kdump.service
            Description=Configures OVS with proper host networking configuration
            # This service is used to move a physical NIC into OVS and reconfigure OVS to use the host IP
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=firstboot-osupdate.target
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service nmstate.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            ExecStart=/usr/local/bin/configure-ovs.sh OVNKubernetes
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: ovs-configuration.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /var/lib/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /etc/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /run/openvswitch'
              ExecStartPost=-/usr/bin/ovs-appctl vlog/set syslog:info
              ExecReload=-/usr/bin/ovs-appctl vlog/set syslog:info
            name: 10-ovs-vswitchd-restart.conf
          name: ovs-vswitchd.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
            name: 10-ovsdb-restart.conf
          enabled: true
          name: ovsdb-server.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          name: pivot.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              # See https://github.com/openshift/machine-config-operator/issues/1897
              [Service]
              Nice=10
              IOSchedulingClass=best-effort
              IOSchedulingPriority=6
            name: mco-controlplane-nice.conf
          name: rpm-ostreed.service
        - contents: |
            [Unit]
            Description=Ensure primary IP is assigned and usable
            Requires=nmstate.service
            After=nmstate.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/wait-for-primary-ip.sh; \
              do \
              sleep 10; \
              done"
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: wait-for-primary-ip.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: zincati.service
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet After Reboot Cleanup
            Before=kubelet.service

            [Service]
            Type=oneshot
            ExecStart=/bin/rm -f /var/lib/kubelet/cpu_manager_state
            ExecStart=/bin/rm -f /var/lib/kubelet/memory_manager_state
            ExecStart=-/bin/rm -f /var/lib/kubelet/dra_manager_state

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet-cleanup.service
    extensions: []
    fips: false
    kernelArguments:
    - systemd.unified_cgroup_hierarchy=1
    - cgroup_no_v1="all"
    - psi=0
    kernelType: default
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:ad394c1a0b0cc7d37e2bc632f795f9140ca3f68bc0f2ca2895b83125c61a7d2e
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: d656f31b697c2671aac38bbe46d9e5b22d27ae90
      machineconfiguration.openshift.io/release-image-version: 4.18.0-ec.3
    creationTimestamp: "2024-11-20T22:36:32Z"
    generation: 1
    name: rendered-master-909adc791f502a35c20ba70158c4c582
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: MachineConfigPool
      name: master
      uid: 8cbf0d60-4f8f-4dfc-932a-7172d44d6e89
    resourceVersion: "10205"
    uid: 74f8e229-2ea5-487e-af5a-2ef7a34e73b2
  spec:
    baseOSExtensionsContainerImage: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:c3a4fec8e58e41a24e4bc15de9c1261b917448246d62b37dc83e4871837e3fbb
    config:
      ignition:
        version: 3.4.0
      passwd:
        users:
        - name: core
          sshAuthorizedKeys:
          - |
            ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDLume21au7DO1U53hRBlP0FdJPJ85QEsm/ahjj3t9ZHUZkIZIZspYkAu6uahm6JReNnAbo2lDvVaVjq134BooT++WRIhk2X4hv7eUFYpBPaztjrTTG+COqLNJHZKNKa+KzRDEDk/TDsBSOgx35qZdC4l2VnJOkFXxGKMC/N4cW+NBJCdEOOz56LodPHmmIM1I0U97tuHkplw4+vMrAh8DgjoaxpijBlGOnVo3fD95EoG4D+d3RkOSsB3AsrkdyZa+A703NvSuIcofbOvXz5tBeKVlgpSyXUKywtKPr7J8UnWy3/ajGTDuY+kY/447Y+n1T5aU/iD8Xk2LTBhIZ7Z7SilYYWgV6Yr+z7DpLUqCBWlggI/Owp8XOaAPRETl3UPxFc4hKkE3cL8eu+Nw25ooUwY4Jikoq+r3WY2FCcVnQL2Rswf7z+pi8q49YaQV0mFGoow036+5f1JA/GvglDZEnKWMH8rwQw0Sw24FG+iC+1Fy6qrKoMFkz2nk4j8lZ368= nmoraiti@localhost.localdomain
      storage:
        files:
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0ANM_DEVICES_DIR%3D%2Frun%2FNetworkManager%2Fdevices%0ANM_RUN_CONN_DIR%3D%2Frun%2FNetworkManager%2Fsystem-connections%0ANM_ETC_CONN_DIR%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A%0Alogger%20-t%20nm-clean-initrd-state%20%22Cleaning%20network%20activation%20state%20generated%20by%20dracut...%22%0Alogger%20-t%20nm-clean-initrd-state%20%22To%20disable%2C%20remove%20%2Fvar%2Flib%2Fmco%2Fnm-clean-initrd-state%22%0A%0Aif%20%5B%20!%20-e%20%22%24NM_DEVICES_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_RUN_CONN_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_ETC_CONN_DIR%22%20%5D%3B%20then%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22There%20is%20no%20network%20activation%20state%20to%20clean%22%0A%20%20exit%0Afi%0A%0A%23%20Some%20deployments%20require%20an%20active%20network%20early%20in%20the%20boot%20process.%20To%0A%23%20achieve%20this%2C%20dracut%20runs%20specific%20NetworkManager%20modules.%20This%20results%20in%0A%23%20NetworkManager%20keyfiles%20being%20generated%20(either%20default%20or%20from%20ip%20kernel%0A%23%20arguments)%20and%20activated.%20This%20activation%20generates%20state%20that%20makes%20those%0A%23%20profiles%20to%20be%20re-activated%20by%20the%20NetworkManager%20service%20later%20in%20the%0A%23%20boot%20process.%20And%20this%20has%20the%20effect%20that%20other%20profiles%20deployed%20by%20the%0A%23%20user%20for%20the%20same%20set%20of%20devices%20are%20ignored.%0A%0A%23%20Most%20of%20the%20time%20this%20is%20the%20desired%20behavior.%20The%20exception%20to%20this%20rule%0A%23%20is%20when%20the%20user%20wants%20to%20run%20the%20boot%20process%20with%20a%20different%20network%0A%23%20setup%20than%20the%20real%20root%20which%20is%20usually%20related%20to%20the%20fact%20that%0A%23%20generating%20images%20with%20customized%20kernel%20arguments%20is%20a%20complication%20in%0A%23%20the%20deployment%20pipeline.%0A%0A%23%20This%20need%20has%20been%20exacerbated%20by%20past%20NetworkManager%20bugs%20that%20activated%0A%23%20the%20network%20on%20boot%20when%20it%20was%20not%20really%20needed.%20Most%20notably%20when%20ip%0A%23%20kernel%20argument%20is%20present%2C%20something%20that%20the%20baremetal%20installer%20adds%20by%0A%23%20default.%0A%0A%23%20The%20intention%20here%20is%20to%20remove%20the%20state%20that%20was%20generated%20with%20the%0A%23%20activation%20of%20those%20profiles%20during%20dracut%20execution.%20Then%20when%0A%23%20NetworkManager%20service%20runs%2C%20the%20profiles%20generated%20by%20dracut%2C%20along%20with%0A%23%20other%20profiles%20configured%20by%20the%20user%2C%20are%20evaluated%20towards%20finding%20the%0A%23%20most%20appropriate%20profile%20to%20connect%20a%20device%20with.%20As%20a%20precaution%2C%20clean%0A%23%20state%20only%20for%20devices%20that%3A%0A%23%20-%20have%20been%20activated%20with%20a%20default%20profile%20(assume%20that%20a%20non-default%0A%23%20%20%20configuration%20expresses%20intention%20by%20user%20to%20run%20with%20it%20permanently)%0A%23%20-%20have%20a%20specific%20configured%20profile%20set%20to%20auto-connect%20(if%20there%20is%20no%0A%23%20%20%20alternate%20configured%20profile%20for%20a%20device%20it%20makes%20no%20sense%20to%0A%23%20%20%20de-activate%20anything)%0A%23%0A%23%20Although%20this%20can%20theoretically%20happen%20on%20any%20deployment%20type%2C%20need%20has%0A%23%20mostly%20come%20from%20IPI%20bare%20metal%20deployments.%20For%20the%20time%20being%2C%20this%0A%23%20should%20be%20opt-in%20in%20any%20other%20deploment%20type.%0A%23%0A%23%20There%20is%20an%20RFE%20filed%20against%20NM%20that%20once%20implemented%20would%20make%20this%0A%23%20script%20unnecessary%3A%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D2089707%0A%0Afor%20device%20in%20%22%24%7BNM_DEVICES_DIR%7D%22%2F*%3B%20do%0A%20%20if%20%5B%20!%20-e%20%22%24device%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20the%20device%20file%20name%20is%20the%20ifindex%0A%20%20ifindex%3D%24(basename%20%22%24device%22)%0A%20%20%0A%20%20%23%20get%20the%20interface%20name%20by%20ifindex%0A%20%20ifname%3D%24(ip%20-j%20link%20show%20%7C%20jq%20-r%20%22.%5B%5D%20%7C%20select(.ifindex%20%3D%3D%20%24%7Bifindex%7D)%20%7C%20.ifname%20%2F%2F%20empty%22)%0A%0A%20%20%23%20no%20interface%20name%20found%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20get%20the%20uuid%20of%20the%20profile%20the%20device%20has%20been%20activated%20with%0A%20%20active_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bdevice%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Econnection-uuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24device%22)%0A%0A%20%20%23%20the%20device%20was%20not%20activated%20with%20any%20profile%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24active_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20generated%20profile%20by%20uuid%0A%20%20for%20profile%20in%20%22%24%7BNM_RUN_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20generated_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24active_profile_uuid%22%20%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20generated%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24active_profile_uuid%22%20!%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20check%20that%20it%20is%20not%20specific%20for%20the%20device%2C%20otherwise%20ignore%0A%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24profile_ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20profile%20not%20generated%20by%20nm-initrd-generator%2C%20ignore%0A%20%20%23%20only%20check%20it%20if%20the%20key%20is%20set%20(from%20NM%201.32.4)%0A%20%20origin%3D%24(sed%20-nr%20'%2F%5E%5C%5Buser%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eorg.freedesktop.NetworkManager.origin%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24origin%22%20%5D%20%26%26%20%5B%20%22%24origin%22%20!%3D%20%22nm-initrd-generator%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20configured%20profile%20by%20name%20with%20auto-connect%20set%0A%20%20for%20profile%20in%20%22%24%7BNM_ETC_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20autoconnect%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eautoconnect%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24profile_ifname%22%20%3D%20%22%24ifname%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20configured%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24profile_ifname%22%20!%3D%20%22%24ifname%22%20%5D%20%7C%7C%20%5B%20%22%24autoconnect%22%20%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20configured_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20activated%20with%20default%20generated%20profile%20%24generated_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20has%20different%20configured%20specific%20profile%20%24configured_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%3A%20removing%20state...%22%0A%20%20%0A%20%20%23%20NM%20can%20still%20generate%20internal%20profiles%20from%20the%20IP%20address%0A%20%20%23%20configuration%20of%20devices%2C%20so%20flush%20addresses%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Flushing%20IP%20addresses%20from%20%24ifname%22%0A%20%20ip%20addr%20flush%20%22%24ifname%22%0A%20%20ip%20-6%20addr%20flush%20%22%24ifname%22%0A%0A%20%20%23%20remove%20device%20state%20file%20to%20prevent%20NM%20to%20unilaterally%20connect%20with%20the%0A%20%20%23%20latest%20activated%20profile%20without%20evaluating%20other%20profiles%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Removing%20%24device%22%0A%20%20rm%20-f%20--%20%22%24device%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nm-clean-initrd-state.sh
        - contents:
            source: data:,%5Bconnection%5D%0Aipv6.dhcp-duid%3Dll%0Aipv6.dhcp-iaid%3Dmac%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/01-ipv6.conf
        - contents:
            source: data:,%5Bmain%5D%0Aplugins%3Dkeyfile%2Cifcfg-rh%0A%5Bkeyfile%5D%0Apath%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/20-keyfiles.conf
        - contents:
            source: data:,
          mode: 384
          overwrite: true
          path: /etc/pki/ca-trust/source/anchors/openshift-config-user-ca-bundle.crt
        - contents:
            source: data:,KUBERNETES_SERVICE_HOST%3D'api-int.ci-ln-hz4dqct-76ef8.aws-2.ci.openshift.org'%0AKUBERNETES_SERVICE_PORT%3D'6443'%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/apiserver-url.env
        - contents:
            source: data:,%23%20This%20file%20is%20managed%20by%20machine-config-operator.%0A%23%20Suppress%20audit%20rules%20which%20always%20trigger%20for%20container%0A%23%20workloads%2C%20as%20they%20spam%20the%20audit%20log.%20%20Workloads%20are%20expected%0A%23%20to%20be%20dynamic%2C%20and%20the%20networking%20stack%20uses%20iptables.%0A-a%20exclude%2Calways%20-F%20msgtype%3DNETFILTER_CFG%0A%23%20The%20default%20bridged%20networking%20enables%20promiscuous%20on%20the%20veth%0A%23%20device.%20%20Ideally%2C%20we'd%20teach%20audit%20to%20ignore%20only%20veth%20devices%2C%0A%23%20since%20one%20might%20legitimately%20care%20about%20promiscuous%20on%20real%20physical%0A%23%20devices.%20%20But%20we%20can't%20currently%20differentiate.%0A-a%20exclude%2Calways%20-F%20msgtype%3DANOM_PROMISCUOUS%0A
          mode: 420
          overwrite: true
          path: /etc/audit/rules.d/mco-audit-quiet-containers.rules
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20It%20has%20been%20observed%20that%20the%20kernel%20enables%20ESP%20offloads%20of%20bond%0A%23%20devices%20in%20active%2Fbackup%20mode%20even%20if%20slaves%20apparently%20don't%20support%0A%23%20it.%20It's%20unclear%20if%20this%20is%20expected%20behavior%20but%20we%20have%20had%20problems%0A%23%20with%20the%20resulting%20configuration%20in%20vsphere.%20So%20set%20ESP%20offload%20features%0A%23%20off%20in%20bond%20devices%20if%20they%20are%20off%20in%20slave%20devices%20for%20the%20time%20being.%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FRHEL-58811%0A%0Aif%20%5B%5B%20%22%242%22%20!%3D%20%22up%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24DEVICE_IFACE%22)%0A%0Aif%20%5B%5B%20%22%24driver%22%20!%3D%20%22bond%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Abond%3D%22%24DEVICE_IFACE%22%0Afor%20feature%20in%20tx-esp-segmentation%20esp-hw-offload%20esp-tx-csum-hw-offload%3B%20do%0A%0A%20%20if%20ethtool%20-k%20%22%24bond%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%23%20already%20disabled%2C%20nothing%20to%20do%0A%20%20%20%20continue%0A%20%20fi%0A%20%20%0A%20%20for%20slave%20in%20%24(nmcli%20-g%20BOND.SLAVES%20dev%20show%20%22%24DEVICE_IFACE%22)%3B%20do%0A%0A%20%20%20%20if%20!%20ethtool%20-k%20%22%24slave%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%20%20%23%20enabled%20in%20slave%2C%20nothing%20to%20do%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20logger%20-t%20bond-esp-offload%20-s%20%22Bond%20link%20%24slave%20has%20%24feature%20off%2C%20setting%20master%20%24DEVICE_IFACE%20%24feature%20off%22%0A%20%20%20%20ethtool%20-K%20%22%24bond%22%20%22%24feature%22%20off%0A%0A%20%20%20%20break%0A%20%20done%0Adone%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-bond-esp-offload
        - contents:
            source: data:,r%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F80-openshift-network.conf%0Ar%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F10-ovn-kubernetes.conf%0Ad%20%2Frun%2Fmultus%2Fcni%2Fnet.d%2F%200755%20root%20root%20-%20-%0AD%20%2Fvar%2Flib%2Fcni%2Fnetworks%2Fopenshift-sdn%2F%200755%20root%20root%20-%20-%0A
          mode: 420
          overwrite: true
          path: /etc/tmpfiles.d/cleanup-cni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Skipping%20configure-ovs%20due%20to%20manual%20network%20configuration%22%0A%20%20exit%200%0Afi%0A%0A%23%20This%20file%20is%20not%20needed%20anymore%20in%204.7%2B%2C%20but%20when%20rolling%20back%20to%204.6%0A%23%20the%20ovs%20pod%20needs%20it%20to%20know%20ovs%20is%20running%20on%20the%20host.%0Atouch%20%2Fvar%2Frun%2Fovs-config-executed%0A%0A%23%20These%20are%20well%20knwon%20NM%20default%20paths%0ANM_CONN_ETC_PATH%3D%22%2Fetc%2FNetworkManager%2Fsystem-connections%22%0ANM_CONN_RUN_PATH%3D%22%2Frun%2FNetworkManager%2Fsystem-connections%22%0A%0A%23%20This%20is%20the%20path%20where%20NM%20is%20known%20to%20be%20configured%20to%20store%20user%20keyfiles%20%0ANM_CONN_CONF_PATH%3D%22%24NM_CONN_ETC_PATH%22%0A%0A%23%20This%20is%20where%20we%20want%20our%20keyfiles%20to%20finally%20reside.%20configure-ovs%0A%23%20operates%20with%20temporary%20keyfiles%20in%20NM_CONN_RUN_PATH%20and%20then%20as%20a%20last%0A%23%20step%20moves%20those%20keyfiles%20to%20NM_CONN_SET_PATH%20if%20it%20is%20a%20different%20path%0A%23%20(not%20by%20default).%20This%20mitigates%20hard%20interruptions%20(SIGKILL%2C%20hard%20reboot)%0A%23%20of%20configure-ovs%20leaving%20the%20machine%20with%20a%20half-baked%20set%20of%20keyfiles%0A%23%20that%20might%20prevent%20machine%20networking%20from%20working%20correctly.%0ANM_CONN_SET_PATH%3D%22%24%7BNM_CONN_SET_PATH%3A-%24NM_CONN_RUN_PATH%7D%22%0A%0AMANAGED_NM_CONN_SUFFIX%3D%22-slave-ovs-clone%22%0A%23%20Workaround%20to%20ensure%20OVS%20is%20installed%20due%20to%20bug%20in%20systemd%20Requires%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1888017%0Acopy_nm_conn_files()%20%7B%0A%20%20local%20dst_path%3D%22%241%22%0A%20%20for%20src%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20src_path%3D%24(dirname%20%22%24src%22)%0A%20%20%20%20file%3D%24(basename%20%22%24src%22)%0A%20%20%20%20if%20%5B%20-f%20%22%24src_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%24dst_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20elif%20!%20cmp%20--silent%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20updated%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20-f%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it's%20equal%20at%20destination%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it%20does%20not%20exist%20at%20source%22%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0Aupdate_nm_conn_files_base()%20%7B%0A%20%20base_path%3D%24%7B1%7D%0A%20%20bridge_name%3D%24%7B2%7D%0A%20%20port_name%3D%24%7B3%7D%0A%20%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%20%20%23%20In%20RHEL7%20files%20in%20%2F%7Betc%2Crun%7D%2FNetworkManager%2Fsystem-connections%20end%20without%20the%20suffix%20'.nmconnection'%2C%20whereas%20in%20RHCOS%20they%20end%20with%20the%20suffix.%0A%20%20MANAGED_NM_CONN_FILES%3D(%24(echo%20%22%24%7Bbase_path%7D%22%2F%7B%22%24bridge_name%22%2C%22%24ovs_interface%22%2C%22%24ovs_port%22%2C%22%24bridge_interface_name%22%2C%22%24default_port_name%22%7D%7B%2C.nmconnection%7D))%0A%20%20shopt%20-s%20nullglob%0A%20%20MANAGED_NM_CONN_FILES%2B%3D(%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D.nmconnection%20%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D)%0A%20%20shopt%20-u%20nullglob%0A%7D%0A%0Aupdate_nm_conn_run_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_RUN_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_set_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_SET_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0A%23%20Move%20and%20reload%20keyfiles%20at%20their%20final%20destination%0Aset_nm_conn_files()%20%7B%0A%20%20if%20%5B%20%22%24NM_CONN_RUN_PATH%22%20!%3D%20%22%24NM_CONN_SET_PATH%22%20%5D%3B%20then%0A%20%20%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%20%20%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%0A%20%20%20%20%23%20reload%20keyfiles%0A%20%20%20%20nmcli%20connection%20reload%0A%20%20fi%0A%7D%0A%0A%23%20Used%20to%20remove%20files%20managed%20by%20configure-ovs%20and%20temporary%20leftover%20files%20from%20network%20manager%0Arm_nm_conn_files()%20%7B%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20rm%20-f%20%22%24file%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20file%20%24file%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20fi%0A%20%20done%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20for%20temp%20in%20%24(compgen%20-G%20%22%24%7Bfile%7D.*%22)%3B%20do%0A%20%20%20%20%20%20rm%20-f%20%22%24temp%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20temporary%20file%20%24temp%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20done%0A%20%20done%0A%7D%0A%0A%23%20Used%20to%20clone%20a%20slave%20connection%20by%20uuid%2C%20returns%20new%20name%0Aclone_slave_connection()%20%7B%0A%20%20local%20uuid%3D%22%241%22%0A%20%20local%20old_name%0A%20%20old_name%3D%22%24(nmcli%20-g%20connection.id%20connection%20show%20uuid%20%22%24uuid%22)%22%0A%20%20local%20new_name%3D%22%24%7Bold_name%7D%24%7BMANAGED_NM_CONN_SUFFIX%7D%22%0A%20%20if%20nmcli%20connection%20show%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20existing%20ovs%20slave%20%24%7Bnew_name%7D%20connection%20profile%20file%20found%2C%20overwriting...%22%20%3E%262%0A%20%20%20%20nmcli%20connection%20delete%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%0A%20%20fi%0A%20%20clone_nm_conn%20%24uuid%20%22%24%7Bnew_name%7D%22%0A%20%20echo%20%22%24%7Bnew_name%7D%22%0A%7D%0A%0A%23%20Used%20to%20replace%20an%20old%20master%20connection%20uuid%20with%20a%20new%20one%20on%20all%20connections%0Areplace_connection_master()%20%7B%0A%20%20local%20old%3D%22%241%22%0A%20%20local%20new%3D%22%242%22%0A%20%20for%20conn_uuid%20in%20%24(nmcli%20-g%20UUID%20connection%20show)%20%3B%20do%0A%20%20%20%20if%20%5B%20%22%24(nmcli%20-g%20connection.master%20connection%20show%20uuid%20%22%24conn_uuid%22)%22%20!%3D%20%22%24old%22%20%5D%3B%20then%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20local%20autoconnect%3D%24(nmcli%20-g%20connection.autoconnect%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20!%3D%20%22activated%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Assume%20that%20slave%20profiles%20intended%20to%20be%20used%20are%20those%20that%20are%3A%0A%20%20%20%20%20%20%23%20-%20active%0A%20%20%20%20%20%20%23%20-%20or%20inactive%20(which%20might%20be%20due%20to%20link%20being%20down)%20but%20to%20be%20autoconnected.%0A%20%20%20%20%20%20%23%20Otherwise%2C%20ignore%20them.%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20make%20changes%20for%20slave%20profiles%20in%20a%20new%20clone%0A%20%20%20%20local%20new_name%0A%20%20%20%20new_name%3D%24(clone_slave_connection%20%24conn_uuid)%0A%0A%20%20%20%20mod_nm_conn%20%22%24new_name%22%20connection.master%20%22%24new%22%20connection.autoconnect-priority%20100%20connection.autoconnect%20no%20%0A%20%20%20%20echo%20%22Replaced%20master%20%24old%20with%20%24new%20for%20slave%20profile%20%24new_name%22%0A%20%20done%0A%7D%0A%0A%23%20when%20creating%20the%20bridge%2C%20we%20use%20a%20value%20lower%20than%20NM's%20ethernet%20device%20default%20route%20metric%0A%23%20(we%20pick%2048%20and%2049%20to%20be%20lower%20than%20anything%20that%20NM%20chooses%20by%20default)%0ABRIDGE_METRIC%3D%2248%22%0ABRIDGE1_METRIC%3D%2249%22%0A%23%20Given%20an%20interface%2C%20generates%20NM%20configuration%20to%20add%20to%20an%20OVS%20bridge%0Aconvert_to_bridge()%20%7B%0A%20%20local%20iface%3D%24%7B1%7D%0A%20%20local%20bridge_name%3D%24%7B2%7D%0A%20%20local%20port_name%3D%24%7B3%7D%0A%20%20local%20bridge_metric%3D%24%7B4%7D%0A%20%20local%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20local%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20local%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20local%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%0A%20%20if%20%5B%20%22%24iface%22%20%3D%20%22%24bridge_name%22%20%5D%3B%20then%0A%20%20%20%20%23%20handle%20vlans%20and%20bonds%20etc%20if%20they%20have%20already%20been%0A%20%20%20%20%23%20configured%20via%20nm%20key%20files%20and%20br-ex%20is%20already%20up%0A%20%20%20%20ifaces%3D%24(ovs-vsctl%20list-ifaces%20%24%7Biface%7D)%0A%20%20%20%20for%20intf%20in%20%24ifaces%3B%20do%20configure_driver_options%20%24intf%3B%20done%0A%20%20%20%20echo%20%22Networking%20already%20configured%20and%20up%20for%20%24%7Bbridge-name%7D!%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20flag%20to%20reload%20NM%20to%20account%20for%20all%20the%20configuration%20changes%0A%20%20%23%20going%20forward%0A%20%20nm_config_changed%3D1%0A%0A%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20Unable%20to%20find%20default%20gateway%20interface%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20%23%20find%20the%20MAC%20from%20OVS%20config%20or%20the%20default%20interface%20to%20use%20for%20OVS%20internal%20port%0A%20%20%23%20this%20prevents%20us%20from%20getting%20a%20different%20DHCP%20lease%20and%20dropping%20connection%0A%20%20if%20!%20iface_mac%3D%24(%3C%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface%7D%2Faddress%22)%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MAC%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20echo%20%22MAC%20address%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mac%7D%22%0A%0A%20%20%23%20find%20MTU%20from%20original%20iface%0A%20%20iface_mtu%3D%24(ip%20link%20show%20%22%24iface%22%20%7C%20awk%20'%7Bprint%20%245%3B%20exit%7D')%0A%20%20if%20%5B%5B%20-z%20%22%24iface_mtu%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MTU%2C%20defaulting%20to%201500%22%0A%20%20%20%20iface_mtu%3D1500%0A%20%20else%0A%20%20%20%20echo%20%22MTU%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mtu%7D%22%0A%20%20fi%0A%0A%20%20%23%20store%20old%20conn%20for%20later%0A%20%20old_conn%3D%24(nmcli%20--fields%20UUID%2CDEVICE%20conn%20show%20--active%20%7C%20awk%20%22%2F%5Cs%24%7Biface%7D%5Cs*%5C%24%2F%20%7Bprint%20%5C%241%7D%22)%0A%0A%20%20if%20%5B%5B%20-z%20%22%24old_conn%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20cannot%20find%20connection%20for%20interface%3A%20%24%7Biface%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20create%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24bridge_name%22%20type%20ovs-bridge%20conn.interface%20%22%24bridge_name%22%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20%23%20find%20default%20port%20to%20add%20to%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24default_port_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%24%7Biface%7D%0A%20%20%20%20add_nm_conn%20%22%24default_port_name%22%20type%20ovs-port%20conn.interface%20%24%7Biface%7D%20master%20%22%24bridge_name%22%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_port%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24ovs_port%22%20type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24bridge_name%22%0A%20%20fi%0A%0A%20%20extra_phys_args%3D()%0A%20%20%23%20check%20if%20this%20interface%20is%20a%20vlan%2C%20bond%2C%20team%2C%20or%20ethernet%20type%0A%20%20if%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22vlan%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dvlan%0A%20%20%20%20vlan_id%3D%24(nmcli%20--get-values%20vlan.id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_id%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20vlan.parent%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_parent%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_parent%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20nmcli%20connection%20show%20uuid%20%22%24vlan_parent%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20%20%20%23%20if%20the%20VLAN%20connection%20is%20configured%20with%20a%20connection%20UUID%20as%20parent%2C%20we%20need%20to%20find%20the%20underlying%20device%0A%20%20%20%20%20%20%23%20and%20create%20the%20bridge%20against%20it%2C%20as%20the%20parent%20connection%20can%20be%20replaced%20by%20another%20bridge.%0A%20%20%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20GENERAL.DEVICES%20conn%20show%20uuid%20%24%7Bvlan_parent%7D)%0A%20%20%20%20fi%0A%0A%20%20%20%20extra_phys_args%3D(%20dev%20%22%24%7Bvlan_parent%7D%22%20id%20%22%24%7Bvlan_id%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbond%0A%20%20%20%20%23%20check%20bond%20options%0A%20%20%20%20bond_opts%3D%24(nmcli%20--get-values%20bond.options%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24bond_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20bond.options%20%22%24%7Bbond_opts%7D%22%20)%0A%20%20%20%20%20%20MODE_REGEX%3D%22(%5E%7C%2C)mode%3Dactive-backup(%2C%7C%24)%22%0A%20%20%20%20%20%20MAC_REGEX%3D%22(%5E%7C%2C)fail_over_mac%3D(1%7Cactive%7C2%7Cfollow)(%2C%7C%24)%22%0A%20%20%20%20%20%20if%20%5B%5B%20%24bond_opts%20%3D~%20%24MODE_REGEX%20%5D%5D%20%26%26%20%5B%5B%20%24bond_opts%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22team%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dteam%0A%20%20%20%20%23%20check%20team%20config%20options%0A%20%20%20%20team_config_opts%3D%24(nmcli%20--get-values%20team.config%20-e%20no%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24team_config_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20team.config%20is%20json%2C%20remove%20spaces%20to%20avoid%20problems%20later%20on%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20team.config%20%22%24%7Bteam_config_opts%2F%2F%5B%5B%3Aspace%3A%5D%5D%2F%7D%22%20)%0A%20%20%20%20%20%20team_mode%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.name%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20team_mac_policy%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.hwaddr_policy%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20MAC_REGEX%3D%22(by_active%7Conly_active)%22%0A%20%20%20%20%20%20if%20%5B%20%22%24team_mode%22%20%3D%20%22activebackup%22%20%5D%20%26%26%20%5B%5B%20%22%24team_mac_policy%22%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22tun%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dtun%0A%20%20%20%20tun_mode%3D%24(nmcli%20--get-values%20tun.mode%20-e%20no%20connection%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20extra_phys_args%2B%3D(%20tun.mode%20%22%24%7Btun_mode%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bridge%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbridge%0A%20%20else%0A%20%20%20%20iface_type%3D802-3-ethernet%0A%20%20fi%0A%0A%20%20if%20%5B%20!%20%22%24%7Bclone_mac%3A-%7D%22%20%3D%20%220%22%20%5D%3B%20then%0A%20%20%20%20%23%20In%20active-backup%20link%20aggregation%2C%20with%20fail_over_mac%20mode%20enabled%2C%0A%20%20%20%20%23%20cloning%20the%20mac%20address%20is%20not%20supported.%20It%20is%20possible%20then%20that%0A%20%20%20%20%23%20br-ex%20has%20a%20different%20mac%20address%20than%20the%20bond%20which%20might%20be%0A%20%20%20%20%23%20troublesome%20on%20some%20platforms%20where%20the%20nic%20won't%20accept%20packets%20with%0A%20%20%20%20%23%20a%20different%20destination%20mac.%20But%20nobody%20has%20complained%20so%20far%20so%20go%20on%0A%20%20%20%20%23%20with%20what%20we%20got.%20%0A%20%20%20%20%0A%20%20%20%20%23%20Do%20set%20it%20though%20for%20other%20link%20aggregation%20configurations%20where%20the%0A%20%20%20%20%23%20mac%20address%20would%20otherwise%20depend%20on%20enslave%20order%20for%20which%20we%20have%0A%20%20%20%20%23%20no%20control%20going%20forward.%0A%20%20%20%20extra_phys_args%2B%3D(%20802-3-ethernet.cloned-mac-address%20%22%24%7Biface_mac%7D%22%20)%0A%20%20fi%0A%0A%20%20%23%20use%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%20instead%20of%20%24%7Bextra_phys_args%5B%40%5D%7D%20to%20be%20compatible%20with%20bash%204.2%20in%20RHEL7.9%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_interface_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%24%7Biface%7D%0A%20%20%20%20ovs_default_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24default_port_name%22)%0A%20%20%20%20add_nm_conn%20%22%24bridge_interface_name%22%20type%20%24%7Biface_type%7D%20conn.interface%20%24%7Biface%7D%20master%20%22%24ovs_default_port_conn%22%20%5C%0A%20%20%20%20%20%20slave-type%20ovs-port%20connection.autoconnect-priority%20100%20connection.autoconnect-slaves%201%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20%20%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%0A%20%20fi%0A%0A%20%20%23%20Get%20the%20new%20connection%20uuids%0A%20%20new_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24bridge_interface_name%22)%0A%20%20ovs_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24ovs_port%22)%0A%0A%20%20%23%20Update%20connections%20with%20master%20property%20set%20to%20use%20the%20new%20connection%0A%20%20replace_connection_master%20%24old_conn%20%24new_conn%0A%20%20replace_connection_master%20%24iface%20%24new_conn%0A%0A%20%20ipv4_method%3D%24(nmcli%20-g%20ipv4.method%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_method%3D%24(nmcli%20-g%20ipv6.method%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20ipv4_addresses%3D%24(nmcli%20-g%20ipv4.addresses%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_addresses%3D%24(nmcli%20-g%20ipv6.addresses%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20%23%20Warn%20about%20an%20invalid%20MTU%20that%20will%20most%20likely%20fail%20in%20one%20way%20or%0A%20%20%23%20another%0A%20%20if%20%5B%20%24%7Biface_mtu%7D%20-lt%201280%20%5D%20%26%26%20%5B%20%22%24%7Bipv6_method%7D%22%20!%3D%20%22disabled%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20MTU%20%24%7Biface_mtu%7D%20is%20lower%20than%20the%20minimum%20required%20of%201280%20for%20IPv6%22%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_interface%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%22%24bridge_name%22%0A%20%20%20%20%23%20Clone%20the%20connection%20in%20case%20the%20method%20is%20manual%20or%20in%20case%20the%20an%20address%20is%20set%20(DHCP%20%2B%20static%20IP)%0A%20%20%20%20if%20%5B%20%22%24%7Bipv4_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv4_addresses%7D%22%20!%3D%20%22%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_addresses%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Static%20IP%20addressing%20detected%20on%20default%20gateway%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%23%20clone%20the%20old%20connection%20to%20get%20the%20address%20settings%0A%20%20%20%20%20%20%23%20prefer%20cloning%20vs%20copying%20the%20connection%20file%20to%20avoid%20problems%20with%20selinux%0A%20%20%20%20%20%20clone_nm_conn%20%22%24%7Bold_conn%7D%22%20%22%24%7Bovs_interface%7D%22%0A%20%20%20%20%20%20shopt%20-s%20nullglob%0A%20%20%20%20%20%20new_conn_files%3D(%24%7BNM_CONN_RUN_PATH%7D%2F%22%24%7Bovs_interface%7D%22*)%0A%20%20%20%20%20%20shopt%20-u%20nullglob%0A%20%20%20%20%20%20if%20%5B%20%24%7B%23new_conn_files%5B%40%5D%7D%20-ne%201%20%5D%20%7C%7C%20%5B%20!%20-f%20%22%24%7Bnew_conn_files%5B0%5D%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20could%20not%20find%20%24%7Bovs_interface%7D%20conn%20file%20after%20cloning%20from%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20new_conn_file%3D%22%24%7Bnew_conn_files%5B0%5D%7D%22%0A%0A%20%20%20%20%20%20%23%20modify%20the%20connection%20type%20directly%20because%20it%20can't%20be%20modified%0A%20%20%20%20%20%20%23%20through%20nmcli%0A%20%20%20%20%20%20sed%20-i%20'%2F%5E%5C%5Bconnection%5C%5D%24%2F%2C%2F%5E%5C%5B%2F%20s%2F%5Etype%3D.*%24%2Ftype%3Dovs-interface%2F'%20%24%7Bnew_conn_file%7D%0A%0A%20%20%20%20%20%20%23%20modify%20some%20more%20settings%20through%20nmcli%0A%20%20%20%20%20%20mod_nm_conn%20%22%24%7Bovs_interface%7D%22%20conn.interface%20%22%24bridge_name%22%20%5C%0A%20%20%20%20%20%20%20%20connection.multi-connect%20%22%22%20connection.autoconnect%20no%20%5C%0A%20%20%20%20%20%20%20%20connection.master%20%22%24ovs_port_conn%22%20connection.slave-type%20ovs-port%20%5C%0A%20%20%20%20%20%20%20%20ovs-interface.type%20internal%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%0A%0A%20%20%20%20%20%20echo%20%22Loaded%20new%20%24ovs_interface%20connection%20file%3A%20%24%7Bnew_conn_file%7D%22%0A%20%20%20%20else%0A%20%20%20%20%20%20extra_if_brex_args%3D%22%22%0A%20%20%20%20%20%20%23%20check%20if%20interface%20had%20ipv4%2Fipv6%20addresses%20assigned%0A%20%20%20%20%20%20num_ipv4_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ipv4_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20IPV6%20should%20have%20at%20least%20a%20link%20local%20address.%20Check%20for%20more%20than%201%20to%20see%20if%20there%20is%20an%0A%20%20%20%20%20%20%23%20assigned%20address.%0A%20%20%20%20%20%20num_ip6_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet6%5C%22%20and%20.scope%20!%3D%20%5C%22link%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ip6_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20check%20for%20dhcp%20client%20ids%0A%20%20%20%20%20%20dhcp_client_id%3D%24(nmcli%20--get-values%20ipv4.dhcp-client-id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.dhcp-client-id%20%24%7Bdhcp_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20dhcp6_client_id%3D%24(nmcli%20--get-values%20ipv6.dhcp-duid%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp6_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.dhcp-duid%20%24%7Bdhcp6_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20ipv6_addr_gen_mode%3D%24(nmcli%20--get-values%20ipv6.addr-gen-mode%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24ipv6_addr_gen_mode%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.addr-gen-mode%20%24%7Bipv6_addr_gen_mode%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20add_nm_conn%20%22%24ovs_interface%22%20type%20ovs-interface%20slave-type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24ovs_port_conn%22%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.method%20%22%24%7Bipv4_method%7D%22%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20ipv6.method%20%22%24%7Bipv6_method%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20%24%7Bextra_if_brex_args%7D%0A%20%20%20%20fi%0A%20%20fi%0A%0A%20%20configure_driver_options%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20remove%20a%20bridge%0Aremove_ovn_bridges()%20%7B%0A%20%20bridge_name%3D%24%7B1%7D%0A%20%20port_name%3D%24%7B2%7D%0A%0A%20%20%23%20Remove%20the%20keyfiles%20from%20known%20configuration%20paths%0A%20%20update_nm_conn_run_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20update_nm_conn_set_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%0A%20%20%23%20NetworkManager%20will%20not%20remove%20%24%7Bbridge_name%7D%20if%20it%20has%20the%20patch%20port%20created%20by%20ovn-kubernetes%0A%20%20%23%20so%20remove%20explicitly%0A%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%24%7Bbridge_name%7D%0A%7D%0A%0A%23%20Removes%20any%20previous%20ovs%20configuration%0Aremove_all_ovn_bridges()%20%7B%0A%20%20echo%20%22Reverting%20any%20previous%20OVS%20configuration%22%0A%20%20%0A%20%20remove_ovn_bridges%20br-ex%20phys0%0A%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%0A%20%20echo%20%22OVS%20configuration%20successfully%20reverted%22%0A%7D%0A%0A%23%20Reloads%20NM%20NetworkManager%20profiles%20if%20any%20configuration%20change%20was%20done.%0A%23%20Accepts%20a%20list%20of%20devices%20that%20should%20be%20re-connect%20after%20reload.%0Areload_profiles_nm()%20%7B%0A%20%20if%20%5B%20%24%7Bnm_config_changed%3A-0%7D%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%23%20no%20config%20was%20changed%2C%20no%20need%20to%20reload%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20reload%20profiles%0A%20%20nmcli%20connection%20reload%0A%0A%20%20%23%20precautionary%20sleep%20of%2010s%20(default%20timeout%20of%20NM%20to%20bring%20down%20devices)%0A%20%20sleep%2010%0A%0A%20%20%23%20After%20reload%2C%20devices%20that%20were%20already%20connected%20should%20connect%20again%0A%20%20%23%20if%20any%20profile%20is%20available.%20If%20no%20profile%20is%20available%2C%20a%20device%20can%0A%20%20%23%20remain%20disconnected%20and%20we%20have%20to%20explicitly%20connect%20it%20so%20that%20a%0A%20%20%23%20profile%20is%20generated.%20This%20can%20happen%20for%20physical%20devices%20but%20should%0A%20%20%23%20not%20happen%20for%20software%20devices%20as%20those%20always%20require%20a%20profile.%0A%20%20for%20dev%20in%20%24%40%3B%20do%0A%20%20%20%20%23%20Only%20attempt%20to%20connect%20a%20disconnected%20device%0A%20%20%20%20local%20connected_state%3D%24(nmcli%20-g%20GENERAL.STATE%20device%20show%20%22%24dev%22%20%7C%7C%20echo%20%22%22)%0A%20%20%20%20if%20%5B%5B%20%22%24connected_state%22%20%3D~%20%22disconnected%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%23%20keep%20track%20if%20a%20profile%20by%20the%20same%20name%20as%20the%20device%20existed%20%0A%20%20%20%20%20%20%23%20before%20we%20attempt%20activation%0A%20%20%20%20%20%20local%20named_profile_existed%3D%24(%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%5D%20%7C%7C%20%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22%20%5D%20%26%26%20echo%20%22yes%22)%0A%20%20%20%20%20%20%0A%20%20%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20connect%20device%20%24dev%22%0A%20%20%20%20%20%20%20%20%20%20nmcli%20device%20connect%20%22%24dev%22%20%26%26%20break%0A%20%20%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%23%20if%20a%20profile%20did%20not%20exist%20before%20but%20does%20now%2C%20it%20was%20generated%0A%20%20%20%20%20%20%23%20but%20we%20want%20it%20to%20be%20ephemeral%2C%20so%20move%20it%20back%20to%20%2Frun%0A%20%20%20%20%20%20if%20%5B%20!%20%22%24named_profile_existed%22%20%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20MANAGED_NM_CONN_FILES%3D(%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22)%0A%20%20%20%20%20%20%20%20copy_nm_conn_files%20%22%24%7BNM_CONN_RUN_PATH%7D%22%0A%20%20%20%20%20%20%20%20rm_nm_conn_files%0A%20%20%20%20%20%20%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20might%20have%20been%20moved%0A%20%20%20%20%20%20%20%20nmcli%20connection%20reload%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20echo%20%22Waiting%20for%20interface%20%24dev%20to%20activate...%22%0A%20%20%20%20if%20!%20timeout%2060%20bash%20-c%20%22while%20!%20nmcli%20-g%20DEVICE%2CSTATE%20c%20%7C%20grep%20%22'%22'%22%24dev%22%3Aactivated'%22'%22%3B%20do%20sleep%205%3B%20done%22%3B%20then%0A%20%20%20%20%20%20echo%20%22WARNING%3A%20%24dev%20did%20not%20activate%22%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20nm_config_changed%3D0%0A%7D%0A%0A%23%20Removes%20all%20configuration%20and%20reloads%20NM%20if%20necessary%0Arollback_nm()%20%7B%0A%20%20phys0%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20phys1%3D%24(get_bridge_physical_interface%20ovs-if-phys1)%0A%20%20%0A%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20remove_all_ovn_bridges%0A%20%20%0A%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20were%20removed%0A%20%20reload_profiles_nm%20%22%24phys0%22%20%22%24phys1%22%0A%7D%0A%0A%23%20Add%20a%20temporary%20deactivated%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20folowed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20add%60%0Aadd_nm_conn()%20%7B%0A%20%20%23%20Use%20%60save%20no%60%20to%20add%20a%20temporary%20profile%0A%20%20nmcli%20c%20add%20save%20no%20con-name%20%22%24%40%22%20connection.autoconnect%20no%0A%7D%0A%0A%23%20Modify%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20followed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20modify%60%0Amod_nm_conn()%20%7B%0A%20%20%23%20the%20easiest%20thing%20to%20do%20here%20would%20be%20to%20use%20%60nmcli%20c%20mod%20--temporary%60%0A%20%20%23%20but%20there%20is%20a%20bug%20in%20selinux%20profiles%20that%20denies%20NM%20from%20performing%0A%20%20%23%20the%20operation%0A%20%20local%20dst_path%3D%24%7BNM_CONN_RUN_PATH%7D%2F%241.nmconnection%0A%20%20local%20src_path%0A%20%20src_path%3D%24(mktemp)%0A%20%20shift%0A%20%20cat%20%22%24dst_path%22%20%3E%20%22%24src_path%22%0A%20%20rm%20-f%20%22%24dst_path%22%0A%20%20nmcli%20--offline%20c%20mod%20%22%24%40%22%20%3C%20%22%24src_path%22%20%3E%20%22%24dst_path%22%0A%20%20rm%20-f%20%22%24src_path%22%0A%20%20chmod%20600%20%22%24dst_path%22%0A%20%20nmcli%20c%20load%20%22%24dst_path%22%0A%7D%0A%0A%23%20Clone%20to%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20to%20clone%2C%20second%20argument%20is%20the%20clone%20name%0Aclone_nm_conn()%20%7B%0A%20%20%23%20clone%20as%20temporary%20so%20that%20it%20is%20generated%20in%20NM_CONN_RUN_PATH%0A%20%20nmcli%20connection%20clone%20--temporary%20%22%241%22%20%22%242%22%20%26%3E%20%2Fdev%2Fnull%0A%7D%0A%0A%23%20Activates%20an%20ordered%20set%20of%20NM%20connection%20profiles%0Aactivate_nm_connections()%20%7B%0A%20%20local%20connections%3D(%22%24%40%22)%0A%0A%20%20%23%20We%20want%20autoconnect%20set%20for%20our%20cloned%20slave%20profiles%20so%20that%20they%20are%0A%20%20%23%20used%20over%20the%20original%20profiles%20if%20implicitly%20re-activated%20with%20other%0A%20%20%23%20dependant%20profiles.%20Otherwise%20if%20a%20slave%20activates%20with%20an%20old%20profile%2C%0A%20%20%23%20the%20old%20master%20profile%20might%20activate%20as%20well%2C%20interfering%20and%20causing%0A%20%20%23%20further%20activations%20to%20fail.%0A%20%20%23%20Slave%20interfaces%20should%20already%20be%20active%20so%20setting%20autoconnect%20here%0A%20%20%23%20won't%20implicitly%20activate%20them%20but%20there%20is%20an%20edge%20case%20where%20a%20slave%0A%20%20%23%20might%20be%20inactive%20(link%20down%20for%20example)%20and%20in%20that%20case%20setting%0A%20%20%23%20autoconnect%20will%20cause%20an%20implicit%20activation.%20This%20is%20not%20necessarily%20a%0A%20%20%23%20problem%20and%20hopefully%20we%20can%20make%20sure%20everything%20is%20activated%20as%20we%0A%20%20%23%20want%20next.%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20Activate%20all%20connections%20and%20fail%20if%20activation%20fails%0A%20%20%23%20For%20slave%20connections%20-%20for%20as%20long%20as%20at%20least%20one%20slave%20that%20belongs%20to%20a%20bond%2Fteam%0A%20%20%23%20comes%20up%2C%20we%20should%20not%20fail%0A%20%20declare%20-A%20master_interfaces%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%23%20Get%20the%20slave%20type%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20local%20is_slave%3Dfalse%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20is_slave%3Dtrue%0A%20%20%20%20fi%20%0A%0A%20%20%20%20%23%20For%20slave%20interfaces%2C%20initialize%20the%20master%20interface%20to%20false%20if%20the%20key%20is%20not%20yet%20in%20the%20array%0A%20%20%20%20local%20master_interface%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20master_interface%3D%24(nmcli%20-g%20connection.master%20connection%20show%20%22%24conn%22)%0A%20%20%20%20%20%20if%20!%20%5B%5B%20-v%20%22master_interfaces%5B%24master_interface%5D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dfalse%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Do%20not%20activate%20interfaces%20that%20are%20already%20active%0A%20%20%20%20%23%20But%20set%20the%20entry%20in%20master_interfaces%20to%20true%20if%20this%20is%20a%20slave%0A%20%20%20%20%23%20Also%20set%20autoconnect%20to%20yes%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20%3D%3D%20%22activated%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Connection%20%24conn%20already%20activated%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%24master_interface%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Activate%20all%20interfaces%20that%20are%20not%20yet%20active%0A%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20bring%20up%20connection%20%24conn%22%0A%20%20%20%20%20%20nmcli%20conn%20up%20%22%24conn%22%20%26%26%20s%3D0%20%26%26%20break%20%7C%7C%20s%3D%24%3F%0A%20%20%20%20%20%20sleep%205%0A%20%20%20%20done%0A%20%20%20%20if%20%5B%20%24s%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Brought%20up%20connection%20%24conn%20successfully%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20elif%20!%20%24is_slave%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20connection%20%24conn%20after%20%24i%20attempts%22%0A%20%20%20%20%20%20return%20%24s%0A%20%20%20%20fi%0A%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20done%0A%20%20%23%20Check%20that%20all%20master%20interfaces%20report%20at%20least%20a%20single%20active%20slave%0A%20%20%23%20Note%3A%20associative%20arrays%20require%20an%20exclamation%20mark%20when%20looping%0A%20%20for%20i%20in%20%22%24%7B!master_interfaces%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20!%20%24%7Bmaster_interfaces%5B%22%24i%22%5D%7D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20any%20slave%20interface%20for%20master%20interface%3A%20%24i%22%0A%20%20%20%20%20%20%20%20return%201%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24iface%0A%23%20Writes%20content%20of%20%24iface%20into%20%24iface_default_hint_file%0Awrite_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%242%22%0A%0A%20%20echo%20%22%24%7Biface%7D%22%20%3E%7C%20%22%24%7Biface_default_hint_file%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%0A%23%20Returns%20the%20stored%20interface%20default%20hint%20if%20the%20hint%20is%20non-empty%2C%0A%23%20not%20br-ex%2C%20not%20br-ex1%20and%20if%20the%20interface%20can%20be%20found%20in%20%2Fsys%2Fclass%2Fnet%0Aget_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%241%0A%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%3B%20then%0A%20%20%20%20local%20iface_default_hint%3D%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex1%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20-d%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface_default_hint%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%22%0A%7D%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0A%23%20This%20function%20waits%20for%20ip%20address%20of%20br-ex%20to%20be%20bindable%20only%20in%20case%20of%20ipv6%0A%23%20This%20is%20workaround%20for%20OCPBUGS-673%20as%20it%20will%20not%20allow%20starting%20crio%0A%23%20before%20address%20is%20bindable%0Atry_to_bind_ipv6_address()%20%7B%0A%20%20%23%20Retry%20for%201%20minute%0A%20%20retries%3D60%0A%20%20until%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20do%0A%20%20%20%20ip%3D%24(ip%20-6%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(.ifname%3D%3D%5C%22br-ex%5C%22)%20%7C%20.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20.local)%22)%0A%20%20%20%20if%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22No%20ipv6%20ip%20to%20bind%20was%20found%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20sleep%201%0A%20%20%20%20((%20retries--%20))%0A%20%20done%0A%20%20if%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Failed%20to%20bind%20ip%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%7D%0A%0A%23%20Get%20interface%20that%20matches%20ip%20from%20node%20ip%20hint%20file%0A%23%20in%20case%20file%20not%20exists%20return%20nothing%20and%0A%23%20fallback%20to%20default%20interface%20search%20flow%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge%3D%22%242%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)%20and%20.ifname!%3D%5C%22br-ex1%5C%22%20and%20.ifname!%3D%5C%22%24%7Bextra_bridge%7D%5C%22))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20fi%0A%7D%0A%0A%23%20Accepts%20parameters%20%24bridge_interface%20(e.g.%20ovs-port-phys0)%0A%23%20Returns%20the%20physical%20interface%20name%20if%20%24bridge_interface%20exists%2C%20%22%22%20otherwise%0Aget_bridge_physical_interface()%20%7B%0A%20%20local%20bridge_interface%3D%22%241%22%0A%20%20local%20physical_interface%3D%22%22%0A%20%20physical_interface%3D%24(nmcli%20-g%20connection.interface-name%20conn%20show%20%22%24%7Bbridge_interface%7D%22%202%3E%2Fdev%2Fnull%20%7C%7C%20echo%20%22%22)%0A%20%20echo%20%22%24%7Bphysical_interface%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24extra_bridge_file%2C%20%24ip_hint_file%2C%20%24default_bridge_file%0A%23%20Determines%20the%20interface%20to%20be%20used%20for%20br-ex.%20Order%20of%20priority%20is%3A%0A%23%201.%20Use%20the%20user%20specified%20interface%20if%20provided%20in%20the%20default%20bridge%20file%0A%23%202.%20Use%20the%20node%20IP%20hint%20interface%0A%23%203.%20Use%20the%20previously%20selected%20interface%0A%23%204.%20Use%20the%20interface%20detected%20as%20default%20gateway%0A%23%0A%23%20Read%20%24default_bridge_file%20and%20return%20the%20contained%20interface.%20Otherwise%2C%0A%23%20read%20%24ip_hint_file%20and%20return%20the%20interface%20that%20matches%20this%20ip.%20Otherwise%2C%0A%23%20if%20the%20default%20interface%20is%20br-ex%2C%20use%20that%20and%20return.%0A%23%20If%20the%20default%20interface%20is%20not%20br-ex%3A%0A%23%20Check%20if%20there%20is%20a%20valid%20hint%20inside%20%24iface_default_hint_file.%20If%20so%2C%20use%20that%20hint.%0A%23%20If%20there%20is%20no%20valid%20hint%2C%20use%20the%20default%20interface%20that%20we%20found%20during%20the%20step%0A%23%20earlier.%0A%23%20Never%20use%20the%20interface%20that%20is%20provided%20inside%20%24extra_bridge_file%20for%20br-ex1.%0A%23%20Never%20use%20br-ex1.%0A%23%20Write%20the%20default%20interface%20to%20%24iface_default_hint_file%0Aget_default_bridge_interface()%20%7B%0A%20%20local%20iface%3D%22%22%0A%20%20local%20counter%3D0%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge_file%3D%22%242%22%0A%20%20local%20ip_hint_file%3D%22%243%22%0A%20%20local%20default_bridge_file%3D%22%244%22%0A%20%20local%20extra_bridge%3D%22%22%0A%0A%20%20if%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%3B%20then%0A%20%20%20%20extra_bridge%3D%24(cat%20%24%7Bextra_bridge_file%7D)%0A%20%20fi%0A%0A%20%20%23%20try%20to%20use%20user%20specified%20file%20first%0A%20%20if%20%5B%20-f%20%22%24default_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20iface%3D%24(cat%20%22%24%7Bdefault_bridge_file%7D%22)%0A%20%20%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20User%20specified%20bridge%20file%20detected%20without%20any%20data%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20if%20node%20ip%20was%20set%2C%20we%20should%20search%20for%20interface%20that%20matches%20it%0A%20%20iface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bextra_bridge%7D%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20find%20default%20interface%0A%20%20%23%20the%20default%20interface%20might%20be%20br-ex%2C%20so%20check%20this%20before%20looking%20at%20the%20hint%0A%20%20while%20%5B%20%24%7Bcounter%7D%20-lt%2012%20%5D%3B%20do%0A%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20sleep%205%0A%20%20done%0A%0A%20%20%23%20if%20the%20default%20interface%20does%20not%20point%20out%20of%20br-ex%20or%20br-ex1%0A%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20%23%20determine%20if%20an%20interface%20default%20hint%20exists%20from%20a%20previous%20run%0A%20%20%20%20%23%20and%20if%20the%20interface%20has%20a%20valid%20default%20route%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%24%7Biface%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20start%20wherever%20count%20left%20off%20in%20the%20previous%20loop%0A%20%20%20%20%20%20%23%20allow%20this%20for%20one%20more%20iteration%20than%20the%20previous%20loop%0A%20%20%20%20%20%20while%20%5B%20%24%7Bcounter%7D%20-le%2012%20%5D%3B%20do%0A%20%20%20%20%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20-6%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%20%20%20%20fi%0A%20%20%20%20%23%20store%20what%20was%20determined%20was%20the%20(new)%20default%20interface%20inside%0A%20%20%20%20%23%20the%20default%20hint%20file%20for%20future%20reference%0A%20%20%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Biface%7D%22%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20print%20network%20state%0Aprint_state()%20%7B%0A%20%20echo%20%22Current%20device%2C%20connection%2C%20interface%20and%20routing%20state%3A%22%0A%20%20nmcli%20-g%20all%20device%20%7C%20grep%20-v%20unmanaged%0A%20%20nmcli%20-g%20all%20connection%0A%20%20ip%20-d%20address%20show%0A%20%20ip%20route%20show%0A%20%20ip%20-6%20route%20show%0A%7D%0A%0A%23%20Setup%20an%20exit%20trap%20to%20rollback%20on%20error%0Ahandle_exit()%20%7B%0A%20%20e%3D%24%3F%0A%20%20tdir%3D%24(mktemp%20-u%20-d%20-t%20%22configure-ovs-%24(date%20%2B%25Y-%25m-%25d-%25H-%25M-%25S)-XXXXXXXXXX%22)%0A%20%20%0A%20%20if%20%5B%20%24e%20-eq%200%20%5D%3B%20then%0A%20%20%20%20print_state%0A%20%20%20%20%23%20remove%20previous%20troubleshooting%20information%0A%20%20%20%20rm%20-rf%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%0A%20%20echo%20%22ERROR%3A%20configure-ovs%20exited%20with%20error%3A%20%24e%22%0A%20%20print_state%0A%0A%20%20%23%20remove%20previous%20troubleshooting%20information%20except%20the%20oldest%20one%0A%20%20mapfile%20-t%20tdirs%20%3C%20%3C(compgen%20-G%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22)%0A%20%20unset%20-v%20%22tdirs%5B0%5D%22%0A%20%20for%20dir%20in%20%22%24%7Btdirs%5B%40%5D%7D%22%3B%20do%20rm%20-rf%20%22%24dir%22%3B%20done%0A%0A%20%20%23%20copy%20configuration%20to%20tmp%20for%20troubleshooting%0A%20%20mkdir%20-p%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20echo%20%22Copied%20OVS%20configuration%20to%20%24tdir%20for%20troubleshooting%22%0A%0A%20%20%23%20attempt%20to%20restore%20the%20previous%20network%20state%0A%20%20echo%20%22Attempting%20to%20restore%20previous%20configuration...%22%0A%20%20rollback_nm%0A%20%20print_state%0A%0A%20%20exit%20%24e%0A%7D%0A%0A%23%20Setup%20a%20signal%20trap%20to%20rollback%0Ahandle_termination()%20%7B%0A%20%20echo%20%22WARNING%3A%20configure-ovs%20has%20been%20requested%20to%20terminate%2C%20quitting...%22%0A%20%20%0A%20%20%23%20by%20exiting%20with%20an%20error%20we%20will%20cleanup%20after%20ourselves%20in%20a%0A%20%20%23%20subsequent%20call%20to%20handle_exit%0A%20%20exit%201%0A%7D%0A%0A%23%20main%20function%0Aconfigure_ovs()%20%7B%0A%20%20set%20-eu%0A%0A%20%20%23%20setup%20traps%20to%20handle%20signals%20and%20other%20abnormal%20exits%0A%20%20trap%20'handle_termination'%20TERM%20INT%0A%20%20trap%20'handle_exit'%20EXIT%0A%0A%20%20%23%20this%20flag%20tracks%20if%20any%20config%20change%20was%20made%0A%20%20nm_config_changed%3D0%0A%0A%20%20%23%20Check%20that%20we%20are%20provided%20a%20valid%20NM%20connection%20path%0A%20%20if%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_CONF_PATH%22%20%5D%20%26%26%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_RUN_PATH%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Error%3A%20Incorrect%20NM%20connection%20path%3A%20%24NM_CONN_SET_PATH%20is%20not%20%24NM_CONN_CONF_PATH%20nor%20%24NM_CONN_RUN_PATH%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0A%20%20if%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0A%20%20fi%0A%0A%20%20if%20!%20rpm%20-qa%20%7C%20grep%20-q%20openvswitch%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20Openvswitch%20package%20is%20not%20installed!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20print%20initial%20state%0A%20%20print_state%0A%0A%20%20if%20%5B%20%22%241%22%20%3D%3D%20%22OVNKubernetes%22%20%5D%3B%20then%0A%20%20%20%20%23%20Configures%20NICs%20onto%20OVS%20bridge%20%22br-ex%22%0A%20%20%20%20%23%20Configuration%20is%20either%20auto-detected%20or%20provided%20through%20a%20config%20file%20written%20already%20in%20Network%20Manager%0A%20%20%20%20%23%20key%20files%20under%20%2Fetc%2FNetworkManager%2Fsystem-connections%2F%0A%20%20%20%20%23%20Managing%20key%20files%20is%20outside%20of%20the%20scope%20of%20this%20script%0A%0A%20%20%20%20%23%20if%20the%20interface%20is%20of%20type%20vmxnet3%20add%20multicast%20capability%20for%20that%20driver%0A%20%20%20%20%23%20History%3A%20BZ%3A1854355%0A%20%20%20%20function%20configure_driver_options%20%7B%0A%20%20%20%20%20%20intf%3D%241%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Device%20file%20doesn't%20exist%2C%20skipping%20setting%20multicast%20mode%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20driver%3D%24(cat%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%7C%20grep%20DRIVER%20%7C%20awk%20-F%20%22%3D%22%20'%7Bprint%20%242%7D')%0A%20%20%20%20%20%20%20%20echo%20%22Driver%20name%20is%22%20%24driver%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24driver%22%20%3D%20%22vmxnet3%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20ip%20link%20set%20dev%20%22%24%7Bintf%7D%22%20allmulticast%20on%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20fi%0A%20%20%20%20%7D%0A%0A%20%20%20%20ovnk_config_dir%3D'%2Fetc%2Fovnk'%0A%20%20%20%20ovnk_var_dir%3D'%2Fvar%2Flib%2Fovnk'%0A%20%20%20%20extra_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fextra_bridge%22%0A%20%20%20%20iface_default_hint_file%3D%22%24%7Bovnk_var_dir%7D%2Fiface_default_hint%22%0A%20%20%20%20ip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%20%20%20%20%23%20explicitly%20specify%20which%20interface%20should%20be%20used%20with%20the%20default%20bridge%0A%20%20%20%20default_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fdefault_bridge%22%0A%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_config_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_config_dir%7D%22%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_var_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_var_dir%7D%22%0A%0A%20%20%20%20%23%20For%20upgrade%20scenarios%2C%20make%20sure%20that%20we%20stabilize%20what%20we%20already%20configured%0A%20%20%20%20%23%20before.%20If%20we%20do%20not%20have%20a%20valid%20interface%20hint%2C%20find%20the%20physical%20interface%0A%20%20%20%20%23%20that's%20attached%20to%20ovs-if-phys0.%0A%20%20%20%20%23%20If%20we%20find%20such%20an%20interface%2C%20write%20it%20to%20the%20hint%20file.%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20current_interface%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20%20%20%20%20if%20%5B%20%22%24%7Bcurrent_interface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bcurrent_interface%7D%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20delete%20iface_default_hint_file%20if%20it%20has%20the%20same%20content%20as%20extra_bridge_file%0A%20%20%20%20%23%20in%20that%20case%2C%20we%20must%20also%20force%20a%20reconfiguration%20of%20our%20network%20interfaces%0A%20%20%20%20%23%20to%20make%20sure%20that%20we%20reconcile%20this%20conflict%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20%22%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%22%20%3D%3D%20%22%24(cat%20%22%24%7Bextra_bridge_file%7D%22)%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint_file%7D%20and%20%24%7Bextra_bridge_file%7D%20share%20the%20same%20content%22%0A%20%20%20%20%20%20echo%20%22Deleting%20file%20%24%7Biface_default_hint_file%7D%20to%20choose%20a%20different%20interface%22%0A%20%20%20%20%20%20rm%20-f%20%22%24%7Biface_default_hint_file%7D%22%0A%20%20%20%20%20%20rm%20-f%20%2Frun%2Fconfigure-ovs-boot-done%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20on%20every%20boot%20we%20rollback%20and%20generate%20the%20configuration%20again%2C%20to%20take%0A%20%20%20%20%23%20in%20any%20changes%20that%20have%20possibly%20been%20applied%20in%20the%20standard%0A%20%20%20%20%23%20configuration%20sources%0A%20%20%20%20if%20%5B%20!%20-f%20%2Frun%2Fconfigure-ovs-boot-done%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Running%20on%20boot%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20print_state%0A%20%20%20%20fi%0A%20%20%20%20touch%20%2Frun%2Fconfigure-ovs-boot-done%0A%0A%20%20%20%20iface%3D%24(get_default_bridge_interface%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bextra_bridge_file%7D%22%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bdefault_bridge_file%7D%22)%0A%0A%20%20%20%20if%20%5B%20%22%24iface%22%20!%3D%20%22br-ex%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Specified%20interface%20is%20not%20br-ex.%0A%20%20%20%20%20%20%23%20Some%20deployments%20use%20a%20temporary%20solution%20where%20br-ex%20is%20moved%20out%20from%20the%20default%20gateway%20interface%0A%20%20%20%20%20%20%23%20and%20bound%20to%20a%20different%20nic%20(https%3A%2F%2Fgithub.com%2Ftrozet%2Fopenshift-ovn-migration).%0A%20%20%20%20%20%20%23%20This%20is%20now%20supported%20through%20an%20extra%20bridge%20if%20requested.%20If%20that%20is%20the%20case%2C%20we%20rollback.%0A%20%20%20%20%20%20%23%20We%20also%20rollback%20if%20it%20looks%20like%20we%20need%20to%20configure%20things%2C%20just%20in%20case%20there%20are%20any%20leftovers%0A%20%20%20%20%20%20%23%20from%20previous%20attempts.%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%7C%7C%20%5B%20-z%20%22%24(nmcli%20connection%20show%20--active%20br-ex%202%3E%20%2Fdev%2Fnull)%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Bridge%20br-ex%20is%20not%20active%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20%20%20print_state%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20convert_to_bridge%20%22%24iface%22%20%22br-ex%22%20%22phys0%22%20%22%24%7BBRIDGE_METRIC%7D%22%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20configure%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(!%20nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20!%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20interface%3D%24(head%20-n%201%20%24extra_bridge_file)%0A%20%20%20%20%20%20convert_to_bridge%20%22%24interface%22%20%22br-ex1%22%20%22phys1%22%20%22%24%7BBRIDGE1_METRIC%7D%22%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20remove%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20!%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20openshift-sdn%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0A%20%20%20%20%23%20Make%20sure%20everything%20is%20activated.%20Do%20it%20in%20a%20specific%20order%3A%0A%20%20%20%20%23%20-%20activate%20br-ex%20first%2C%20due%20to%20autoconnect-slaves%20this%20will%20also%0A%20%20%20%20%23%20%20%20activate%20ovs-port-br-ex%2C%20ovs-port-phys0%20and%20ovs-if-phys0.%20It%20is%0A%20%20%20%20%23%20%20%20important%20that%20ovs-if-phys0%20activates%20with%20br-ex%20to%20avoid%20the%0A%20%20%20%20%23%20%20%20ovs-if-phys0%20profile%20being%20overridden%20with%20a%20profile%20generated%20from%0A%20%20%20%20%23%20%20%20kargs.%20The%20activation%20of%20ovs-if-phys0%2C%20if%20a%20bond%2C%20might%20cause%20the%0A%20%20%20%20%23%20%20%20slaves%20to%20re-activate%2C%20but%20it%20should%20be%20with%20our%20profiles%20since%20they%0A%20%20%20%20%23%20%20%20have%20higher%20priority%0A%20%20%20%20%23%20-%20make%20sure%20that%20ovs-if-phys0%20and%20its%20slaves%2C%20if%20any%2C%20are%20activated.%0A%20%20%20%20%23%20-%20finally%20activate%20ovs-if-br-ex%20which%20holds%20the%20IP%20configuration.%0A%20%20%20%20connections%3D(br-ex%20ovs-if-phys0)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(br-ex1%20ovs-if-phys1)%0A%20%20%20%20fi%0A%20%20%20%20while%20IFS%3D%20read%20-r%20connection%3B%20do%0A%20%20%20%20%20%20if%20%5B%5B%20%24connection%20%3D%3D%20*%22%24MANAGED_NM_CONN_SUFFIX%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20connections%2B%3D(%22%24connection%22)%0A%20%20%20%20%20%20fi%0A%20%20%20%20done%20%3C%20%3C(nmcli%20-g%20NAME%20c)%0A%20%20%20%20connections%2B%3D(ovs-if-br-ex)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(ovs-if-br-ex1)%0A%20%20%20%20fi%0A%20%20%20%20activate_nm_connections%20%22%24%7Bconnections%5B%40%5D%7D%22%0A%20%20%20%20try_to_bind_ipv6_address%0A%20%20%20%20set_nm_conn_files%0A%20%20elif%20%5B%20%22%241%22%20%3D%3D%20%22OpenShiftSDN%22%20%5D%3B%20then%0A%20%20%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20%20%20rollback_nm%0A%20%20%20%20%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20ovn-kubernetes%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-int%20--%20--if-exists%20del-br%20br-local%0A%20%20fi%0A%7D%0A%0A%23%20Retry%20configure_ovs%20until%20it%20succeeds.%0A%23%20By%20default%2C%20retry%20every%2015%20minutes%20to%20give%20enough%20time%20to%20gather%0A%23%20troubleshooting%20information%20in%20between.%20Note%20that%20configure_ovs%20has%20other%0A%23%20internal%20retry%20mechanisms.%20This%20retry%20is%20intended%20to%20give%20some%0A%23%20self-healing%20capabilities%20to%20temporary%20but%20not%20necessarily%20short-lived%0A%23%20infrastructure%20problems.%0ARETRY%3D%22%24%7BRETRY-15m%7D%22%0Awhile%20true%3B%20do%0A%0A%20%20%23%20Disable%20retries%20if%20termination%20signal%20is%20received.%20Note%20that%20systemd%0A%20%20%23%20sends%20the%20signals%20to%20all%20processes%20in%20the%20group%20by%20default%20so%20we%20expect%0A%20%20%23%20configure_ovs%20to%20get%20its%20own%20signals.%0A%20%20trap%20'echo%20%22WARNING%3A%20termination%20requested%2C%20disabling%20retries%22%3B%20RETRY%3D%22%22'%20INT%20TERM%0A%20%20%0A%20%20%23%20Run%20configure_ovs%20in%20a%20sub-shell.%20%0A%20%20(%20configure_ovs%20%22%24%40%22%20)%0A%20%20e%3D%24%3F%0A%0A%20%20%23%20Handle%20signals%20while%20we%20sleep%0A%20%20trap%20'handle_termination'%20INT%20TERM%0A%20%20%0A%20%20%23%20Exit%20if%20succesful%20and%20not%20configured%20to%20retry%0A%20%20%5B%20%22%24e%22%20-eq%200%20%5D%20%7C%7C%20%5B%20-z%20%22%24RETRY%22%20%5D%20%26%26%20exit%20%22%24e%22%0A%20%20%0A%20%20echo%20%22configure-ovs%20failed%2C%20will%20retry%20after%20%24RETRY%22%0A%20%20%23%20flag%20that%20a%20retry%20has%20happened%0A%20%20touch%20%2Ftmp%2Fconfigure-ovs-retry%0A%20%20sleep%20%22%24RETRY%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ovs.sh
        - contents:
            source: data:,%23%20This%20file%20is%20generated%20by%20the%20Machine%20Config%20Operator's%20containerruntimeconfig%20controller.%0A%23%0A%23%20storage.conf%20is%20the%20configuration%20file%20for%20all%20tools%0A%23%20that%20share%20the%20containers%2Fstorage%20libraries%0A%23%20See%20man%205%20containers-storage.conf%20for%20more%20information%0A%23%20The%20%22container%20storage%22%20table%20contains%20all%20of%20the%20server%20options.%0A%5Bstorage%5D%0A%0A%23%20Default%20Storage%20Driver%0Adriver%20%3D%20%22overlay%22%0A%0A%23%20Temporary%20storage%20location%0Arunroot%20%3D%20%22%2Fvar%2Frun%2Fcontainers%2Fstorage%22%0A%0A%23%20Primary%20Read%2FWrite%20location%20of%20container%20storage%0Agraphroot%20%3D%20%22%2Fvar%2Flib%2Fcontainers%2Fstorage%22%0A%0A%5Bstorage.options%5D%0A%23%20Storage%20options%20to%20be%20passed%20to%20underlying%20storage%20drivers%0A%0A%23%20AdditionalImageStores%20is%20used%20to%20pass%20paths%20to%20additional%20Read%2FOnly%20image%20stores%0A%23%20Must%20be%20comma%20separated%20list.%0Aadditionalimagestores%20%3D%20%5B%0A%5D%0A%0A%23%20Size%20is%20used%20to%20set%20a%20maximum%20size%20of%20the%20container%20image.%20%20Only%20supported%20by%0A%23%20certain%20container%20storage%20drivers.%0Asize%20%3D%20%22%22%0A%0A%23%20Remap-UIDs%2FGIDs%20is%20the%20mapping%20from%20UIDs%2FGIDs%20as%20they%20should%20appear%20inside%20of%0A%23%20a%20container%2C%20to%20UIDs%2FGIDs%20as%20they%20should%20appear%20outside%20of%20the%20container%2C%20and%0A%23%20the%20length%20of%20the%20range%20of%20UIDs%2FGIDs.%20%20Additional%20mapped%20sets%20can%20be%20listed%0A%23%20and%20will%20be%20heeded%20by%20libraries%2C%20but%20there%20are%20limits%20to%20the%20number%20of%0A%23%20mappings%20which%20the%20kernel%20will%20allow%20when%20you%20later%20attempt%20to%20run%20a%0A%23%20container.%0A%23%0A%23%20remap-uids%20%3D%200%3A1668442479%3A65536%0A%23%20remap-gids%20%3D%200%3A1668442479%3A65536%0A%0A%23%20Remap-User%2FGroup%20is%20a%20name%20which%20can%20be%20used%20to%20look%20up%20one%20or%20more%20UID%2FGID%0A%23%20ranges%20in%20the%20%2Fetc%2Fsubuid%20or%20%2Fetc%2Fsubgid%20file.%20%20Mappings%20are%20set%20up%20starting%0A%23%20with%20an%20in-container%20ID%20of%200%20and%20the%20a%20host-level%20ID%20taken%20from%20the%20lowest%0A%23%20range%20that%20matches%20the%20specified%20name%2C%20and%20using%20the%20length%20of%20that%20range.%0A%23%20Additional%20ranges%20are%20then%20assigned%2C%20using%20the%20ranges%20which%20specify%20the%0A%23%20lowest%20host-level%20IDs%20first%2C%20to%20the%20lowest%20not-yet-mapped%20container-level%20ID%2C%0A%23%20until%20all%20of%20the%20entries%20have%20been%20used%20for%20maps.%0A%23%0A%23%20remap-user%20%3D%20%22storage%22%0A%23%20remap-group%20%3D%20%22storage%22%0A%0A%5Bstorage.options.overlay%5D%0A%23%20Storage%20Options%20for%20overlay%0A%0A%23%20Do%20not%20create%20a%20PRIVATE%20bind%20mount%20on%20the%20home%20directory.%0Askip_mount_home%20%3D%20%22true%22%0A%0A%5Bstorage.options.thinpool%5D%0A%23%20Storage%20Options%20for%20thinpool%0A%0A%23%20autoextend_percent%20determines%20the%20amount%20by%20which%20pool%20needs%20to%20be%0A%23%20grown.%20This%20is%20specified%20in%20terms%20of%20%25%20of%20pool%20size.%20So%20a%20value%20of%2020%20means%0A%23%20that%20when%20threshold%20is%20hit%2C%20pool%20will%20be%20grown%20by%2020%25%20of%20existing%0A%23%20pool%20size.%0A%23%20autoextend_percent%20%3D%20%2220%22%0A%0A%23%20autoextend_threshold%20determines%20the%20pool%20extension%20threshold%20in%20terms%0A%23%20of%20percentage%20of%20pool%20size.%20For%20example%2C%20if%20threshold%20is%2060%2C%20that%20means%20when%0A%23%20pool%20is%2060%25%20full%2C%20threshold%20has%20been%20hit.%0A%23%20autoextend_threshold%20%3D%20%2280%22%0A%0A%23%20basesize%20specifies%20the%20size%20to%20use%20when%20creating%20the%20base%20device%2C%20which%0A%23%20limits%20the%20size%20of%20images%20and%20containers.%0A%23%20basesize%20%3D%20%2210G%22%0A%0A%23%20blocksize%20specifies%20a%20custom%20blocksize%20to%20use%20for%20the%20thin%20pool.%0A%23%20blocksize%3D%2264k%22%0A%0A%23%20directlvm_device%20specifies%20a%20custom%20block%20storage%20device%20to%20use%20for%20the%0A%23%20thin%20pool.%20Required%20if%20you%20setup%20devicemapper%0A%23%20directlvm_device%20%3D%20%22%22%0A%0A%23%20directlvm_device_force%20wipes%20device%20even%20if%20device%20already%20has%20a%20filesystem%0A%23%20directlvm_device_force%20%3D%20%22True%22%0A%0A%23%20fs%20specifies%20the%20filesystem%20type%20to%20use%20for%20the%20base%20device.%0A%23%20fs%3D%22xfs%22%0A%0A%23%20log_level%20sets%20the%20log%20level%20of%20devicemapper.%0A%23%200%3A%20LogLevelSuppress%200%20(Default)%0A%23%202%3A%20LogLevelFatal%0A%23%203%3A%20LogLevelErr%0A%23%204%3A%20LogLevelWarn%0A%23%205%3A%20LogLevelNotice%0A%23%206%3A%20LogLevelInfo%0A%23%207%3A%20LogLevelDebug%0A%23%20log_level%20%3D%20%227%22%0A%0A%23%20min_free_space%20specifies%20the%20min%20free%20space%20percent%20in%20a%20thin%20pool%20require%20for%0A%23%20new%20device%20creation%20to%20succeed.%20Valid%20values%20are%20from%200%25%20-%2099%25.%0A%23%20Value%200%25%20disables%0A%23%20min_free_space%20%3D%20%2210%25%22%0A%0A%23%20mkfsarg%20specifies%20extra%20mkfs%20arguments%20to%20be%20used%20when%20creating%20the%20base%0A%23%20device.%0A%23%20mkfsarg%20%3D%20%22%22%0A%0A%23%20mountopt%20specifies%20extra%20mount%20options%20used%20when%20mounting%20the%20thin%20devices.%0A%23%20mountopt%20%3D%20%22%22%0A%0A%23%20use_deferred_removal%20Marking%20device%20for%20deferred%20removal%0A%23%20use_deferred_removal%20%3D%20%22True%22%0A%0A%23%20use_deferred_deletion%20Marking%20device%20for%20deferred%20deletion%0A%23%20use_deferred_deletion%20%3D%20%22True%22%0A%0A%23%20xfs_nospace_max_retries%20specifies%20the%20maximum%20number%20of%20retries%20XFS%20should%0A%23%20attempt%20to%20complete%20IO%20when%20ENOSPC%20(no%20space)%20error%20is%20returned%20by%0A%23%20underlying%20storage%20device.%0A%23%20xfs_nospace_max_retries%20%3D%20%220%22%0A
          mode: 420
          overwrite: true
          path: /etc/containers/storage.conf
        - contents:
            source: data:,apiVersion%3A%20kubelet.config.k8s.io%2Fv1%0Akind%3A%20CredentialProviderConfig%0Aproviders%3A%0A%20%20-%20name%3A%20ecr-credential-provider%0A%20%20%20%20matchImages%3A%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.*.amazonaws.com%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.*.amazonaws.com.cn%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr-fips.*.amazonaws.com%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.us-iso-east-1.c2s.ic.gov%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.us-isob-east-1.sc2s.sgov.gov%22%0A%20%20%20%20defaultCacheDuration%3A%20%2212h%22%0A%20%20%20%20apiVersion%3A%20credentialprovider.kubelet.k8s.io%2Fv1%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/credential-providers/ecr-credential-provider.yaml
        - contents:
            source: data:,%23%20Proxy%20environment%20variables%20will%20be%20populated%20in%20this%20file.%20Properly%0A%23%20url%20encoded%20passwords%20with%20special%20characters%20will%20use%20'%25%3CHEX%3E%3CHEX%3E'.%0A%23%20Systemd%20requires%20that%20any%20%25%20used%20in%20a%20password%20be%20represented%20as%0A%23%20%25%25%20in%20a%20unit%20file%20since%20%25%20is%20a%20prefix%20for%20macros%3B%20this%20restriction%20does%20not%0A%23%20apply%20for%20environment%20files.%20Templates%20that%20need%20the%20proxy%20set%20should%20use%0A%23%20'EnvironmentFile%3D%2Fetc%2Fmco%2Fproxy.env'.%0A
          mode: 420
          overwrite: true
          path: /etc/mco/proxy.env
        - contents:
            source: data:,%5BManager%5D%0ADefaultEnvironment%3DGODEBUG%3Dx509ignoreCN%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/10-default-env-godebug.conf
        - contents:
            source: data:,%23%20Force-load%20legacy%20iptables%20so%20it%20is%20usable%20from%20pod%20network%20namespaces%0Aip_tables%0A
          mode: 420
          overwrite: true
          path: /etc/modules-load.d/iptables.conf
        - contents:
            source: data:,NODE_SIZING_ENABLED%3Dfalse%0ASYSTEM_RESERVED_MEMORY%3D1Gi%0ASYSTEM_RESERVED_CPU%3D500m%0ASYSTEM_RESERVED_ES%3D1Gi
          mode: 420
          overwrite: true
          path: /etc/node-sizing-enabled.env
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%0ANODE_SIZES_ENV%3D%24%7BNODE_SIZES_ENV%3A-%2Fetc%2Fnode-sizing.env%7D%0AVERSION_1%3D1%0AVERSION_2%3D2%0ANODE_AUTO_SIZING_VERSION%3D%24%7BNODE_AUTO_SIZING_VERSION%3A-%24VERSION_2%7D%0ANODE_AUTO_SIZING_VERSION_FILE%3D%24%7BNODE_AUTO_SIZING_VERSION_FILE%3A-%2Fetc%2Fnode-sizing-version.json%7D%0Afunction%20dynamic_memory_sizing%20%7B%0A%20%20%20%20total_memory%3D%24(free%20-g%7Cawk%20'%2F%5EMem%3A%2F%7Bprint%20%242%7D')%0A%20%20%20%20%23%20total_memory%3D8%20test%20the%20recommended%20values%20by%20modifying%20this%20value%0A%20%20%20%20recommended_systemreserved_memory%3D0%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2025%25%20of%20the%20first%204GB%20of%20memory%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24total_memory%200.25%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D1%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2020%25%20of%20the%20next%204GB%20of%20memory%20(up%20to%208GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.20%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%208))%3B%20then%20%23%2010%25%20of%20the%20next%208GB%20of%20memory%20(up%20to%2016GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.10%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-8))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%20112))%3B%20then%20%23%206%25%20of%20the%20next%20112GB%20of%20memory%20(up%20to%20128GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%206.72%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-112))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3E%3D%200))%3B%20then%20%23%202%25%20of%20any%20memory%20above%20128GB%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.02%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20fi%0A%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%7C%20awk%20'%7Bprintf(%22%25d%5Cn%22%2C%241%20%2B%200.5)%7D')%20%23%20Round%20off%20so%20we%20avoid%20float%20conversions%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7Brecommended_systemreserved_memory%7DGi%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_cpu_sizing%20%7B%0A%20%20%20%20total_cpu%3D%24(getconf%20_NPROCESSORS_ONLN)%0A%20%20%20%20if%20%5B%20%22%241%22%20-eq%20%22%24VERSION_1%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%206%25%20of%20the%20first%20core%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24total_cpu%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0.06%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%201%25%20of%20the%20next%20core%20(up%20to%202%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%202))%3B%20then%20%23%200.5%25%20of%20the%20next%202%20cores%20(up%20to%204%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.005%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-2))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3E%3D%200))%3B%20then%20%23%200.25%25%20of%20any%20cores%20above%204%20cores%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.0025%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20%23%20Base%20allocation%20for%201%20CPU%20in%20fractions%20of%20a%20core%20(60%20millicores%20%3D%200.06%20CPU%20core)%0A%20%20%20%20%20%20%20%20base_allocation_fraction%3D0.06%0A%20%20%20%20%20%20%20%20%23%20Increment%20per%20additional%20CPU%20in%20fractions%20of%20a%20core%20(12%20millicores%20%3D%200.012%20CPU%20core)%0A%20%20%20%20%20%20%20%20increment_per_cpu_fraction%3D0.012%0A%20%20%20%20%20%20%20%20if%20((total_cpu%20%3E%201))%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20the%20total%20system-reserved%20CPU%20in%20fractions%2C%20starting%20with%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20and%20adding%20the%20incremental%20fraction%20for%20each%20additional%20CPU%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20base%3D%22%24base_allocation_fraction%22%20-v%20increment%3D%22%24increment_per_cpu_fraction%22%20-v%20cpus%3D%22%24total_cpu%22%20'BEGIN%20%7Bprintf%20%22%25.2f%5Cn%22%2C%20base%20%2B%20increment%20*%20(cpus%20-%201)%7D')%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20a%20single%20CPU%2C%20use%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24base_allocation_fraction%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7Brecommended_systemreserved_cpu%7D%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_ephemeral_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20dynamic_pid_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20set_memory%20%7B%0A%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_cpu%20%7B%0A%20%20%20%20SYSTEM_RESERVED_CPU%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_CPU%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_CPU%3D%22500m%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7BSYSTEM_RESERVED_CPU%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_es%20%7B%0A%20%20%20%20SYSTEM_RESERVED_ES%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_ES%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_ES%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_ES%3D%24%7BSYSTEM_RESERVED_ES%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20dynamic_memory_sizing%0A%20%20%20%20dynamic_cpu_sizing%20%242%0A%20%20%20%20set_es%20%241%0A%20%20%20%20%23dynamic_ephemeral_sizing%0A%20%20%20%20%23dynamic_pid_sizing%0A%7D%0Afunction%20static_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20set_memory%20%241%0A%20%20%20%20set_cpu%20%242%0A%20%20%20%20set_es%20%243%0A%7D%0Afunction%20create_version_file%20%7B%0A%20%20%20%20echo%20%22%7B%5C%22version%5C%22%3A%20%241%7D%22%20%3E%20%242%0A%7D%0Aif%20!%20%5B%20-f%20%24NODE_AUTO_SIZING_VERSION_FILE%20%5D%3B%20then%0A%20%20%20%20create_version_file%20%24NODE_AUTO_SIZING_VERSION%20%24NODE_AUTO_SIZING_VERSION_FILE%0Afi%0Anew_version%3D%24(jq%20.version%20%24NODE_AUTO_SIZING_VERSION_FILE)%0Aif%20%5B%20%241%20%3D%3D%20%22true%22%20%5D%3B%20then%0A%20%20%20%20dynamic_node_sizing%20%244%20%24new_version%0Aelif%20%5B%20%241%20%3D%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20static_node_sizing%20%242%20%243%20%244%0Aelse%0A%20%20%20%20echo%20%22Unrecognized%20command%20line%20option.%20Valid%20options%20are%20%5C%22true%5C%22%20or%20%5C%22false%5C%22%22%0Afi
          mode: 493
          overwrite: true
          path: /usr/local/sbin/dynamic-system-reserved-calc.sh
        - contents:
            source: data:,%23%20Turning%20on%20Accounting%20helps%20track%20down%20performance%20issues.%0A%5BManager%5D%0ADefaultCPUAccounting%3Dyes%0ADefaultMemoryAccounting%3Dyes%0ADefaultBlockIOAccounting%3Dyes%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/kubelet-cgroups.conf
        - contents:
            source: data:,%5BService%5D%0AEnvironment%3D%22KUBELET_LOG_LEVEL%3D2%22%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system/kubelet.service.d/20-logging.conf
        - contents:
            source: data:,%23%20ignore%20known%20SDN-managed%20devices%0A%5Bdevice%5D%0Amatch-device%3Dinterface-name%3Abr-int%3Binterface-name%3Abr-local%3Binterface-name%3Abr-nexthop%3Binterface-name%3Aovn-k8s-*%3Binterface-name%3Ak8s-*%3Binterface-name%3Atun0%3Binterface-name%3Abr0%3Binterface-name%3Apatch-br-*%3Binterface-name%3Abr-ext%3Binterface-name%3Aext-vxlan%3Binterface-name%3Aext%3Binterface-name%3Aint%3Binterface-name%3Avxlan_sys_*%3Binterface-name%3Agenev_sys_*%3Bdriver%3Aveth%0Amanaged%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/sdn.conf
        - contents:
            source: data:,%5Bservice%5D%0Akeep_state_file_after_apply%20%3D%20true%0A
          mode: 420
          overwrite: true
          path: /etc/nmstate/nmstate.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Set%20interface%20ofport_request%20to%20guarantee%20stable%20ofport%20numbers.%20This%20is%20important%20for%20flow%20matches.%0A%23%20Otherwise%2C%20another%20ofport%20number%20is%20assigned%20to%20the%20interface%20on%20every%20restart%20of%20NetworkManager.%0A%23%20This%20script%20will%20build%20an%20associative%20array%20INTERFACE_NAME-%3Eofport_request%20and%20will%20save%20it%20to%20file%20CONFIGURATION_FILE.%0A%23%20When%20an%20interface%20is%20brought%20up%2C%20this%20will%20reuse%20the%20value%20from%20the%20associative%20array%20if%20such%20a%20value%20exists.%0A%23%20Otherwise%2C%20this%20will%20try%20to%20use%20the%20current%20ofport%20value.%20If%20the%20ofport%20value%20is%20already%20reserved%2C%20then%0A%23%20this%20uses%20the%20lowest%20available%20numerical%20value%2C%20instead.%0Aset%20-eux%20-o%20pipefail%0Aif%20%5B%5B%20%22OVNKubernetes%22%20!%3D%20%22OVNKubernetes%22%20%5D%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0AINTERFACE_NAME%3D%241%0AOPERATION%3D%242%0A%0A%23%20Only%20execute%20this%20on%20pre-up%0Aif%20%5B%20%22%24%7BOPERATION%7D%22%20!%3D%20%22pre-up%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0AINTERFACE_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%241%3D%3D%22'%24%7BINTERFACE_NAME%7D'%22%20%26%26%20%242!~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20slave-type.%20If%20this%20is%20not%20an%20ovs-port%2C%20then%20exit%0AINTERFACE_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-port%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20This%20is%20not%20necessarily%20a%20UUID%20(can%20be%20a%20name%20in%20case%20of%20bonds)%20but%20this%20should%20be%20unique%0APORT%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0APORT_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%20(%241%3D%3D%22'%24%7BPORT%7D'%22%20%7C%7C%20%243%3D%3D%22'%24%7BPORT%7D'%22)%20%26%26%20%242~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20slave-type.%20If%20this%20is%20not%20an%20ovs-bridge%2C%20then%20exit%0APORT_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-bridge%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20master.%20If%20it%20doesn't%20have%20any%2C%20assume%20it's%20not%20our%20bridge%0ABRIDGE_ID%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BBRIDGE_ID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20bridge%20name%0ABRIDGE_NAME%3D%24(nmcli%20-t%20-f%20connection.interface-name%20conn%20show%20%22%24%7BBRIDGE_ID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0A%23%20Limit%20this%20to%20br-ex%20and%20br-ex1%20only.%20If%20one%20wanted%20to%20enable%20this%20for%20all%20OVS%20bridges%2C%0A%23%20the%20condition%20would%20be%3A%20if%20%5B%20%22%24BRIDGE_NAME%22%20%3D%3D%20%22%22%20%5D%3B%20then%0Aif%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Make%20sure%20that%20the%20interface%20is%20plugged%20into%20OVS%0A%23%20This%20should%20always%20be%20the%20case%20given%20that%20we%20are%20in%20pre-up%2C%20but%20exit%20gracefully%20in%20the%20odd%20case%20that%20it's%20not%0Aif%20!%20ovs-vsctl%20list%20interface%20%22%24%7BINTERFACE_NAME%7D%22%20%3E%2Fdev%2Fnull%202%3E%261%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0ACONFIGURATION_FILE%3D%22%2Frun%2Fofport_requests.%24%7BBRIDGE_NAME%7D%22%0A%0A%23%20Declare%20a%20new%20associative%20array.%20If%20CONFIGURATION_FILE%20exists%2C%20source%20entries%20from%20there%0Adeclare%20-A%20INTERFACES%0Aif%20%5B%20-f%20%22%24%7BCONFIGURATION_FILE%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Sourcing%20configuration%20file%20'%24%7BCONFIGURATION_FILE%7D'%20with%20contents%3A%22%0A%20%20%20%20cat%20%22%24%7BCONFIGURATION_FILE%7D%22%0A%20%20%20%20source%20%22%24%7BCONFIGURATION_FILE%7D%22%0Afi%0A%0A%23%20get_interface_ofport_request%20will%20return%0A%23%20*%20either%3A%20the%20current%20ofport%20assignment%20for%20the%20port%20if%20no%20interface%20has%20claimed%20this%20ofport%20number%2C%20yet%0A%23%20*%20or%3A%20%20%20%20%20the%20lowest%20available%20free%20ofport%20number%0Afunction%20get_interface_ofport_request()%20%7B%0A%20%20%20%20%23%20Build%20an%20array%20that%20only%20contains%20the%20currently%20reserved%20ofport_requests%0A%20%20%20%20declare%20-A%20ofport_requests%0A%20%20%20%20for%20interface_name%20in%20%22%24%7B!INTERFACES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%20%20%20%20ofport_requests%5B%24%7BINTERFACES%5B%24interface_name%5D%7D%5D%3D%24%7BINTERFACES%5B%24interface_name%5D%7D%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20Get%20the%20current%20ofport%20number%20assignment%0A%20%20%20%20local%20current_ofport%3D%24(ovs-vsctl%20get%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport)%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20still%20free%2C%20use%20it%0A%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24current_ofport%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%24current_ofport%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20not%20free%2C%20return%20the%20lowest%20free%20entry%0A%20%20%20%20i%3D0%0A%20%20%20%20for%20i%20in%20%7B1..65000%7D%3B%20do%0A%20%20%20%20%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24i%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%24i%0A%20%20%20%20%20%20%20%20%20%20%20%20return%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20if%20we%20still%20cannot%20find%20an%20ID%2C%20exit%20with%20an%20error%0A%20%20%20%20echo%20%22Impossible%20to%20find%20an%20ofport%20ID%20for%20interface%20%24%7BINTERFACE_NAME%7D%22%20%3E%262%0A%20%20%20%20exit%201%0A%7D%0A%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20exists%2C%20use%20that%20value%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20does%20not%20exists%2C%20use%20the%20value%20from%20get_interface_ofport_request%0Aif%20!%20%5B%20%22%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20INTERFACES%5B%24INTERFACE_NAME%5D%3D%24(get_interface_ofport_request)%0Afi%0A%23%20Set%20ofport_request%20according%20to%20INTERFACES%5BINTERFACE_NAME%5D%0Aovs-vsctl%20set%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport_request%3D%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%7D%0A%0A%23%20Save%20current%20state%20of%20INTERFACES%20to%20CONFIGURATION_FILE%0Adeclare%20-p%20INTERFACES%20%3E%7C%20%22%24%7BCONFIGURATION_FILE%7D%22%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/pre-up.d/10-ofport-request.sh
        - contents:
            source: data:,%7B%22auths%22%3A%7B%22cloud.openshift.com%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfN2JmN2FjMTAyMDMxNDY1N2EwZjdiMDdiNDNjM2FiZDg6OE1YQ0gyTldMSktPVU9DQk5UNk9NSERPUzc2NkYxTURFTjlXQjhXN0xTTUtDNjk1NjI0N1c1OFUySzFDRUcwVw%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22quay.io%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfN2JmN2FjMTAyMDMxNDY1N2EwZjdiMDdiNDNjM2FiZDg6OE1YQ0gyTldMSktPVU9DQk5UNk9NSERPUzc2NkYxTURFTjlXQjhXN0xTTUtDNjk1NjI0N1c1OFUySzFDRUcwVw%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22registry.ci.openshift.org%22%3A%7B%22auth%22%3A%22c2VydmljZWFjY291bnQ6ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNkluWjBaVmc1TVVkUlpGRjZRME5OWkVWa2JGOXNTSG90YlVSd2EwRlVPR2RzWjJoUVRtMVBkamxLUmpBaWZRLmV5SmhkV1FpT2xzaWFIUjBjSE02THk5amFTMWtkakp1Y0MxdmFXUmpMbk16TG1GdFlYcHZibUYzY3k1amIyMGlYU3dpWlhod0lqb3hOek0wTlRNd05EWXlMQ0pwWVhRaU9qRTNNekl4TVRFeU5qSXNJbWx6Y3lJNkltaDBkSEJ6T2k4dlkya3RaSFl5Ym5BdGIybGtZeTV6TXk1aGJXRjZiMjVoZDNNdVkyOXRJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5STZleUp1WVcxbGMzQmhZMlVpT2lKamFTSXNJbk5sWTNKbGRDSTZleUp1WVcxbElqb2lkRzlyWlc0dFltOTFibVF0YjJKcVpXTjBMVEVpTENKMWFXUWlPaUkxWkRJd1pHUTBNQzFqT1RCaExUUXpNVFl0WVdNd05DMW1OVGczT0RFeVpUVTFZamdpZlN3aWMyVnlkbWxqWldGalkyOTFiblFpT25zaWJtRnRaU0k2SW1sdFlXZGxMWEIxYkd4bGNpSXNJblZwWkNJNkltRTNOMlk1TkdFeUxXVXdOelV0TkRGaU9DMDVPV1JoTFdRMlpEbGtNbUZpTlRGak9TSjlmU3dpYm1KbUlqb3hOek15TVRFeE1qWXlMQ0p6ZFdJaU9pSnplWE4wWlcwNmMyVnlkbWxqWldGalkyOTFiblE2WTJrNmFXMWhaMlV0Y0hWc2JHVnlJbjAuVGFqMktGY1JOV0FIRHJGT0NPQjBhWUJGUTUwVW9FUmdXMWFZYUNTVTQ0NF9jdnpCOFJDamNxR04xdV9jOFRRbFBDNXU0NG5JNklaYTdvU1RnMUh4dE9aQmEyYW5OS0JPMk5UNVF5WEhhX0R5cVJlaUUxb0YtcmphRms2TEJrNWllT1BSWXJHbklpWlJJNkQ2S0kxMmxJVFZQdFBPYUgtaXFuNV9LMXdOcmR4SDhYb2dCdlJ5UlJwRDBLTUxGNkJfeFBzbi1VeHVQQklIbjVRTFlXSkJtOVFMRVlIM0tzZDN2by03Uzc0anlZMkswMUF1OUpwYkFFR3k4Z2lyUDE1YlRnUXJReW1zS1NrbFN6U3BUbEM0MDJxVjNBanVPSjA4eGxrSE5VeXJROFk3dklJWDFBUUVmbHJaaC13ZVcyVy1aNWtnZjFOMXhNVVl6QnplZW5BZF9n%22%7D%2C%22registry.connect.redhat.com%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLWU3NDlmYWFiLTM0ZjktNDg0ZS1hNWQwLTJkNzFhMzgzMTg1MjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSXpORGszTURVMU5URTFObUkwTXpOaFltVmxNRGt5TVRJM09UZzNZV0V5WVNKOS50MUxtR0FhMTQzdnJIWG13RFZVVjNYaWhYa203Vk95bDFLek9kZm9QN0tTd3NqVFpKeUlSN1lKQjNyNGxGN3pVNWMwa0ZyOVYweUtwSFdPRU94clhJekVSaXlfOXkwQzRxbXRDOUhYNjJNVThsdmJtQW9GSXhZbHZXWnREVXVQZWgzSVFqS25CN2FJYlZ6MFJ3SWZWYVZucXFOUzhHbDNFcDRTUjVpNGZmUzE5akJCUnpxdmxBSjF6QkNVWWI3S1ZLTHVGRHJsNjdNNy1rWWwxTUhseTRBN2JVdjVISU5MaEhOdDVfRk5JX3RWbjdQM0RzQkVjcWxkWTd0Y0J4UlNoLTdQbWpzMGJEWm9ZZTZ6by1QY25TeEY0RV94QzF6aGZYYUNpdEU4UVZTUmk2MjhnM1c4WjVQQzc4VFBJWGtvaTBJWG9IX1E4QTd4SDlKaDhsWWhTTnBCaUxHODMyaFNhRUdtYkEtaU5kd3BrTGk0a0oyeTlYWE55ZlNUbU1mRUppUGwyWEI5VXRTT3lva05XU0ZqVk1kZ3l5WFlaUWtTNGh6Ql83VkpzTEh6RHpKaTJGcUZNNE56LW5Qd28zalZ3c3d3YXgzUUZZVUk2YzA5MVZnT0NUdEtpeEJXeTBaVEZyT3hEVDh4ZFRQOXcxY1JoR1N1UzU5WG55c2I2bndDLWQ5ZS11SWZpS2x4dDNZNkJaUkhRYmVUZlRtdGFoMUxOYWhRaXRzclVubVBjZXhnLVFXdzhCS3VENUFwbFc3eFVHcm9Lb1lkSEowVTJtc0ZWcjhZZ2FjVDl1UC1hWGUtTHd0dnJ3ZG1fWGtVdWRMRnFsRklxby1lWTdhVE03Xy1HRk8xWE8xTTIwQWVtSU5oUXJqUkN4TGRJeXlMSU9uOURBZUdYeGc5bUJiWQ%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22registry.redhat.io%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLWU3NDlmYWFiLTM0ZjktNDg0ZS1hNWQwLTJkNzFhMzgzMTg1MjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSXpORGszTURVMU5URTFObUkwTXpOaFltVmxNRGt5TVRJM09UZzNZV0V5WVNKOS50MUxtR0FhMTQzdnJIWG13RFZVVjNYaWhYa203Vk95bDFLek9kZm9QN0tTd3NqVFpKeUlSN1lKQjNyNGxGN3pVNWMwa0ZyOVYweUtwSFdPRU94clhJekVSaXlfOXkwQzRxbXRDOUhYNjJNVThsdmJtQW9GSXhZbHZXWnREVXVQZWgzSVFqS25CN2FJYlZ6MFJ3SWZWYVZucXFOUzhHbDNFcDRTUjVpNGZmUzE5akJCUnpxdmxBSjF6QkNVWWI3S1ZLTHVGRHJsNjdNNy1rWWwxTUhseTRBN2JVdjVISU5MaEhOdDVfRk5JX3RWbjdQM0RzQkVjcWxkWTd0Y0J4UlNoLTdQbWpzMGJEWm9ZZTZ6by1QY25TeEY0RV94QzF6aGZYYUNpdEU4UVZTUmk2MjhnM1c4WjVQQzc4VFBJWGtvaTBJWG9IX1E4QTd4SDlKaDhsWWhTTnBCaUxHODMyaFNhRUdtYkEtaU5kd3BrTGk0a0oyeTlYWE55ZlNUbU1mRUppUGwyWEI5VXRTT3lva05XU0ZqVk1kZ3l5WFlaUWtTNGh6Ql83VkpzTEh6RHpKaTJGcUZNNE56LW5Qd28zalZ3c3d3YXgzUUZZVUk2YzA5MVZnT0NUdEtpeEJXeTBaVEZyT3hEVDh4ZFRQOXcxY1JoR1N1UzU5WG55c2I2bndDLWQ5ZS11SWZpS2x4dDNZNkJaUkhRYmVUZlRtdGFoMUxOYWhRaXRzclVubVBjZXhnLVFXdzhCS3VENUFwbFc3eFVHcm9Lb1lkSEowVTJtc0ZWcjhZZ2FjVDl1UC1hWGUtTHd0dnJ3ZG1fWGtVdWRMRnFsRklxby1lWTdhVE03Xy1HRk8xWE8xTTIwQWVtSU5oUXJqUkN4TGRJeXlMSU9uOURBZUdYeGc5bUJiWQ%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%7D%7D%0A
          mode: 384
          overwrite: true
          path: /var/lib/kubelet/config.json
        - contents:
            source: data:,%23%20Needed%20by%20the%20OpenShift%20SDN.%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1758552%0Anet.ipv4.conf.all.arp_announce%20%3D%202%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/arp.conf
        - contents:
            source: data:,%23%20See%3A%20rhbz%231384746%2C%20OCPBUGS-24012%0Anet.ipv4.neigh.default.gc_thresh1%3D8192%0Anet.ipv4.neigh.default.gc_thresh2%3D32768%0Anet.ipv4.neigh.default.gc_thresh3%3D65536%0Anet.ipv6.neigh.default.gc_thresh1%3D8192%0Anet.ipv6.neigh.default.gc_thresh2%3D32768%0Anet.ipv6.neigh.default.gc_thresh3%3D65536%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/gc-thresh.conf
        - contents:
            source: data:,%0Afs.inotify.max_user_watches%20%3D%2065536%0Afs.inotify.max_user_instances%20%3D%208192%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/inotify.conf
        - contents:
            source: data:,vm.unprivileged_userfaultfd%20%3D%201
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/enable-userfaultfd.conf
        - contents:
            source: data:,%23%20Needed%20for%20OpenShift%20Logging%20(ElasticSearch).%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1793714%0Avm.max_map_count%20%3D%20262144%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/vm-max-map.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%20-o%20pipefail%0A%0ANODEENV%3D%2Fetc%2Fkubernetes%2Fnode.env%0A%0A%23%20This%20can%20be%20removed%201%20release%20after%20it%20merges%20because%20all%20affected%20nodes%0A%23%20will%20have%20upgraded%0ALEGACY_NODEENV%3D%2Fetc%2Fsystemd%2Fsystem%2Fkubelet.service.d%2F20-aws-node-name.conf%0Aif%20%5B%20-e%20%22%24%7BLEGACY_NODEENV%7D%22%20%5D%3B%20then%0A%20%20%20%20%23%20Legacy%20file%20was%20a%20systemd%20stanza%20with%20KUBELET_NODE_NAME%20specified%20in%0A%20%20%20%20%23%20a%20directive%20of%20the%20format%3A%0A%20%20%20%20%23%20%20%20Environment%3D%22KUBELET_NODE_NAME%3Dnode.example.com%22%0A%20%20%20%20%23%20New%20format%20is%20an%20environment%20file.%20The%20following%20extracts%20only%20the%0A%20%20%20%20%23%20contents%20of%20any%20Environment%20directives.%0A%20%20%20%20echo%20%22Migrating%20%24%7BLEGACY_NODEENV%7D%20to%20%24%7BNODEENV%7D%22%0A%20%20%20%20awk%20'match(%240%2C%20%2F%5E%5Cs*Environment%5Cs*%3D%5Cs*%22(.*)%22%5Cs*%24%2F%2C%20value)%20%7B%20print%20value%5B1%5D%20%7D'%20%3C%20%22%24%7BLEGACY_NODEENV%7D%22%20%3E%20%22%24%7BNODEENV%7D%22%0A%20%20%20%20rm%20%22%24%7BLEGACY_NODEENV%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20-e%20%22%24%7BNODEENV%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Not%20replacing%20existing%20%24%7BNODEENV%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20afterburn%20service%20is%20expected%20to%20be%20used%20for%20metadata%20retrival%2C%20see%20respective%20systemd%20unit.%0A%23%20However%2C%20on%20older%20OCP%20boot%20images%20does%20not%20contain%20afterburn%20service%2C%20check%20if%20afterburn%20variables%20are%20there%0A%23%20otherwise%20try%20to%20communicate%20IMDS%20here.%0A%23%20metadata%20related%20afterburn%20doc%3A%20https%3A%2F%2Fcoreos.github.io%2Fafterburn%2Fusage%2Fattributes%2F%0A%0AHOSTNAME%3D%24%7BAFTERBURN_AWS_HOSTNAME%3A-%7D%0Awhile%20%5B%5B%20-z%20%22%24%7BHOSTNAME%7D%22%20%5D%5D%3B%20do%0A%20%20HOSTNAME%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Flocal-hostname)%0A%20%20if%20%5B%5B%20-z%20%22%24%7BHOSTNAME%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Can%20not%20obtain%20hostname%20from%20the%20metadata%20service.%22%201%3E%262%0A%20%20%20%20sleep%205%0A%20%20fi%20%0Adone%0A%0A%23%20For%20compatibility%20with%20the%20AWS%20in-tree%20provider%0A%23%20Set%20node%20name%20to%20be%20instance%20FQDN%20instead%20of%20the%20default%20hostname%0Acat%20%3E%20%22%24%7BNODEENV%7D%22%20%3C%3CEOF%0AKUBELET_NODE_NAME%3D%24%7BHOSTNAME%25%25%20*%7D%0AEOF%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/aws-kubelet-nodename
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%20-o%20pipefail%0A%0ANODECONF%3D%2Fetc%2Fsystemd%2Fsystem%2Fkubelet.service.d%2F20-aws-providerid.conf%0A%0Aif%20%5B%20-e%20%22%24%7BNODECONF%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Not%20replacing%20existing%20%24%7BNODECONF%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20afterburn%20service%20is%20expected%20to%20be%20used%20for%20metadata%20retrival%2C%20see%20respective%20systemd%20unit.%0A%23%20However%2C%20on%20older%20OCP%20boot%20images%20does%20not%20contain%20afterburn%20service%2C%20check%20if%20afterburn%20variables%20are%20there%0A%23%20otherwise%20try%20to%20communicate%20IMDS%20here.%0A%23%20metadata%20related%20afterburn%20doc%3A%20https%3A%2F%2Fcoreos.github.io%2Fafterburn%2Fusage%2Fattributes%2F%0A%0AINSTANCE_ID%3D%24%7BAFTERBURN_AWS_INSTANCE_ID%3A-%7D%0AAVAILABILITY_ZONE%3D%24%7BAFTERBURN_AWS_AVAILABILITY_ZONE%3A-%7D%0Aif%20%5B%5B%20-z%20%22%24%7BINSTANCE_ID%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20-z%20%22%24%7BAVAILABILITY_ZONE%7D%22%20%5D%5D%3B%20then%0A%20%20INSTANCE_ID%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Finstance-id)%0A%20%20AVAILABILITY_ZONE%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Fplacement%2Favailability-zone)%0A%20%20if%20%5B%5B%20-z%20%22%24%7BINSTANCE_ID%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20-z%20%22%24%7BAVAILABILITY_ZONE%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Can%20not%20obtain%20instance-id%20and%20availability%20zone%20info%20from%20the%20metadata%20service.%22%0A%20%20%20%20exit%201%0A%20%20fi%20%0Afi%0A%0A%23%20Due%20to%20a%20potential%20mismatch%20between%20Hostname%20and%20PrivateDNSName%20with%20clusters%20that%20use%20custom%20DHCP%20Option%20Sets%0A%23%20which%20can%20cause%20issues%20in%20cloud%20controller%20manager%20node%20syncing%0A%23%20(see%3A%20https%3A%2F%2Fgithub.com%2Fkubernetes%2Fcloud-provider-aws%2Fissues%2F384)%2C%0A%23%20set%20KUBELET_PROVIDERID%20to%20be%20a%20fully%20qualified%20AWS%20instace%20provider%20id.%0A%23%20This%20new%20variable%20is%20later%20used%20to%20populate%20the%20kubelet's%20%60provider-id%60%20flag%2C%20later%20set%20on%20the%20Node%20.spec%0A%23%20and%20used%20by%20the%20cloud%20controller%20manager's%20node%20controller%20to%20retrieve%20the%20Node's%20backing%20instance.%0Acat%20%3E%20%22%24%7BNODECONF%7D%22%20%3C%3CEOF%0A%5BService%5D%0AEnvironment%3D%22KUBELET_PROVIDERID%3Daws%3A%2F%2F%2F%24%7BAVAILABILITY_ZONE%7D%2F%24%7BINSTANCE_ID%7D%22%0AEOF%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/aws-kubelet-providerid
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20First%2C%20we%20need%20to%20wait%20until%20DHCP%20finishes%20and%20the%20node%20has%20a%20non-%60localhost%60%0A%23%20hostname%20before%20%60kubelet.service%60%20starts.%0A%23%20That's%20the%20%60--wait%60%20argument%20as%20used%20by%20%60node-valid-hostname.service%60.%0A%23%0A%23%20Second%2C%20on%20GCP%20specifically%20we%20truncate%20the%20hostname%20if%20it's%20%3E63%20characters.%0A%23%20That's%20%60gcp-hostname.service%60.%0A%0A%23%20Block%20indefinitely%20until%20the%20host%20gets%20a%20non-localhost%20name.%0A%23%20Note%20node-valid-hostname.service%20uses%20systemd%20to%20abort%20if%20this%20takes%20too%20long.%0Await_localhost()%20%7B%0A%20%20%20%20echo%20%22waiting%20for%20non-localhost%20hostname%20to%20be%20assigned%22%0A%20%20%20%20while%20%5B%5B%20%22%24(%3C%20%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%20%3D~%20(localhost%7Clocalhost.localdomain)%20%5D%5D%3B%0A%20%20%20%20do%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20done%0A%20%20%20%20echo%20%22node%20identified%20as%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%0A%20%20%20%20echo%20%22saving%20hostname%20to%20prevent%20NetworkManager%20from%20ever%20unsetting%20it%22%0A%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_gcp_hostname()%20%7B%0A%20%20%20%20%2Fusr%2Fbin%2Fafterburn%20--provider%20gcp%20--hostname%3D%2Frun%2Fafterburn.hostname%0A%0A%20%20%20%20local%20host_name%3D%24(cat%20%2Frun%2Fafterburn.hostname)%0A%20%20%20%20local%20type_arg%3D%22transient%22%0A%0A%20%20%20%20%23%20%2Fetc%2Fhostname%20is%20used%20for%20static%20hostnames%20and%20is%20authoritative.%0A%20%20%20%20%23%20This%20will%20check%20to%20make%20sure%20that%20the%20static%20hostname%20is%20the%0A%20%20%20%20%23%20less%20than%20or%20equal%20to%2063%20characters%20in%20length.%0A%20%20%20%20if%20%5B%20-f%20%2Fetc%2Fhostname%20%5D%20%26%26%20%5B%20%22%24(cat%20%2Fetc%2Fhostname%20%7C%20wc%20-m)%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20etc_name%3D%22%24(%3C%20%2Fetc%2Fhostname)%22%0A%20%20%20%20%20%20%20%20type_arg%3D%22static%22%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24%7Betc_name%7D%22%20!%3D%20%22%24%7Bhost_name%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%2Fetc%2Fhostname%20is%20set%20to%20%24%7Betc_name%7D%20but%20does%20not%20match%20%24%7Bhost_name%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22using%20%2Fetc%2Fhostname%20as%20the%20authoritative%20name%22%0A%20%20%20%20%20%20%20%20%20%20%20%20host_name%3D%22%24%7Betc_name%7D%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Only%20mutate%20the%20hostname%20if%20the%20length%20is%20longer%20than%2063%20characters.%20The%0A%20%20%20%20%23%20hostname%20will%20be%20the%20lesser%20of%2063%20characters%20after%20the%20first%20dot%20in%20the%0A%20%20%20%20%23%20FQDN.%20%20This%20algorithm%20is%20only%20known%20to%20work%20in%20GCP%2C%20and%20hence%20is%20only%0A%20%20%20%20%23%20executed%20in%20GCP.%0A%20%20%20%20if%20%5B%20%22%24%7B%23host_name%7D%22%20-gt%2063%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20alt_name%3D%24(printf%20%22%24%7Bhost_name%7D%22%20%7C%20cut%20-f1%20-d'.'%20%7C%20cut%20-c%20-63)%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Bhost_name%7D%20is%20longer%20than%2063%20characters%2C%20using%20truncated%20hostname%22%0A%20%20%20%20%20%20%20%20host_name%3D%22%24%7Balt_name%7D%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22setting%20%24%7Btype_arg%7D%20hostname%20to%20%24%7Bhost_name%7D%22%0A%20%20%20%20%2Fbin%2Fhostnamectl%20%22--%24%7Btype_arg%7D%22%20set-hostname%20%22%24%7Bhost_name%7D%22%0A%20%20%20%20exit%200%0A%7D%0A%0Aarg%3D%24%7B1%7D%3B%20shift%3B%0Acase%20%22%24%7Barg%7D%22%20in%0A%20%20%20%20--wait)%20wait_localhost%3B%3B%0A%20%20%20%20--gcp)%20set_gcp_hostname%3B%3B%0A%20%20%20%20*)%20echo%20%22Unhandled%20arg%20%24arg%22%3B%20exit%201%0Aesac%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/mco-hostname
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0Aset%20-eou%20pipefail%0A%0A%23%20context%0Aintapi%3D%24(oc%20get%20infrastructures.config.openshift.io%20cluster%20-o%20%22jsonpath%3D%7B.status.apiServerInternalURI%7D%22)%0Acontext%3D%22%24(oc%20config%20current-context)%22%0A%23%20cluster%0Acluster%3D%22%24(oc%20config%20view%20-o%20%22jsonpath%3D%7B.contexts%5B%3F(%40.name%3D%3D%5C%22%24context%5C%22)%5D.context.cluster%7D%22)%22%0Aserver%3D%22%24(oc%20config%20view%20-o%20%22jsonpath%3D%7B.clusters%5B%3F(%40.name%3D%3D%5C%22%24cluster%5C%22)%5D.cluster.server%7D%22)%22%0A%23%20token%0Aca_crt_data%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20-o%20%22jsonpath%3D%7B.data.ca%5C.crt%7D%22%20%7C%20base64%20--decode)%22%0Anamespace%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20%20-o%20%22jsonpath%3D%7B.data.namespace%7D%22%20%7C%20base64%20--decode)%22%0Atoken%3D%22%24(oc%20get%20secret%20-n%20openshift-machine-config-operator%20node-bootstrapper-token%20-o%20%22jsonpath%3D%7B.data.token%7D%22%20%7C%20base64%20--decode)%22%0A%0Aexport%20KUBECONFIG%3D%22%24(mktemp)%22%0Akubectl%20config%20set-credentials%20%22kubelet%22%20--token%3D%22%24token%22%20%3E%2Fdev%2Fnull%0Aca_crt%3D%22%24(mktemp)%22%3B%20echo%20%22%24ca_crt_data%22%20%3E%20%24ca_crt%0Akubectl%20config%20set-cluster%20%24cluster%20--server%3D%22%24intapi%22%20--certificate-authority%3D%22%24ca_crt%22%20--embed-certs%20%3E%2Fdev%2Fnull%0Akubectl%20config%20set-context%20kubelet%20--cluster%3D%22%24cluster%22%20--user%3D%22kubelet%22%20%3E%2Fdev%2Fnull%0Akubectl%20config%20use-context%20kubelet%20%3E%2Fdev%2Fnull%0Acat%20%22%24KUBECONFIG%22%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/recover-kubeconfig.sh
        - contents:
            source: data:,
          mode: 493
          overwrite: true
          path: /etc/kubernetes/kubelet-plugins/volume/exec/.dummy
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1941714%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1935539%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1987108%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22vmxnet3%22%20%5D%5D%3B%20then%0A%20%20logger%20-s%20%2299-vsphere-disable-tx-udp-tnl%20triggered%20by%20%24%7B2%7D%20on%20device%20%24%7BDEVICE_IFACE%7D.%22%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-csum-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksum-ip-generic%20off%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-vsphere-disable-tx-udp-tnl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0Aif%20%5B%20!%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20%23%20No%20need%20to%20do%20this%20if%20no%20NMState%20configuration%20was%20applied%0A%20%20exit%200%0Afi%0A%0A%23%20This%20logic%20is%20borrowed%20from%20configure-ovs.sh%0A%23%20TODO%3A%20Find%20a%20platform-agnostic%20way%20to%20do%20this.%20It%20won't%20work%20on%20platforms%20where%0A%23%20nodeip-configuration%20is%20not%20used.%0Aip%3D%24(cat%20%2Frun%2Fnodeip-configuration%2Fprimary-ip)%0Aif%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20echo%20%22No%20ip%20to%20bind%20was%20found%22%0A%20%20exit%201%0Afi%0Awhile%20%3A%0Ado%0A%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%20%20sleep%2010%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-primary-ip.sh
        - contents:
            source: data:,unqualified-search-registries%20%3D%20%5B'registry.access.redhat.com'%2C%20'docker.io'%5D%0A
          mode: 420
          overwrite: true
          path: /etc/containers/registries.conf
        - contents:
            source: data:,%5Bcrio%5D%0Ainternal_wipe%20%3D%20true%0Ainternal_repair%20%3D%20true%0A%0A%5Bcrio.api%5D%0Astream_address%20%3D%20%22127.0.0.1%22%0Astream_port%20%3D%20%220%22%0A%0A%5Bcrio.runtime%5D%0Aselinux%20%3D%20true%0Aconmon%20%3D%20%22%22%0Aconmon_cgroup%20%3D%20%22pod%22%0Adefault_env%20%3D%20%5B%0A%20%20%20%20%22NSS_SDB_USE_CACHE%3Dno%22%2C%0A%5D%0Adefault_runtime%20%3D%20%22crun%22%0Alog_level%20%3D%20%22info%22%0Acgroup_manager%20%3D%20%22systemd%22%0Adefault_sysctls%20%3D%20%5B%0A%20%20%20%20%22net.ipv4.ping_group_range%3D0%202147483647%22%2C%0A%5D%0Ahooks_dir%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Frun%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Fusr%2Fshare%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%5D%0Amanage_ns_lifecycle%20%3D%20true%0Aabsent_mount_sources_to_reject%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fhostname%22%2C%0A%5D%0Adrop_infra_ctr%20%3D%20true%0A%0A%5Bcrio.runtime.runtimes.runc%5D%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%0A%5Bcrio.runtime.runtimes.crun%5D%0Aruntime_root%20%3D%20%22%2Frun%2Fcrun%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%23%20Based%20on%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcrun%2Fblob%2F27d7dd3a0%2FREADME.md%3Fplain%3D1%23L48%0Acontainer_min_memory%20%3D%20%22512KiB%22%0A%0A%5Bcrio.runtime.workloads.openshift-builder%5D%0Aactivation_annotation%20%3D%20%22io.openshift.builder%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%22io.kubernetes.cri-o.userns-mode%22%2C%0A%20%20%22io.kubernetes.cri-o.Devices%22%0A%5D%0A%5Bcrio.runtime.workloads.openshift-builder.resources%5D%0A%0A%5Bcrio.image%5D%0Aglobal_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_image%20%3D%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A4f60bb3e2e42085b82096277c09906c2fc64083a9d8d5aba56c177aa547c4b7f%22%0Apause_image_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_command%20%3D%20%22%2Fusr%2Fbin%2Fpod%22%0A%0A%5Bcrio.network%5D%0Anetwork_dir%20%3D%20%22%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F%22%0Aplugin_dirs%20%3D%20%5B%0A%20%20%20%20%22%2Fvar%2Flib%2Fcni%2Fbin%22%2C%0A%20%20%20%20%22%2Fusr%2Flibexec%2Fcni%22%2C%0A%5D%0A%0A%5Bcrio.metrics%5D%0Aenable_metrics%20%3D%20true%0Ametrics_host%20%3D%20%22127.0.0.1%22%0Ametrics_port%20%3D%209537%0Ametrics_collectors%20%3D%20%5B%0A%20%20%22operations%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_total%22%0A%20%20%22operations_latency_microseconds_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds_total%22%0A%20%20%22operations_latency_microseconds%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds%22%0A%20%20%22operations_errors%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_errors_total%22%0A%20%20%22image_pulls_layer_size%22%2C%0A%20%20%22containers_oom_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22containers_oom_count_total%22%0A%20%20%22containers_oom%22%2C%0A%20%20%23%20Drop%20metrics%20with%20excessive%20label%20cardinality.%0A%20%20%23%20%22image_pulls_by_digest%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name_skipped%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_skipped_bytes_total%22%0A%20%20%23%20%22image_pulls_failures%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_failure_total%22%0A%20%20%23%20%22image_pulls_successes%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_success_total%22%0A%20%20%23%20%22image_layer_reuse%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_layer_reuse_total%22%0A%20%20%22operations_total%22%2C%0A%20%20%22operations_latency_seconds_total%22%2C%0A%20%20%22operations_latency_seconds%22%2C%0A%20%20%22operations_errors_total%22%2C%0A%20%20%22image_pulls_bytes_total%22%2C%0A%20%20%22image_pulls_skipped_bytes_total%22%2C%0A%20%20%22image_pulls_success_total%22%2C%0A%20%20%22image_pulls_failure_total%22%2C%0A%20%20%22image_layer_reuse_total%22%2C%0A%20%20%22containers_oom_count_total%22%2C%0A%20%20%22processes_defunct%22%0A%5D%0A
          mode: 420
          overwrite: true
          path: /etc/crio/crio.conf.d/00-default
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D
          mode: 420
          overwrite: true
          path: /etc/containers/policy.json
        - contents:
            source: data:,%5BGlobal%5D
          mode: 420
          overwrite: true
          path: /etc/kubernetes/cloud.conf
        - contents:
            source: data:,authorization%3A%0A%20%20static%3A%0A%20%20%20%20-%20resourceRequest%3A%20false%0A%20%20%20%20%20%20path%3A%20%2Fmetrics%0A%20%20%20%20%20%20verb%3A%20get%0A%20%20%20%20%20%20user%3A%0A%20%20%20%20%20%20%20%20name%3A%20system%3Aserviceaccount%3Aopenshift-monitoring%3Aprometheus-k8s
          mode: 420
          overwrite: true
          path: /etc/kubernetes/crio-metrics-proxy.cfg
        - contents:
            source: data:,apiVersion%3A%20v1%0Akind%3A%20Pod%0Ametadata%3A%0A%20%20name%3A%20kube-rbac-proxy-crio%0A%20%20namespace%3A%20openshift-machine-config-operator%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20etc-kube%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20hostNetwork%3A%20true%0A%20%20priorityClassName%3A%20system-cluster-critical%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20setup%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A4c0c2e423c4481a1e5ecd844aa6a62c3ee3f26edb40642056d802a14d2fd46f6%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20command%3A%20%5B'%2Fbin%2Fbash'%2C%20'-ec'%5D%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20echo%20-n%20%22Waiting%20for%20kubelet%20key%20and%20certificate%20to%20be%20available%22%0A%20%20%20%20%20%20while%20%5B%20-n%20%22%24(test%20-e%20%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem)%22%20%5D%20%3B%20do%0A%20%20%20%20%20%20%20%20echo%20-n%20%22.%22%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20%20%20%20%20((%20tries%20%2B%3D%201%20))%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20%22%24%7Btries%7D%22%20-gt%2010%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Timed%20out%20waiting%20for%20kubelet%20key%20and%20cert.%22%0A%20%20%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20done%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20%20%20%20%20cpu%3A%205m%0A%20%20containers%3A%0A%20%20-%20name%3A%20kube-rbac-proxy-crio%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A4c0c2e423c4481a1e5ecd844aa6a62c3ee3f26edb40642056d802a14d2fd46f6%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20ports%3A%0A%20%20%20%20-%20containerPort%3A%209637%0A%20%20%20%20args%3A%0A%20%20%20%20-%20--secure-listen-address%3D%3A9637%0A%20%20%20%20-%20--config-file%3D%2Fetc%2Fkubernetes%2Fcrio-metrics-proxy.cfg%0A%20%20%20%20-%20--client-ca-file%3D%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20%20%20-%20--logtostderr%3Dtrue%0A%20%20%20%20-%20--kubeconfig%3D%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%0A%20%20%20%20-%20--tls-cipher-suites%3DTLS_AES_128_GCM_SHA256%2CTLS_AES_256_GCM_SHA384%2CTLS_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%20%0A%20%20%20%20-%20--tls-min-version%3DVersionTLS12%0A%20%20%20%20-%20--upstream%3Dhttp%3A%2F%2F127.0.0.1%3A9537%0A%20%20%20%20-%20--tls-cert-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20-%20--tls-private-key-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%2020m%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20etc-kube%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/criometricsproxy.yaml
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,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
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
        - contents:
            source: data:,%23!%2Fbin%2Fsh%0Aif%20%5B%20-x%20%2Fusr%2Fbin%2Fkubensenter%20%5D%3B%20then%0A%20%20exec%20%2Fusr%2Fbin%2Fkubensenter%20%22%24%40%22%0Aelse%0A%20%20exec%20%22%24%40%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/kubenswrapper
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Cleans NetworkManager state generated by dracut
            # Removal of this file signals firstboot completion
            ConditionPathExists=!/etc/ignition-machine-config-encapsulated.json
            # This is opt-in for some deployment types, and opt-out for others.
            ConditionPathExists=/var/lib/mco/nm-clean-initrd-state
            Wants=network-pre.target
            Before=network-pre.target

            [Service]
            Type=oneshot
            # Remove any existing state possibly generated NM run by dracut. We want NM to
            # consider all profiles autoconnect priority when it starts instead of
            # remembering which profile was a device activated with when NM is run by
            # dracut.
            ExecStart=/usr/local/bin/nm-clean-initrd-state.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: NetworkManager-clean-initrd-state.service
        - contents: |
            [Unit]
            Description=Fetch kubelet node name from AWS Metadata

            # Run afterburn service for collect info from metadata server
            # see: https://coreos.github.io/afterburn/usage/attributes/
            # Not required due to OCP 4.1 boot image does not contain afterburn service
            # see: https://issues.redhat.com/browse/OCPBUGS-7559
            Wants=afterburn.service
            After=afterburn.service

            # Wait for NetworkManager to report it's online
            After=NetworkManager-wait-online.service
            # Run before kubelet
            Before=kubelet-dependencies.target

            [Service]
            # Mark afterburn environment file optional, due to it is possible that afterburn service was not executed
            EnvironmentFile=-/run/metadata/afterburn
            ExecStart=/usr/local/bin/aws-kubelet-nodename
            Type=oneshot

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: aws-kubelet-nodename.service
        - contents: |
            [Unit]
            Description=Fetch kubelet provider id from AWS Metadata

            # Run afterburn service for collect info from metadata server
            # see: https://coreos.github.io/afterburn/usage/attributes/
            # Not required due to OCP 4.1 boot image does not contain afterburn service
            # see: https://issues.redhat.com/browse/OCPBUGS-7559
            Wants=afterburn.service
            After=afterburn.service

            # Wait for NetworkManager to report it's online
            After=NetworkManager-wait-online.service
            # Run before kubelet
            Before=kubelet-dependencies.target

            [Service]
            # Mark afterburn environment file optional, due to it is possible that afterburn service was not executed
            EnvironmentFile=-/run/metadata/afterburn
            ExecStart=/usr/local/bin/aws-kubelet-providerid
            Type=oneshot

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: aws-kubelet-providerid.service
        - dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="ENABLE_PROFILE_UNIX_SOCKET=true"
            name: 10-mco-profile-unix-socket.conf
          - contents: |
              [Unit]
              After=kubelet-dependencies.target
              Requires=kubelet-dependencies.target
            name: 05-mco-ordering.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: crio.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: docker.socket
        - contents: |
            [Unit]
            Description=The firstboot OS update has completed
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target

            [Install]
            WantedBy=default.target
          enabled: true
          name: firstboot-osupdate.target
        - contents: |
            [Unit]
            Description=Dynamically sets the system reserved for the kubelet
            Wants=network-online.target
            After=network-online.target firstboot-osupdate.target
            Before=kubelet-dependencies.target

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            RemainAfterExit=yes
            EnvironmentFile=/etc/node-sizing-enabled.env
            ExecStart=/bin/bash /usr/local/sbin/dynamic-system-reserved-calc.sh ${NODE_SIZING_ENABLED} ${SYSTEM_RESERVED_MEMORY} ${SYSTEM_RESERVED_CPU} ${SYSTEM_RESERVED_ES}
            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: kubelet-auto-node-size.service
        - contents: |
            [Unit]
            Description=Dependencies necessary to run kubelet
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target network-online.target
            Wants=NetworkManager-wait-online.service crio-wipe.service
            Wants=rpc-statd.service chrony-wait.service
          name: kubelet-dependencies.target
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet
            Requires=crio.service kubelet-dependencies.target
            After=kubelet-dependencies.target
            After=ostree-finalize-staged.service

            [Service]
            Type=notify
            ExecStartPre=/bin/mkdir --parents /etc/kubernetes/manifests
            ExecStartPre=-/usr/sbin/restorecon -rv /var/lib/kubelet/ /usr/local/bin/kubenswrapper /usr/bin/kubensenter
            Environment="KUBELET_NODE_IP=0.0.0.0"
            EnvironmentFile=/etc/os-release
            EnvironmentFile=-/etc/kubernetes/kubelet-workaround
            EnvironmentFile=-/etc/kubernetes/kubelet-env
            EnvironmentFile=/etc/node-sizing.env

            ExecStart=/usr/local/bin/kubenswrapper \
                /usr/bin/kubelet \
                  --config=/etc/kubernetes/kubelet.conf \
                  --bootstrap-kubeconfig=/etc/kubernetes/kubeconfig \
                  --kubeconfig=/var/lib/kubelet/kubeconfig \
                  --container-runtime-endpoint=/var/run/crio/crio.sock \
                  --runtime-cgroups=/system.slice/crio.service \
                  --node-labels=node-role.kubernetes.io/control-plane,node-role.kubernetes.io/master,node.openshift.io/os_id=${ID} \
                  --node-ip=${KUBELET_NODE_IP} \
                  --minimum-container-ttl-duration=6m0s \
                  --cloud-provider=external \
                  --volume-plugin-dir=/etc/kubernetes/kubelet-plugins/volume/exec \
                  --image-credential-provider-bin-dir=/usr/libexec/kubelet-image-credential-provider-plugins --image-credential-provider-config=/etc/kubernetes/credential-providers/ecr-credential-provider.yaml \
                  --hostname-override=${KUBELET_NODE_NAME} \
                  --provider-id=${KUBELET_PROVIDERID} \
                  --register-with-taints=node-role.kubernetes.io/master=:NoSchedule \
                  --pod-infra-container-image=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4f60bb3e2e42085b82096277c09906c2fc64083a9d8d5aba56c177aa547c4b7f \
                  --system-reserved=cpu=${SYSTEM_RESERVED_CPU},memory=${SYSTEM_RESERVED_MEMORY},ephemeral-storage=${SYSTEM_RESERVED_ES} \
                  --v=${KUBELET_LOG_LEVEL}

            Restart=always
            RestartSec=10

            [Install]
            WantedBy=multi-user.target
          dropins:
          - contents: |
              [Service]
              EnvironmentFile=/etc/kubernetes/node.env
            name: 20-node-env.conf
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          enabled: true
          name: kubelet.service
        - contents: |
            [Unit]
            Description=Manages a mount namespace for kubernetes-specific mounts

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            RuntimeDirectory=kubens
            Environment=RUNTIME_DIRECTORY=%t/kubens
            Environment=BIND_POINT=%t/kubens/mnt
            Environment=ENVFILE=%t/kubens/env

            # Set up the runtime directory as an unbindable mountpoint
            ExecStartPre=bash -c "findmnt ${RUNTIME_DIRECTORY} || mount --make-unbindable --bind ${RUNTIME_DIRECTORY} ${RUNTIME_DIRECTORY}"
            # Ensure the bind point exists
            ExecStartPre=touch ${BIND_POINT}
            # Use 'unshare' to create the new mountpoint, then 'mount --make-rshared' so it cascades internally
            ExecStart=unshare --mount=${BIND_POINT} --propagation slave mount --make-rshared /
            # Finally, set an env pointer for ease-of-use
            ExecStartPost=bash -c 'echo "KUBENSMNT=${BIND_POINT}" > "${ENVFILE}"'

            # On stop, a recursive unmount cleans up the namespace and bind-mounted unbindable parent directory
            ExecStop=umount -R ${RUNTIME_DIRECTORY}

            [Install]
            WantedBy=multi-user.target
          enabled: false
          name: kubens.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Firstboot
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # Removal of this file signals firstboot completion
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            After=machine-config-daemon-pull.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            # Disable existing repos (if any) so that OS extensions would use embedded RPMs only
            ExecStartPre=-/usr/bin/sh -c "sed -i 's/enabled=1/enabled=0/' /etc/yum.repos.d/*.repo"
            # Run this via podman because we want to use the nmstatectl binary in our container
            ExecStart=/usr/bin/podman run --rm --privileged --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2ca9b7808dd922f00fc37100229c08f005357386e4b24628faeef49222b2ea' firstboot-complete-machineconfig --persist-nics
            ExecStart=/usr/bin/podman run --rm --privileged --pid=host --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2ca9b7808dd922f00fc37100229c08f005357386e4b24628faeef49222b2ea' firstboot-complete-machineconfig
            [Install]
            RequiredBy=firstboot-osupdate.target
          enabled: true
          name: machine-config-daemon-firstboot.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Pull
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # This "stamp file" is unlinked when we complete
            # machine-config-daemon-firstboot.service
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            # Run after crio-wipe so the pulled MCD image is protected against a corrupted storage from a forced shutdown
            Wants=crio-wipe.service NetworkManager-wait-online.service
            After=crio-wipe.service NetworkManager-wait-online.service network.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStart=/bin/sh -c "while ! /usr/bin/podman pull --authfile=/var/lib/kubelet/config.json 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2ca9b7808dd922f00fc37100229c08f005357386e4b24628faeef49222b2ea'; do sleep 1; done"
            [Install]
            RequiredBy=machine-config-daemon-firstboot.service
          enabled: true
          name: machine-config-daemon-pull.service
        - contents: |
            [Unit]
            Description=Wait for a non-localhost hostname
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            User=root
            ExecStart=/usr/local/bin/mco-hostname --wait

            # Wait up to 5min for the node to get a non-localhost name
            TimeoutSec=300

            [Install]
            # TODO: Change this to RequiredBy after we fix https://github.com/openshift/machine-config-operator/pull/3865#issuecomment-1746963115
            WantedBy=kubelet-dependencies.target
          enabled: true
          name: node-valid-hostname.service
        - contents: |
            [Unit]
            Description=Writes IP address configuration so that kubelet and crio services select a valid node IP
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service firstboot-osupdate.target
            Before=kubelet-dependencies.target ovs-configuration.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/bin/podman run --rm \
              --authfile /var/lib/kubelet/config.json \
              --net=host \
              --security-opt label=disable \
              --volume /etc/systemd/system:/etc/systemd/system \
              --volume /run/nodeip-configuration:/run/nodeip-configuration \
              quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cbf609319cf2f1132992bf214e94d15e30d28c22c39407835ea3235836bd5b77 \
              node-ip \
              set \
              --retry-on-failure \
              --network-type OVNKubernetes \
              ${NODEIP_HINT:-${KUBELET_NODEIP_HINT:-}}; \
              do \
              sleep 5; \
              done"
            ExecStart=/bin/systemctl daemon-reload
            ExecStartPre=/bin/mkdir -p /run/nodeip-configuration
            StandardOutput=journal+console
            StandardError=journal+console

            EnvironmentFile=-/etc/default/nodeip-configuration

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: false
          name: nodeip-configuration.service
        - enabled: true
          name: openvswitch.service
        - contents: |
            [Unit]
            # Kdump will generate it's initramfs based on the running state when kdump.service run
            # If OVS has already run, the kdump fails to gather a working network config,
            # which prevent network log exports, sush as SSH.
            # See https://issues.redhat.com/browse/OCPBUGS-28239
            After=kdump.service
            Description=Configures OVS with proper host networking configuration
            # This service is used to move a physical NIC into OVS and reconfigure OVS to use the host IP
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=firstboot-osupdate.target
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service nmstate.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            ExecStart=/usr/local/bin/configure-ovs.sh OVNKubernetes
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: ovs-configuration.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /var/lib/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /etc/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /run/openvswitch'
              ExecStartPost=-/usr/bin/ovs-appctl vlog/set syslog:info
              ExecReload=-/usr/bin/ovs-appctl vlog/set syslog:info
            name: 10-ovs-vswitchd-restart.conf
          name: ovs-vswitchd.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
            name: 10-ovsdb-restart.conf
          enabled: true
          name: ovsdb-server.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          name: pivot.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              # See https://github.com/openshift/machine-config-operator/issues/1897
              [Service]
              Nice=10
              IOSchedulingClass=best-effort
              IOSchedulingPriority=6
            name: mco-controlplane-nice.conf
          name: rpm-ostreed.service
        - contents: |
            [Unit]
            Description=Ensure primary IP is assigned and usable
            Requires=nmstate.service
            After=nmstate.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/wait-for-primary-ip.sh; \
              do \
              sleep 10; \
              done"
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: wait-for-primary-ip.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: zincati.service
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet After Reboot Cleanup
            Before=kubelet.service

            [Service]
            Type=oneshot
            ExecStart=/bin/rm -f /var/lib/kubelet/cpu_manager_state
            ExecStart=/bin/rm -f /var/lib/kubelet/memory_manager_state
            ExecStart=-/bin/rm -f /var/lib/kubelet/dra_manager_state

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet-cleanup.service
    extensions: []
    fips: false
    kernelArguments:
    - systemd.unified_cgroup_hierarchy=1
    - cgroup_no_v1="all"
    - psi=0
    kernelType: default
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:44b6a5f0d598f4b4cc4a5556c56f2cb01f9a0330f958df5848479ca47e9b43eb
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: d656f31b697c2671aac38bbe46d9e5b22d27ae90
      machineconfiguration.openshift.io/release-image-version: 4.18.0-ec.3
    creationTimestamp: "2024-11-20T22:36:32Z"
    generation: 1
    name: rendered-worker-869799cd72c887a5da8248efd58bb2a9
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: MachineConfigPool
      name: worker
      uid: b6b86d5e-02f1-4b15-a3da-1c04f9fcb4b3
    resourceVersion: "10206"
    uid: 2d8c1ab1-0a92-4e85-8cde-17b6da80c6b9
  spec:
    baseOSExtensionsContainerImage: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:c3a4fec8e58e41a24e4bc15de9c1261b917448246d62b37dc83e4871837e3fbb
    config:
      ignition:
        version: 3.4.0
      passwd:
        users:
        - name: core
          sshAuthorizedKeys:
          - |
            ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDLume21au7DO1U53hRBlP0FdJPJ85QEsm/ahjj3t9ZHUZkIZIZspYkAu6uahm6JReNnAbo2lDvVaVjq134BooT++WRIhk2X4hv7eUFYpBPaztjrTTG+COqLNJHZKNKa+KzRDEDk/TDsBSOgx35qZdC4l2VnJOkFXxGKMC/N4cW+NBJCdEOOz56LodPHmmIM1I0U97tuHkplw4+vMrAh8DgjoaxpijBlGOnVo3fD95EoG4D+d3RkOSsB3AsrkdyZa+A703NvSuIcofbOvXz5tBeKVlgpSyXUKywtKPr7J8UnWy3/ajGTDuY+kY/447Y+n1T5aU/iD8Xk2LTBhIZ7Z7SilYYWgV6Yr+z7DpLUqCBWlggI/Owp8XOaAPRETl3UPxFc4hKkE3cL8eu+Nw25ooUwY4Jikoq+r3WY2FCcVnQL2Rswf7z+pi8q49YaQV0mFGoow036+5f1JA/GvglDZEnKWMH8rwQw0Sw24FG+iC+1Fy6qrKoMFkz2nk4j8lZ368= nmoraiti@localhost.localdomain
      storage:
        files:
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0ANM_DEVICES_DIR%3D%2Frun%2FNetworkManager%2Fdevices%0ANM_RUN_CONN_DIR%3D%2Frun%2FNetworkManager%2Fsystem-connections%0ANM_ETC_CONN_DIR%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A%0Alogger%20-t%20nm-clean-initrd-state%20%22Cleaning%20network%20activation%20state%20generated%20by%20dracut...%22%0Alogger%20-t%20nm-clean-initrd-state%20%22To%20disable%2C%20remove%20%2Fvar%2Flib%2Fmco%2Fnm-clean-initrd-state%22%0A%0Aif%20%5B%20!%20-e%20%22%24NM_DEVICES_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_RUN_CONN_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_ETC_CONN_DIR%22%20%5D%3B%20then%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22There%20is%20no%20network%20activation%20state%20to%20clean%22%0A%20%20exit%0Afi%0A%0A%23%20Some%20deployments%20require%20an%20active%20network%20early%20in%20the%20boot%20process.%20To%0A%23%20achieve%20this%2C%20dracut%20runs%20specific%20NetworkManager%20modules.%20This%20results%20in%0A%23%20NetworkManager%20keyfiles%20being%20generated%20(either%20default%20or%20from%20ip%20kernel%0A%23%20arguments)%20and%20activated.%20This%20activation%20generates%20state%20that%20makes%20those%0A%23%20profiles%20to%20be%20re-activated%20by%20the%20NetworkManager%20service%20later%20in%20the%0A%23%20boot%20process.%20And%20this%20has%20the%20effect%20that%20other%20profiles%20deployed%20by%20the%0A%23%20user%20for%20the%20same%20set%20of%20devices%20are%20ignored.%0A%0A%23%20Most%20of%20the%20time%20this%20is%20the%20desired%20behavior.%20The%20exception%20to%20this%20rule%0A%23%20is%20when%20the%20user%20wants%20to%20run%20the%20boot%20process%20with%20a%20different%20network%0A%23%20setup%20than%20the%20real%20root%20which%20is%20usually%20related%20to%20the%20fact%20that%0A%23%20generating%20images%20with%20customized%20kernel%20arguments%20is%20a%20complication%20in%0A%23%20the%20deployment%20pipeline.%0A%0A%23%20This%20need%20has%20been%20exacerbated%20by%20past%20NetworkManager%20bugs%20that%20activated%0A%23%20the%20network%20on%20boot%20when%20it%20was%20not%20really%20needed.%20Most%20notably%20when%20ip%0A%23%20kernel%20argument%20is%20present%2C%20something%20that%20the%20baremetal%20installer%20adds%20by%0A%23%20default.%0A%0A%23%20The%20intention%20here%20is%20to%20remove%20the%20state%20that%20was%20generated%20with%20the%0A%23%20activation%20of%20those%20profiles%20during%20dracut%20execution.%20Then%20when%0A%23%20NetworkManager%20service%20runs%2C%20the%20profiles%20generated%20by%20dracut%2C%20along%20with%0A%23%20other%20profiles%20configured%20by%20the%20user%2C%20are%20evaluated%20towards%20finding%20the%0A%23%20most%20appropriate%20profile%20to%20connect%20a%20device%20with.%20As%20a%20precaution%2C%20clean%0A%23%20state%20only%20for%20devices%20that%3A%0A%23%20-%20have%20been%20activated%20with%20a%20default%20profile%20(assume%20that%20a%20non-default%0A%23%20%20%20configuration%20expresses%20intention%20by%20user%20to%20run%20with%20it%20permanently)%0A%23%20-%20have%20a%20specific%20configured%20profile%20set%20to%20auto-connect%20(if%20there%20is%20no%0A%23%20%20%20alternate%20configured%20profile%20for%20a%20device%20it%20makes%20no%20sense%20to%0A%23%20%20%20de-activate%20anything)%0A%23%0A%23%20Although%20this%20can%20theoretically%20happen%20on%20any%20deployment%20type%2C%20need%20has%0A%23%20mostly%20come%20from%20IPI%20bare%20metal%20deployments.%20For%20the%20time%20being%2C%20this%0A%23%20should%20be%20opt-in%20in%20any%20other%20deploment%20type.%0A%23%0A%23%20There%20is%20an%20RFE%20filed%20against%20NM%20that%20once%20implemented%20would%20make%20this%0A%23%20script%20unnecessary%3A%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D2089707%0A%0Afor%20device%20in%20%22%24%7BNM_DEVICES_DIR%7D%22%2F*%3B%20do%0A%20%20if%20%5B%20!%20-e%20%22%24device%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20the%20device%20file%20name%20is%20the%20ifindex%0A%20%20ifindex%3D%24(basename%20%22%24device%22)%0A%20%20%0A%20%20%23%20get%20the%20interface%20name%20by%20ifindex%0A%20%20ifname%3D%24(ip%20-j%20link%20show%20%7C%20jq%20-r%20%22.%5B%5D%20%7C%20select(.ifindex%20%3D%3D%20%24%7Bifindex%7D)%20%7C%20.ifname%20%2F%2F%20empty%22)%0A%0A%20%20%23%20no%20interface%20name%20found%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20get%20the%20uuid%20of%20the%20profile%20the%20device%20has%20been%20activated%20with%0A%20%20active_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bdevice%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Econnection-uuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24device%22)%0A%0A%20%20%23%20the%20device%20was%20not%20activated%20with%20any%20profile%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24active_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20generated%20profile%20by%20uuid%0A%20%20for%20profile%20in%20%22%24%7BNM_RUN_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20generated_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24active_profile_uuid%22%20%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20generated%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24active_profile_uuid%22%20!%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20check%20that%20it%20is%20not%20specific%20for%20the%20device%2C%20otherwise%20ignore%0A%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24profile_ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20profile%20not%20generated%20by%20nm-initrd-generator%2C%20ignore%0A%20%20%23%20only%20check%20it%20if%20the%20key%20is%20set%20(from%20NM%201.32.4)%0A%20%20origin%3D%24(sed%20-nr%20'%2F%5E%5C%5Buser%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eorg.freedesktop.NetworkManager.origin%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24origin%22%20%5D%20%26%26%20%5B%20%22%24origin%22%20!%3D%20%22nm-initrd-generator%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20configured%20profile%20by%20name%20with%20auto-connect%20set%0A%20%20for%20profile%20in%20%22%24%7BNM_ETC_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20autoconnect%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eautoconnect%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24profile_ifname%22%20%3D%20%22%24ifname%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20configured%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24profile_ifname%22%20!%3D%20%22%24ifname%22%20%5D%20%7C%7C%20%5B%20%22%24autoconnect%22%20%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20configured_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20activated%20with%20default%20generated%20profile%20%24generated_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20has%20different%20configured%20specific%20profile%20%24configured_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%3A%20removing%20state...%22%0A%20%20%0A%20%20%23%20NM%20can%20still%20generate%20internal%20profiles%20from%20the%20IP%20address%0A%20%20%23%20configuration%20of%20devices%2C%20so%20flush%20addresses%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Flushing%20IP%20addresses%20from%20%24ifname%22%0A%20%20ip%20addr%20flush%20%22%24ifname%22%0A%20%20ip%20-6%20addr%20flush%20%22%24ifname%22%0A%0A%20%20%23%20remove%20device%20state%20file%20to%20prevent%20NM%20to%20unilaterally%20connect%20with%20the%0A%20%20%23%20latest%20activated%20profile%20without%20evaluating%20other%20profiles%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Removing%20%24device%22%0A%20%20rm%20-f%20--%20%22%24device%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nm-clean-initrd-state.sh
        - contents:
            source: data:,%5Bconnection%5D%0Aipv6.dhcp-duid%3Dll%0Aipv6.dhcp-iaid%3Dmac%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/01-ipv6.conf
        - contents:
            source: data:,%5Bmain%5D%0Aplugins%3Dkeyfile%2Cifcfg-rh%0A%5Bkeyfile%5D%0Apath%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/20-keyfiles.conf
        - contents:
            source: data:,
          mode: 384
          overwrite: true
          path: /etc/pki/ca-trust/source/anchors/openshift-config-user-ca-bundle.crt
        - contents:
            source: data:,KUBERNETES_SERVICE_HOST%3D'api-int.ci-ln-hz4dqct-76ef8.aws-2.ci.openshift.org'%0AKUBERNETES_SERVICE_PORT%3D'6443'%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/apiserver-url.env
        - contents:
            source: data:,%23%20This%20file%20is%20managed%20by%20machine-config-operator.%0A%23%20Suppress%20audit%20rules%20which%20always%20trigger%20for%20container%0A%23%20workloads%2C%20as%20they%20spam%20the%20audit%20log.%20%20Workloads%20are%20expected%0A%23%20to%20be%20dynamic%2C%20and%20the%20networking%20stack%20uses%20iptables.%0A-a%20exclude%2Calways%20-F%20msgtype%3DNETFILTER_CFG%0A%23%20The%20default%20bridged%20networking%20enables%20promiscuous%20on%20the%20veth%0A%23%20device.%20%20Ideally%2C%20we'd%20teach%20audit%20to%20ignore%20only%20veth%20devices%2C%0A%23%20since%20one%20might%20legitimately%20care%20about%20promiscuous%20on%20real%20physical%0A%23%20devices.%20%20But%20we%20can't%20currently%20differentiate.%0A-a%20exclude%2Calways%20-F%20msgtype%3DANOM_PROMISCUOUS%0A
          mode: 420
          overwrite: true
          path: /etc/audit/rules.d/mco-audit-quiet-containers.rules
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20It%20has%20been%20observed%20that%20the%20kernel%20enables%20ESP%20offloads%20of%20bond%0A%23%20devices%20in%20active%2Fbackup%20mode%20even%20if%20slaves%20apparently%20don't%20support%0A%23%20it.%20It's%20unclear%20if%20this%20is%20expected%20behavior%20but%20we%20have%20had%20problems%0A%23%20with%20the%20resulting%20configuration%20in%20vsphere.%20So%20set%20ESP%20offload%20features%0A%23%20off%20in%20bond%20devices%20if%20they%20are%20off%20in%20slave%20devices%20for%20the%20time%20being.%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FRHEL-58811%0A%0Aif%20%5B%5B%20%22%242%22%20!%3D%20%22up%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24DEVICE_IFACE%22)%0A%0Aif%20%5B%5B%20%22%24driver%22%20!%3D%20%22bond%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Abond%3D%22%24DEVICE_IFACE%22%0Afor%20feature%20in%20tx-esp-segmentation%20esp-hw-offload%20esp-tx-csum-hw-offload%3B%20do%0A%0A%20%20if%20ethtool%20-k%20%22%24bond%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%23%20already%20disabled%2C%20nothing%20to%20do%0A%20%20%20%20continue%0A%20%20fi%0A%20%20%0A%20%20for%20slave%20in%20%24(nmcli%20-g%20BOND.SLAVES%20dev%20show%20%22%24DEVICE_IFACE%22)%3B%20do%0A%0A%20%20%20%20if%20!%20ethtool%20-k%20%22%24slave%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%20%20%23%20enabled%20in%20slave%2C%20nothing%20to%20do%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20logger%20-t%20bond-esp-offload%20-s%20%22Bond%20link%20%24slave%20has%20%24feature%20off%2C%20setting%20master%20%24DEVICE_IFACE%20%24feature%20off%22%0A%20%20%20%20ethtool%20-K%20%22%24bond%22%20%22%24feature%22%20off%0A%0A%20%20%20%20break%0A%20%20done%0Adone%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-bond-esp-offload
        - contents:
            source: data:,r%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F80-openshift-network.conf%0Ar%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F10-ovn-kubernetes.conf%0Ad%20%2Frun%2Fmultus%2Fcni%2Fnet.d%2F%200755%20root%20root%20-%20-%0AD%20%2Fvar%2Flib%2Fcni%2Fnetworks%2Fopenshift-sdn%2F%200755%20root%20root%20-%20-%0A
          mode: 420
          overwrite: true
          path: /etc/tmpfiles.d/cleanup-cni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Skipping%20configure-ovs%20due%20to%20manual%20network%20configuration%22%0A%20%20exit%200%0Afi%0A%0A%23%20This%20file%20is%20not%20needed%20anymore%20in%204.7%2B%2C%20but%20when%20rolling%20back%20to%204.6%0A%23%20the%20ovs%20pod%20needs%20it%20to%20know%20ovs%20is%20running%20on%20the%20host.%0Atouch%20%2Fvar%2Frun%2Fovs-config-executed%0A%0A%23%20These%20are%20well%20knwon%20NM%20default%20paths%0ANM_CONN_ETC_PATH%3D%22%2Fetc%2FNetworkManager%2Fsystem-connections%22%0ANM_CONN_RUN_PATH%3D%22%2Frun%2FNetworkManager%2Fsystem-connections%22%0A%0A%23%20This%20is%20the%20path%20where%20NM%20is%20known%20to%20be%20configured%20to%20store%20user%20keyfiles%20%0ANM_CONN_CONF_PATH%3D%22%24NM_CONN_ETC_PATH%22%0A%0A%23%20This%20is%20where%20we%20want%20our%20keyfiles%20to%20finally%20reside.%20configure-ovs%0A%23%20operates%20with%20temporary%20keyfiles%20in%20NM_CONN_RUN_PATH%20and%20then%20as%20a%20last%0A%23%20step%20moves%20those%20keyfiles%20to%20NM_CONN_SET_PATH%20if%20it%20is%20a%20different%20path%0A%23%20(not%20by%20default).%20This%20mitigates%20hard%20interruptions%20(SIGKILL%2C%20hard%20reboot)%0A%23%20of%20configure-ovs%20leaving%20the%20machine%20with%20a%20half-baked%20set%20of%20keyfiles%0A%23%20that%20might%20prevent%20machine%20networking%20from%20working%20correctly.%0ANM_CONN_SET_PATH%3D%22%24%7BNM_CONN_SET_PATH%3A-%24NM_CONN_RUN_PATH%7D%22%0A%0AMANAGED_NM_CONN_SUFFIX%3D%22-slave-ovs-clone%22%0A%23%20Workaround%20to%20ensure%20OVS%20is%20installed%20due%20to%20bug%20in%20systemd%20Requires%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1888017%0Acopy_nm_conn_files()%20%7B%0A%20%20local%20dst_path%3D%22%241%22%0A%20%20for%20src%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20src_path%3D%24(dirname%20%22%24src%22)%0A%20%20%20%20file%3D%24(basename%20%22%24src%22)%0A%20%20%20%20if%20%5B%20-f%20%22%24src_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%24dst_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20elif%20!%20cmp%20--silent%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20updated%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20-f%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it's%20equal%20at%20destination%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it%20does%20not%20exist%20at%20source%22%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0Aupdate_nm_conn_files_base()%20%7B%0A%20%20base_path%3D%24%7B1%7D%0A%20%20bridge_name%3D%24%7B2%7D%0A%20%20port_name%3D%24%7B3%7D%0A%20%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%20%20%23%20In%20RHEL7%20files%20in%20%2F%7Betc%2Crun%7D%2FNetworkManager%2Fsystem-connections%20end%20without%20the%20suffix%20'.nmconnection'%2C%20whereas%20in%20RHCOS%20they%20end%20with%20the%20suffix.%0A%20%20MANAGED_NM_CONN_FILES%3D(%24(echo%20%22%24%7Bbase_path%7D%22%2F%7B%22%24bridge_name%22%2C%22%24ovs_interface%22%2C%22%24ovs_port%22%2C%22%24bridge_interface_name%22%2C%22%24default_port_name%22%7D%7B%2C.nmconnection%7D))%0A%20%20shopt%20-s%20nullglob%0A%20%20MANAGED_NM_CONN_FILES%2B%3D(%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D.nmconnection%20%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D)%0A%20%20shopt%20-u%20nullglob%0A%7D%0A%0Aupdate_nm_conn_run_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_RUN_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_set_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_SET_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0A%23%20Move%20and%20reload%20keyfiles%20at%20their%20final%20destination%0Aset_nm_conn_files()%20%7B%0A%20%20if%20%5B%20%22%24NM_CONN_RUN_PATH%22%20!%3D%20%22%24NM_CONN_SET_PATH%22%20%5D%3B%20then%0A%20%20%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%20%20%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%0A%20%20%20%20%23%20reload%20keyfiles%0A%20%20%20%20nmcli%20connection%20reload%0A%20%20fi%0A%7D%0A%0A%23%20Used%20to%20remove%20files%20managed%20by%20configure-ovs%20and%20temporary%20leftover%20files%20from%20network%20manager%0Arm_nm_conn_files()%20%7B%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20rm%20-f%20%22%24file%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20file%20%24file%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20fi%0A%20%20done%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20for%20temp%20in%20%24(compgen%20-G%20%22%24%7Bfile%7D.*%22)%3B%20do%0A%20%20%20%20%20%20rm%20-f%20%22%24temp%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20temporary%20file%20%24temp%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20done%0A%20%20done%0A%7D%0A%0A%23%20Used%20to%20clone%20a%20slave%20connection%20by%20uuid%2C%20returns%20new%20name%0Aclone_slave_connection()%20%7B%0A%20%20local%20uuid%3D%22%241%22%0A%20%20local%20old_name%0A%20%20old_name%3D%22%24(nmcli%20-g%20connection.id%20connection%20show%20uuid%20%22%24uuid%22)%22%0A%20%20local%20new_name%3D%22%24%7Bold_name%7D%24%7BMANAGED_NM_CONN_SUFFIX%7D%22%0A%20%20if%20nmcli%20connection%20show%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20existing%20ovs%20slave%20%24%7Bnew_name%7D%20connection%20profile%20file%20found%2C%20overwriting...%22%20%3E%262%0A%20%20%20%20nmcli%20connection%20delete%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%0A%20%20fi%0A%20%20clone_nm_conn%20%24uuid%20%22%24%7Bnew_name%7D%22%0A%20%20echo%20%22%24%7Bnew_name%7D%22%0A%7D%0A%0A%23%20Used%20to%20replace%20an%20old%20master%20connection%20uuid%20with%20a%20new%20one%20on%20all%20connections%0Areplace_connection_master()%20%7B%0A%20%20local%20old%3D%22%241%22%0A%20%20local%20new%3D%22%242%22%0A%20%20for%20conn_uuid%20in%20%24(nmcli%20-g%20UUID%20connection%20show)%20%3B%20do%0A%20%20%20%20if%20%5B%20%22%24(nmcli%20-g%20connection.master%20connection%20show%20uuid%20%22%24conn_uuid%22)%22%20!%3D%20%22%24old%22%20%5D%3B%20then%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20local%20autoconnect%3D%24(nmcli%20-g%20connection.autoconnect%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20!%3D%20%22activated%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Assume%20that%20slave%20profiles%20intended%20to%20be%20used%20are%20those%20that%20are%3A%0A%20%20%20%20%20%20%23%20-%20active%0A%20%20%20%20%20%20%23%20-%20or%20inactive%20(which%20might%20be%20due%20to%20link%20being%20down)%20but%20to%20be%20autoconnected.%0A%20%20%20%20%20%20%23%20Otherwise%2C%20ignore%20them.%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20make%20changes%20for%20slave%20profiles%20in%20a%20new%20clone%0A%20%20%20%20local%20new_name%0A%20%20%20%20new_name%3D%24(clone_slave_connection%20%24conn_uuid)%0A%0A%20%20%20%20mod_nm_conn%20%22%24new_name%22%20connection.master%20%22%24new%22%20connection.autoconnect-priority%20100%20connection.autoconnect%20no%20%0A%20%20%20%20echo%20%22Replaced%20master%20%24old%20with%20%24new%20for%20slave%20profile%20%24new_name%22%0A%20%20done%0A%7D%0A%0A%23%20when%20creating%20the%20bridge%2C%20we%20use%20a%20value%20lower%20than%20NM's%20ethernet%20device%20default%20route%20metric%0A%23%20(we%20pick%2048%20and%2049%20to%20be%20lower%20than%20anything%20that%20NM%20chooses%20by%20default)%0ABRIDGE_METRIC%3D%2248%22%0ABRIDGE1_METRIC%3D%2249%22%0A%23%20Given%20an%20interface%2C%20generates%20NM%20configuration%20to%20add%20to%20an%20OVS%20bridge%0Aconvert_to_bridge()%20%7B%0A%20%20local%20iface%3D%24%7B1%7D%0A%20%20local%20bridge_name%3D%24%7B2%7D%0A%20%20local%20port_name%3D%24%7B3%7D%0A%20%20local%20bridge_metric%3D%24%7B4%7D%0A%20%20local%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20local%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20local%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20local%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%0A%20%20if%20%5B%20%22%24iface%22%20%3D%20%22%24bridge_name%22%20%5D%3B%20then%0A%20%20%20%20%23%20handle%20vlans%20and%20bonds%20etc%20if%20they%20have%20already%20been%0A%20%20%20%20%23%20configured%20via%20nm%20key%20files%20and%20br-ex%20is%20already%20up%0A%20%20%20%20ifaces%3D%24(ovs-vsctl%20list-ifaces%20%24%7Biface%7D)%0A%20%20%20%20for%20intf%20in%20%24ifaces%3B%20do%20configure_driver_options%20%24intf%3B%20done%0A%20%20%20%20echo%20%22Networking%20already%20configured%20and%20up%20for%20%24%7Bbridge-name%7D!%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20flag%20to%20reload%20NM%20to%20account%20for%20all%20the%20configuration%20changes%0A%20%20%23%20going%20forward%0A%20%20nm_config_changed%3D1%0A%0A%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20Unable%20to%20find%20default%20gateway%20interface%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20%23%20find%20the%20MAC%20from%20OVS%20config%20or%20the%20default%20interface%20to%20use%20for%20OVS%20internal%20port%0A%20%20%23%20this%20prevents%20us%20from%20getting%20a%20different%20DHCP%20lease%20and%20dropping%20connection%0A%20%20if%20!%20iface_mac%3D%24(%3C%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface%7D%2Faddress%22)%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MAC%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20echo%20%22MAC%20address%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mac%7D%22%0A%0A%20%20%23%20find%20MTU%20from%20original%20iface%0A%20%20iface_mtu%3D%24(ip%20link%20show%20%22%24iface%22%20%7C%20awk%20'%7Bprint%20%245%3B%20exit%7D')%0A%20%20if%20%5B%5B%20-z%20%22%24iface_mtu%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MTU%2C%20defaulting%20to%201500%22%0A%20%20%20%20iface_mtu%3D1500%0A%20%20else%0A%20%20%20%20echo%20%22MTU%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mtu%7D%22%0A%20%20fi%0A%0A%20%20%23%20store%20old%20conn%20for%20later%0A%20%20old_conn%3D%24(nmcli%20--fields%20UUID%2CDEVICE%20conn%20show%20--active%20%7C%20awk%20%22%2F%5Cs%24%7Biface%7D%5Cs*%5C%24%2F%20%7Bprint%20%5C%241%7D%22)%0A%0A%20%20if%20%5B%5B%20-z%20%22%24old_conn%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20cannot%20find%20connection%20for%20interface%3A%20%24%7Biface%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20create%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24bridge_name%22%20type%20ovs-bridge%20conn.interface%20%22%24bridge_name%22%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20%23%20find%20default%20port%20to%20add%20to%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24default_port_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%24%7Biface%7D%0A%20%20%20%20add_nm_conn%20%22%24default_port_name%22%20type%20ovs-port%20conn.interface%20%24%7Biface%7D%20master%20%22%24bridge_name%22%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_port%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24ovs_port%22%20type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24bridge_name%22%0A%20%20fi%0A%0A%20%20extra_phys_args%3D()%0A%20%20%23%20check%20if%20this%20interface%20is%20a%20vlan%2C%20bond%2C%20team%2C%20or%20ethernet%20type%0A%20%20if%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22vlan%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dvlan%0A%20%20%20%20vlan_id%3D%24(nmcli%20--get-values%20vlan.id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_id%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20vlan.parent%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_parent%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_parent%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20nmcli%20connection%20show%20uuid%20%22%24vlan_parent%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20%20%20%23%20if%20the%20VLAN%20connection%20is%20configured%20with%20a%20connection%20UUID%20as%20parent%2C%20we%20need%20to%20find%20the%20underlying%20device%0A%20%20%20%20%20%20%23%20and%20create%20the%20bridge%20against%20it%2C%20as%20the%20parent%20connection%20can%20be%20replaced%20by%20another%20bridge.%0A%20%20%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20GENERAL.DEVICES%20conn%20show%20uuid%20%24%7Bvlan_parent%7D)%0A%20%20%20%20fi%0A%0A%20%20%20%20extra_phys_args%3D(%20dev%20%22%24%7Bvlan_parent%7D%22%20id%20%22%24%7Bvlan_id%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbond%0A%20%20%20%20%23%20check%20bond%20options%0A%20%20%20%20bond_opts%3D%24(nmcli%20--get-values%20bond.options%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24bond_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20bond.options%20%22%24%7Bbond_opts%7D%22%20)%0A%20%20%20%20%20%20MODE_REGEX%3D%22(%5E%7C%2C)mode%3Dactive-backup(%2C%7C%24)%22%0A%20%20%20%20%20%20MAC_REGEX%3D%22(%5E%7C%2C)fail_over_mac%3D(1%7Cactive%7C2%7Cfollow)(%2C%7C%24)%22%0A%20%20%20%20%20%20if%20%5B%5B%20%24bond_opts%20%3D~%20%24MODE_REGEX%20%5D%5D%20%26%26%20%5B%5B%20%24bond_opts%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22team%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dteam%0A%20%20%20%20%23%20check%20team%20config%20options%0A%20%20%20%20team_config_opts%3D%24(nmcli%20--get-values%20team.config%20-e%20no%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24team_config_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20team.config%20is%20json%2C%20remove%20spaces%20to%20avoid%20problems%20later%20on%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20team.config%20%22%24%7Bteam_config_opts%2F%2F%5B%5B%3Aspace%3A%5D%5D%2F%7D%22%20)%0A%20%20%20%20%20%20team_mode%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.name%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20team_mac_policy%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.hwaddr_policy%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20MAC_REGEX%3D%22(by_active%7Conly_active)%22%0A%20%20%20%20%20%20if%20%5B%20%22%24team_mode%22%20%3D%20%22activebackup%22%20%5D%20%26%26%20%5B%5B%20%22%24team_mac_policy%22%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22tun%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dtun%0A%20%20%20%20tun_mode%3D%24(nmcli%20--get-values%20tun.mode%20-e%20no%20connection%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20extra_phys_args%2B%3D(%20tun.mode%20%22%24%7Btun_mode%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bridge%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbridge%0A%20%20else%0A%20%20%20%20iface_type%3D802-3-ethernet%0A%20%20fi%0A%0A%20%20if%20%5B%20!%20%22%24%7Bclone_mac%3A-%7D%22%20%3D%20%220%22%20%5D%3B%20then%0A%20%20%20%20%23%20In%20active-backup%20link%20aggregation%2C%20with%20fail_over_mac%20mode%20enabled%2C%0A%20%20%20%20%23%20cloning%20the%20mac%20address%20is%20not%20supported.%20It%20is%20possible%20then%20that%0A%20%20%20%20%23%20br-ex%20has%20a%20different%20mac%20address%20than%20the%20bond%20which%20might%20be%0A%20%20%20%20%23%20troublesome%20on%20some%20platforms%20where%20the%20nic%20won't%20accept%20packets%20with%0A%20%20%20%20%23%20a%20different%20destination%20mac.%20But%20nobody%20has%20complained%20so%20far%20so%20go%20on%0A%20%20%20%20%23%20with%20what%20we%20got.%20%0A%20%20%20%20%0A%20%20%20%20%23%20Do%20set%20it%20though%20for%20other%20link%20aggregation%20configurations%20where%20the%0A%20%20%20%20%23%20mac%20address%20would%20otherwise%20depend%20on%20enslave%20order%20for%20which%20we%20have%0A%20%20%20%20%23%20no%20control%20going%20forward.%0A%20%20%20%20extra_phys_args%2B%3D(%20802-3-ethernet.cloned-mac-address%20%22%24%7Biface_mac%7D%22%20)%0A%20%20fi%0A%0A%20%20%23%20use%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%20instead%20of%20%24%7Bextra_phys_args%5B%40%5D%7D%20to%20be%20compatible%20with%20bash%204.2%20in%20RHEL7.9%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_interface_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%24%7Biface%7D%0A%20%20%20%20ovs_default_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24default_port_name%22)%0A%20%20%20%20add_nm_conn%20%22%24bridge_interface_name%22%20type%20%24%7Biface_type%7D%20conn.interface%20%24%7Biface%7D%20master%20%22%24ovs_default_port_conn%22%20%5C%0A%20%20%20%20%20%20slave-type%20ovs-port%20connection.autoconnect-priority%20100%20connection.autoconnect-slaves%201%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20%20%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%0A%20%20fi%0A%0A%20%20%23%20Get%20the%20new%20connection%20uuids%0A%20%20new_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24bridge_interface_name%22)%0A%20%20ovs_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24ovs_port%22)%0A%0A%20%20%23%20Update%20connections%20with%20master%20property%20set%20to%20use%20the%20new%20connection%0A%20%20replace_connection_master%20%24old_conn%20%24new_conn%0A%20%20replace_connection_master%20%24iface%20%24new_conn%0A%0A%20%20ipv4_method%3D%24(nmcli%20-g%20ipv4.method%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_method%3D%24(nmcli%20-g%20ipv6.method%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20ipv4_addresses%3D%24(nmcli%20-g%20ipv4.addresses%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_addresses%3D%24(nmcli%20-g%20ipv6.addresses%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20%23%20Warn%20about%20an%20invalid%20MTU%20that%20will%20most%20likely%20fail%20in%20one%20way%20or%0A%20%20%23%20another%0A%20%20if%20%5B%20%24%7Biface_mtu%7D%20-lt%201280%20%5D%20%26%26%20%5B%20%22%24%7Bipv6_method%7D%22%20!%3D%20%22disabled%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20MTU%20%24%7Biface_mtu%7D%20is%20lower%20than%20the%20minimum%20required%20of%201280%20for%20IPv6%22%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_interface%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%22%24bridge_name%22%0A%20%20%20%20%23%20Clone%20the%20connection%20in%20case%20the%20method%20is%20manual%20or%20in%20case%20the%20an%20address%20is%20set%20(DHCP%20%2B%20static%20IP)%0A%20%20%20%20if%20%5B%20%22%24%7Bipv4_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv4_addresses%7D%22%20!%3D%20%22%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_addresses%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Static%20IP%20addressing%20detected%20on%20default%20gateway%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%23%20clone%20the%20old%20connection%20to%20get%20the%20address%20settings%0A%20%20%20%20%20%20%23%20prefer%20cloning%20vs%20copying%20the%20connection%20file%20to%20avoid%20problems%20with%20selinux%0A%20%20%20%20%20%20clone_nm_conn%20%22%24%7Bold_conn%7D%22%20%22%24%7Bovs_interface%7D%22%0A%20%20%20%20%20%20shopt%20-s%20nullglob%0A%20%20%20%20%20%20new_conn_files%3D(%24%7BNM_CONN_RUN_PATH%7D%2F%22%24%7Bovs_interface%7D%22*)%0A%20%20%20%20%20%20shopt%20-u%20nullglob%0A%20%20%20%20%20%20if%20%5B%20%24%7B%23new_conn_files%5B%40%5D%7D%20-ne%201%20%5D%20%7C%7C%20%5B%20!%20-f%20%22%24%7Bnew_conn_files%5B0%5D%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20could%20not%20find%20%24%7Bovs_interface%7D%20conn%20file%20after%20cloning%20from%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20new_conn_file%3D%22%24%7Bnew_conn_files%5B0%5D%7D%22%0A%0A%20%20%20%20%20%20%23%20modify%20the%20connection%20type%20directly%20because%20it%20can't%20be%20modified%0A%20%20%20%20%20%20%23%20through%20nmcli%0A%20%20%20%20%20%20sed%20-i%20'%2F%5E%5C%5Bconnection%5C%5D%24%2F%2C%2F%5E%5C%5B%2F%20s%2F%5Etype%3D.*%24%2Ftype%3Dovs-interface%2F'%20%24%7Bnew_conn_file%7D%0A%0A%20%20%20%20%20%20%23%20modify%20some%20more%20settings%20through%20nmcli%0A%20%20%20%20%20%20mod_nm_conn%20%22%24%7Bovs_interface%7D%22%20conn.interface%20%22%24bridge_name%22%20%5C%0A%20%20%20%20%20%20%20%20connection.multi-connect%20%22%22%20connection.autoconnect%20no%20%5C%0A%20%20%20%20%20%20%20%20connection.master%20%22%24ovs_port_conn%22%20connection.slave-type%20ovs-port%20%5C%0A%20%20%20%20%20%20%20%20ovs-interface.type%20internal%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%0A%0A%20%20%20%20%20%20echo%20%22Loaded%20new%20%24ovs_interface%20connection%20file%3A%20%24%7Bnew_conn_file%7D%22%0A%20%20%20%20else%0A%20%20%20%20%20%20extra_if_brex_args%3D%22%22%0A%20%20%20%20%20%20%23%20check%20if%20interface%20had%20ipv4%2Fipv6%20addresses%20assigned%0A%20%20%20%20%20%20num_ipv4_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ipv4_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20IPV6%20should%20have%20at%20least%20a%20link%20local%20address.%20Check%20for%20more%20than%201%20to%20see%20if%20there%20is%20an%0A%20%20%20%20%20%20%23%20assigned%20address.%0A%20%20%20%20%20%20num_ip6_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet6%5C%22%20and%20.scope%20!%3D%20%5C%22link%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ip6_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20check%20for%20dhcp%20client%20ids%0A%20%20%20%20%20%20dhcp_client_id%3D%24(nmcli%20--get-values%20ipv4.dhcp-client-id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.dhcp-client-id%20%24%7Bdhcp_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20dhcp6_client_id%3D%24(nmcli%20--get-values%20ipv6.dhcp-duid%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp6_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.dhcp-duid%20%24%7Bdhcp6_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20ipv6_addr_gen_mode%3D%24(nmcli%20--get-values%20ipv6.addr-gen-mode%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24ipv6_addr_gen_mode%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.addr-gen-mode%20%24%7Bipv6_addr_gen_mode%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20add_nm_conn%20%22%24ovs_interface%22%20type%20ovs-interface%20slave-type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24ovs_port_conn%22%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.method%20%22%24%7Bipv4_method%7D%22%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20ipv6.method%20%22%24%7Bipv6_method%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20%24%7Bextra_if_brex_args%7D%0A%20%20%20%20fi%0A%20%20fi%0A%0A%20%20configure_driver_options%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20remove%20a%20bridge%0Aremove_ovn_bridges()%20%7B%0A%20%20bridge_name%3D%24%7B1%7D%0A%20%20port_name%3D%24%7B2%7D%0A%0A%20%20%23%20Remove%20the%20keyfiles%20from%20known%20configuration%20paths%0A%20%20update_nm_conn_run_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20update_nm_conn_set_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%0A%20%20%23%20NetworkManager%20will%20not%20remove%20%24%7Bbridge_name%7D%20if%20it%20has%20the%20patch%20port%20created%20by%20ovn-kubernetes%0A%20%20%23%20so%20remove%20explicitly%0A%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%24%7Bbridge_name%7D%0A%7D%0A%0A%23%20Removes%20any%20previous%20ovs%20configuration%0Aremove_all_ovn_bridges()%20%7B%0A%20%20echo%20%22Reverting%20any%20previous%20OVS%20configuration%22%0A%20%20%0A%20%20remove_ovn_bridges%20br-ex%20phys0%0A%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%0A%20%20echo%20%22OVS%20configuration%20successfully%20reverted%22%0A%7D%0A%0A%23%20Reloads%20NM%20NetworkManager%20profiles%20if%20any%20configuration%20change%20was%20done.%0A%23%20Accepts%20a%20list%20of%20devices%20that%20should%20be%20re-connect%20after%20reload.%0Areload_profiles_nm()%20%7B%0A%20%20if%20%5B%20%24%7Bnm_config_changed%3A-0%7D%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%23%20no%20config%20was%20changed%2C%20no%20need%20to%20reload%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20reload%20profiles%0A%20%20nmcli%20connection%20reload%0A%0A%20%20%23%20precautionary%20sleep%20of%2010s%20(default%20timeout%20of%20NM%20to%20bring%20down%20devices)%0A%20%20sleep%2010%0A%0A%20%20%23%20After%20reload%2C%20devices%20that%20were%20already%20connected%20should%20connect%20again%0A%20%20%23%20if%20any%20profile%20is%20available.%20If%20no%20profile%20is%20available%2C%20a%20device%20can%0A%20%20%23%20remain%20disconnected%20and%20we%20have%20to%20explicitly%20connect%20it%20so%20that%20a%0A%20%20%23%20profile%20is%20generated.%20This%20can%20happen%20for%20physical%20devices%20but%20should%0A%20%20%23%20not%20happen%20for%20software%20devices%20as%20those%20always%20require%20a%20profile.%0A%20%20for%20dev%20in%20%24%40%3B%20do%0A%20%20%20%20%23%20Only%20attempt%20to%20connect%20a%20disconnected%20device%0A%20%20%20%20local%20connected_state%3D%24(nmcli%20-g%20GENERAL.STATE%20device%20show%20%22%24dev%22%20%7C%7C%20echo%20%22%22)%0A%20%20%20%20if%20%5B%5B%20%22%24connected_state%22%20%3D~%20%22disconnected%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%23%20keep%20track%20if%20a%20profile%20by%20the%20same%20name%20as%20the%20device%20existed%20%0A%20%20%20%20%20%20%23%20before%20we%20attempt%20activation%0A%20%20%20%20%20%20local%20named_profile_existed%3D%24(%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%5D%20%7C%7C%20%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22%20%5D%20%26%26%20echo%20%22yes%22)%0A%20%20%20%20%20%20%0A%20%20%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20connect%20device%20%24dev%22%0A%20%20%20%20%20%20%20%20%20%20nmcli%20device%20connect%20%22%24dev%22%20%26%26%20break%0A%20%20%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%23%20if%20a%20profile%20did%20not%20exist%20before%20but%20does%20now%2C%20it%20was%20generated%0A%20%20%20%20%20%20%23%20but%20we%20want%20it%20to%20be%20ephemeral%2C%20so%20move%20it%20back%20to%20%2Frun%0A%20%20%20%20%20%20if%20%5B%20!%20%22%24named_profile_existed%22%20%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20MANAGED_NM_CONN_FILES%3D(%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22)%0A%20%20%20%20%20%20%20%20copy_nm_conn_files%20%22%24%7BNM_CONN_RUN_PATH%7D%22%0A%20%20%20%20%20%20%20%20rm_nm_conn_files%0A%20%20%20%20%20%20%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20might%20have%20been%20moved%0A%20%20%20%20%20%20%20%20nmcli%20connection%20reload%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20echo%20%22Waiting%20for%20interface%20%24dev%20to%20activate...%22%0A%20%20%20%20if%20!%20timeout%2060%20bash%20-c%20%22while%20!%20nmcli%20-g%20DEVICE%2CSTATE%20c%20%7C%20grep%20%22'%22'%22%24dev%22%3Aactivated'%22'%22%3B%20do%20sleep%205%3B%20done%22%3B%20then%0A%20%20%20%20%20%20echo%20%22WARNING%3A%20%24dev%20did%20not%20activate%22%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20nm_config_changed%3D0%0A%7D%0A%0A%23%20Removes%20all%20configuration%20and%20reloads%20NM%20if%20necessary%0Arollback_nm()%20%7B%0A%20%20phys0%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20phys1%3D%24(get_bridge_physical_interface%20ovs-if-phys1)%0A%20%20%0A%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20remove_all_ovn_bridges%0A%20%20%0A%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20were%20removed%0A%20%20reload_profiles_nm%20%22%24phys0%22%20%22%24phys1%22%0A%7D%0A%0A%23%20Add%20a%20temporary%20deactivated%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20folowed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20add%60%0Aadd_nm_conn()%20%7B%0A%20%20%23%20Use%20%60save%20no%60%20to%20add%20a%20temporary%20profile%0A%20%20nmcli%20c%20add%20save%20no%20con-name%20%22%24%40%22%20connection.autoconnect%20no%0A%7D%0A%0A%23%20Modify%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20followed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20modify%60%0Amod_nm_conn()%20%7B%0A%20%20%23%20the%20easiest%20thing%20to%20do%20here%20would%20be%20to%20use%20%60nmcli%20c%20mod%20--temporary%60%0A%20%20%23%20but%20there%20is%20a%20bug%20in%20selinux%20profiles%20that%20denies%20NM%20from%20performing%0A%20%20%23%20the%20operation%0A%20%20local%20dst_path%3D%24%7BNM_CONN_RUN_PATH%7D%2F%241.nmconnection%0A%20%20local%20src_path%0A%20%20src_path%3D%24(mktemp)%0A%20%20shift%0A%20%20cat%20%22%24dst_path%22%20%3E%20%22%24src_path%22%0A%20%20rm%20-f%20%22%24dst_path%22%0A%20%20nmcli%20--offline%20c%20mod%20%22%24%40%22%20%3C%20%22%24src_path%22%20%3E%20%22%24dst_path%22%0A%20%20rm%20-f%20%22%24src_path%22%0A%20%20chmod%20600%20%22%24dst_path%22%0A%20%20nmcli%20c%20load%20%22%24dst_path%22%0A%7D%0A%0A%23%20Clone%20to%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20to%20clone%2C%20second%20argument%20is%20the%20clone%20name%0Aclone_nm_conn()%20%7B%0A%20%20%23%20clone%20as%20temporary%20so%20that%20it%20is%20generated%20in%20NM_CONN_RUN_PATH%0A%20%20nmcli%20connection%20clone%20--temporary%20%22%241%22%20%22%242%22%20%26%3E%20%2Fdev%2Fnull%0A%7D%0A%0A%23%20Activates%20an%20ordered%20set%20of%20NM%20connection%20profiles%0Aactivate_nm_connections()%20%7B%0A%20%20local%20connections%3D(%22%24%40%22)%0A%0A%20%20%23%20We%20want%20autoconnect%20set%20for%20our%20cloned%20slave%20profiles%20so%20that%20they%20are%0A%20%20%23%20used%20over%20the%20original%20profiles%20if%20implicitly%20re-activated%20with%20other%0A%20%20%23%20dependant%20profiles.%20Otherwise%20if%20a%20slave%20activates%20with%20an%20old%20profile%2C%0A%20%20%23%20the%20old%20master%20profile%20might%20activate%20as%20well%2C%20interfering%20and%20causing%0A%20%20%23%20further%20activations%20to%20fail.%0A%20%20%23%20Slave%20interfaces%20should%20already%20be%20active%20so%20setting%20autoconnect%20here%0A%20%20%23%20won't%20implicitly%20activate%20them%20but%20there%20is%20an%20edge%20case%20where%20a%20slave%0A%20%20%23%20might%20be%20inactive%20(link%20down%20for%20example)%20and%20in%20that%20case%20setting%0A%20%20%23%20autoconnect%20will%20cause%20an%20implicit%20activation.%20This%20is%20not%20necessarily%20a%0A%20%20%23%20problem%20and%20hopefully%20we%20can%20make%20sure%20everything%20is%20activated%20as%20we%0A%20%20%23%20want%20next.%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20Activate%20all%20connections%20and%20fail%20if%20activation%20fails%0A%20%20%23%20For%20slave%20connections%20-%20for%20as%20long%20as%20at%20least%20one%20slave%20that%20belongs%20to%20a%20bond%2Fteam%0A%20%20%23%20comes%20up%2C%20we%20should%20not%20fail%0A%20%20declare%20-A%20master_interfaces%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%23%20Get%20the%20slave%20type%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20local%20is_slave%3Dfalse%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20is_slave%3Dtrue%0A%20%20%20%20fi%20%0A%0A%20%20%20%20%23%20For%20slave%20interfaces%2C%20initialize%20the%20master%20interface%20to%20false%20if%20the%20key%20is%20not%20yet%20in%20the%20array%0A%20%20%20%20local%20master_interface%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20master_interface%3D%24(nmcli%20-g%20connection.master%20connection%20show%20%22%24conn%22)%0A%20%20%20%20%20%20if%20!%20%5B%5B%20-v%20%22master_interfaces%5B%24master_interface%5D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dfalse%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Do%20not%20activate%20interfaces%20that%20are%20already%20active%0A%20%20%20%20%23%20But%20set%20the%20entry%20in%20master_interfaces%20to%20true%20if%20this%20is%20a%20slave%0A%20%20%20%20%23%20Also%20set%20autoconnect%20to%20yes%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20%3D%3D%20%22activated%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Connection%20%24conn%20already%20activated%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%24master_interface%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Activate%20all%20interfaces%20that%20are%20not%20yet%20active%0A%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20bring%20up%20connection%20%24conn%22%0A%20%20%20%20%20%20nmcli%20conn%20up%20%22%24conn%22%20%26%26%20s%3D0%20%26%26%20break%20%7C%7C%20s%3D%24%3F%0A%20%20%20%20%20%20sleep%205%0A%20%20%20%20done%0A%20%20%20%20if%20%5B%20%24s%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Brought%20up%20connection%20%24conn%20successfully%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20elif%20!%20%24is_slave%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20connection%20%24conn%20after%20%24i%20attempts%22%0A%20%20%20%20%20%20return%20%24s%0A%20%20%20%20fi%0A%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20done%0A%20%20%23%20Check%20that%20all%20master%20interfaces%20report%20at%20least%20a%20single%20active%20slave%0A%20%20%23%20Note%3A%20associative%20arrays%20require%20an%20exclamation%20mark%20when%20looping%0A%20%20for%20i%20in%20%22%24%7B!master_interfaces%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20!%20%24%7Bmaster_interfaces%5B%22%24i%22%5D%7D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20any%20slave%20interface%20for%20master%20interface%3A%20%24i%22%0A%20%20%20%20%20%20%20%20return%201%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24iface%0A%23%20Writes%20content%20of%20%24iface%20into%20%24iface_default_hint_file%0Awrite_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%242%22%0A%0A%20%20echo%20%22%24%7Biface%7D%22%20%3E%7C%20%22%24%7Biface_default_hint_file%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%0A%23%20Returns%20the%20stored%20interface%20default%20hint%20if%20the%20hint%20is%20non-empty%2C%0A%23%20not%20br-ex%2C%20not%20br-ex1%20and%20if%20the%20interface%20can%20be%20found%20in%20%2Fsys%2Fclass%2Fnet%0Aget_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%241%0A%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%3B%20then%0A%20%20%20%20local%20iface_default_hint%3D%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex1%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20-d%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface_default_hint%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%22%0A%7D%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0A%23%20This%20function%20waits%20for%20ip%20address%20of%20br-ex%20to%20be%20bindable%20only%20in%20case%20of%20ipv6%0A%23%20This%20is%20workaround%20for%20OCPBUGS-673%20as%20it%20will%20not%20allow%20starting%20crio%0A%23%20before%20address%20is%20bindable%0Atry_to_bind_ipv6_address()%20%7B%0A%20%20%23%20Retry%20for%201%20minute%0A%20%20retries%3D60%0A%20%20until%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20do%0A%20%20%20%20ip%3D%24(ip%20-6%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(.ifname%3D%3D%5C%22br-ex%5C%22)%20%7C%20.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20.local)%22)%0A%20%20%20%20if%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22No%20ipv6%20ip%20to%20bind%20was%20found%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20sleep%201%0A%20%20%20%20((%20retries--%20))%0A%20%20done%0A%20%20if%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Failed%20to%20bind%20ip%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%7D%0A%0A%23%20Get%20interface%20that%20matches%20ip%20from%20node%20ip%20hint%20file%0A%23%20in%20case%20file%20not%20exists%20return%20nothing%20and%0A%23%20fallback%20to%20default%20interface%20search%20flow%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge%3D%22%242%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)%20and%20.ifname!%3D%5C%22br-ex1%5C%22%20and%20.ifname!%3D%5C%22%24%7Bextra_bridge%7D%5C%22))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20fi%0A%7D%0A%0A%23%20Accepts%20parameters%20%24bridge_interface%20(e.g.%20ovs-port-phys0)%0A%23%20Returns%20the%20physical%20interface%20name%20if%20%24bridge_interface%20exists%2C%20%22%22%20otherwise%0Aget_bridge_physical_interface()%20%7B%0A%20%20local%20bridge_interface%3D%22%241%22%0A%20%20local%20physical_interface%3D%22%22%0A%20%20physical_interface%3D%24(nmcli%20-g%20connection.interface-name%20conn%20show%20%22%24%7Bbridge_interface%7D%22%202%3E%2Fdev%2Fnull%20%7C%7C%20echo%20%22%22)%0A%20%20echo%20%22%24%7Bphysical_interface%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24extra_bridge_file%2C%20%24ip_hint_file%2C%20%24default_bridge_file%0A%23%20Determines%20the%20interface%20to%20be%20used%20for%20br-ex.%20Order%20of%20priority%20is%3A%0A%23%201.%20Use%20the%20user%20specified%20interface%20if%20provided%20in%20the%20default%20bridge%20file%0A%23%202.%20Use%20the%20node%20IP%20hint%20interface%0A%23%203.%20Use%20the%20previously%20selected%20interface%0A%23%204.%20Use%20the%20interface%20detected%20as%20default%20gateway%0A%23%0A%23%20Read%20%24default_bridge_file%20and%20return%20the%20contained%20interface.%20Otherwise%2C%0A%23%20read%20%24ip_hint_file%20and%20return%20the%20interface%20that%20matches%20this%20ip.%20Otherwise%2C%0A%23%20if%20the%20default%20interface%20is%20br-ex%2C%20use%20that%20and%20return.%0A%23%20If%20the%20default%20interface%20is%20not%20br-ex%3A%0A%23%20Check%20if%20there%20is%20a%20valid%20hint%20inside%20%24iface_default_hint_file.%20If%20so%2C%20use%20that%20hint.%0A%23%20If%20there%20is%20no%20valid%20hint%2C%20use%20the%20default%20interface%20that%20we%20found%20during%20the%20step%0A%23%20earlier.%0A%23%20Never%20use%20the%20interface%20that%20is%20provided%20inside%20%24extra_bridge_file%20for%20br-ex1.%0A%23%20Never%20use%20br-ex1.%0A%23%20Write%20the%20default%20interface%20to%20%24iface_default_hint_file%0Aget_default_bridge_interface()%20%7B%0A%20%20local%20iface%3D%22%22%0A%20%20local%20counter%3D0%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge_file%3D%22%242%22%0A%20%20local%20ip_hint_file%3D%22%243%22%0A%20%20local%20default_bridge_file%3D%22%244%22%0A%20%20local%20extra_bridge%3D%22%22%0A%0A%20%20if%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%3B%20then%0A%20%20%20%20extra_bridge%3D%24(cat%20%24%7Bextra_bridge_file%7D)%0A%20%20fi%0A%0A%20%20%23%20try%20to%20use%20user%20specified%20file%20first%0A%20%20if%20%5B%20-f%20%22%24default_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20iface%3D%24(cat%20%22%24%7Bdefault_bridge_file%7D%22)%0A%20%20%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20User%20specified%20bridge%20file%20detected%20without%20any%20data%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20if%20node%20ip%20was%20set%2C%20we%20should%20search%20for%20interface%20that%20matches%20it%0A%20%20iface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bextra_bridge%7D%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20find%20default%20interface%0A%20%20%23%20the%20default%20interface%20might%20be%20br-ex%2C%20so%20check%20this%20before%20looking%20at%20the%20hint%0A%20%20while%20%5B%20%24%7Bcounter%7D%20-lt%2012%20%5D%3B%20do%0A%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20sleep%205%0A%20%20done%0A%0A%20%20%23%20if%20the%20default%20interface%20does%20not%20point%20out%20of%20br-ex%20or%20br-ex1%0A%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20%23%20determine%20if%20an%20interface%20default%20hint%20exists%20from%20a%20previous%20run%0A%20%20%20%20%23%20and%20if%20the%20interface%20has%20a%20valid%20default%20route%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%24%7Biface%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20start%20wherever%20count%20left%20off%20in%20the%20previous%20loop%0A%20%20%20%20%20%20%23%20allow%20this%20for%20one%20more%20iteration%20than%20the%20previous%20loop%0A%20%20%20%20%20%20while%20%5B%20%24%7Bcounter%7D%20-le%2012%20%5D%3B%20do%0A%20%20%20%20%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20-6%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%20%20%20%20fi%0A%20%20%20%20%23%20store%20what%20was%20determined%20was%20the%20(new)%20default%20interface%20inside%0A%20%20%20%20%23%20the%20default%20hint%20file%20for%20future%20reference%0A%20%20%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Biface%7D%22%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20print%20network%20state%0Aprint_state()%20%7B%0A%20%20echo%20%22Current%20device%2C%20connection%2C%20interface%20and%20routing%20state%3A%22%0A%20%20nmcli%20-g%20all%20device%20%7C%20grep%20-v%20unmanaged%0A%20%20nmcli%20-g%20all%20connection%0A%20%20ip%20-d%20address%20show%0A%20%20ip%20route%20show%0A%20%20ip%20-6%20route%20show%0A%7D%0A%0A%23%20Setup%20an%20exit%20trap%20to%20rollback%20on%20error%0Ahandle_exit()%20%7B%0A%20%20e%3D%24%3F%0A%20%20tdir%3D%24(mktemp%20-u%20-d%20-t%20%22configure-ovs-%24(date%20%2B%25Y-%25m-%25d-%25H-%25M-%25S)-XXXXXXXXXX%22)%0A%20%20%0A%20%20if%20%5B%20%24e%20-eq%200%20%5D%3B%20then%0A%20%20%20%20print_state%0A%20%20%20%20%23%20remove%20previous%20troubleshooting%20information%0A%20%20%20%20rm%20-rf%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%0A%20%20echo%20%22ERROR%3A%20configure-ovs%20exited%20with%20error%3A%20%24e%22%0A%20%20print_state%0A%0A%20%20%23%20remove%20previous%20troubleshooting%20information%20except%20the%20oldest%20one%0A%20%20mapfile%20-t%20tdirs%20%3C%20%3C(compgen%20-G%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22)%0A%20%20unset%20-v%20%22tdirs%5B0%5D%22%0A%20%20for%20dir%20in%20%22%24%7Btdirs%5B%40%5D%7D%22%3B%20do%20rm%20-rf%20%22%24dir%22%3B%20done%0A%0A%20%20%23%20copy%20configuration%20to%20tmp%20for%20troubleshooting%0A%20%20mkdir%20-p%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20echo%20%22Copied%20OVS%20configuration%20to%20%24tdir%20for%20troubleshooting%22%0A%0A%20%20%23%20attempt%20to%20restore%20the%20previous%20network%20state%0A%20%20echo%20%22Attempting%20to%20restore%20previous%20configuration...%22%0A%20%20rollback_nm%0A%20%20print_state%0A%0A%20%20exit%20%24e%0A%7D%0A%0A%23%20Setup%20a%20signal%20trap%20to%20rollback%0Ahandle_termination()%20%7B%0A%20%20echo%20%22WARNING%3A%20configure-ovs%20has%20been%20requested%20to%20terminate%2C%20quitting...%22%0A%20%20%0A%20%20%23%20by%20exiting%20with%20an%20error%20we%20will%20cleanup%20after%20ourselves%20in%20a%0A%20%20%23%20subsequent%20call%20to%20handle_exit%0A%20%20exit%201%0A%7D%0A%0A%23%20main%20function%0Aconfigure_ovs()%20%7B%0A%20%20set%20-eu%0A%0A%20%20%23%20setup%20traps%20to%20handle%20signals%20and%20other%20abnormal%20exits%0A%20%20trap%20'handle_termination'%20TERM%20INT%0A%20%20trap%20'handle_exit'%20EXIT%0A%0A%20%20%23%20this%20flag%20tracks%20if%20any%20config%20change%20was%20made%0A%20%20nm_config_changed%3D0%0A%0A%20%20%23%20Check%20that%20we%20are%20provided%20a%20valid%20NM%20connection%20path%0A%20%20if%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_CONF_PATH%22%20%5D%20%26%26%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_RUN_PATH%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Error%3A%20Incorrect%20NM%20connection%20path%3A%20%24NM_CONN_SET_PATH%20is%20not%20%24NM_CONN_CONF_PATH%20nor%20%24NM_CONN_RUN_PATH%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0A%20%20if%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0A%20%20fi%0A%0A%20%20if%20!%20rpm%20-qa%20%7C%20grep%20-q%20openvswitch%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20Openvswitch%20package%20is%20not%20installed!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20print%20initial%20state%0A%20%20print_state%0A%0A%20%20if%20%5B%20%22%241%22%20%3D%3D%20%22OVNKubernetes%22%20%5D%3B%20then%0A%20%20%20%20%23%20Configures%20NICs%20onto%20OVS%20bridge%20%22br-ex%22%0A%20%20%20%20%23%20Configuration%20is%20either%20auto-detected%20or%20provided%20through%20a%20config%20file%20written%20already%20in%20Network%20Manager%0A%20%20%20%20%23%20key%20files%20under%20%2Fetc%2FNetworkManager%2Fsystem-connections%2F%0A%20%20%20%20%23%20Managing%20key%20files%20is%20outside%20of%20the%20scope%20of%20this%20script%0A%0A%20%20%20%20%23%20if%20the%20interface%20is%20of%20type%20vmxnet3%20add%20multicast%20capability%20for%20that%20driver%0A%20%20%20%20%23%20History%3A%20BZ%3A1854355%0A%20%20%20%20function%20configure_driver_options%20%7B%0A%20%20%20%20%20%20intf%3D%241%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Device%20file%20doesn't%20exist%2C%20skipping%20setting%20multicast%20mode%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20driver%3D%24(cat%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%7C%20grep%20DRIVER%20%7C%20awk%20-F%20%22%3D%22%20'%7Bprint%20%242%7D')%0A%20%20%20%20%20%20%20%20echo%20%22Driver%20name%20is%22%20%24driver%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24driver%22%20%3D%20%22vmxnet3%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20ip%20link%20set%20dev%20%22%24%7Bintf%7D%22%20allmulticast%20on%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20fi%0A%20%20%20%20%7D%0A%0A%20%20%20%20ovnk_config_dir%3D'%2Fetc%2Fovnk'%0A%20%20%20%20ovnk_var_dir%3D'%2Fvar%2Flib%2Fovnk'%0A%20%20%20%20extra_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fextra_bridge%22%0A%20%20%20%20iface_default_hint_file%3D%22%24%7Bovnk_var_dir%7D%2Fiface_default_hint%22%0A%20%20%20%20ip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%20%20%20%20%23%20explicitly%20specify%20which%20interface%20should%20be%20used%20with%20the%20default%20bridge%0A%20%20%20%20default_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fdefault_bridge%22%0A%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_config_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_config_dir%7D%22%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_var_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_var_dir%7D%22%0A%0A%20%20%20%20%23%20For%20upgrade%20scenarios%2C%20make%20sure%20that%20we%20stabilize%20what%20we%20already%20configured%0A%20%20%20%20%23%20before.%20If%20we%20do%20not%20have%20a%20valid%20interface%20hint%2C%20find%20the%20physical%20interface%0A%20%20%20%20%23%20that's%20attached%20to%20ovs-if-phys0.%0A%20%20%20%20%23%20If%20we%20find%20such%20an%20interface%2C%20write%20it%20to%20the%20hint%20file.%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20current_interface%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20%20%20%20%20if%20%5B%20%22%24%7Bcurrent_interface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bcurrent_interface%7D%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20delete%20iface_default_hint_file%20if%20it%20has%20the%20same%20content%20as%20extra_bridge_file%0A%20%20%20%20%23%20in%20that%20case%2C%20we%20must%20also%20force%20a%20reconfiguration%20of%20our%20network%20interfaces%0A%20%20%20%20%23%20to%20make%20sure%20that%20we%20reconcile%20this%20conflict%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20%22%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%22%20%3D%3D%20%22%24(cat%20%22%24%7Bextra_bridge_file%7D%22)%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint_file%7D%20and%20%24%7Bextra_bridge_file%7D%20share%20the%20same%20content%22%0A%20%20%20%20%20%20echo%20%22Deleting%20file%20%24%7Biface_default_hint_file%7D%20to%20choose%20a%20different%20interface%22%0A%20%20%20%20%20%20rm%20-f%20%22%24%7Biface_default_hint_file%7D%22%0A%20%20%20%20%20%20rm%20-f%20%2Frun%2Fconfigure-ovs-boot-done%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20on%20every%20boot%20we%20rollback%20and%20generate%20the%20configuration%20again%2C%20to%20take%0A%20%20%20%20%23%20in%20any%20changes%20that%20have%20possibly%20been%20applied%20in%20the%20standard%0A%20%20%20%20%23%20configuration%20sources%0A%20%20%20%20if%20%5B%20!%20-f%20%2Frun%2Fconfigure-ovs-boot-done%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Running%20on%20boot%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20print_state%0A%20%20%20%20fi%0A%20%20%20%20touch%20%2Frun%2Fconfigure-ovs-boot-done%0A%0A%20%20%20%20iface%3D%24(get_default_bridge_interface%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bextra_bridge_file%7D%22%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bdefault_bridge_file%7D%22)%0A%0A%20%20%20%20if%20%5B%20%22%24iface%22%20!%3D%20%22br-ex%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Specified%20interface%20is%20not%20br-ex.%0A%20%20%20%20%20%20%23%20Some%20deployments%20use%20a%20temporary%20solution%20where%20br-ex%20is%20moved%20out%20from%20the%20default%20gateway%20interface%0A%20%20%20%20%20%20%23%20and%20bound%20to%20a%20different%20nic%20(https%3A%2F%2Fgithub.com%2Ftrozet%2Fopenshift-ovn-migration).%0A%20%20%20%20%20%20%23%20This%20is%20now%20supported%20through%20an%20extra%20bridge%20if%20requested.%20If%20that%20is%20the%20case%2C%20we%20rollback.%0A%20%20%20%20%20%20%23%20We%20also%20rollback%20if%20it%20looks%20like%20we%20need%20to%20configure%20things%2C%20just%20in%20case%20there%20are%20any%20leftovers%0A%20%20%20%20%20%20%23%20from%20previous%20attempts.%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%7C%7C%20%5B%20-z%20%22%24(nmcli%20connection%20show%20--active%20br-ex%202%3E%20%2Fdev%2Fnull)%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Bridge%20br-ex%20is%20not%20active%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20%20%20print_state%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20convert_to_bridge%20%22%24iface%22%20%22br-ex%22%20%22phys0%22%20%22%24%7BBRIDGE_METRIC%7D%22%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20configure%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(!%20nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20!%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20interface%3D%24(head%20-n%201%20%24extra_bridge_file)%0A%20%20%20%20%20%20convert_to_bridge%20%22%24interface%22%20%22br-ex1%22%20%22phys1%22%20%22%24%7BBRIDGE1_METRIC%7D%22%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20remove%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20!%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20openshift-sdn%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0A%20%20%20%20%23%20Make%20sure%20everything%20is%20activated.%20Do%20it%20in%20a%20specific%20order%3A%0A%20%20%20%20%23%20-%20activate%20br-ex%20first%2C%20due%20to%20autoconnect-slaves%20this%20will%20also%0A%20%20%20%20%23%20%20%20activate%20ovs-port-br-ex%2C%20ovs-port-phys0%20and%20ovs-if-phys0.%20It%20is%0A%20%20%20%20%23%20%20%20important%20that%20ovs-if-phys0%20activates%20with%20br-ex%20to%20avoid%20the%0A%20%20%20%20%23%20%20%20ovs-if-phys0%20profile%20being%20overridden%20with%20a%20profile%20generated%20from%0A%20%20%20%20%23%20%20%20kargs.%20The%20activation%20of%20ovs-if-phys0%2C%20if%20a%20bond%2C%20might%20cause%20the%0A%20%20%20%20%23%20%20%20slaves%20to%20re-activate%2C%20but%20it%20should%20be%20with%20our%20profiles%20since%20they%0A%20%20%20%20%23%20%20%20have%20higher%20priority%0A%20%20%20%20%23%20-%20make%20sure%20that%20ovs-if-phys0%20and%20its%20slaves%2C%20if%20any%2C%20are%20activated.%0A%20%20%20%20%23%20-%20finally%20activate%20ovs-if-br-ex%20which%20holds%20the%20IP%20configuration.%0A%20%20%20%20connections%3D(br-ex%20ovs-if-phys0)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(br-ex1%20ovs-if-phys1)%0A%20%20%20%20fi%0A%20%20%20%20while%20IFS%3D%20read%20-r%20connection%3B%20do%0A%20%20%20%20%20%20if%20%5B%5B%20%24connection%20%3D%3D%20*%22%24MANAGED_NM_CONN_SUFFIX%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20connections%2B%3D(%22%24connection%22)%0A%20%20%20%20%20%20fi%0A%20%20%20%20done%20%3C%20%3C(nmcli%20-g%20NAME%20c)%0A%20%20%20%20connections%2B%3D(ovs-if-br-ex)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(ovs-if-br-ex1)%0A%20%20%20%20fi%0A%20%20%20%20activate_nm_connections%20%22%24%7Bconnections%5B%40%5D%7D%22%0A%20%20%20%20try_to_bind_ipv6_address%0A%20%20%20%20set_nm_conn_files%0A%20%20elif%20%5B%20%22%241%22%20%3D%3D%20%22OpenShiftSDN%22%20%5D%3B%20then%0A%20%20%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20%20%20rollback_nm%0A%20%20%20%20%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20ovn-kubernetes%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-int%20--%20--if-exists%20del-br%20br-local%0A%20%20fi%0A%7D%0A%0A%23%20Retry%20configure_ovs%20until%20it%20succeeds.%0A%23%20By%20default%2C%20retry%20every%2015%20minutes%20to%20give%20enough%20time%20to%20gather%0A%23%20troubleshooting%20information%20in%20between.%20Note%20that%20configure_ovs%20has%20other%0A%23%20internal%20retry%20mechanisms.%20This%20retry%20is%20intended%20to%20give%20some%0A%23%20self-healing%20capabilities%20to%20temporary%20but%20not%20necessarily%20short-lived%0A%23%20infrastructure%20problems.%0ARETRY%3D%22%24%7BRETRY-15m%7D%22%0Awhile%20true%3B%20do%0A%0A%20%20%23%20Disable%20retries%20if%20termination%20signal%20is%20received.%20Note%20that%20systemd%0A%20%20%23%20sends%20the%20signals%20to%20all%20processes%20in%20the%20group%20by%20default%20so%20we%20expect%0A%20%20%23%20configure_ovs%20to%20get%20its%20own%20signals.%0A%20%20trap%20'echo%20%22WARNING%3A%20termination%20requested%2C%20disabling%20retries%22%3B%20RETRY%3D%22%22'%20INT%20TERM%0A%20%20%0A%20%20%23%20Run%20configure_ovs%20in%20a%20sub-shell.%20%0A%20%20(%20configure_ovs%20%22%24%40%22%20)%0A%20%20e%3D%24%3F%0A%0A%20%20%23%20Handle%20signals%20while%20we%20sleep%0A%20%20trap%20'handle_termination'%20INT%20TERM%0A%20%20%0A%20%20%23%20Exit%20if%20succesful%20and%20not%20configured%20to%20retry%0A%20%20%5B%20%22%24e%22%20-eq%200%20%5D%20%7C%7C%20%5B%20-z%20%22%24RETRY%22%20%5D%20%26%26%20exit%20%22%24e%22%0A%20%20%0A%20%20echo%20%22configure-ovs%20failed%2C%20will%20retry%20after%20%24RETRY%22%0A%20%20%23%20flag%20that%20a%20retry%20has%20happened%0A%20%20touch%20%2Ftmp%2Fconfigure-ovs-retry%0A%20%20sleep%20%22%24RETRY%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ovs.sh
        - contents:
            source: data:,%23%20This%20file%20is%20generated%20by%20the%20Machine%20Config%20Operator's%20containerruntimeconfig%20controller.%0A%23%0A%23%20storage.conf%20is%20the%20configuration%20file%20for%20all%20tools%0A%23%20that%20share%20the%20containers%2Fstorage%20libraries%0A%23%20See%20man%205%20containers-storage.conf%20for%20more%20information%0A%23%20The%20%22container%20storage%22%20table%20contains%20all%20of%20the%20server%20options.%0A%5Bstorage%5D%0A%0A%23%20Default%20Storage%20Driver%0Adriver%20%3D%20%22overlay%22%0A%0A%23%20Temporary%20storage%20location%0Arunroot%20%3D%20%22%2Fvar%2Frun%2Fcontainers%2Fstorage%22%0A%0A%23%20Primary%20Read%2FWrite%20location%20of%20container%20storage%0Agraphroot%20%3D%20%22%2Fvar%2Flib%2Fcontainers%2Fstorage%22%0A%0A%5Bstorage.options%5D%0A%23%20Storage%20options%20to%20be%20passed%20to%20underlying%20storage%20drivers%0A%0A%23%20AdditionalImageStores%20is%20used%20to%20pass%20paths%20to%20additional%20Read%2FOnly%20image%20stores%0A%23%20Must%20be%20comma%20separated%20list.%0Aadditionalimagestores%20%3D%20%5B%0A%5D%0A%0A%23%20Size%20is%20used%20to%20set%20a%20maximum%20size%20of%20the%20container%20image.%20%20Only%20supported%20by%0A%23%20certain%20container%20storage%20drivers.%0Asize%20%3D%20%22%22%0A%0A%23%20Remap-UIDs%2FGIDs%20is%20the%20mapping%20from%20UIDs%2FGIDs%20as%20they%20should%20appear%20inside%20of%0A%23%20a%20container%2C%20to%20UIDs%2FGIDs%20as%20they%20should%20appear%20outside%20of%20the%20container%2C%20and%0A%23%20the%20length%20of%20the%20range%20of%20UIDs%2FGIDs.%20%20Additional%20mapped%20sets%20can%20be%20listed%0A%23%20and%20will%20be%20heeded%20by%20libraries%2C%20but%20there%20are%20limits%20to%20the%20number%20of%0A%23%20mappings%20which%20the%20kernel%20will%20allow%20when%20you%20later%20attempt%20to%20run%20a%0A%23%20container.%0A%23%0A%23%20remap-uids%20%3D%200%3A1668442479%3A65536%0A%23%20remap-gids%20%3D%200%3A1668442479%3A65536%0A%0A%23%20Remap-User%2FGroup%20is%20a%20name%20which%20can%20be%20used%20to%20look%20up%20one%20or%20more%20UID%2FGID%0A%23%20ranges%20in%20the%20%2Fetc%2Fsubuid%20or%20%2Fetc%2Fsubgid%20file.%20%20Mappings%20are%20set%20up%20starting%0A%23%20with%20an%20in-container%20ID%20of%200%20and%20the%20a%20host-level%20ID%20taken%20from%20the%20lowest%0A%23%20range%20that%20matches%20the%20specified%20name%2C%20and%20using%20the%20length%20of%20that%20range.%0A%23%20Additional%20ranges%20are%20then%20assigned%2C%20using%20the%20ranges%20which%20specify%20the%0A%23%20lowest%20host-level%20IDs%20first%2C%20to%20the%20lowest%20not-yet-mapped%20container-level%20ID%2C%0A%23%20until%20all%20of%20the%20entries%20have%20been%20used%20for%20maps.%0A%23%0A%23%20remap-user%20%3D%20%22storage%22%0A%23%20remap-group%20%3D%20%22storage%22%0A%0A%5Bstorage.options.overlay%5D%0A%23%20Storage%20Options%20for%20overlay%0A%0A%23%20Do%20not%20create%20a%20PRIVATE%20bind%20mount%20on%20the%20home%20directory.%0Askip_mount_home%20%3D%20%22true%22%0A%0A%5Bstorage.options.thinpool%5D%0A%23%20Storage%20Options%20for%20thinpool%0A%0A%23%20autoextend_percent%20determines%20the%20amount%20by%20which%20pool%20needs%20to%20be%0A%23%20grown.%20This%20is%20specified%20in%20terms%20of%20%25%20of%20pool%20size.%20So%20a%20value%20of%2020%20means%0A%23%20that%20when%20threshold%20is%20hit%2C%20pool%20will%20be%20grown%20by%2020%25%20of%20existing%0A%23%20pool%20size.%0A%23%20autoextend_percent%20%3D%20%2220%22%0A%0A%23%20autoextend_threshold%20determines%20the%20pool%20extension%20threshold%20in%20terms%0A%23%20of%20percentage%20of%20pool%20size.%20For%20example%2C%20if%20threshold%20is%2060%2C%20that%20means%20when%0A%23%20pool%20is%2060%25%20full%2C%20threshold%20has%20been%20hit.%0A%23%20autoextend_threshold%20%3D%20%2280%22%0A%0A%23%20basesize%20specifies%20the%20size%20to%20use%20when%20creating%20the%20base%20device%2C%20which%0A%23%20limits%20the%20size%20of%20images%20and%20containers.%0A%23%20basesize%20%3D%20%2210G%22%0A%0A%23%20blocksize%20specifies%20a%20custom%20blocksize%20to%20use%20for%20the%20thin%20pool.%0A%23%20blocksize%3D%2264k%22%0A%0A%23%20directlvm_device%20specifies%20a%20custom%20block%20storage%20device%20to%20use%20for%20the%0A%23%20thin%20pool.%20Required%20if%20you%20setup%20devicemapper%0A%23%20directlvm_device%20%3D%20%22%22%0A%0A%23%20directlvm_device_force%20wipes%20device%20even%20if%20device%20already%20has%20a%20filesystem%0A%23%20directlvm_device_force%20%3D%20%22True%22%0A%0A%23%20fs%20specifies%20the%20filesystem%20type%20to%20use%20for%20the%20base%20device.%0A%23%20fs%3D%22xfs%22%0A%0A%23%20log_level%20sets%20the%20log%20level%20of%20devicemapper.%0A%23%200%3A%20LogLevelSuppress%200%20(Default)%0A%23%202%3A%20LogLevelFatal%0A%23%203%3A%20LogLevelErr%0A%23%204%3A%20LogLevelWarn%0A%23%205%3A%20LogLevelNotice%0A%23%206%3A%20LogLevelInfo%0A%23%207%3A%20LogLevelDebug%0A%23%20log_level%20%3D%20%227%22%0A%0A%23%20min_free_space%20specifies%20the%20min%20free%20space%20percent%20in%20a%20thin%20pool%20require%20for%0A%23%20new%20device%20creation%20to%20succeed.%20Valid%20values%20are%20from%200%25%20-%2099%25.%0A%23%20Value%200%25%20disables%0A%23%20min_free_space%20%3D%20%2210%25%22%0A%0A%23%20mkfsarg%20specifies%20extra%20mkfs%20arguments%20to%20be%20used%20when%20creating%20the%20base%0A%23%20device.%0A%23%20mkfsarg%20%3D%20%22%22%0A%0A%23%20mountopt%20specifies%20extra%20mount%20options%20used%20when%20mounting%20the%20thin%20devices.%0A%23%20mountopt%20%3D%20%22%22%0A%0A%23%20use_deferred_removal%20Marking%20device%20for%20deferred%20removal%0A%23%20use_deferred_removal%20%3D%20%22True%22%0A%0A%23%20use_deferred_deletion%20Marking%20device%20for%20deferred%20deletion%0A%23%20use_deferred_deletion%20%3D%20%22True%22%0A%0A%23%20xfs_nospace_max_retries%20specifies%20the%20maximum%20number%20of%20retries%20XFS%20should%0A%23%20attempt%20to%20complete%20IO%20when%20ENOSPC%20(no%20space)%20error%20is%20returned%20by%0A%23%20underlying%20storage%20device.%0A%23%20xfs_nospace_max_retries%20%3D%20%220%22%0A
          mode: 420
          overwrite: true
          path: /etc/containers/storage.conf
        - contents:
            source: data:,apiVersion%3A%20kubelet.config.k8s.io%2Fv1%0Akind%3A%20CredentialProviderConfig%0Aproviders%3A%0A%20%20-%20name%3A%20ecr-credential-provider%0A%20%20%20%20matchImages%3A%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.*.amazonaws.com%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.*.amazonaws.com.cn%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr-fips.*.amazonaws.com%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.us-iso-east-1.c2s.ic.gov%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.us-isob-east-1.sc2s.sgov.gov%22%0A%20%20%20%20defaultCacheDuration%3A%20%2212h%22%0A%20%20%20%20apiVersion%3A%20credentialprovider.kubelet.k8s.io%2Fv1%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/credential-providers/ecr-credential-provider.yaml
        - contents:
            source: data:,%23%20Proxy%20environment%20variables%20will%20be%20populated%20in%20this%20file.%20Properly%0A%23%20url%20encoded%20passwords%20with%20special%20characters%20will%20use%20'%25%3CHEX%3E%3CHEX%3E'.%0A%23%20Systemd%20requires%20that%20any%20%25%20used%20in%20a%20password%20be%20represented%20as%0A%23%20%25%25%20in%20a%20unit%20file%20since%20%25%20is%20a%20prefix%20for%20macros%3B%20this%20restriction%20does%20not%0A%23%20apply%20for%20environment%20files.%20Templates%20that%20need%20the%20proxy%20set%20should%20use%0A%23%20'EnvironmentFile%3D%2Fetc%2Fmco%2Fproxy.env'.%0A
          mode: 420
          overwrite: true
          path: /etc/mco/proxy.env
        - contents:
            source: data:,%5BManager%5D%0ADefaultEnvironment%3DGODEBUG%3Dx509ignoreCN%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/10-default-env-godebug.conf
        - contents:
            source: data:,%23%20Force-load%20legacy%20iptables%20so%20it%20is%20usable%20from%20pod%20network%20namespaces%0Aip_tables%0A
          mode: 420
          overwrite: true
          path: /etc/modules-load.d/iptables.conf
        - contents:
            source: data:,NODE_SIZING_ENABLED%3Dfalse%0ASYSTEM_RESERVED_MEMORY%3D1Gi%0ASYSTEM_RESERVED_CPU%3D500m%0ASYSTEM_RESERVED_ES%3D1Gi
          mode: 420
          overwrite: true
          path: /etc/node-sizing-enabled.env
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%0ANODE_SIZES_ENV%3D%24%7BNODE_SIZES_ENV%3A-%2Fetc%2Fnode-sizing.env%7D%0AVERSION_1%3D1%0AVERSION_2%3D2%0ANODE_AUTO_SIZING_VERSION%3D%24%7BNODE_AUTO_SIZING_VERSION%3A-%24VERSION_2%7D%0ANODE_AUTO_SIZING_VERSION_FILE%3D%24%7BNODE_AUTO_SIZING_VERSION_FILE%3A-%2Fetc%2Fnode-sizing-version.json%7D%0Afunction%20dynamic_memory_sizing%20%7B%0A%20%20%20%20total_memory%3D%24(free%20-g%7Cawk%20'%2F%5EMem%3A%2F%7Bprint%20%242%7D')%0A%20%20%20%20%23%20total_memory%3D8%20test%20the%20recommended%20values%20by%20modifying%20this%20value%0A%20%20%20%20recommended_systemreserved_memory%3D0%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2025%25%20of%20the%20first%204GB%20of%20memory%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24total_memory%200.25%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D1%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2020%25%20of%20the%20next%204GB%20of%20memory%20(up%20to%208GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.20%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%208))%3B%20then%20%23%2010%25%20of%20the%20next%208GB%20of%20memory%20(up%20to%2016GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.10%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-8))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%20112))%3B%20then%20%23%206%25%20of%20the%20next%20112GB%20of%20memory%20(up%20to%20128GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%206.72%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-112))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3E%3D%200))%3B%20then%20%23%202%25%20of%20any%20memory%20above%20128GB%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.02%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20fi%0A%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%7C%20awk%20'%7Bprintf(%22%25d%5Cn%22%2C%241%20%2B%200.5)%7D')%20%23%20Round%20off%20so%20we%20avoid%20float%20conversions%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7Brecommended_systemreserved_memory%7DGi%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_cpu_sizing%20%7B%0A%20%20%20%20total_cpu%3D%24(getconf%20_NPROCESSORS_ONLN)%0A%20%20%20%20if%20%5B%20%22%241%22%20-eq%20%22%24VERSION_1%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%206%25%20of%20the%20first%20core%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24total_cpu%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0.06%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%201%25%20of%20the%20next%20core%20(up%20to%202%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%202))%3B%20then%20%23%200.5%25%20of%20the%20next%202%20cores%20(up%20to%204%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.005%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-2))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3E%3D%200))%3B%20then%20%23%200.25%25%20of%20any%20cores%20above%204%20cores%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.0025%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20%23%20Base%20allocation%20for%201%20CPU%20in%20fractions%20of%20a%20core%20(60%20millicores%20%3D%200.06%20CPU%20core)%0A%20%20%20%20%20%20%20%20base_allocation_fraction%3D0.06%0A%20%20%20%20%20%20%20%20%23%20Increment%20per%20additional%20CPU%20in%20fractions%20of%20a%20core%20(12%20millicores%20%3D%200.012%20CPU%20core)%0A%20%20%20%20%20%20%20%20increment_per_cpu_fraction%3D0.012%0A%20%20%20%20%20%20%20%20if%20((total_cpu%20%3E%201))%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20the%20total%20system-reserved%20CPU%20in%20fractions%2C%20starting%20with%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20and%20adding%20the%20incremental%20fraction%20for%20each%20additional%20CPU%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20base%3D%22%24base_allocation_fraction%22%20-v%20increment%3D%22%24increment_per_cpu_fraction%22%20-v%20cpus%3D%22%24total_cpu%22%20'BEGIN%20%7Bprintf%20%22%25.2f%5Cn%22%2C%20base%20%2B%20increment%20*%20(cpus%20-%201)%7D')%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20a%20single%20CPU%2C%20use%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24base_allocation_fraction%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7Brecommended_systemreserved_cpu%7D%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_ephemeral_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20dynamic_pid_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20set_memory%20%7B%0A%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_cpu%20%7B%0A%20%20%20%20SYSTEM_RESERVED_CPU%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_CPU%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_CPU%3D%22500m%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7BSYSTEM_RESERVED_CPU%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_es%20%7B%0A%20%20%20%20SYSTEM_RESERVED_ES%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_ES%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_ES%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_ES%3D%24%7BSYSTEM_RESERVED_ES%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20dynamic_memory_sizing%0A%20%20%20%20dynamic_cpu_sizing%20%242%0A%20%20%20%20set_es%20%241%0A%20%20%20%20%23dynamic_ephemeral_sizing%0A%20%20%20%20%23dynamic_pid_sizing%0A%7D%0Afunction%20static_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20set_memory%20%241%0A%20%20%20%20set_cpu%20%242%0A%20%20%20%20set_es%20%243%0A%7D%0Afunction%20create_version_file%20%7B%0A%20%20%20%20echo%20%22%7B%5C%22version%5C%22%3A%20%241%7D%22%20%3E%20%242%0A%7D%0Aif%20!%20%5B%20-f%20%24NODE_AUTO_SIZING_VERSION_FILE%20%5D%3B%20then%0A%20%20%20%20create_version_file%20%24NODE_AUTO_SIZING_VERSION%20%24NODE_AUTO_SIZING_VERSION_FILE%0Afi%0Anew_version%3D%24(jq%20.version%20%24NODE_AUTO_SIZING_VERSION_FILE)%0Aif%20%5B%20%241%20%3D%3D%20%22true%22%20%5D%3B%20then%0A%20%20%20%20dynamic_node_sizing%20%244%20%24new_version%0Aelif%20%5B%20%241%20%3D%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20static_node_sizing%20%242%20%243%20%244%0Aelse%0A%20%20%20%20echo%20%22Unrecognized%20command%20line%20option.%20Valid%20options%20are%20%5C%22true%5C%22%20or%20%5C%22false%5C%22%22%0Afi
          mode: 493
          overwrite: true
          path: /usr/local/sbin/dynamic-system-reserved-calc.sh
        - contents:
            source: data:,%23%20Turning%20on%20Accounting%20helps%20track%20down%20performance%20issues.%0A%5BManager%5D%0ADefaultCPUAccounting%3Dyes%0ADefaultMemoryAccounting%3Dyes%0ADefaultBlockIOAccounting%3Dyes%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/kubelet-cgroups.conf
        - contents:
            source: data:,%5BService%5D%0AEnvironment%3D%22KUBELET_LOG_LEVEL%3D2%22%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system/kubelet.service.d/20-logging.conf
        - contents:
            source: data:,%23%20ignore%20known%20SDN-managed%20devices%0A%5Bdevice%5D%0Amatch-device%3Dinterface-name%3Abr-int%3Binterface-name%3Abr-local%3Binterface-name%3Abr-nexthop%3Binterface-name%3Aovn-k8s-*%3Binterface-name%3Ak8s-*%3Binterface-name%3Atun0%3Binterface-name%3Abr0%3Binterface-name%3Apatch-br-*%3Binterface-name%3Abr-ext%3Binterface-name%3Aext-vxlan%3Binterface-name%3Aext%3Binterface-name%3Aint%3Binterface-name%3Avxlan_sys_*%3Binterface-name%3Agenev_sys_*%3Bdriver%3Aveth%0Amanaged%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/sdn.conf
        - contents:
            source: data:,%5Bservice%5D%0Akeep_state_file_after_apply%20%3D%20true%0A
          mode: 420
          overwrite: true
          path: /etc/nmstate/nmstate.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Set%20interface%20ofport_request%20to%20guarantee%20stable%20ofport%20numbers.%20This%20is%20important%20for%20flow%20matches.%0A%23%20Otherwise%2C%20another%20ofport%20number%20is%20assigned%20to%20the%20interface%20on%20every%20restart%20of%20NetworkManager.%0A%23%20This%20script%20will%20build%20an%20associative%20array%20INTERFACE_NAME-%3Eofport_request%20and%20will%20save%20it%20to%20file%20CONFIGURATION_FILE.%0A%23%20When%20an%20interface%20is%20brought%20up%2C%20this%20will%20reuse%20the%20value%20from%20the%20associative%20array%20if%20such%20a%20value%20exists.%0A%23%20Otherwise%2C%20this%20will%20try%20to%20use%20the%20current%20ofport%20value.%20If%20the%20ofport%20value%20is%20already%20reserved%2C%20then%0A%23%20this%20uses%20the%20lowest%20available%20numerical%20value%2C%20instead.%0Aset%20-eux%20-o%20pipefail%0Aif%20%5B%5B%20%22OVNKubernetes%22%20!%3D%20%22OVNKubernetes%22%20%5D%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0AINTERFACE_NAME%3D%241%0AOPERATION%3D%242%0A%0A%23%20Only%20execute%20this%20on%20pre-up%0Aif%20%5B%20%22%24%7BOPERATION%7D%22%20!%3D%20%22pre-up%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0AINTERFACE_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%241%3D%3D%22'%24%7BINTERFACE_NAME%7D'%22%20%26%26%20%242!~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20slave-type.%20If%20this%20is%20not%20an%20ovs-port%2C%20then%20exit%0AINTERFACE_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-port%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20This%20is%20not%20necessarily%20a%20UUID%20(can%20be%20a%20name%20in%20case%20of%20bonds)%20but%20this%20should%20be%20unique%0APORT%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0APORT_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%20(%241%3D%3D%22'%24%7BPORT%7D'%22%20%7C%7C%20%243%3D%3D%22'%24%7BPORT%7D'%22)%20%26%26%20%242~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20slave-type.%20If%20this%20is%20not%20an%20ovs-bridge%2C%20then%20exit%0APORT_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-bridge%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20master.%20If%20it%20doesn't%20have%20any%2C%20assume%20it's%20not%20our%20bridge%0ABRIDGE_ID%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BBRIDGE_ID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20bridge%20name%0ABRIDGE_NAME%3D%24(nmcli%20-t%20-f%20connection.interface-name%20conn%20show%20%22%24%7BBRIDGE_ID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0A%23%20Limit%20this%20to%20br-ex%20and%20br-ex1%20only.%20If%20one%20wanted%20to%20enable%20this%20for%20all%20OVS%20bridges%2C%0A%23%20the%20condition%20would%20be%3A%20if%20%5B%20%22%24BRIDGE_NAME%22%20%3D%3D%20%22%22%20%5D%3B%20then%0Aif%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Make%20sure%20that%20the%20interface%20is%20plugged%20into%20OVS%0A%23%20This%20should%20always%20be%20the%20case%20given%20that%20we%20are%20in%20pre-up%2C%20but%20exit%20gracefully%20in%20the%20odd%20case%20that%20it's%20not%0Aif%20!%20ovs-vsctl%20list%20interface%20%22%24%7BINTERFACE_NAME%7D%22%20%3E%2Fdev%2Fnull%202%3E%261%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0ACONFIGURATION_FILE%3D%22%2Frun%2Fofport_requests.%24%7BBRIDGE_NAME%7D%22%0A%0A%23%20Declare%20a%20new%20associative%20array.%20If%20CONFIGURATION_FILE%20exists%2C%20source%20entries%20from%20there%0Adeclare%20-A%20INTERFACES%0Aif%20%5B%20-f%20%22%24%7BCONFIGURATION_FILE%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Sourcing%20configuration%20file%20'%24%7BCONFIGURATION_FILE%7D'%20with%20contents%3A%22%0A%20%20%20%20cat%20%22%24%7BCONFIGURATION_FILE%7D%22%0A%20%20%20%20source%20%22%24%7BCONFIGURATION_FILE%7D%22%0Afi%0A%0A%23%20get_interface_ofport_request%20will%20return%0A%23%20*%20either%3A%20the%20current%20ofport%20assignment%20for%20the%20port%20if%20no%20interface%20has%20claimed%20this%20ofport%20number%2C%20yet%0A%23%20*%20or%3A%20%20%20%20%20the%20lowest%20available%20free%20ofport%20number%0Afunction%20get_interface_ofport_request()%20%7B%0A%20%20%20%20%23%20Build%20an%20array%20that%20only%20contains%20the%20currently%20reserved%20ofport_requests%0A%20%20%20%20declare%20-A%20ofport_requests%0A%20%20%20%20for%20interface_name%20in%20%22%24%7B!INTERFACES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%20%20%20%20ofport_requests%5B%24%7BINTERFACES%5B%24interface_name%5D%7D%5D%3D%24%7BINTERFACES%5B%24interface_name%5D%7D%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20Get%20the%20current%20ofport%20number%20assignment%0A%20%20%20%20local%20current_ofport%3D%24(ovs-vsctl%20get%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport)%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20still%20free%2C%20use%20it%0A%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24current_ofport%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%24current_ofport%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20not%20free%2C%20return%20the%20lowest%20free%20entry%0A%20%20%20%20i%3D0%0A%20%20%20%20for%20i%20in%20%7B1..65000%7D%3B%20do%0A%20%20%20%20%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24i%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%24i%0A%20%20%20%20%20%20%20%20%20%20%20%20return%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20if%20we%20still%20cannot%20find%20an%20ID%2C%20exit%20with%20an%20error%0A%20%20%20%20echo%20%22Impossible%20to%20find%20an%20ofport%20ID%20for%20interface%20%24%7BINTERFACE_NAME%7D%22%20%3E%262%0A%20%20%20%20exit%201%0A%7D%0A%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20exists%2C%20use%20that%20value%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20does%20not%20exists%2C%20use%20the%20value%20from%20get_interface_ofport_request%0Aif%20!%20%5B%20%22%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20INTERFACES%5B%24INTERFACE_NAME%5D%3D%24(get_interface_ofport_request)%0Afi%0A%23%20Set%20ofport_request%20according%20to%20INTERFACES%5BINTERFACE_NAME%5D%0Aovs-vsctl%20set%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport_request%3D%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%7D%0A%0A%23%20Save%20current%20state%20of%20INTERFACES%20to%20CONFIGURATION_FILE%0Adeclare%20-p%20INTERFACES%20%3E%7C%20%22%24%7BCONFIGURATION_FILE%7D%22%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/pre-up.d/10-ofport-request.sh
        - contents:
            source: data:,%7B%22auths%22%3A%7B%22cloud.openshift.com%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfN2JmN2FjMTAyMDMxNDY1N2EwZjdiMDdiNDNjM2FiZDg6OE1YQ0gyTldMSktPVU9DQk5UNk9NSERPUzc2NkYxTURFTjlXQjhXN0xTTUtDNjk1NjI0N1c1OFUySzFDRUcwVw%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22quay.io%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfN2JmN2FjMTAyMDMxNDY1N2EwZjdiMDdiNDNjM2FiZDg6OE1YQ0gyTldMSktPVU9DQk5UNk9NSERPUzc2NkYxTURFTjlXQjhXN0xTTUtDNjk1NjI0N1c1OFUySzFDRUcwVw%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22registry.ci.openshift.org%22%3A%7B%22auth%22%3A%22c2VydmljZWFjY291bnQ6ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNkluWjBaVmc1TVVkUlpGRjZRME5OWkVWa2JGOXNTSG90YlVSd2EwRlVPR2RzWjJoUVRtMVBkamxLUmpBaWZRLmV5SmhkV1FpT2xzaWFIUjBjSE02THk5amFTMWtkakp1Y0MxdmFXUmpMbk16TG1GdFlYcHZibUYzY3k1amIyMGlYU3dpWlhod0lqb3hOek0wTlRNd05EWXlMQ0pwWVhRaU9qRTNNekl4TVRFeU5qSXNJbWx6Y3lJNkltaDBkSEJ6T2k4dlkya3RaSFl5Ym5BdGIybGtZeTV6TXk1aGJXRjZiMjVoZDNNdVkyOXRJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5STZleUp1WVcxbGMzQmhZMlVpT2lKamFTSXNJbk5sWTNKbGRDSTZleUp1WVcxbElqb2lkRzlyWlc0dFltOTFibVF0YjJKcVpXTjBMVEVpTENKMWFXUWlPaUkxWkRJd1pHUTBNQzFqT1RCaExUUXpNVFl0WVdNd05DMW1OVGczT0RFeVpUVTFZamdpZlN3aWMyVnlkbWxqWldGalkyOTFiblFpT25zaWJtRnRaU0k2SW1sdFlXZGxMWEIxYkd4bGNpSXNJblZwWkNJNkltRTNOMlk1TkdFeUxXVXdOelV0TkRGaU9DMDVPV1JoTFdRMlpEbGtNbUZpTlRGak9TSjlmU3dpYm1KbUlqb3hOek15TVRFeE1qWXlMQ0p6ZFdJaU9pSnplWE4wWlcwNmMyVnlkbWxqWldGalkyOTFiblE2WTJrNmFXMWhaMlV0Y0hWc2JHVnlJbjAuVGFqMktGY1JOV0FIRHJGT0NPQjBhWUJGUTUwVW9FUmdXMWFZYUNTVTQ0NF9jdnpCOFJDamNxR04xdV9jOFRRbFBDNXU0NG5JNklaYTdvU1RnMUh4dE9aQmEyYW5OS0JPMk5UNVF5WEhhX0R5cVJlaUUxb0YtcmphRms2TEJrNWllT1BSWXJHbklpWlJJNkQ2S0kxMmxJVFZQdFBPYUgtaXFuNV9LMXdOcmR4SDhYb2dCdlJ5UlJwRDBLTUxGNkJfeFBzbi1VeHVQQklIbjVRTFlXSkJtOVFMRVlIM0tzZDN2by03Uzc0anlZMkswMUF1OUpwYkFFR3k4Z2lyUDE1YlRnUXJReW1zS1NrbFN6U3BUbEM0MDJxVjNBanVPSjA4eGxrSE5VeXJROFk3dklJWDFBUUVmbHJaaC13ZVcyVy1aNWtnZjFOMXhNVVl6QnplZW5BZF9n%22%7D%2C%22registry.connect.redhat.com%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLWU3NDlmYWFiLTM0ZjktNDg0ZS1hNWQwLTJkNzFhMzgzMTg1MjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSXpORGszTURVMU5URTFObUkwTXpOaFltVmxNRGt5TVRJM09UZzNZV0V5WVNKOS50MUxtR0FhMTQzdnJIWG13RFZVVjNYaWhYa203Vk95bDFLek9kZm9QN0tTd3NqVFpKeUlSN1lKQjNyNGxGN3pVNWMwa0ZyOVYweUtwSFdPRU94clhJekVSaXlfOXkwQzRxbXRDOUhYNjJNVThsdmJtQW9GSXhZbHZXWnREVXVQZWgzSVFqS25CN2FJYlZ6MFJ3SWZWYVZucXFOUzhHbDNFcDRTUjVpNGZmUzE5akJCUnpxdmxBSjF6QkNVWWI3S1ZLTHVGRHJsNjdNNy1rWWwxTUhseTRBN2JVdjVISU5MaEhOdDVfRk5JX3RWbjdQM0RzQkVjcWxkWTd0Y0J4UlNoLTdQbWpzMGJEWm9ZZTZ6by1QY25TeEY0RV94QzF6aGZYYUNpdEU4UVZTUmk2MjhnM1c4WjVQQzc4VFBJWGtvaTBJWG9IX1E4QTd4SDlKaDhsWWhTTnBCaUxHODMyaFNhRUdtYkEtaU5kd3BrTGk0a0oyeTlYWE55ZlNUbU1mRUppUGwyWEI5VXRTT3lva05XU0ZqVk1kZ3l5WFlaUWtTNGh6Ql83VkpzTEh6RHpKaTJGcUZNNE56LW5Qd28zalZ3c3d3YXgzUUZZVUk2YzA5MVZnT0NUdEtpeEJXeTBaVEZyT3hEVDh4ZFRQOXcxY1JoR1N1UzU5WG55c2I2bndDLWQ5ZS11SWZpS2x4dDNZNkJaUkhRYmVUZlRtdGFoMUxOYWhRaXRzclVubVBjZXhnLVFXdzhCS3VENUFwbFc3eFVHcm9Lb1lkSEowVTJtc0ZWcjhZZ2FjVDl1UC1hWGUtTHd0dnJ3ZG1fWGtVdWRMRnFsRklxby1lWTdhVE03Xy1HRk8xWE8xTTIwQWVtSU5oUXJqUkN4TGRJeXlMSU9uOURBZUdYeGc5bUJiWQ%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22registry.redhat.io%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLWU3NDlmYWFiLTM0ZjktNDg0ZS1hNWQwLTJkNzFhMzgzMTg1MjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSXpORGszTURVMU5URTFObUkwTXpOaFltVmxNRGt5TVRJM09UZzNZV0V5WVNKOS50MUxtR0FhMTQzdnJIWG13RFZVVjNYaWhYa203Vk95bDFLek9kZm9QN0tTd3NqVFpKeUlSN1lKQjNyNGxGN3pVNWMwa0ZyOVYweUtwSFdPRU94clhJekVSaXlfOXkwQzRxbXRDOUhYNjJNVThsdmJtQW9GSXhZbHZXWnREVXVQZWgzSVFqS25CN2FJYlZ6MFJ3SWZWYVZucXFOUzhHbDNFcDRTUjVpNGZmUzE5akJCUnpxdmxBSjF6QkNVWWI3S1ZLTHVGRHJsNjdNNy1rWWwxTUhseTRBN2JVdjVISU5MaEhOdDVfRk5JX3RWbjdQM0RzQkVjcWxkWTd0Y0J4UlNoLTdQbWpzMGJEWm9ZZTZ6by1QY25TeEY0RV94QzF6aGZYYUNpdEU4UVZTUmk2MjhnM1c4WjVQQzc4VFBJWGtvaTBJWG9IX1E4QTd4SDlKaDhsWWhTTnBCaUxHODMyaFNhRUdtYkEtaU5kd3BrTGk0a0oyeTlYWE55ZlNUbU1mRUppUGwyWEI5VXRTT3lva05XU0ZqVk1kZ3l5WFlaUWtTNGh6Ql83VkpzTEh6RHpKaTJGcUZNNE56LW5Qd28zalZ3c3d3YXgzUUZZVUk2YzA5MVZnT0NUdEtpeEJXeTBaVEZyT3hEVDh4ZFRQOXcxY1JoR1N1UzU5WG55c2I2bndDLWQ5ZS11SWZpS2x4dDNZNkJaUkhRYmVUZlRtdGFoMUxOYWhRaXRzclVubVBjZXhnLVFXdzhCS3VENUFwbFc3eFVHcm9Lb1lkSEowVTJtc0ZWcjhZZ2FjVDl1UC1hWGUtTHd0dnJ3ZG1fWGtVdWRMRnFsRklxby1lWTdhVE03Xy1HRk8xWE8xTTIwQWVtSU5oUXJqUkN4TGRJeXlMSU9uOURBZUdYeGc5bUJiWQ%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%7D%7D%0A
          mode: 384
          overwrite: true
          path: /var/lib/kubelet/config.json
        - contents:
            source: data:,%23%20Needed%20by%20the%20OpenShift%20SDN.%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1758552%0Anet.ipv4.conf.all.arp_announce%20%3D%202%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/arp.conf
        - contents:
            source: data:,%23%20See%3A%20rhbz%231384746%2C%20OCPBUGS-24012%0Anet.ipv4.neigh.default.gc_thresh1%3D8192%0Anet.ipv4.neigh.default.gc_thresh2%3D32768%0Anet.ipv4.neigh.default.gc_thresh3%3D65536%0Anet.ipv6.neigh.default.gc_thresh1%3D8192%0Anet.ipv6.neigh.default.gc_thresh2%3D32768%0Anet.ipv6.neigh.default.gc_thresh3%3D65536%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/gc-thresh.conf
        - contents:
            source: data:,%0Afs.inotify.max_user_watches%20%3D%2065536%0Afs.inotify.max_user_instances%20%3D%208192%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/inotify.conf
        - contents:
            source: data:,vm.unprivileged_userfaultfd%20%3D%201
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/enable-userfaultfd.conf
        - contents:
            source: data:,%23%20Needed%20for%20OpenShift%20Logging%20(ElasticSearch).%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1793714%0Avm.max_map_count%20%3D%20262144%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/vm-max-map.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%20-o%20pipefail%0A%0ANODEENV%3D%2Fetc%2Fkubernetes%2Fnode.env%0A%0A%23%20This%20can%20be%20removed%201%20release%20after%20it%20merges%20because%20all%20affected%20nodes%0A%23%20will%20have%20upgraded%0ALEGACY_NODEENV%3D%2Fetc%2Fsystemd%2Fsystem%2Fkubelet.service.d%2F20-aws-node-name.conf%0Aif%20%5B%20-e%20%22%24%7BLEGACY_NODEENV%7D%22%20%5D%3B%20then%0A%20%20%20%20%23%20Legacy%20file%20was%20a%20systemd%20stanza%20with%20KUBELET_NODE_NAME%20specified%20in%0A%20%20%20%20%23%20a%20directive%20of%20the%20format%3A%0A%20%20%20%20%23%20%20%20Environment%3D%22KUBELET_NODE_NAME%3Dnode.example.com%22%0A%20%20%20%20%23%20New%20format%20is%20an%20environment%20file.%20The%20following%20extracts%20only%20the%0A%20%20%20%20%23%20contents%20of%20any%20Environment%20directives.%0A%20%20%20%20echo%20%22Migrating%20%24%7BLEGACY_NODEENV%7D%20to%20%24%7BNODEENV%7D%22%0A%20%20%20%20awk%20'match(%240%2C%20%2F%5E%5Cs*Environment%5Cs*%3D%5Cs*%22(.*)%22%5Cs*%24%2F%2C%20value)%20%7B%20print%20value%5B1%5D%20%7D'%20%3C%20%22%24%7BLEGACY_NODEENV%7D%22%20%3E%20%22%24%7BNODEENV%7D%22%0A%20%20%20%20rm%20%22%24%7BLEGACY_NODEENV%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20-e%20%22%24%7BNODEENV%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Not%20replacing%20existing%20%24%7BNODEENV%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20afterburn%20service%20is%20expected%20to%20be%20used%20for%20metadata%20retrival%2C%20see%20respective%20systemd%20unit.%0A%23%20However%2C%20on%20older%20OCP%20boot%20images%20does%20not%20contain%20afterburn%20service%2C%20check%20if%20afterburn%20variables%20are%20there%0A%23%20otherwise%20try%20to%20communicate%20IMDS%20here.%0A%23%20metadata%20related%20afterburn%20doc%3A%20https%3A%2F%2Fcoreos.github.io%2Fafterburn%2Fusage%2Fattributes%2F%0A%0AHOSTNAME%3D%24%7BAFTERBURN_AWS_HOSTNAME%3A-%7D%0Awhile%20%5B%5B%20-z%20%22%24%7BHOSTNAME%7D%22%20%5D%5D%3B%20do%0A%20%20HOSTNAME%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Flocal-hostname)%0A%20%20if%20%5B%5B%20-z%20%22%24%7BHOSTNAME%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Can%20not%20obtain%20hostname%20from%20the%20metadata%20service.%22%201%3E%262%0A%20%20%20%20sleep%205%0A%20%20fi%20%0Adone%0A%0A%23%20For%20compatibility%20with%20the%20AWS%20in-tree%20provider%0A%23%20Set%20node%20name%20to%20be%20instance%20FQDN%20instead%20of%20the%20default%20hostname%0Acat%20%3E%20%22%24%7BNODEENV%7D%22%20%3C%3CEOF%0AKUBELET_NODE_NAME%3D%24%7BHOSTNAME%25%25%20*%7D%0AEOF%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/aws-kubelet-nodename
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%20-o%20pipefail%0A%0ANODECONF%3D%2Fetc%2Fsystemd%2Fsystem%2Fkubelet.service.d%2F20-aws-providerid.conf%0A%0Aif%20%5B%20-e%20%22%24%7BNODECONF%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Not%20replacing%20existing%20%24%7BNODECONF%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20afterburn%20service%20is%20expected%20to%20be%20used%20for%20metadata%20retrival%2C%20see%20respective%20systemd%20unit.%0A%23%20However%2C%20on%20older%20OCP%20boot%20images%20does%20not%20contain%20afterburn%20service%2C%20check%20if%20afterburn%20variables%20are%20there%0A%23%20otherwise%20try%20to%20communicate%20IMDS%20here.%0A%23%20metadata%20related%20afterburn%20doc%3A%20https%3A%2F%2Fcoreos.github.io%2Fafterburn%2Fusage%2Fattributes%2F%0A%0AINSTANCE_ID%3D%24%7BAFTERBURN_AWS_INSTANCE_ID%3A-%7D%0AAVAILABILITY_ZONE%3D%24%7BAFTERBURN_AWS_AVAILABILITY_ZONE%3A-%7D%0Aif%20%5B%5B%20-z%20%22%24%7BINSTANCE_ID%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20-z%20%22%24%7BAVAILABILITY_ZONE%7D%22%20%5D%5D%3B%20then%0A%20%20INSTANCE_ID%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Finstance-id)%0A%20%20AVAILABILITY_ZONE%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Fplacement%2Favailability-zone)%0A%20%20if%20%5B%5B%20-z%20%22%24%7BINSTANCE_ID%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20-z%20%22%24%7BAVAILABILITY_ZONE%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Can%20not%20obtain%20instance-id%20and%20availability%20zone%20info%20from%20the%20metadata%20service.%22%0A%20%20%20%20exit%201%0A%20%20fi%20%0Afi%0A%0A%23%20Due%20to%20a%20potential%20mismatch%20between%20Hostname%20and%20PrivateDNSName%20with%20clusters%20that%20use%20custom%20DHCP%20Option%20Sets%0A%23%20which%20can%20cause%20issues%20in%20cloud%20controller%20manager%20node%20syncing%0A%23%20(see%3A%20https%3A%2F%2Fgithub.com%2Fkubernetes%2Fcloud-provider-aws%2Fissues%2F384)%2C%0A%23%20set%20KUBELET_PROVIDERID%20to%20be%20a%20fully%20qualified%20AWS%20instace%20provider%20id.%0A%23%20This%20new%20variable%20is%20later%20used%20to%20populate%20the%20kubelet's%20%60provider-id%60%20flag%2C%20later%20set%20on%20the%20Node%20.spec%0A%23%20and%20used%20by%20the%20cloud%20controller%20manager's%20node%20controller%20to%20retrieve%20the%20Node's%20backing%20instance.%0Acat%20%3E%20%22%24%7BNODECONF%7D%22%20%3C%3CEOF%0A%5BService%5D%0AEnvironment%3D%22KUBELET_PROVIDERID%3Daws%3A%2F%2F%2F%24%7BAVAILABILITY_ZONE%7D%2F%24%7BINSTANCE_ID%7D%22%0AEOF%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/aws-kubelet-providerid
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20First%2C%20we%20need%20to%20wait%20until%20DHCP%20finishes%20and%20the%20node%20has%20a%20non-%60localhost%60%0A%23%20hostname%20before%20%60kubelet.service%60%20starts.%0A%23%20That's%20the%20%60--wait%60%20argument%20as%20used%20by%20%60node-valid-hostname.service%60.%0A%23%0A%23%20Second%2C%20on%20GCP%20specifically%20we%20truncate%20the%20hostname%20if%20it's%20%3E63%20characters.%0A%23%20That's%20%60gcp-hostname.service%60.%0A%0A%23%20Block%20indefinitely%20until%20the%20host%20gets%20a%20non-localhost%20name.%0A%23%20Note%20node-valid-hostname.service%20uses%20systemd%20to%20abort%20if%20this%20takes%20too%20long.%0Await_localhost()%20%7B%0A%20%20%20%20echo%20%22waiting%20for%20non-localhost%20hostname%20to%20be%20assigned%22%0A%20%20%20%20while%20%5B%5B%20%22%24(%3C%20%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%20%3D~%20(localhost%7Clocalhost.localdomain)%20%5D%5D%3B%0A%20%20%20%20do%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20done%0A%20%20%20%20echo%20%22node%20identified%20as%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%0A%20%20%20%20echo%20%22saving%20hostname%20to%20prevent%20NetworkManager%20from%20ever%20unsetting%20it%22%0A%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_gcp_hostname()%20%7B%0A%20%20%20%20%2Fusr%2Fbin%2Fafterburn%20--provider%20gcp%20--hostname%3D%2Frun%2Fafterburn.hostname%0A%0A%20%20%20%20local%20host_name%3D%24(cat%20%2Frun%2Fafterburn.hostname)%0A%20%20%20%20local%20type_arg%3D%22transient%22%0A%0A%20%20%20%20%23%20%2Fetc%2Fhostname%20is%20used%20for%20static%20hostnames%20and%20is%20authoritative.%0A%20%20%20%20%23%20This%20will%20check%20to%20make%20sure%20that%20the%20static%20hostname%20is%20the%0A%20%20%20%20%23%20less%20than%20or%20equal%20to%2063%20characters%20in%20length.%0A%20%20%20%20if%20%5B%20-f%20%2Fetc%2Fhostname%20%5D%20%26%26%20%5B%20%22%24(cat%20%2Fetc%2Fhostname%20%7C%20wc%20-m)%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20etc_name%3D%22%24(%3C%20%2Fetc%2Fhostname)%22%0A%20%20%20%20%20%20%20%20type_arg%3D%22static%22%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24%7Betc_name%7D%22%20!%3D%20%22%24%7Bhost_name%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%2Fetc%2Fhostname%20is%20set%20to%20%24%7Betc_name%7D%20but%20does%20not%20match%20%24%7Bhost_name%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22using%20%2Fetc%2Fhostname%20as%20the%20authoritative%20name%22%0A%20%20%20%20%20%20%20%20%20%20%20%20host_name%3D%22%24%7Betc_name%7D%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Only%20mutate%20the%20hostname%20if%20the%20length%20is%20longer%20than%2063%20characters.%20The%0A%20%20%20%20%23%20hostname%20will%20be%20the%20lesser%20of%2063%20characters%20after%20the%20first%20dot%20in%20the%0A%20%20%20%20%23%20FQDN.%20%20This%20algorithm%20is%20only%20known%20to%20work%20in%20GCP%2C%20and%20hence%20is%20only%0A%20%20%20%20%23%20executed%20in%20GCP.%0A%20%20%20%20if%20%5B%20%22%24%7B%23host_name%7D%22%20-gt%2063%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20alt_name%3D%24(printf%20%22%24%7Bhost_name%7D%22%20%7C%20cut%20-f1%20-d'.'%20%7C%20cut%20-c%20-63)%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Bhost_name%7D%20is%20longer%20than%2063%20characters%2C%20using%20truncated%20hostname%22%0A%20%20%20%20%20%20%20%20host_name%3D%22%24%7Balt_name%7D%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22setting%20%24%7Btype_arg%7D%20hostname%20to%20%24%7Bhost_name%7D%22%0A%20%20%20%20%2Fbin%2Fhostnamectl%20%22--%24%7Btype_arg%7D%22%20set-hostname%20%22%24%7Bhost_name%7D%22%0A%20%20%20%20exit%200%0A%7D%0A%0Aarg%3D%24%7B1%7D%3B%20shift%3B%0Acase%20%22%24%7Barg%7D%22%20in%0A%20%20%20%20--wait)%20wait_localhost%3B%3B%0A%20%20%20%20--gcp)%20set_gcp_hostname%3B%3B%0A%20%20%20%20*)%20echo%20%22Unhandled%20arg%20%24arg%22%3B%20exit%201%0Aesac%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/mco-hostname
        - contents:
            source: data:,
          mode: 493
          overwrite: true
          path: /etc/kubernetes/kubelet-plugins/volume/exec/.dummy
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1941714%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1935539%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1987108%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22vmxnet3%22%20%5D%5D%3B%20then%0A%20%20logger%20-s%20%2299-vsphere-disable-tx-udp-tnl%20triggered%20by%20%24%7B2%7D%20on%20device%20%24%7BDEVICE_IFACE%7D.%22%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-csum-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksum-ip-generic%20off%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-vsphere-disable-tx-udp-tnl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0Aif%20%5B%20!%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20%23%20No%20need%20to%20do%20this%20if%20no%20NMState%20configuration%20was%20applied%0A%20%20exit%200%0Afi%0A%0A%23%20This%20logic%20is%20borrowed%20from%20configure-ovs.sh%0A%23%20TODO%3A%20Find%20a%20platform-agnostic%20way%20to%20do%20this.%20It%20won't%20work%20on%20platforms%20where%0A%23%20nodeip-configuration%20is%20not%20used.%0Aip%3D%24(cat%20%2Frun%2Fnodeip-configuration%2Fprimary-ip)%0Aif%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20echo%20%22No%20ip%20to%20bind%20was%20found%22%0A%20%20exit%201%0Afi%0Awhile%20%3A%0Ado%0A%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%20%20sleep%2010%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-primary-ip.sh
        - contents:
            source: data:,unqualified-search-registries%20%3D%20%5B'registry.access.redhat.com'%2C%20'docker.io'%5D%0A
          mode: 420
          overwrite: true
          path: /etc/containers/registries.conf
        - contents:
            source: data:,%5Bcrio%5D%0Ainternal_wipe%20%3D%20true%0Ainternal_repair%20%3D%20true%0A%0A%5Bcrio.api%5D%0Astream_address%20%3D%20%22127.0.0.1%22%0Astream_port%20%3D%20%220%22%0A%0A%5Bcrio.runtime%5D%0Aselinux%20%3D%20true%0Aconmon%20%3D%20%22%22%0Aconmon_cgroup%20%3D%20%22pod%22%0Adefault_env%20%3D%20%5B%0A%20%20%20%20%22NSS_SDB_USE_CACHE%3Dno%22%2C%0A%5D%0Alog_level%20%3D%20%22info%22%0Acgroup_manager%20%3D%20%22systemd%22%0Adefault_sysctls%20%3D%20%5B%0A%20%20%20%20%22net.ipv4.ping_group_range%3D0%202147483647%22%2C%0A%5D%0Adefault_runtime%20%3D%20%22crun%22%0Ahooks_dir%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Frun%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Fusr%2Fshare%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%5D%0Amanage_ns_lifecycle%20%3D%20true%0Aabsent_mount_sources_to_reject%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fhostname%22%2C%0A%5D%0Adrop_infra_ctr%20%3D%20true%0A%0A%5Bcrio.runtime.runtimes.runc%5D%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%0A%5Bcrio.runtime.runtimes.crun%5D%0Aruntime_root%20%3D%20%22%2Frun%2Fcrun%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%23%20Based%20on%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcrun%2Fblob%2F27d7dd3a0%2FREADME.md%3Fplain%3D1%23L48%0Acontainer_min_memory%20%3D%20%22512KiB%22%0A%0A%5Bcrio.runtime.workloads.openshift-builder%5D%0Aactivation_annotation%20%3D%20%22io.openshift.builder%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%22io.kubernetes.cri-o.userns-mode%22%2C%0A%20%20%22io.kubernetes.cri-o.Devices%22%0A%5D%0A%5Bcrio.runtime.workloads.openshift-builder.resources%5D%0A%0A%5Bcrio.image%5D%0Aglobal_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_image%20%3D%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A4f60bb3e2e42085b82096277c09906c2fc64083a9d8d5aba56c177aa547c4b7f%22%0Apause_image_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_command%20%3D%20%22%2Fusr%2Fbin%2Fpod%22%0A%0A%5Bcrio.network%5D%0Anetwork_dir%20%3D%20%22%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F%22%0Aplugin_dirs%20%3D%20%5B%0A%20%20%20%20%22%2Fvar%2Flib%2Fcni%2Fbin%22%2C%0A%20%20%20%20%22%2Fusr%2Flibexec%2Fcni%22%2C%0A%5D%0A%0A%5Bcrio.metrics%5D%0Aenable_metrics%20%3D%20true%0Ametrics_host%20%3D%20%22127.0.0.1%22%0Ametrics_port%20%3D%209537%0Ametrics_collectors%20%3D%20%5B%0A%20%20%22operations%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_total%22%0A%20%20%22operations_latency_microseconds_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds_total%22%0A%20%20%22operations_latency_microseconds%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds%22%0A%20%20%22operations_errors%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_errors_total%22%0A%20%20%22image_pulls_layer_size%22%2C%0A%20%20%22containers_oom_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22containers_oom_count_total%22%0A%20%20%22containers_oom%22%2C%0A%20%20%23%20Drop%20metrics%20with%20excessive%20label%20cardinality.%0A%20%20%23%20%22image_pulls_by_digest%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name_skipped%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_skipped_bytes_total%22%0A%20%20%23%20%22image_pulls_failures%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_failure_total%22%0A%20%20%23%20%22image_pulls_successes%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_success_total%22%0A%20%20%23%20%22image_layer_reuse%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_layer_reuse_total%22%0A%20%20%22operations_total%22%2C%0A%20%20%22operations_latency_seconds_total%22%2C%0A%20%20%22operations_latency_seconds%22%2C%0A%20%20%22operations_errors_total%22%2C%0A%20%20%22image_pulls_bytes_total%22%2C%0A%20%20%22image_pulls_skipped_bytes_total%22%2C%0A%20%20%22image_pulls_success_total%22%2C%0A%20%20%22image_pulls_failure_total%22%2C%0A%20%20%22image_layer_reuse_total%22%2C%0A%20%20%22containers_oom_count_total%22%2C%0A%20%20%22processes_defunct%22%0A%5D%0A
          mode: 420
          overwrite: true
          path: /etc/crio/crio.conf.d/00-default
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D
          mode: 420
          overwrite: true
          path: /etc/containers/policy.json
        - contents:
            source: data:,%5BGlobal%5D
          mode: 420
          overwrite: true
          path: /etc/kubernetes/cloud.conf
        - contents:
            source: data:,authorization%3A%0A%20%20static%3A%0A%20%20%20%20-%20resourceRequest%3A%20false%0A%20%20%20%20%20%20path%3A%20%2Fmetrics%0A%20%20%20%20%20%20verb%3A%20get%0A%20%20%20%20%20%20user%3A%0A%20%20%20%20%20%20%20%20name%3A%20system%3Aserviceaccount%3Aopenshift-monitoring%3Aprometheus-k8s
          mode: 420
          overwrite: true
          path: /etc/kubernetes/crio-metrics-proxy.cfg
        - contents:
            source: data:,apiVersion%3A%20v1%0Akind%3A%20Pod%0Ametadata%3A%0A%20%20name%3A%20kube-rbac-proxy-crio%0A%20%20namespace%3A%20openshift-machine-config-operator%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20etc-kube%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20hostNetwork%3A%20true%0A%20%20priorityClassName%3A%20system-cluster-critical%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20setup%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A4c0c2e423c4481a1e5ecd844aa6a62c3ee3f26edb40642056d802a14d2fd46f6%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20command%3A%20%5B'%2Fbin%2Fbash'%2C%20'-ec'%5D%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20echo%20-n%20%22Waiting%20for%20kubelet%20key%20and%20certificate%20to%20be%20available%22%0A%20%20%20%20%20%20while%20%5B%20-n%20%22%24(test%20-e%20%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem)%22%20%5D%20%3B%20do%0A%20%20%20%20%20%20%20%20echo%20-n%20%22.%22%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20%20%20%20%20((%20tries%20%2B%3D%201%20))%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20%22%24%7Btries%7D%22%20-gt%2010%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Timed%20out%20waiting%20for%20kubelet%20key%20and%20cert.%22%0A%20%20%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20done%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20%20%20%20%20cpu%3A%205m%0A%20%20containers%3A%0A%20%20-%20name%3A%20kube-rbac-proxy-crio%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A4c0c2e423c4481a1e5ecd844aa6a62c3ee3f26edb40642056d802a14d2fd46f6%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20ports%3A%0A%20%20%20%20-%20containerPort%3A%209637%0A%20%20%20%20args%3A%0A%20%20%20%20-%20--secure-listen-address%3D%3A9637%0A%20%20%20%20-%20--config-file%3D%2Fetc%2Fkubernetes%2Fcrio-metrics-proxy.cfg%0A%20%20%20%20-%20--client-ca-file%3D%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20%20%20-%20--logtostderr%3Dtrue%0A%20%20%20%20-%20--kubeconfig%3D%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%0A%20%20%20%20-%20--tls-cipher-suites%3DTLS_AES_128_GCM_SHA256%2CTLS_AES_256_GCM_SHA384%2CTLS_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%20%0A%20%20%20%20-%20--tls-min-version%3DVersionTLS12%0A%20%20%20%20-%20--upstream%3Dhttp%3A%2F%2F127.0.0.1%3A9537%0A%20%20%20%20-%20--tls-cert-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20-%20--tls-private-key-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%2020m%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20etc-kube%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/criometricsproxy.yaml
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,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
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
        - contents:
            source: data:,%23!%2Fbin%2Fsh%0Aif%20%5B%20-x%20%2Fusr%2Fbin%2Fkubensenter%20%5D%3B%20then%0A%20%20exec%20%2Fusr%2Fbin%2Fkubensenter%20%22%24%40%22%0Aelse%0A%20%20exec%20%22%24%40%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/kubenswrapper
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Cleans NetworkManager state generated by dracut
            # Removal of this file signals firstboot completion
            ConditionPathExists=!/etc/ignition-machine-config-encapsulated.json
            # This is opt-in for some deployment types, and opt-out for others.
            ConditionPathExists=/var/lib/mco/nm-clean-initrd-state
            Wants=network-pre.target
            Before=network-pre.target

            [Service]
            Type=oneshot
            # Remove any existing state possibly generated NM run by dracut. We want NM to
            # consider all profiles autoconnect priority when it starts instead of
            # remembering which profile was a device activated with when NM is run by
            # dracut.
            ExecStart=/usr/local/bin/nm-clean-initrd-state.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: NetworkManager-clean-initrd-state.service
        - contents: |
            [Unit]
            Description=Fetch kubelet node name from AWS Metadata

            # Run afterburn service for collect info from metadata server
            # see: https://coreos.github.io/afterburn/usage/attributes/
            # Not required due to OCP 4.1 boot image does not contain afterburn service
            # see: https://issues.redhat.com/browse/OCPBUGS-7559
            Wants=afterburn.service
            After=afterburn.service

            # Wait for NetworkManager to report it's online
            After=NetworkManager-wait-online.service
            # Run before kubelet
            Before=kubelet-dependencies.target

            [Service]
            # Mark afterburn environment file optional, due to it is possible that afterburn service was not executed
            EnvironmentFile=-/run/metadata/afterburn
            ExecStart=/usr/local/bin/aws-kubelet-nodename
            Type=oneshot

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: aws-kubelet-nodename.service
        - contents: |
            [Unit]
            Description=Fetch kubelet provider id from AWS Metadata

            # Run afterburn service for collect info from metadata server
            # see: https://coreos.github.io/afterburn/usage/attributes/
            # Not required due to OCP 4.1 boot image does not contain afterburn service
            # see: https://issues.redhat.com/browse/OCPBUGS-7559
            Wants=afterburn.service
            After=afterburn.service

            # Wait for NetworkManager to report it's online
            After=NetworkManager-wait-online.service
            # Run before kubelet
            Before=kubelet-dependencies.target

            [Service]
            # Mark afterburn environment file optional, due to it is possible that afterburn service was not executed
            EnvironmentFile=-/run/metadata/afterburn
            ExecStart=/usr/local/bin/aws-kubelet-providerid
            Type=oneshot

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: aws-kubelet-providerid.service
        - dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="ENABLE_PROFILE_UNIX_SOCKET=true"
            name: 10-mco-profile-unix-socket.conf
          - contents: |
              [Unit]
              After=kubelet-dependencies.target
              Requires=kubelet-dependencies.target
            name: 05-mco-ordering.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: crio.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: docker.socket
        - contents: |
            [Unit]
            Description=The firstboot OS update has completed
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target

            [Install]
            WantedBy=default.target
          enabled: true
          name: firstboot-osupdate.target
        - contents: |
            [Unit]
            Description=Dynamically sets the system reserved for the kubelet
            Wants=network-online.target
            After=network-online.target firstboot-osupdate.target
            Before=kubelet-dependencies.target

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            RemainAfterExit=yes
            EnvironmentFile=/etc/node-sizing-enabled.env
            ExecStart=/bin/bash /usr/local/sbin/dynamic-system-reserved-calc.sh ${NODE_SIZING_ENABLED} ${SYSTEM_RESERVED_MEMORY} ${SYSTEM_RESERVED_CPU} ${SYSTEM_RESERVED_ES}
            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: kubelet-auto-node-size.service
        - contents: |
            [Unit]
            Description=Dependencies necessary to run kubelet
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target network-online.target
            Wants=NetworkManager-wait-online.service crio-wipe.service
            Wants=rpc-statd.service chrony-wait.service
          name: kubelet-dependencies.target
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet
            Requires=crio.service kubelet-dependencies.target
            After=kubelet-dependencies.target
            After=ostree-finalize-staged.service

            [Service]
            Type=notify
            ExecStartPre=/bin/mkdir --parents /etc/kubernetes/manifests
            ExecStartPre=-/usr/sbin/restorecon -rv /var/lib/kubelet/ /usr/local/bin/kubenswrapper /usr/bin/kubensenter
            Environment="KUBELET_NODE_IP=0.0.0.0"
            EnvironmentFile=/etc/os-release
            EnvironmentFile=-/etc/kubernetes/kubelet-workaround
            EnvironmentFile=-/etc/kubernetes/kubelet-env
            EnvironmentFile=/etc/node-sizing.env

            ExecStart=/usr/local/bin/kubenswrapper \
                /usr/bin/kubelet \
                  --config=/etc/kubernetes/kubelet.conf \
                  --bootstrap-kubeconfig=/etc/kubernetes/kubeconfig \
                  --kubeconfig=/var/lib/kubelet/kubeconfig \
                  --container-runtime-endpoint=/var/run/crio/crio.sock \
                  --runtime-cgroups=/system.slice/crio.service \
                  --node-labels=node-role.kubernetes.io/worker,node.openshift.io/os_id=${ID} \
                  --node-ip=${KUBELET_NODE_IP} \
                  --minimum-container-ttl-duration=6m0s \
                  --volume-plugin-dir=/etc/kubernetes/kubelet-plugins/volume/exec \
                  --cloud-provider=external \
                  --image-credential-provider-bin-dir=/usr/libexec/kubelet-image-credential-provider-plugins --image-credential-provider-config=/etc/kubernetes/credential-providers/ecr-credential-provider.yaml \
                  --hostname-override=${KUBELET_NODE_NAME} \
                  --provider-id=${KUBELET_PROVIDERID} \
                  --pod-infra-container-image=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4f60bb3e2e42085b82096277c09906c2fc64083a9d8d5aba56c177aa547c4b7f \
                  --system-reserved=cpu=${SYSTEM_RESERVED_CPU},memory=${SYSTEM_RESERVED_MEMORY},ephemeral-storage=${SYSTEM_RESERVED_ES} \
                  --v=${KUBELET_LOG_LEVEL}

            Restart=always
            RestartSec=10

            [Install]
            WantedBy=multi-user.target
          dropins:
          - contents: |
              [Service]
              EnvironmentFile=/etc/kubernetes/node.env
            name: 20-node-env.conf
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          enabled: true
          name: kubelet.service
        - contents: |
            [Unit]
            Description=Manages a mount namespace for kubernetes-specific mounts

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            RuntimeDirectory=kubens
            Environment=RUNTIME_DIRECTORY=%t/kubens
            Environment=BIND_POINT=%t/kubens/mnt
            Environment=ENVFILE=%t/kubens/env

            # Set up the runtime directory as an unbindable mountpoint
            ExecStartPre=bash -c "findmnt ${RUNTIME_DIRECTORY} || mount --make-unbindable --bind ${RUNTIME_DIRECTORY} ${RUNTIME_DIRECTORY}"
            # Ensure the bind point exists
            ExecStartPre=touch ${BIND_POINT}
            # Use 'unshare' to create the new mountpoint, then 'mount --make-rshared' so it cascades internally
            ExecStart=unshare --mount=${BIND_POINT} --propagation slave mount --make-rshared /
            # Finally, set an env pointer for ease-of-use
            ExecStartPost=bash -c 'echo "KUBENSMNT=${BIND_POINT}" > "${ENVFILE}"'

            # On stop, a recursive unmount cleans up the namespace and bind-mounted unbindable parent directory
            ExecStop=umount -R ${RUNTIME_DIRECTORY}

            [Install]
            WantedBy=multi-user.target
          enabled: false
          name: kubens.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Firstboot
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # Removal of this file signals firstboot completion
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            After=machine-config-daemon-pull.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            # Disable existing repos (if any) so that OS extensions would use embedded RPMs only
            ExecStartPre=-/usr/bin/sh -c "sed -i 's/enabled=1/enabled=0/' /etc/yum.repos.d/*.repo"
            # Run this via podman because we want to use the nmstatectl binary in our container
            ExecStart=/usr/bin/podman run --rm --privileged --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2ca9b7808dd922f00fc37100229c08f005357386e4b24628faeef49222b2ea' firstboot-complete-machineconfig --persist-nics
            ExecStart=/usr/bin/podman run --rm --privileged --pid=host --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2ca9b7808dd922f00fc37100229c08f005357386e4b24628faeef49222b2ea' firstboot-complete-machineconfig
            [Install]
            RequiredBy=firstboot-osupdate.target
          enabled: true
          name: machine-config-daemon-firstboot.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Pull
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # This "stamp file" is unlinked when we complete
            # machine-config-daemon-firstboot.service
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            # Run after crio-wipe so the pulled MCD image is protected against a corrupted storage from a forced shutdown
            Wants=crio-wipe.service NetworkManager-wait-online.service
            After=crio-wipe.service NetworkManager-wait-online.service network.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStart=/bin/sh -c "while ! /usr/bin/podman pull --authfile=/var/lib/kubelet/config.json 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9a2ca9b7808dd922f00fc37100229c08f005357386e4b24628faeef49222b2ea'; do sleep 1; done"
            [Install]
            RequiredBy=machine-config-daemon-firstboot.service
          enabled: true
          name: machine-config-daemon-pull.service
        - contents: |
            [Unit]
            Description=Wait for a non-localhost hostname
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            User=root
            ExecStart=/usr/local/bin/mco-hostname --wait

            # Wait up to 5min for the node to get a non-localhost name
            TimeoutSec=300

            [Install]
            # TODO: Change this to RequiredBy after we fix https://github.com/openshift/machine-config-operator/pull/3865#issuecomment-1746963115
            WantedBy=kubelet-dependencies.target
          enabled: true
          name: node-valid-hostname.service
        - contents: |
            [Unit]
            Description=Writes IP address configuration so that kubelet and crio services select a valid node IP
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service firstboot-osupdate.target
            Before=kubelet-dependencies.target ovs-configuration.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/bin/podman run --rm \
              --authfile /var/lib/kubelet/config.json \
              --net=host \
              --security-opt label=disable \
              --volume /etc/systemd/system:/etc/systemd/system \
              --volume /run/nodeip-configuration:/run/nodeip-configuration \
              quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:cbf609319cf2f1132992bf214e94d15e30d28c22c39407835ea3235836bd5b77 \
              node-ip \
              set \
              --retry-on-failure \
              --network-type OVNKubernetes \
              ${NODEIP_HINT:-${KUBELET_NODEIP_HINT:-}}; \
              do \
              sleep 5; \
              done"
            ExecStart=/bin/systemctl daemon-reload
            ExecStartPre=/bin/mkdir -p /run/nodeip-configuration
            StandardOutput=journal+console
            StandardError=journal+console

            EnvironmentFile=-/etc/default/nodeip-configuration

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: false
          name: nodeip-configuration.service
        - enabled: true
          name: openvswitch.service
        - contents: |
            [Unit]
            # Kdump will generate it's initramfs based on the running state when kdump.service run
            # If OVS has already run, the kdump fails to gather a working network config,
            # which prevent network log exports, sush as SSH.
            # See https://issues.redhat.com/browse/OCPBUGS-28239
            After=kdump.service
            Description=Configures OVS with proper host networking configuration
            # This service is used to move a physical NIC into OVS and reconfigure OVS to use the host IP
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=firstboot-osupdate.target
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service nmstate.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            ExecStart=/usr/local/bin/configure-ovs.sh OVNKubernetes
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: ovs-configuration.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /var/lib/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /etc/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /run/openvswitch'
              ExecStartPost=-/usr/bin/ovs-appctl vlog/set syslog:info
              ExecReload=-/usr/bin/ovs-appctl vlog/set syslog:info
            name: 10-ovs-vswitchd-restart.conf
          name: ovs-vswitchd.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
            name: 10-ovsdb-restart.conf
          enabled: true
          name: ovsdb-server.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          name: pivot.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          name: rpm-ostreed.service
        - contents: |
            [Unit]
            Description=Ensure primary IP is assigned and usable
            Requires=nmstate.service
            After=nmstate.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/wait-for-primary-ip.sh; \
              do \
              sleep 10; \
              done"
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: wait-for-primary-ip.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: zincati.service
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet After Reboot Cleanup
            Before=kubelet.service

            [Service]
            Type=oneshot
            ExecStart=/bin/rm -f /var/lib/kubelet/cpu_manager_state
            ExecStart=/bin/rm -f /var/lib/kubelet/memory_manager_state
            ExecStart=-/bin/rm -f /var/lib/kubelet/dra_manager_state

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet-cleanup.service
    extensions: []
    fips: false
    kernelArguments:
    - systemd.unified_cgroup_hierarchy=1
    - cgroup_no_v1="all"
    - psi=0
    kernelType: default
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:44b6a5f0d598f4b4cc4a5556c56f2cb01f9a0330f958df5848479ca47e9b43eb
- apiVersion: machineconfiguration.openshift.io/v1
  kind: MachineConfig
  metadata:
    annotations:
      machineconfiguration.openshift.io/generated-by-controller-version: d656f31b697c2671aac38bbe46d9e5b22d27ae90
      machineconfiguration.openshift.io/release-image-version: 4.18.0-ec.3
    creationTimestamp: "2024-11-20T23:24:40Z"
    generation: 1
    name: rendered-worker-a079988a31206987bed827f0242d7b3f
    ownerReferences:
    - apiVersion: machineconfiguration.openshift.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: MachineConfigPool
      name: worker
      uid: b6b86d5e-02f1-4b15-a3da-1c04f9fcb4b3
    resourceVersion: "46713"
    uid: 1ea16ec1-ae79-43ea-a0ba-65e224524adb
  spec:
    baseOSExtensionsContainerImage: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f135a14056f31c9c21782ac194f527e358d59a67e20ccf75f08706cc68c8c980
    config:
      ignition:
        version: 3.4.0
      passwd:
        users:
        - name: core
          sshAuthorizedKeys:
          - |
            ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDLume21au7DO1U53hRBlP0FdJPJ85QEsm/ahjj3t9ZHUZkIZIZspYkAu6uahm6JReNnAbo2lDvVaVjq134BooT++WRIhk2X4hv7eUFYpBPaztjrTTG+COqLNJHZKNKa+KzRDEDk/TDsBSOgx35qZdC4l2VnJOkFXxGKMC/N4cW+NBJCdEOOz56LodPHmmIM1I0U97tuHkplw4+vMrAh8DgjoaxpijBlGOnVo3fD95EoG4D+d3RkOSsB3AsrkdyZa+A703NvSuIcofbOvXz5tBeKVlgpSyXUKywtKPr7J8UnWy3/ajGTDuY+kY/447Y+n1T5aU/iD8Xk2LTBhIZ7Z7SilYYWgV6Yr+z7DpLUqCBWlggI/Owp8XOaAPRETl3UPxFc4hKkE3cL8eu+Nw25ooUwY4Jikoq+r3WY2FCcVnQL2Rswf7z+pi8q49YaQV0mFGoow036+5f1JA/GvglDZEnKWMH8rwQw0Sw24FG+iC+1Fy6qrKoMFkz2nk4j8lZ368= nmoraiti@localhost.localdomain
      storage:
        files:
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-ex%20-o%20pipefail%0A%0ANM_DEVICES_DIR%3D%2Frun%2FNetworkManager%2Fdevices%0ANM_RUN_CONN_DIR%3D%2Frun%2FNetworkManager%2Fsystem-connections%0ANM_ETC_CONN_DIR%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A%0Alogger%20-t%20nm-clean-initrd-state%20%22Cleaning%20network%20activation%20state%20generated%20by%20dracut...%22%0Alogger%20-t%20nm-clean-initrd-state%20%22To%20disable%2C%20remove%20%2Fvar%2Flib%2Fmco%2Fnm-clean-initrd-state%22%0A%0Aif%20%5B%20!%20-e%20%22%24NM_DEVICES_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_RUN_CONN_DIR%22%20%5D%20%7C%7C%20%5B%20!%20-e%20%22%24NM_ETC_CONN_DIR%22%20%5D%3B%20then%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22There%20is%20no%20network%20activation%20state%20to%20clean%22%0A%20%20exit%0Afi%0A%0A%23%20Some%20deployments%20require%20an%20active%20network%20early%20in%20the%20boot%20process.%20To%0A%23%20achieve%20this%2C%20dracut%20runs%20specific%20NetworkManager%20modules.%20This%20results%20in%0A%23%20NetworkManager%20keyfiles%20being%20generated%20(either%20default%20or%20from%20ip%20kernel%0A%23%20arguments)%20and%20activated.%20This%20activation%20generates%20state%20that%20makes%20those%0A%23%20profiles%20to%20be%20re-activated%20by%20the%20NetworkManager%20service%20later%20in%20the%0A%23%20boot%20process.%20And%20this%20has%20the%20effect%20that%20other%20profiles%20deployed%20by%20the%0A%23%20user%20for%20the%20same%20set%20of%20devices%20are%20ignored.%0A%0A%23%20Most%20of%20the%20time%20this%20is%20the%20desired%20behavior.%20The%20exception%20to%20this%20rule%0A%23%20is%20when%20the%20user%20wants%20to%20run%20the%20boot%20process%20with%20a%20different%20network%0A%23%20setup%20than%20the%20real%20root%20which%20is%20usually%20related%20to%20the%20fact%20that%0A%23%20generating%20images%20with%20customized%20kernel%20arguments%20is%20a%20complication%20in%0A%23%20the%20deployment%20pipeline.%0A%0A%23%20This%20need%20has%20been%20exacerbated%20by%20past%20NetworkManager%20bugs%20that%20activated%0A%23%20the%20network%20on%20boot%20when%20it%20was%20not%20really%20needed.%20Most%20notably%20when%20ip%0A%23%20kernel%20argument%20is%20present%2C%20something%20that%20the%20baremetal%20installer%20adds%20by%0A%23%20default.%0A%0A%23%20The%20intention%20here%20is%20to%20remove%20the%20state%20that%20was%20generated%20with%20the%0A%23%20activation%20of%20those%20profiles%20during%20dracut%20execution.%20Then%20when%0A%23%20NetworkManager%20service%20runs%2C%20the%20profiles%20generated%20by%20dracut%2C%20along%20with%0A%23%20other%20profiles%20configured%20by%20the%20user%2C%20are%20evaluated%20towards%20finding%20the%0A%23%20most%20appropriate%20profile%20to%20connect%20a%20device%20with.%20As%20a%20precaution%2C%20clean%0A%23%20state%20only%20for%20devices%20that%3A%0A%23%20-%20have%20been%20activated%20with%20a%20default%20profile%20(assume%20that%20a%20non-default%0A%23%20%20%20configuration%20expresses%20intention%20by%20user%20to%20run%20with%20it%20permanently)%0A%23%20-%20have%20a%20specific%20configured%20profile%20set%20to%20auto-connect%20(if%20there%20is%20no%0A%23%20%20%20alternate%20configured%20profile%20for%20a%20device%20it%20makes%20no%20sense%20to%0A%23%20%20%20de-activate%20anything)%0A%23%0A%23%20Although%20this%20can%20theoretically%20happen%20on%20any%20deployment%20type%2C%20need%20has%0A%23%20mostly%20come%20from%20IPI%20bare%20metal%20deployments.%20For%20the%20time%20being%2C%20this%0A%23%20should%20be%20opt-in%20in%20any%20other%20deploment%20type.%0A%23%0A%23%20There%20is%20an%20RFE%20filed%20against%20NM%20that%20once%20implemented%20would%20make%20this%0A%23%20script%20unnecessary%3A%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D2089707%0A%0Afor%20device%20in%20%22%24%7BNM_DEVICES_DIR%7D%22%2F*%3B%20do%0A%20%20if%20%5B%20!%20-e%20%22%24device%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20the%20device%20file%20name%20is%20the%20ifindex%0A%20%20ifindex%3D%24(basename%20%22%24device%22)%0A%20%20%0A%20%20%23%20get%20the%20interface%20name%20by%20ifindex%0A%20%20ifname%3D%24(ip%20-j%20link%20show%20%7C%20jq%20-r%20%22.%5B%5D%20%7C%20select(.ifindex%20%3D%3D%20%24%7Bifindex%7D)%20%7C%20.ifname%20%2F%2F%20empty%22)%0A%0A%20%20%23%20no%20interface%20name%20found%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20get%20the%20uuid%20of%20the%20profile%20the%20device%20has%20been%20activated%20with%0A%20%20active_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bdevice%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Econnection-uuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24device%22)%0A%0A%20%20%23%20the%20device%20was%20not%20activated%20with%20any%20profile%2C%20ignore%0A%20%20if%20%5B%20-z%20%22%24active_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20generated%20profile%20by%20uuid%0A%20%20for%20profile%20in%20%22%24%7BNM_RUN_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20generated_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24active_profile_uuid%22%20%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20generated%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24active_profile_uuid%22%20!%3D%20%22%24generated_profile_uuid%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20check%20that%20it%20is%20not%20specific%20for%20the%20device%2C%20otherwise%20ignore%0A%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24profile_ifname%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20profile%20not%20generated%20by%20nm-initrd-generator%2C%20ignore%0A%20%20%23%20only%20check%20it%20if%20the%20key%20is%20set%20(from%20NM%201.32.4)%0A%20%20origin%3D%24(sed%20-nr%20'%2F%5E%5C%5Buser%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eorg.freedesktop.NetworkManager.origin%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20if%20%5B%20-n%20%22%24origin%22%20%5D%20%26%26%20%5B%20%22%24origin%22%20!%3D%20%22nm-initrd-generator%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20%23%20find%20the%20configured%20profile%20by%20name%20with%20auto-connect%20set%0A%20%20for%20profile%20in%20%22%24%7BNM_ETC_CONN_DIR%7D%22%2F*%3B%20do%0A%20%20%20%20profile_ifname%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Einterface-name%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20autoconnect%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Eautoconnect%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%20%20if%20%5B%20%22%24profile_ifname%22%20%3D%20%22%24ifname%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20configured%20profile%20not%20found%2C%20ignore%0A%20%20if%20%5B%20%22%24profile_ifname%22%20!%3D%20%22%24ifname%22%20%5D%20%7C%7C%20%5B%20%22%24autoconnect%22%20%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20continue%0A%20%20fi%0A%0A%20%20configured_profile_uuid%3D%24(sed%20-nr%20'%2F%5E%5C%5Bconnection%5C%5D%2F%2C%2F%5E%5C%5B%2F%7B%2F%5Euuid%5Cs*%3D%2F%7Bs%2F%5B%5E%3D%5D%2B%5Cs*%3D%5Cs*%2F%2F%3BP%7D%7D'%20%22%24profile%22)%0A%20%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20activated%20with%20default%20generated%20profile%20%24generated_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%20has%20different%20configured%20specific%20profile%20%24configured_profile_uuid%22%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22%24ifname%3A%20removing%20state...%22%0A%20%20%0A%20%20%23%20NM%20can%20still%20generate%20internal%20profiles%20from%20the%20IP%20address%0A%20%20%23%20configuration%20of%20devices%2C%20so%20flush%20addresses%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Flushing%20IP%20addresses%20from%20%24ifname%22%0A%20%20ip%20addr%20flush%20%22%24ifname%22%0A%20%20ip%20-6%20addr%20flush%20%22%24ifname%22%0A%0A%20%20%23%20remove%20device%20state%20file%20to%20prevent%20NM%20to%20unilaterally%20connect%20with%20the%0A%20%20%23%20latest%20activated%20profile%20without%20evaluating%20other%20profiles%20%0A%20%20logger%20-t%20nm-clean-initrd-state%20%22Removing%20%24device%22%0A%20%20rm%20-f%20--%20%22%24device%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/nm-clean-initrd-state.sh
        - contents:
            source: data:,%5Bconnection%5D%0Aipv6.dhcp-duid%3Dll%0Aipv6.dhcp-iaid%3Dmac%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/01-ipv6.conf
        - contents:
            source: data:,%5Bmain%5D%0Aplugins%3Dkeyfile%2Cifcfg-rh%0A%5Bkeyfile%5D%0Apath%3D%2Fetc%2FNetworkManager%2Fsystem-connections%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/20-keyfiles.conf
        - contents:
            source: data:,
          mode: 384
          overwrite: true
          path: /etc/pki/ca-trust/source/anchors/openshift-config-user-ca-bundle.crt
        - contents:
            source: data:,KUBERNETES_SERVICE_HOST%3D'api-int.ci-ln-hz4dqct-76ef8.aws-2.ci.openshift.org'%0AKUBERNETES_SERVICE_PORT%3D'6443'%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/apiserver-url.env
        - contents:
            source: data:,%23%20This%20file%20is%20managed%20by%20machine-config-operator.%0A%23%20Suppress%20audit%20rules%20which%20always%20trigger%20for%20container%0A%23%20workloads%2C%20as%20they%20spam%20the%20audit%20log.%20%20Workloads%20are%20expected%0A%23%20to%20be%20dynamic%2C%20and%20the%20networking%20stack%20uses%20iptables.%0A-a%20exclude%2Calways%20-F%20msgtype%3DNETFILTER_CFG%0A%23%20The%20default%20bridged%20networking%20enables%20promiscuous%20on%20the%20veth%0A%23%20device.%20%20Ideally%2C%20we'd%20teach%20audit%20to%20ignore%20only%20veth%20devices%2C%0A%23%20since%20one%20might%20legitimately%20care%20about%20promiscuous%20on%20real%20physical%0A%23%20devices.%20%20But%20we%20can't%20currently%20differentiate.%0A-a%20exclude%2Calways%20-F%20msgtype%3DANOM_PROMISCUOUS%0A
          mode: 420
          overwrite: true
          path: /etc/audit/rules.d/mco-audit-quiet-containers.rules
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%0A%23%20It%20has%20been%20observed%20that%20the%20kernel%20enables%20ESP%20offloads%20of%20bond%0A%23%20devices%20in%20active%2Fbackup%20mode%20even%20if%20slaves%20apparently%20don't%20support%0A%23%20it.%20It's%20unclear%20if%20this%20is%20expected%20behavior%20but%20we%20have%20had%20problems%0A%23%20with%20the%20resulting%20configuration%20in%20vsphere.%20So%20set%20ESP%20offload%20features%0A%23%20off%20in%20bond%20devices%20if%20they%20are%20off%20in%20slave%20devices%20for%20the%20time%20being.%0A%23%20https%3A%2F%2Fissues.redhat.com%2Fbrowse%2FRHEL-58811%0A%0Aif%20%5B%5B%20%22%242%22%20!%3D%20%22up%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24DEVICE_IFACE%22)%0A%0Aif%20%5B%5B%20%22%24driver%22%20!%3D%20%22bond%22%20%5D%5D%3B%20then%0A%20%20exit%0Afi%0A%0Abond%3D%22%24DEVICE_IFACE%22%0Afor%20feature%20in%20tx-esp-segmentation%20esp-hw-offload%20esp-tx-csum-hw-offload%3B%20do%0A%0A%20%20if%20ethtool%20-k%20%22%24bond%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%23%20already%20disabled%2C%20nothing%20to%20do%0A%20%20%20%20continue%0A%20%20fi%0A%20%20%0A%20%20for%20slave%20in%20%24(nmcli%20-g%20BOND.SLAVES%20dev%20show%20%22%24DEVICE_IFACE%22)%3B%20do%0A%0A%20%20%20%20if%20!%20ethtool%20-k%20%22%24slave%22%20%7C%20grep%20-qE%20%22%5E%24%7Bfeature%7D%3A%20off%22%3B%20then%0A%20%20%20%20%20%20%23%20enabled%20in%20slave%2C%20nothing%20to%20do%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20logger%20-t%20bond-esp-offload%20-s%20%22Bond%20link%20%24slave%20has%20%24feature%20off%2C%20setting%20master%20%24DEVICE_IFACE%20%24feature%20off%22%0A%20%20%20%20ethtool%20-K%20%22%24bond%22%20%22%24feature%22%20off%0A%0A%20%20%20%20break%0A%20%20done%0Adone%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-bond-esp-offload
        - contents:
            source: data:,r%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F80-openshift-network.conf%0Ar%20%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F10-ovn-kubernetes.conf%0Ad%20%2Frun%2Fmultus%2Fcni%2Fnet.d%2F%200755%20root%20root%20-%20-%0AD%20%2Fvar%2Flib%2Fcni%2Fnetworks%2Fopenshift-sdn%2F%200755%20root%20root%20-%20-%0A
          mode: 420
          overwrite: true
          path: /etc/tmpfiles.d/cleanup-cni.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-x%0A%0Aif%20%5B%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20echo%20%22Skipping%20configure-ovs%20due%20to%20manual%20network%20configuration%22%0A%20%20exit%200%0Afi%0A%0A%23%20This%20file%20is%20not%20needed%20anymore%20in%204.7%2B%2C%20but%20when%20rolling%20back%20to%204.6%0A%23%20the%20ovs%20pod%20needs%20it%20to%20know%20ovs%20is%20running%20on%20the%20host.%0Atouch%20%2Fvar%2Frun%2Fovs-config-executed%0A%0A%23%20These%20are%20well%20knwon%20NM%20default%20paths%0ANM_CONN_ETC_PATH%3D%22%2Fetc%2FNetworkManager%2Fsystem-connections%22%0ANM_CONN_RUN_PATH%3D%22%2Frun%2FNetworkManager%2Fsystem-connections%22%0A%0A%23%20This%20is%20the%20path%20where%20NM%20is%20known%20to%20be%20configured%20to%20store%20user%20keyfiles%20%0ANM_CONN_CONF_PATH%3D%22%24NM_CONN_ETC_PATH%22%0A%0A%23%20This%20is%20where%20we%20want%20our%20keyfiles%20to%20finally%20reside.%20configure-ovs%0A%23%20operates%20with%20temporary%20keyfiles%20in%20NM_CONN_RUN_PATH%20and%20then%20as%20a%20last%0A%23%20step%20moves%20those%20keyfiles%20to%20NM_CONN_SET_PATH%20if%20it%20is%20a%20different%20path%0A%23%20(not%20by%20default).%20This%20mitigates%20hard%20interruptions%20(SIGKILL%2C%20hard%20reboot)%0A%23%20of%20configure-ovs%20leaving%20the%20machine%20with%20a%20half-baked%20set%20of%20keyfiles%0A%23%20that%20might%20prevent%20machine%20networking%20from%20working%20correctly.%0ANM_CONN_SET_PATH%3D%22%24%7BNM_CONN_SET_PATH%3A-%24NM_CONN_RUN_PATH%7D%22%0A%0AMANAGED_NM_CONN_SUFFIX%3D%22-slave-ovs-clone%22%0A%23%20Workaround%20to%20ensure%20OVS%20is%20installed%20due%20to%20bug%20in%20systemd%20Requires%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1888017%0Acopy_nm_conn_files()%20%7B%0A%20%20local%20dst_path%3D%22%241%22%0A%20%20for%20src%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20src_path%3D%24(dirname%20%22%24src%22)%0A%20%20%20%20file%3D%24(basename%20%22%24src%22)%0A%20%20%20%20if%20%5B%20-f%20%22%24src_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%24dst_path%2F%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20elif%20!%20cmp%20--silent%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Copying%20updated%20configuration%20%24file%22%0A%20%20%20%20%20%20%20%20cp%20-f%20%22%24src_path%2F%24file%22%20%22%24dst_path%2F%24file%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it's%20equal%20at%20destination%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20echo%20%22Skipping%20%24file%20since%20it%20does%20not%20exist%20at%20source%22%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0Aupdate_nm_conn_files_base()%20%7B%0A%20%20base_path%3D%24%7B1%7D%0A%20%20bridge_name%3D%24%7B2%7D%0A%20%20port_name%3D%24%7B3%7D%0A%20%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%20%20%23%20In%20RHEL7%20files%20in%20%2F%7Betc%2Crun%7D%2FNetworkManager%2Fsystem-connections%20end%20without%20the%20suffix%20'.nmconnection'%2C%20whereas%20in%20RHCOS%20they%20end%20with%20the%20suffix.%0A%20%20MANAGED_NM_CONN_FILES%3D(%24(echo%20%22%24%7Bbase_path%7D%22%2F%7B%22%24bridge_name%22%2C%22%24ovs_interface%22%2C%22%24ovs_port%22%2C%22%24bridge_interface_name%22%2C%22%24default_port_name%22%7D%7B%2C.nmconnection%7D))%0A%20%20shopt%20-s%20nullglob%0A%20%20MANAGED_NM_CONN_FILES%2B%3D(%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D.nmconnection%20%24%7Bbase_path%7D%2F*%24%7BMANAGED_NM_CONN_SUFFIX%7D)%0A%20%20shopt%20-u%20nullglob%0A%7D%0A%0Aupdate_nm_conn_run_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_RUN_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0Aupdate_nm_conn_set_files()%20%7B%0A%20%20update_nm_conn_files_base%20%22%24%7BNM_CONN_SET_PATH%7D%22%20%22%24%7B1%7D%22%20%22%24%7B2%7D%22%0A%7D%0A%0A%23%20Move%20and%20reload%20keyfiles%20at%20their%20final%20destination%0Aset_nm_conn_files()%20%7B%0A%20%20if%20%5B%20%22%24NM_CONN_RUN_PATH%22%20!%3D%20%22%24NM_CONN_SET_PATH%22%20%5D%3B%20then%0A%20%20%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%20%20%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20%20%20copy_nm_conn_files%20%22%24NM_CONN_SET_PATH%22%0A%20%20%20%20rm_nm_conn_files%0A%0A%20%20%20%20%23%20reload%20keyfiles%0A%20%20%20%20nmcli%20connection%20reload%0A%20%20fi%0A%7D%0A%0A%23%20Used%20to%20remove%20files%20managed%20by%20configure-ovs%20and%20temporary%20leftover%20files%20from%20network%20manager%0Arm_nm_conn_files()%20%7B%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20%5B%20-f%20%22%24file%22%20%5D%3B%20then%0A%20%20%20%20%20%20rm%20-f%20%22%24file%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20file%20%24file%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20fi%0A%20%20done%0A%20%20for%20file%20in%20%22%24%7BMANAGED_NM_CONN_FILES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20for%20temp%20in%20%24(compgen%20-G%20%22%24%7Bfile%7D.*%22)%3B%20do%0A%20%20%20%20%20%20rm%20-f%20%22%24temp%22%0A%20%20%20%20%20%20echo%20%22Removed%20nmconnection%20temporary%20file%20%24temp%22%0A%20%20%20%20%20%20nm_config_changed%3D1%0A%20%20%20%20done%0A%20%20done%0A%7D%0A%0A%23%20Used%20to%20clone%20a%20slave%20connection%20by%20uuid%2C%20returns%20new%20name%0Aclone_slave_connection()%20%7B%0A%20%20local%20uuid%3D%22%241%22%0A%20%20local%20old_name%0A%20%20old_name%3D%22%24(nmcli%20-g%20connection.id%20connection%20show%20uuid%20%22%24uuid%22)%22%0A%20%20local%20new_name%3D%22%24%7Bold_name%7D%24%7BMANAGED_NM_CONN_SUFFIX%7D%22%0A%20%20if%20nmcli%20connection%20show%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20existing%20ovs%20slave%20%24%7Bnew_name%7D%20connection%20profile%20file%20found%2C%20overwriting...%22%20%3E%262%0A%20%20%20%20nmcli%20connection%20delete%20id%20%22%24%7Bnew_name%7D%22%20%26%3E%20%2Fdev%2Fnull%0A%20%20fi%0A%20%20clone_nm_conn%20%24uuid%20%22%24%7Bnew_name%7D%22%0A%20%20echo%20%22%24%7Bnew_name%7D%22%0A%7D%0A%0A%23%20Used%20to%20replace%20an%20old%20master%20connection%20uuid%20with%20a%20new%20one%20on%20all%20connections%0Areplace_connection_master()%20%7B%0A%20%20local%20old%3D%22%241%22%0A%20%20local%20new%3D%22%242%22%0A%20%20for%20conn_uuid%20in%20%24(nmcli%20-g%20UUID%20connection%20show)%20%3B%20do%0A%20%20%20%20if%20%5B%20%22%24(nmcli%20-g%20connection.master%20connection%20show%20uuid%20%22%24conn_uuid%22)%22%20!%3D%20%22%24old%22%20%5D%3B%20then%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20local%20autoconnect%3D%24(nmcli%20-g%20connection.autoconnect%20connection%20show%20%22%24conn_uuid%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20!%3D%20%22activated%22%20%5D%20%26%26%20%5B%20%22%24autoconnect%22%20!%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Assume%20that%20slave%20profiles%20intended%20to%20be%20used%20are%20those%20that%20are%3A%0A%20%20%20%20%20%20%23%20-%20active%0A%20%20%20%20%20%20%23%20-%20or%20inactive%20(which%20might%20be%20due%20to%20link%20being%20down)%20but%20to%20be%20autoconnected.%0A%20%20%20%20%20%20%23%20Otherwise%2C%20ignore%20them.%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20make%20changes%20for%20slave%20profiles%20in%20a%20new%20clone%0A%20%20%20%20local%20new_name%0A%20%20%20%20new_name%3D%24(clone_slave_connection%20%24conn_uuid)%0A%0A%20%20%20%20mod_nm_conn%20%22%24new_name%22%20connection.master%20%22%24new%22%20connection.autoconnect-priority%20100%20connection.autoconnect%20no%20%0A%20%20%20%20echo%20%22Replaced%20master%20%24old%20with%20%24new%20for%20slave%20profile%20%24new_name%22%0A%20%20done%0A%7D%0A%0A%23%20when%20creating%20the%20bridge%2C%20we%20use%20a%20value%20lower%20than%20NM's%20ethernet%20device%20default%20route%20metric%0A%23%20(we%20pick%2048%20and%2049%20to%20be%20lower%20than%20anything%20that%20NM%20chooses%20by%20default)%0ABRIDGE_METRIC%3D%2248%22%0ABRIDGE1_METRIC%3D%2249%22%0A%23%20Given%20an%20interface%2C%20generates%20NM%20configuration%20to%20add%20to%20an%20OVS%20bridge%0Aconvert_to_bridge()%20%7B%0A%20%20local%20iface%3D%24%7B1%7D%0A%20%20local%20bridge_name%3D%24%7B2%7D%0A%20%20local%20port_name%3D%24%7B3%7D%0A%20%20local%20bridge_metric%3D%24%7B4%7D%0A%20%20local%20ovs_port%3D%22ovs-port-%24%7Bbridge_name%7D%22%0A%20%20local%20ovs_interface%3D%22ovs-if-%24%7Bbridge_name%7D%22%0A%20%20local%20default_port_name%3D%22ovs-port-%24%7Bport_name%7D%22%20%23%20ovs-port-phys0%0A%20%20local%20bridge_interface_name%3D%22ovs-if-%24%7Bport_name%7D%22%20%23%20ovs-if-phys0%0A%0A%20%20if%20%5B%20%22%24iface%22%20%3D%20%22%24bridge_name%22%20%5D%3B%20then%0A%20%20%20%20%23%20handle%20vlans%20and%20bonds%20etc%20if%20they%20have%20already%20been%0A%20%20%20%20%23%20configured%20via%20nm%20key%20files%20and%20br-ex%20is%20already%20up%0A%20%20%20%20ifaces%3D%24(ovs-vsctl%20list-ifaces%20%24%7Biface%7D)%0A%20%20%20%20for%20intf%20in%20%24ifaces%3B%20do%20configure_driver_options%20%24intf%3B%20done%0A%20%20%20%20echo%20%22Networking%20already%20configured%20and%20up%20for%20%24%7Bbridge-name%7D!%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20flag%20to%20reload%20NM%20to%20account%20for%20all%20the%20configuration%20changes%0A%20%20%23%20going%20forward%0A%20%20nm_config_changed%3D1%0A%0A%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20Unable%20to%20find%20default%20gateway%20interface%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%20%20%23%20find%20the%20MAC%20from%20OVS%20config%20or%20the%20default%20interface%20to%20use%20for%20OVS%20internal%20port%0A%20%20%23%20this%20prevents%20us%20from%20getting%20a%20different%20DHCP%20lease%20and%20dropping%20connection%0A%20%20if%20!%20iface_mac%3D%24(%3C%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface%7D%2Faddress%22)%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MAC%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20echo%20%22MAC%20address%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mac%7D%22%0A%0A%20%20%23%20find%20MTU%20from%20original%20iface%0A%20%20iface_mtu%3D%24(ip%20link%20show%20%22%24iface%22%20%7C%20awk%20'%7Bprint%20%245%3B%20exit%7D')%0A%20%20if%20%5B%5B%20-z%20%22%24iface_mtu%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Unable%20to%20determine%20default%20interface%20MTU%2C%20defaulting%20to%201500%22%0A%20%20%20%20iface_mtu%3D1500%0A%20%20else%0A%20%20%20%20echo%20%22MTU%20found%20for%20iface%3A%20%24%7Biface%7D%3A%20%24%7Biface_mtu%7D%22%0A%20%20fi%0A%0A%20%20%23%20store%20old%20conn%20for%20later%0A%20%20old_conn%3D%24(nmcli%20--fields%20UUID%2CDEVICE%20conn%20show%20--active%20%7C%20awk%20%22%2F%5Cs%24%7Biface%7D%5Cs*%5C%24%2F%20%7Bprint%20%5C%241%7D%22)%0A%0A%20%20if%20%5B%5B%20-z%20%22%24old_conn%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22ERROR%3A%20cannot%20find%20connection%20for%20interface%3A%20%24%7Biface%7D%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20create%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24bridge_name%22%20type%20ovs-bridge%20conn.interface%20%22%24bridge_name%22%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20%23%20find%20default%20port%20to%20add%20to%20bridge%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24default_port_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%24%7Biface%7D%0A%20%20%20%20add_nm_conn%20%22%24default_port_name%22%20type%20ovs-port%20conn.interface%20%24%7Biface%7D%20master%20%22%24bridge_name%22%20%5C%0A%20%20%20%20connection.autoconnect-slaves%201%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_port%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-port%20%22%24bridge_name%22%20%22%24bridge_name%22%0A%20%20%20%20add_nm_conn%20%22%24ovs_port%22%20type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24bridge_name%22%0A%20%20fi%0A%0A%20%20extra_phys_args%3D()%0A%20%20%23%20check%20if%20this%20interface%20is%20a%20vlan%2C%20bond%2C%20team%2C%20or%20ethernet%20type%0A%20%20if%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22vlan%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dvlan%0A%20%20%20%20vlan_id%3D%24(nmcli%20--get-values%20vlan.id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_id%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20vlan.parent%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-z%20%22%24vlan_parent%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20unable%20to%20determine%20vlan_parent%20for%20vlan%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%0A%20%20%20%20if%20nmcli%20connection%20show%20uuid%20%22%24vlan_parent%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20%20%20%23%20if%20the%20VLAN%20connection%20is%20configured%20with%20a%20connection%20UUID%20as%20parent%2C%20we%20need%20to%20find%20the%20underlying%20device%0A%20%20%20%20%20%20%23%20and%20create%20the%20bridge%20against%20it%2C%20as%20the%20parent%20connection%20can%20be%20replaced%20by%20another%20bridge.%0A%20%20%20%20%20%20vlan_parent%3D%24(nmcli%20--get-values%20GENERAL.DEVICES%20conn%20show%20uuid%20%24%7Bvlan_parent%7D)%0A%20%20%20%20fi%0A%0A%20%20%20%20extra_phys_args%3D(%20dev%20%22%24%7Bvlan_parent%7D%22%20id%20%22%24%7Bvlan_id%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbond%0A%20%20%20%20%23%20check%20bond%20options%0A%20%20%20%20bond_opts%3D%24(nmcli%20--get-values%20bond.options%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24bond_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20bond.options%20%22%24%7Bbond_opts%7D%22%20)%0A%20%20%20%20%20%20MODE_REGEX%3D%22(%5E%7C%2C)mode%3Dactive-backup(%2C%7C%24)%22%0A%20%20%20%20%20%20MAC_REGEX%3D%22(%5E%7C%2C)fail_over_mac%3D(1%7Cactive%7C2%7Cfollow)(%2C%7C%24)%22%0A%20%20%20%20%20%20if%20%5B%5B%20%24bond_opts%20%3D~%20%24MODE_REGEX%20%5D%5D%20%26%26%20%5B%5B%20%24bond_opts%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22team%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dteam%0A%20%20%20%20%23%20check%20team%20config%20options%0A%20%20%20%20team_config_opts%3D%24(nmcli%20--get-values%20team.config%20-e%20no%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20if%20%5B%20-n%20%22%24team_config_opts%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20team.config%20is%20json%2C%20remove%20spaces%20to%20avoid%20problems%20later%20on%0A%20%20%20%20%20%20extra_phys_args%2B%3D(%20team.config%20%22%24%7Bteam_config_opts%2F%2F%5B%5B%3Aspace%3A%5D%5D%2F%7D%22%20)%0A%20%20%20%20%20%20team_mode%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.name%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20team_mac_policy%3D%24(echo%20%22%24%7Bteam_config_opts%7D%22%20%7C%20jq%20-r%20%22.runner.hwaddr_policy%20%2F%2F%20empty%22)%0A%20%20%20%20%20%20MAC_REGEX%3D%22(by_active%7Conly_active)%22%0A%20%20%20%20%20%20if%20%5B%20%22%24team_mode%22%20%3D%20%22activebackup%22%20%5D%20%26%26%20%5B%5B%20%22%24team_mac_policy%22%20%3D~%20%24MAC_REGEX%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20clone_mac%3D0%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22tun%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dtun%0A%20%20%20%20tun_mode%3D%24(nmcli%20--get-values%20tun.mode%20-e%20no%20connection%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20extra_phys_args%2B%3D(%20tun.mode%20%22%24%7Btun_mode%7D%22%20)%0A%20%20elif%20%5B%20%22%24(nmcli%20--get-values%20connection.type%20conn%20show%20%24%7Bold_conn%7D)%22%20%3D%3D%20%22bridge%22%20%5D%3B%20then%0A%20%20%20%20iface_type%3Dbridge%0A%20%20else%0A%20%20%20%20iface_type%3D802-3-ethernet%0A%20%20fi%0A%0A%20%20if%20%5B%20!%20%22%24%7Bclone_mac%3A-%7D%22%20%3D%20%220%22%20%5D%3B%20then%0A%20%20%20%20%23%20In%20active-backup%20link%20aggregation%2C%20with%20fail_over_mac%20mode%20enabled%2C%0A%20%20%20%20%23%20cloning%20the%20mac%20address%20is%20not%20supported.%20It%20is%20possible%20then%20that%0A%20%20%20%20%23%20br-ex%20has%20a%20different%20mac%20address%20than%20the%20bond%20which%20might%20be%0A%20%20%20%20%23%20troublesome%20on%20some%20platforms%20where%20the%20nic%20won't%20accept%20packets%20with%0A%20%20%20%20%23%20a%20different%20destination%20mac.%20But%20nobody%20has%20complained%20so%20far%20so%20go%20on%0A%20%20%20%20%23%20with%20what%20we%20got.%20%0A%20%20%20%20%0A%20%20%20%20%23%20Do%20set%20it%20though%20for%20other%20link%20aggregation%20configurations%20where%20the%0A%20%20%20%20%23%20mac%20address%20would%20otherwise%20depend%20on%20enslave%20order%20for%20which%20we%20have%0A%20%20%20%20%23%20no%20control%20going%20forward.%0A%20%20%20%20extra_phys_args%2B%3D(%20802-3-ethernet.cloned-mac-address%20%22%24%7Biface_mac%7D%22%20)%0A%20%20fi%0A%0A%20%20%23%20use%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%20instead%20of%20%24%7Bextra_phys_args%5B%40%5D%7D%20to%20be%20compatible%20with%20bash%204.2%20in%20RHEL7.9%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24bridge_interface_name%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%24%7Biface%7D%0A%20%20%20%20ovs_default_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24default_port_name%22)%0A%20%20%20%20add_nm_conn%20%22%24bridge_interface_name%22%20type%20%24%7Biface_type%7D%20conn.interface%20%24%7Biface%7D%20master%20%22%24ovs_default_port_conn%22%20%5C%0A%20%20%20%20%20%20slave-type%20ovs-port%20connection.autoconnect-priority%20100%20connection.autoconnect-slaves%201%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20%5C%0A%20%20%20%20%20%20%24%7Bextra_phys_args%5B%40%5D%2B%22%24%7Bextra_phys_args%5B%40%5D%7D%22%7D%0A%20%20fi%0A%0A%20%20%23%20Get%20the%20new%20connection%20uuids%0A%20%20new_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24bridge_interface_name%22)%0A%20%20ovs_port_conn%3D%24(nmcli%20-g%20connection.uuid%20conn%20show%20%22%24ovs_port%22)%0A%0A%20%20%23%20Update%20connections%20with%20master%20property%20set%20to%20use%20the%20new%20connection%0A%20%20replace_connection_master%20%24old_conn%20%24new_conn%0A%20%20replace_connection_master%20%24iface%20%24new_conn%0A%0A%20%20ipv4_method%3D%24(nmcli%20-g%20ipv4.method%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_method%3D%24(nmcli%20-g%20ipv6.method%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20ipv4_addresses%3D%24(nmcli%20-g%20ipv4.addresses%20conn%20show%20%22%24old_conn%22)%0A%20%20ipv6_addresses%3D%24(nmcli%20-g%20ipv6.addresses%20conn%20show%20%22%24old_conn%22)%0A%0A%20%20%23%20Warn%20about%20an%20invalid%20MTU%20that%20will%20most%20likely%20fail%20in%20one%20way%20or%0A%20%20%23%20another%0A%20%20if%20%5B%20%24%7Biface_mtu%7D%20-lt%201280%20%5D%20%26%26%20%5B%20%22%24%7Bipv6_method%7D%22%20!%3D%20%22disabled%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20MTU%20%24%7Biface_mtu%7D%20is%20lower%20than%20the%20minimum%20required%20of%201280%20for%20IPv6%22%0A%20%20fi%0A%0A%20%20if%20!%20nmcli%20connection%20show%20%22%24ovs_interface%22%20%26%3E%20%2Fdev%2Fnull%3B%20then%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20destroy%20interface%20%22%24bridge_name%22%0A%20%20%20%20%23%20Clone%20the%20connection%20in%20case%20the%20method%20is%20manual%20or%20in%20case%20the%20an%20address%20is%20set%20(DHCP%20%2B%20static%20IP)%0A%20%20%20%20if%20%5B%20%22%24%7Bipv4_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv4_addresses%7D%22%20!%3D%20%22%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_method%7D%22%20%3D%20%22manual%22%20%5D%20%7C%7C%20%5B%20%22%24%7Bipv6_addresses%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Static%20IP%20addressing%20detected%20on%20default%20gateway%20connection%3A%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%23%20clone%20the%20old%20connection%20to%20get%20the%20address%20settings%0A%20%20%20%20%20%20%23%20prefer%20cloning%20vs%20copying%20the%20connection%20file%20to%20avoid%20problems%20with%20selinux%0A%20%20%20%20%20%20clone_nm_conn%20%22%24%7Bold_conn%7D%22%20%22%24%7Bovs_interface%7D%22%0A%20%20%20%20%20%20shopt%20-s%20nullglob%0A%20%20%20%20%20%20new_conn_files%3D(%24%7BNM_CONN_RUN_PATH%7D%2F%22%24%7Bovs_interface%7D%22*)%0A%20%20%20%20%20%20shopt%20-u%20nullglob%0A%20%20%20%20%20%20if%20%5B%20%24%7B%23new_conn_files%5B%40%5D%7D%20-ne%201%20%5D%20%7C%7C%20%5B%20!%20-f%20%22%24%7Bnew_conn_files%5B0%5D%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20could%20not%20find%20%24%7Bovs_interface%7D%20conn%20file%20after%20cloning%20from%20%24%7Bold_conn%7D%22%0A%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20new_conn_file%3D%22%24%7Bnew_conn_files%5B0%5D%7D%22%0A%0A%20%20%20%20%20%20%23%20modify%20the%20connection%20type%20directly%20because%20it%20can't%20be%20modified%0A%20%20%20%20%20%20%23%20through%20nmcli%0A%20%20%20%20%20%20sed%20-i%20'%2F%5E%5C%5Bconnection%5C%5D%24%2F%2C%2F%5E%5C%5B%2F%20s%2F%5Etype%3D.*%24%2Ftype%3Dovs-interface%2F'%20%24%7Bnew_conn_file%7D%0A%0A%20%20%20%20%20%20%23%20modify%20some%20more%20settings%20through%20nmcli%0A%20%20%20%20%20%20mod_nm_conn%20%22%24%7Bovs_interface%7D%22%20conn.interface%20%22%24bridge_name%22%20%5C%0A%20%20%20%20%20%20%20%20connection.multi-connect%20%22%22%20connection.autoconnect%20no%20%5C%0A%20%20%20%20%20%20%20%20connection.master%20%22%24ovs_port_conn%22%20connection.slave-type%20ovs-port%20%5C%0A%20%20%20%20%20%20%20%20ovs-interface.type%20internal%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%0A%0A%20%20%20%20%20%20echo%20%22Loaded%20new%20%24ovs_interface%20connection%20file%3A%20%24%7Bnew_conn_file%7D%22%0A%20%20%20%20else%0A%20%20%20%20%20%20extra_if_brex_args%3D%22%22%0A%20%20%20%20%20%20%23%20check%20if%20interface%20had%20ipv4%2Fipv6%20addresses%20assigned%0A%20%20%20%20%20%20num_ipv4_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ipv4_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20IPV6%20should%20have%20at%20least%20a%20link%20local%20address.%20Check%20for%20more%20than%201%20to%20see%20if%20there%20is%20an%0A%20%20%20%20%20%20%23%20assigned%20address.%0A%20%20%20%20%20%20num_ip6_addrs%3D%24(ip%20-j%20a%20show%20dev%20%24%7Biface%7D%20%7C%20jq%20%22.%5B0%5D.addr_info%20%7C%20map(.%20%7C%20select(.family%20%3D%3D%20%5C%22inet6%5C%22%20and%20.scope%20!%3D%20%5C%22link%5C%22))%20%7C%20length%22)%0A%20%20%20%20%20%20if%20%5B%20%22%24num_ip6_addrs%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.may-fail%20no%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20%23%20check%20for%20dhcp%20client%20ids%0A%20%20%20%20%20%20dhcp_client_id%3D%24(nmcli%20--get-values%20ipv4.dhcp-client-id%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv4.dhcp-client-id%20%24%7Bdhcp_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20dhcp6_client_id%3D%24(nmcli%20--get-values%20ipv6.dhcp-duid%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24dhcp6_client_id%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.dhcp-duid%20%24%7Bdhcp6_client_id%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20ipv6_addr_gen_mode%3D%24(nmcli%20--get-values%20ipv6.addr-gen-mode%20conn%20show%20%24%7Bold_conn%7D)%0A%20%20%20%20%20%20if%20%5B%20-n%20%22%24ipv6_addr_gen_mode%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20extra_if_brex_args%2B%3D%22ipv6.addr-gen-mode%20%24%7Bipv6_addr_gen_mode%7D%20%22%0A%20%20%20%20%20%20fi%0A%0A%20%20%20%20%20%20add_nm_conn%20%22%24ovs_interface%22%20type%20ovs-interface%20slave-type%20ovs-port%20conn.interface%20%22%24bridge_name%22%20master%20%22%24ovs_port_conn%22%20%5C%0A%20%20%20%20%20%20%20%20802-3-ethernet.mtu%20%24%7Biface_mtu%7D%20802-3-ethernet.cloned-mac-address%20%24%7Biface_mac%7D%20%5C%0A%20%20%20%20%20%20%20%20ipv4.method%20%22%24%7Bipv4_method%7D%22%20ipv4.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20ipv6.method%20%22%24%7Bipv6_method%7D%22%20ipv6.route-metric%20%22%24%7Bbridge_metric%7D%22%20%5C%0A%20%20%20%20%20%20%20%20%24%7Bextra_if_brex_args%7D%0A%20%20%20%20fi%0A%20%20fi%0A%0A%20%20configure_driver_options%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20remove%20a%20bridge%0Aremove_ovn_bridges()%20%7B%0A%20%20bridge_name%3D%24%7B1%7D%0A%20%20port_name%3D%24%7B2%7D%0A%0A%20%20%23%20Remove%20the%20keyfiles%20from%20known%20configuration%20paths%0A%20%20update_nm_conn_run_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%20%20update_nm_conn_set_files%20%24%7Bbridge_name%7D%20%24%7Bport_name%7D%0A%20%20rm_nm_conn_files%0A%0A%20%20%23%20NetworkManager%20will%20not%20remove%20%24%7Bbridge_name%7D%20if%20it%20has%20the%20patch%20port%20created%20by%20ovn-kubernetes%0A%20%20%23%20so%20remove%20explicitly%0A%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20%24%7Bbridge_name%7D%0A%7D%0A%0A%23%20Removes%20any%20previous%20ovs%20configuration%0Aremove_all_ovn_bridges()%20%7B%0A%20%20echo%20%22Reverting%20any%20previous%20OVS%20configuration%22%0A%20%20%0A%20%20remove_ovn_bridges%20br-ex%20phys0%0A%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%0A%20%20echo%20%22OVS%20configuration%20successfully%20reverted%22%0A%7D%0A%0A%23%20Reloads%20NM%20NetworkManager%20profiles%20if%20any%20configuration%20change%20was%20done.%0A%23%20Accepts%20a%20list%20of%20devices%20that%20should%20be%20re-connect%20after%20reload.%0Areload_profiles_nm()%20%7B%0A%20%20if%20%5B%20%24%7Bnm_config_changed%3A-0%7D%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%23%20no%20config%20was%20changed%2C%20no%20need%20to%20reload%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20reload%20profiles%0A%20%20nmcli%20connection%20reload%0A%0A%20%20%23%20precautionary%20sleep%20of%2010s%20(default%20timeout%20of%20NM%20to%20bring%20down%20devices)%0A%20%20sleep%2010%0A%0A%20%20%23%20After%20reload%2C%20devices%20that%20were%20already%20connected%20should%20connect%20again%0A%20%20%23%20if%20any%20profile%20is%20available.%20If%20no%20profile%20is%20available%2C%20a%20device%20can%0A%20%20%23%20remain%20disconnected%20and%20we%20have%20to%20explicitly%20connect%20it%20so%20that%20a%0A%20%20%23%20profile%20is%20generated.%20This%20can%20happen%20for%20physical%20devices%20but%20should%0A%20%20%23%20not%20happen%20for%20software%20devices%20as%20those%20always%20require%20a%20profile.%0A%20%20for%20dev%20in%20%24%40%3B%20do%0A%20%20%20%20%23%20Only%20attempt%20to%20connect%20a%20disconnected%20device%0A%20%20%20%20local%20connected_state%3D%24(nmcli%20-g%20GENERAL.STATE%20device%20show%20%22%24dev%22%20%7C%7C%20echo%20%22%22)%0A%20%20%20%20if%20%5B%5B%20%22%24connected_state%22%20%3D~%20%22disconnected%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%23%20keep%20track%20if%20a%20profile%20by%20the%20same%20name%20as%20the%20device%20existed%20%0A%20%20%20%20%20%20%23%20before%20we%20attempt%20activation%0A%20%20%20%20%20%20local%20named_profile_existed%3D%24(%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%5D%20%7C%7C%20%5B%20-f%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22%20%5D%20%26%26%20echo%20%22yes%22)%0A%20%20%20%20%20%20%0A%20%20%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20connect%20device%20%24dev%22%0A%20%20%20%20%20%20%20%20%20%20nmcli%20device%20connect%20%22%24dev%22%20%26%26%20break%0A%20%20%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%0A%20%20%20%20%20%20%23%20if%20a%20profile%20did%20not%20exist%20before%20but%20does%20now%2C%20it%20was%20generated%0A%20%20%20%20%20%20%23%20but%20we%20want%20it%20to%20be%20ephemeral%2C%20so%20move%20it%20back%20to%20%2Frun%0A%20%20%20%20%20%20if%20%5B%20!%20%22%24named_profile_existed%22%20%3D%20%22yes%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20MANAGED_NM_CONN_FILES%3D(%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D%22%20%22%24%7BNM_CONN_CONF_PATH%7D%2F%24%7Bdev%7D.nmconnection%22)%0A%20%20%20%20%20%20%20%20copy_nm_conn_files%20%22%24%7BNM_CONN_RUN_PATH%7D%22%0A%20%20%20%20%20%20%20%20rm_nm_conn_files%0A%20%20%20%20%20%20%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20might%20have%20been%20moved%0A%20%20%20%20%20%20%20%20nmcli%20connection%20reload%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20echo%20%22Waiting%20for%20interface%20%24dev%20to%20activate...%22%0A%20%20%20%20if%20!%20timeout%2060%20bash%20-c%20%22while%20!%20nmcli%20-g%20DEVICE%2CSTATE%20c%20%7C%20grep%20%22'%22'%22%24dev%22%3Aactivated'%22'%22%3B%20do%20sleep%205%3B%20done%22%3B%20then%0A%20%20%20%20%20%20echo%20%22WARNING%3A%20%24dev%20did%20not%20activate%22%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20nm_config_changed%3D0%0A%7D%0A%0A%23%20Removes%20all%20configuration%20and%20reloads%20NM%20if%20necessary%0Arollback_nm()%20%7B%0A%20%20phys0%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20phys1%3D%24(get_bridge_physical_interface%20ovs-if-phys1)%0A%20%20%0A%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20remove_all_ovn_bridges%0A%20%20%0A%20%20%23%20reload%20profiles%20so%20that%20NM%20notices%20that%20some%20were%20removed%0A%20%20reload_profiles_nm%20%22%24phys0%22%20%22%24phys1%22%0A%7D%0A%0A%23%20Add%20a%20temporary%20deactivated%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20folowed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20add%60%0Aadd_nm_conn()%20%7B%0A%20%20%23%20Use%20%60save%20no%60%20to%20add%20a%20temporary%20profile%0A%20%20nmcli%20c%20add%20save%20no%20con-name%20%22%24%40%22%20connection.autoconnect%20no%0A%7D%0A%0A%23%20Modify%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20name%20followed%20by%20arguments%20passed%20to%0A%23%20%60nmcli%20connection%20modify%60%0Amod_nm_conn()%20%7B%0A%20%20%23%20the%20easiest%20thing%20to%20do%20here%20would%20be%20to%20use%20%60nmcli%20c%20mod%20--temporary%60%0A%20%20%23%20but%20there%20is%20a%20bug%20in%20selinux%20profiles%20that%20denies%20NM%20from%20performing%0A%20%20%23%20the%20operation%0A%20%20local%20dst_path%3D%24%7BNM_CONN_RUN_PATH%7D%2F%241.nmconnection%0A%20%20local%20src_path%0A%20%20src_path%3D%24(mktemp)%0A%20%20shift%0A%20%20cat%20%22%24dst_path%22%20%3E%20%22%24src_path%22%0A%20%20rm%20-f%20%22%24dst_path%22%0A%20%20nmcli%20--offline%20c%20mod%20%22%24%40%22%20%3C%20%22%24src_path%22%20%3E%20%22%24dst_path%22%0A%20%20rm%20-f%20%22%24src_path%22%0A%20%20chmod%20600%20%22%24dst_path%22%0A%20%20nmcli%20c%20load%20%22%24dst_path%22%0A%7D%0A%0A%23%20Clone%20to%20a%20temporary%20connection%20profile%20%0A%23%20First%20argument%20is%20the%20connection%20to%20clone%2C%20second%20argument%20is%20the%20clone%20name%0Aclone_nm_conn()%20%7B%0A%20%20%23%20clone%20as%20temporary%20so%20that%20it%20is%20generated%20in%20NM_CONN_RUN_PATH%0A%20%20nmcli%20connection%20clone%20--temporary%20%22%241%22%20%22%242%22%20%26%3E%20%2Fdev%2Fnull%0A%7D%0A%0A%23%20Activates%20an%20ordered%20set%20of%20NM%20connection%20profiles%0Aactivate_nm_connections()%20%7B%0A%20%20local%20connections%3D(%22%24%40%22)%0A%0A%20%20%23%20We%20want%20autoconnect%20set%20for%20our%20cloned%20slave%20profiles%20so%20that%20they%20are%0A%20%20%23%20used%20over%20the%20original%20profiles%20if%20implicitly%20re-activated%20with%20other%0A%20%20%23%20dependant%20profiles.%20Otherwise%20if%20a%20slave%20activates%20with%20an%20old%20profile%2C%0A%20%20%23%20the%20old%20master%20profile%20might%20activate%20as%20well%2C%20interfering%20and%20causing%0A%20%20%23%20further%20activations%20to%20fail.%0A%20%20%23%20Slave%20interfaces%20should%20already%20be%20active%20so%20setting%20autoconnect%20here%0A%20%20%23%20won't%20implicitly%20activate%20them%20but%20there%20is%20an%20edge%20case%20where%20a%20slave%0A%20%20%23%20might%20be%20inactive%20(link%20down%20for%20example)%20and%20in%20that%20case%20setting%0A%20%20%23%20autoconnect%20will%20cause%20an%20implicit%20activation.%20This%20is%20not%20necessarily%20a%0A%20%20%23%20problem%20and%20hopefully%20we%20can%20make%20sure%20everything%20is%20activated%20as%20we%0A%20%20%23%20want%20next.%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20fi%0A%20%20done%0A%0A%20%20%23%20Activate%20all%20connections%20and%20fail%20if%20activation%20fails%0A%20%20%23%20For%20slave%20connections%20-%20for%20as%20long%20as%20at%20least%20one%20slave%20that%20belongs%20to%20a%20bond%2Fteam%0A%20%20%23%20comes%20up%2C%20we%20should%20not%20fail%0A%20%20declare%20-A%20master_interfaces%0A%20%20for%20conn%20in%20%22%24%7Bconnections%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%23%20Get%20the%20slave%20type%0A%20%20%20%20local%20slave_type%3D%24(nmcli%20-g%20connection.slave-type%20connection%20show%20%22%24conn%22)%0A%20%20%20%20local%20is_slave%3Dfalse%0A%20%20%20%20if%20%5B%20%22%24slave_type%22%20%3D%20%22team%22%20%5D%20%7C%7C%20%5B%20%22%24slave_type%22%20%3D%20%22bond%22%20%5D%3B%20then%0A%20%20%20%20%20%20is_slave%3Dtrue%0A%20%20%20%20fi%20%0A%0A%20%20%20%20%23%20For%20slave%20interfaces%2C%20initialize%20the%20master%20interface%20to%20false%20if%20the%20key%20is%20not%20yet%20in%20the%20array%0A%20%20%20%20local%20master_interface%0A%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20master_interface%3D%24(nmcli%20-g%20connection.master%20connection%20show%20%22%24conn%22)%0A%20%20%20%20%20%20if%20!%20%5B%5B%20-v%20%22master_interfaces%5B%24master_interface%5D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dfalse%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Do%20not%20activate%20interfaces%20that%20are%20already%20active%0A%20%20%20%20%23%20But%20set%20the%20entry%20in%20master_interfaces%20to%20true%20if%20this%20is%20a%20slave%0A%20%20%20%20%23%20Also%20set%20autoconnect%20to%20yes%0A%20%20%20%20local%20active_state%3D%24(nmcli%20-g%20GENERAL.STATE%20conn%20show%20%22%24conn%22)%0A%20%20%20%20if%20%5B%20%22%24active_state%22%20%3D%3D%20%22activated%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Connection%20%24conn%20already%20activated%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%24master_interface%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20%20%20%20%20continue%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Activate%20all%20interfaces%20that%20are%20not%20yet%20active%0A%20%20%20%20for%20i%20in%20%7B1..10%7D%3B%20do%0A%20%20%20%20%20%20echo%20%22Attempt%20%24i%20to%20bring%20up%20connection%20%24conn%22%0A%20%20%20%20%20%20nmcli%20conn%20up%20%22%24conn%22%20%26%26%20s%3D0%20%26%26%20break%20%7C%7C%20s%3D%24%3F%0A%20%20%20%20%20%20sleep%205%0A%20%20%20%20done%0A%20%20%20%20if%20%5B%20%24s%20-eq%200%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Brought%20up%20connection%20%24conn%20successfully%22%0A%20%20%20%20%20%20if%20%24is_slave%3B%20then%0A%20%20%20%20%20%20%20%20master_interfaces%5B%22%24master_interface%22%5D%3Dtrue%0A%20%20%20%20%20%20fi%0A%20%20%20%20elif%20!%20%24is_slave%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20connection%20%24conn%20after%20%24i%20attempts%22%0A%20%20%20%20%20%20return%20%24s%0A%20%20%20%20fi%0A%20%20%20%20mod_nm_conn%20%22%24conn%22%20connection.autoconnect%20yes%0A%20%20done%0A%20%20%23%20Check%20that%20all%20master%20interfaces%20report%20at%20least%20a%20single%20active%20slave%0A%20%20%23%20Note%3A%20associative%20arrays%20require%20an%20exclamation%20mark%20when%20looping%0A%20%20for%20i%20in%20%22%24%7B!master_interfaces%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20if%20!%20%24%7Bmaster_interfaces%5B%22%24i%22%5D%7D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22ERROR%3A%20Cannot%20bring%20up%20any%20slave%20interface%20for%20master%20interface%3A%20%24i%22%0A%20%20%20%20%20%20%20%20return%201%0A%20%20%20%20fi%0A%20%20done%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24iface%0A%23%20Writes%20content%20of%20%24iface%20into%20%24iface_default_hint_file%0Awrite_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20iface%3D%22%242%22%0A%0A%20%20echo%20%22%24%7Biface%7D%22%20%3E%7C%20%22%24%7Biface_default_hint_file%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%0A%23%20Returns%20the%20stored%20interface%20default%20hint%20if%20the%20hint%20is%20non-empty%2C%0A%23%20not%20br-ex%2C%20not%20br-ex1%20and%20if%20the%20interface%20can%20be%20found%20in%20%2Fsys%2Fclass%2Fnet%0Aget_iface_default_hint()%20%7B%0A%20%20local%20iface_default_hint_file%3D%241%0A%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%3B%20then%0A%20%20%20%20local%20iface_default_hint%3D%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22br-ex1%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20-d%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Biface_default_hint%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%22%0A%7D%0A%0Aget_ip_from_ip_hint_file()%20%7B%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20if%20%5B%5B%20!%20-f%20%22%24%7Bip_hint_file%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%20%20ip_hint%3D%24(cat%20%22%24%7Bip_hint_file%7D%22)%0A%20%20echo%20%22%24%7Bip_hint%7D%22%0A%7D%0A%0A%23%20This%20function%20waits%20for%20ip%20address%20of%20br-ex%20to%20be%20bindable%20only%20in%20case%20of%20ipv6%0A%23%20This%20is%20workaround%20for%20OCPBUGS-673%20as%20it%20will%20not%20allow%20starting%20crio%0A%23%20before%20address%20is%20bindable%0Atry_to_bind_ipv6_address()%20%7B%0A%20%20%23%20Retry%20for%201%20minute%0A%20%20retries%3D60%0A%20%20until%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20do%0A%20%20%20%20ip%3D%24(ip%20-6%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(.ifname%3D%3D%5C%22br-ex%5C%22)%20%7C%20.addr_info%5B%5D%20%7C%20select(.scope%3D%3D%5C%22global%5C%22)%20%7C%20.local)%22)%0A%20%20%20%20if%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22No%20ipv6%20ip%20to%20bind%20was%20found%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20sleep%201%0A%20%20%20%20((%20retries--%20))%0A%20%20done%0A%20%20if%20%5B%5B%20%24%7Bretries%7D%20-eq%200%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Failed%20to%20bind%20ip%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%7D%0A%0A%23%20Get%20interface%20that%20matches%20ip%20from%20node%20ip%20hint%20file%0A%23%20in%20case%20file%20not%20exists%20return%20nothing%20and%0A%23%20fallback%20to%20default%20interface%20search%20flow%0Aget_nodeip_hint_interface()%20%7B%0A%20%20local%20ip_hint%3D%22%22%0A%20%20local%20ip_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge%3D%22%242%22%0A%20%20local%20iface%3D%22%22%0A%0A%20%20ip_hint%3D%24(get_ip_from_ip_hint_file%20%22%24%7Bip_hint_file%7D%22)%0A%20%20if%20%5B%5B%20-z%20%22%24%7Bip_hint%7D%22%20%20%5D%5D%3B%20then%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20iface%3D%24(ip%20-j%20addr%20%7C%20jq%20-r%20%22first(.%5B%5D%20%7C%20select(any(.addr_info%5B%5D%3B%20.local%3D%3D%5C%22%24%7Bip_hint%7D%5C%22)%20and%20.ifname!%3D%5C%22br-ex1%5C%22%20and%20.ifname!%3D%5C%22%24%7Bextra_bridge%7D%5C%22))%20%7C%20.ifname%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20fi%0A%7D%0A%0A%23%20Accepts%20parameters%20%24bridge_interface%20(e.g.%20ovs-port-phys0)%0A%23%20Returns%20the%20physical%20interface%20name%20if%20%24bridge_interface%20exists%2C%20%22%22%20otherwise%0Aget_bridge_physical_interface()%20%7B%0A%20%20local%20bridge_interface%3D%22%241%22%0A%20%20local%20physical_interface%3D%22%22%0A%20%20physical_interface%3D%24(nmcli%20-g%20connection.interface-name%20conn%20show%20%22%24%7Bbridge_interface%7D%22%202%3E%2Fdev%2Fnull%20%7C%7C%20echo%20%22%22)%0A%20%20echo%20%22%24%7Bphysical_interface%7D%22%0A%7D%0A%0A%23%20Accepts%20parameters%20%24iface_default_hint_file%2C%20%24extra_bridge_file%2C%20%24ip_hint_file%2C%20%24default_bridge_file%0A%23%20Determines%20the%20interface%20to%20be%20used%20for%20br-ex.%20Order%20of%20priority%20is%3A%0A%23%201.%20Use%20the%20user%20specified%20interface%20if%20provided%20in%20the%20default%20bridge%20file%0A%23%202.%20Use%20the%20node%20IP%20hint%20interface%0A%23%203.%20Use%20the%20previously%20selected%20interface%0A%23%204.%20Use%20the%20interface%20detected%20as%20default%20gateway%0A%23%0A%23%20Read%20%24default_bridge_file%20and%20return%20the%20contained%20interface.%20Otherwise%2C%0A%23%20read%20%24ip_hint_file%20and%20return%20the%20interface%20that%20matches%20this%20ip.%20Otherwise%2C%0A%23%20if%20the%20default%20interface%20is%20br-ex%2C%20use%20that%20and%20return.%0A%23%20If%20the%20default%20interface%20is%20not%20br-ex%3A%0A%23%20Check%20if%20there%20is%20a%20valid%20hint%20inside%20%24iface_default_hint_file.%20If%20so%2C%20use%20that%20hint.%0A%23%20If%20there%20is%20no%20valid%20hint%2C%20use%20the%20default%20interface%20that%20we%20found%20during%20the%20step%0A%23%20earlier.%0A%23%20Never%20use%20the%20interface%20that%20is%20provided%20inside%20%24extra_bridge_file%20for%20br-ex1.%0A%23%20Never%20use%20br-ex1.%0A%23%20Write%20the%20default%20interface%20to%20%24iface_default_hint_file%0Aget_default_bridge_interface()%20%7B%0A%20%20local%20iface%3D%22%22%0A%20%20local%20counter%3D0%0A%20%20local%20iface_default_hint_file%3D%22%241%22%0A%20%20local%20extra_bridge_file%3D%22%242%22%0A%20%20local%20ip_hint_file%3D%22%243%22%0A%20%20local%20default_bridge_file%3D%22%244%22%0A%20%20local%20extra_bridge%3D%22%22%0A%0A%20%20if%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%3B%20then%0A%20%20%20%20extra_bridge%3D%24(cat%20%24%7Bextra_bridge_file%7D)%0A%20%20fi%0A%0A%20%20%23%20try%20to%20use%20user%20specified%20file%20first%0A%20%20if%20%5B%20-f%20%22%24default_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20iface%3D%24(cat%20%22%24%7Bdefault_bridge_file%7D%22)%0A%20%20%20%20if%20%5B%20-z%20%22%24iface%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22ERROR%3A%20User%20specified%20bridge%20file%20detected%20without%20any%20data%22%0A%20%20%20%20%20%20exit%201%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20if%20node%20ip%20was%20set%2C%20we%20should%20search%20for%20interface%20that%20matches%20it%0A%20%20iface%3D%24(get_nodeip_hint_interface%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bextra_bridge%7D%22)%0A%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22%24%7Biface%7D%22%0A%20%20%20%20return%0A%20%20fi%0A%0A%20%20%23%20find%20default%20interface%0A%20%20%23%20the%20default%20interface%20might%20be%20br-ex%2C%20so%20check%20this%20before%20looking%20at%20the%20hint%0A%20%20while%20%5B%20%24%7Bcounter%7D%20-lt%2012%20%5D%3B%20do%0A%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%23%20never%20use%20the%20interface%20that's%20specified%20in%20extra_bridge_file%0A%20%20%20%20%23%20never%20use%20br-ex1%0A%20%20%20%20if%20%5B%20%22%24%7Bextra_bridge%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20grep%20-v%20%22%24%7Bextra_bridge%7D%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20else%0A%20%20%20%20%20%20iface%3D%24(ip%20-6%20route%20show%20default%20%7C%20grep%20-v%20%22br-ex1%22%20%7C%20awk%20'%7B%20if%20(%244%20%3D%3D%20%22dev%22)%20%7B%20print%20%245%3B%20exit%20%7D%20%7D')%0A%20%20%20%20fi%0A%20%20%20%20if%20%5B%5B%20-n%20%22%24%7Biface%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20break%0A%20%20%20%20fi%0A%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20sleep%205%0A%20%20done%0A%0A%20%20%23%20if%20the%20default%20interface%20does%20not%20point%20out%20of%20br-ex%20or%20br-ex1%0A%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20%23%20determine%20if%20an%20interface%20default%20hint%20exists%20from%20a%20previous%20run%0A%20%20%20%20%23%20and%20if%20the%20interface%20has%20a%20valid%20default%20route%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%22%20%5D%20%26%26%0A%20%20%20%20%20%20%20%20%5B%20%22%24%7Biface_default_hint%7D%22%20!%3D%20%22%24%7Biface%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20start%20wherever%20count%20left%20off%20in%20the%20previous%20loop%0A%20%20%20%20%20%20%23%20allow%20this%20for%20one%20more%20iteration%20than%20the%20previous%20loop%0A%20%20%20%20%20%20while%20%5B%20%24%7Bcounter%7D%20-le%2012%20%5D%3B%20do%0A%20%20%20%20%20%20%20%20%23%20check%20ipv4%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20%23%20check%20ipv6%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24(ip%20-6%20route%20show%20default%20dev%20%22%24%7Biface_default_hint%7D%22)%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20iface%3D%22%24%7Biface_default_hint%7D%22%0A%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20counter%3D%24((counter%2B1))%0A%20%20%20%20%20%20%20%20sleep%205%0A%20%20%20%20%20%20done%0A%20%20%20%20fi%0A%20%20%20%20%23%20store%20what%20was%20determined%20was%20the%20(new)%20default%20interface%20inside%0A%20%20%20%20%23%20the%20default%20hint%20file%20for%20future%20reference%0A%20%20%20%20if%20%5B%20%22%24%7Biface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Biface%7D%22%0A%20%20%20%20fi%0A%20%20fi%0A%20%20echo%20%22%24%7Biface%7D%22%0A%7D%0A%0A%23%20Used%20to%20print%20network%20state%0Aprint_state()%20%7B%0A%20%20echo%20%22Current%20device%2C%20connection%2C%20interface%20and%20routing%20state%3A%22%0A%20%20nmcli%20-g%20all%20device%20%7C%20grep%20-v%20unmanaged%0A%20%20nmcli%20-g%20all%20connection%0A%20%20ip%20-d%20address%20show%0A%20%20ip%20route%20show%0A%20%20ip%20-6%20route%20show%0A%7D%0A%0A%23%20Setup%20an%20exit%20trap%20to%20rollback%20on%20error%0Ahandle_exit()%20%7B%0A%20%20e%3D%24%3F%0A%20%20tdir%3D%24(mktemp%20-u%20-d%20-t%20%22configure-ovs-%24(date%20%2B%25Y-%25m-%25d-%25H-%25M-%25S)-XXXXXXXXXX%22)%0A%20%20%0A%20%20if%20%5B%20%24e%20-eq%200%20%5D%3B%20then%0A%20%20%20%20print_state%0A%20%20%20%20%23%20remove%20previous%20troubleshooting%20information%0A%20%20%20%20rm%20-rf%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%0A%20%20echo%20%22ERROR%3A%20configure-ovs%20exited%20with%20error%3A%20%24e%22%0A%20%20print_state%0A%0A%20%20%23%20remove%20previous%20troubleshooting%20information%20except%20the%20oldest%20one%0A%20%20mapfile%20-t%20tdirs%20%3C%20%3C(compgen%20-G%20%22%24(dirname%20%22%24tdir%22)%2Fconfigure-ovs-*%22)%0A%20%20unset%20-v%20%22tdirs%5B0%5D%22%0A%20%20for%20dir%20in%20%22%24%7Btdirs%5B%40%5D%7D%22%3B%20do%20rm%20-rf%20%22%24dir%22%3B%20done%0A%0A%20%20%23%20copy%20configuration%20to%20tmp%20for%20troubleshooting%0A%20%20mkdir%20-p%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex%20phys0%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20update_nm_conn_run_files%20br-ex1%20phys1%0A%20%20copy_nm_conn_files%20%22%24tdir%22%0A%20%20echo%20%22Copied%20OVS%20configuration%20to%20%24tdir%20for%20troubleshooting%22%0A%0A%20%20%23%20attempt%20to%20restore%20the%20previous%20network%20state%0A%20%20echo%20%22Attempting%20to%20restore%20previous%20configuration...%22%0A%20%20rollback_nm%0A%20%20print_state%0A%0A%20%20exit%20%24e%0A%7D%0A%0A%23%20Setup%20a%20signal%20trap%20to%20rollback%0Ahandle_termination()%20%7B%0A%20%20echo%20%22WARNING%3A%20configure-ovs%20has%20been%20requested%20to%20terminate%2C%20quitting...%22%0A%20%20%0A%20%20%23%20by%20exiting%20with%20an%20error%20we%20will%20cleanup%20after%20ourselves%20in%20a%0A%20%20%23%20subsequent%20call%20to%20handle_exit%0A%20%20exit%201%0A%7D%0A%0A%23%20main%20function%0Aconfigure_ovs()%20%7B%0A%20%20set%20-eu%0A%0A%20%20%23%20setup%20traps%20to%20handle%20signals%20and%20other%20abnormal%20exits%0A%20%20trap%20'handle_termination'%20TERM%20INT%0A%20%20trap%20'handle_exit'%20EXIT%0A%0A%20%20%23%20this%20flag%20tracks%20if%20any%20config%20change%20was%20made%0A%20%20nm_config_changed%3D0%0A%0A%20%20%23%20Check%20that%20we%20are%20provided%20a%20valid%20NM%20connection%20path%0A%20%20if%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_CONF_PATH%22%20%5D%20%26%26%20%5B%20%22%24NM_CONN_SET_PATH%22%20!%3D%20%22%24NM_CONN_RUN_PATH%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Error%3A%20Incorrect%20NM%20connection%20path%3A%20%24NM_CONN_SET_PATH%20is%20not%20%24NM_CONN_CONF_PATH%20nor%20%24NM_CONN_RUN_PATH%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20Clean%20up%20old%20config%20on%20behalf%20of%20mtu-migration%0A%20%20if%20!%20systemctl%20-q%20is-enabled%20mtu-migration%3B%20then%0A%20%20%20%20echo%20%22Cleaning%20up%20left%20over%20mtu%20migration%20configuration%22%0A%20%20%20%20rm%20-rf%20%2Fetc%2Fcno%2Fmtu-migration%0A%20%20fi%0A%0A%20%20if%20!%20rpm%20-qa%20%7C%20grep%20-q%20openvswitch%3B%20then%0A%20%20%20%20echo%20%22WARNING%3A%20Openvswitch%20package%20is%20not%20installed!%22%0A%20%20%20%20exit%201%0A%20%20fi%0A%0A%20%20%23%20print%20initial%20state%0A%20%20print_state%0A%0A%20%20if%20%5B%20%22%241%22%20%3D%3D%20%22OVNKubernetes%22%20%5D%3B%20then%0A%20%20%20%20%23%20Configures%20NICs%20onto%20OVS%20bridge%20%22br-ex%22%0A%20%20%20%20%23%20Configuration%20is%20either%20auto-detected%20or%20provided%20through%20a%20config%20file%20written%20already%20in%20Network%20Manager%0A%20%20%20%20%23%20key%20files%20under%20%2Fetc%2FNetworkManager%2Fsystem-connections%2F%0A%20%20%20%20%23%20Managing%20key%20files%20is%20outside%20of%20the%20scope%20of%20this%20script%0A%0A%20%20%20%20%23%20if%20the%20interface%20is%20of%20type%20vmxnet3%20add%20multicast%20capability%20for%20that%20driver%0A%20%20%20%20%23%20History%3A%20BZ%3A1854355%0A%20%20%20%20function%20configure_driver_options%20%7B%0A%20%20%20%20%20%20intf%3D%241%0A%20%20%20%20%20%20if%20%5B%20!%20-f%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Device%20file%20doesn't%20exist%2C%20skipping%20setting%20multicast%20mode%22%0A%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20driver%3D%24(cat%20%22%2Fsys%2Fclass%2Fnet%2F%24%7Bintf%7D%2Fdevice%2Fuevent%22%20%7C%20grep%20DRIVER%20%7C%20awk%20-F%20%22%3D%22%20'%7Bprint%20%242%7D')%0A%20%20%20%20%20%20%20%20echo%20%22Driver%20name%20is%22%20%24driver%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24driver%22%20%3D%20%22vmxnet3%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20ip%20link%20set%20dev%20%22%24%7Bintf%7D%22%20allmulticast%20on%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20fi%0A%20%20%20%20%7D%0A%0A%20%20%20%20ovnk_config_dir%3D'%2Fetc%2Fovnk'%0A%20%20%20%20ovnk_var_dir%3D'%2Fvar%2Flib%2Fovnk'%0A%20%20%20%20extra_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fextra_bridge%22%0A%20%20%20%20iface_default_hint_file%3D%22%24%7Bovnk_var_dir%7D%2Fiface_default_hint%22%0A%20%20%20%20ip_hint_file%3D%22%2Frun%2Fnodeip-configuration%2Fprimary-ip%22%0A%20%20%20%20%23%20explicitly%20specify%20which%20interface%20should%20be%20used%20with%20the%20default%20bridge%0A%20%20%20%20default_bridge_file%3D%22%24%7Bovnk_config_dir%7D%2Fdefault_bridge%22%0A%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_config_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_config_dir%7D%22%0A%20%20%20%20%23%20make%20sure%20to%20create%20ovnk_var_dir%20if%20it%20does%20not%20exist%2C%20yet%0A%20%20%20%20mkdir%20-p%20%22%24%7Bovnk_var_dir%7D%22%0A%0A%20%20%20%20%23%20For%20upgrade%20scenarios%2C%20make%20sure%20that%20we%20stabilize%20what%20we%20already%20configured%0A%20%20%20%20%23%20before.%20If%20we%20do%20not%20have%20a%20valid%20interface%20hint%2C%20find%20the%20physical%20interface%0A%20%20%20%20%23%20that's%20attached%20to%20ovs-if-phys0.%0A%20%20%20%20%23%20If%20we%20find%20such%20an%20interface%2C%20write%20it%20to%20the%20hint%20file.%0A%20%20%20%20iface_default_hint%3D%24(get_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22)%0A%20%20%20%20if%20%5B%20%22%24%7Biface_default_hint%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20current_interface%3D%24(get_bridge_physical_interface%20ovs-if-phys0)%0A%20%20%20%20%20%20if%20%5B%20%22%24%7Bcurrent_interface%7D%22%20!%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20write_iface_default_hint%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bcurrent_interface%7D%22%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20delete%20iface_default_hint_file%20if%20it%20has%20the%20same%20content%20as%20extra_bridge_file%0A%20%20%20%20%23%20in%20that%20case%2C%20we%20must%20also%20force%20a%20reconfiguration%20of%20our%20network%20interfaces%0A%20%20%20%20%23%20to%20make%20sure%20that%20we%20reconcile%20this%20conflict%0A%20%20%20%20if%20%5B%20-f%20%22%24%7Biface_default_hint_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20-f%20%22%24%7Bextra_bridge_file%7D%22%20%5D%20%26%26%0A%20%20%20%20%20%20%5B%20%22%24(cat%20%22%24%7Biface_default_hint_file%7D%22)%22%20%3D%3D%20%22%24(cat%20%22%24%7Bextra_bridge_file%7D%22)%22%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22%24%7Biface_default_hint_file%7D%20and%20%24%7Bextra_bridge_file%7D%20share%20the%20same%20content%22%0A%20%20%20%20%20%20echo%20%22Deleting%20file%20%24%7Biface_default_hint_file%7D%20to%20choose%20a%20different%20interface%22%0A%20%20%20%20%20%20rm%20-f%20%22%24%7Biface_default_hint_file%7D%22%0A%20%20%20%20%20%20rm%20-f%20%2Frun%2Fconfigure-ovs-boot-done%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20on%20every%20boot%20we%20rollback%20and%20generate%20the%20configuration%20again%2C%20to%20take%0A%20%20%20%20%23%20in%20any%20changes%20that%20have%20possibly%20been%20applied%20in%20the%20standard%0A%20%20%20%20%23%20configuration%20sources%0A%20%20%20%20if%20%5B%20!%20-f%20%2Frun%2Fconfigure-ovs-boot-done%20%5D%3B%20then%0A%20%20%20%20%20%20echo%20%22Running%20on%20boot%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20print_state%0A%20%20%20%20fi%0A%20%20%20%20touch%20%2Frun%2Fconfigure-ovs-boot-done%0A%0A%20%20%20%20iface%3D%24(get_default_bridge_interface%20%22%24%7Biface_default_hint_file%7D%22%20%22%24%7Bextra_bridge_file%7D%22%20%22%24%7Bip_hint_file%7D%22%20%22%24%7Bdefault_bridge_file%7D%22)%0A%0A%20%20%20%20if%20%5B%20%22%24iface%22%20!%3D%20%22br-ex%22%20%5D%3B%20then%0A%20%20%20%20%20%20%23%20Specified%20interface%20is%20not%20br-ex.%0A%20%20%20%20%20%20%23%20Some%20deployments%20use%20a%20temporary%20solution%20where%20br-ex%20is%20moved%20out%20from%20the%20default%20gateway%20interface%0A%20%20%20%20%20%20%23%20and%20bound%20to%20a%20different%20nic%20(https%3A%2F%2Fgithub.com%2Ftrozet%2Fopenshift-ovn-migration).%0A%20%20%20%20%20%20%23%20This%20is%20now%20supported%20through%20an%20extra%20bridge%20if%20requested.%20If%20that%20is%20the%20case%2C%20we%20rollback.%0A%20%20%20%20%20%20%23%20We%20also%20rollback%20if%20it%20looks%20like%20we%20need%20to%20configure%20things%2C%20just%20in%20case%20there%20are%20any%20leftovers%0A%20%20%20%20%20%20%23%20from%20previous%20attempts.%0A%20%20%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%7C%7C%20%5B%20-z%20%22%24(nmcli%20connection%20show%20--active%20br-ex%202%3E%20%2Fdev%2Fnull)%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%22Bridge%20br-ex%20is%20not%20active%2C%20restoring%20previous%20configuration%20before%20proceeding...%22%0A%20%20%20%20%20%20%20%20rollback_nm%0A%20%20%20%20%20%20%20%20print_state%0A%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20convert_to_bridge%20%22%24iface%22%20%22br-ex%22%20%22phys0%22%20%22%24%7BBRIDGE_METRIC%7D%22%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20configure%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(!%20nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20!%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20interface%3D%24(head%20-n%201%20%24extra_bridge_file)%0A%20%20%20%20%20%20convert_to_bridge%20%22%24interface%22%20%22br-ex1%22%20%22phys1%22%20%22%24%7BBRIDGE1_METRIC%7D%22%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Check%20if%20we%20need%20to%20remove%20the%20second%20bridge%0A%20%20%20%20if%20%5B%20!%20-f%20%22%24extra_bridge_file%22%20%5D%20%26%26%20(nmcli%20connection%20show%20br-ex1%20%26%3E%20%2Fdev%2Fnull%20%7C%7C%20nmcli%20connection%20show%20ovs-if-phys1%20%26%3E%20%2Fdev%2Fnull)%3B%20then%0A%20%20%20%20%20%20remove_ovn_bridges%20br-ex1%20phys1%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20openshift-sdn%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br0%0A%0A%20%20%20%20%23%20Make%20sure%20everything%20is%20activated.%20Do%20it%20in%20a%20specific%20order%3A%0A%20%20%20%20%23%20-%20activate%20br-ex%20first%2C%20due%20to%20autoconnect-slaves%20this%20will%20also%0A%20%20%20%20%23%20%20%20activate%20ovs-port-br-ex%2C%20ovs-port-phys0%20and%20ovs-if-phys0.%20It%20is%0A%20%20%20%20%23%20%20%20important%20that%20ovs-if-phys0%20activates%20with%20br-ex%20to%20avoid%20the%0A%20%20%20%20%23%20%20%20ovs-if-phys0%20profile%20being%20overridden%20with%20a%20profile%20generated%20from%0A%20%20%20%20%23%20%20%20kargs.%20The%20activation%20of%20ovs-if-phys0%2C%20if%20a%20bond%2C%20might%20cause%20the%0A%20%20%20%20%23%20%20%20slaves%20to%20re-activate%2C%20but%20it%20should%20be%20with%20our%20profiles%20since%20they%0A%20%20%20%20%23%20%20%20have%20higher%20priority%0A%20%20%20%20%23%20-%20make%20sure%20that%20ovs-if-phys0%20and%20its%20slaves%2C%20if%20any%2C%20are%20activated.%0A%20%20%20%20%23%20-%20finally%20activate%20ovs-if-br-ex%20which%20holds%20the%20IP%20configuration.%0A%20%20%20%20connections%3D(br-ex%20ovs-if-phys0)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(br-ex1%20ovs-if-phys1)%0A%20%20%20%20fi%0A%20%20%20%20while%20IFS%3D%20read%20-r%20connection%3B%20do%0A%20%20%20%20%20%20if%20%5B%5B%20%24connection%20%3D%3D%20*%22%24MANAGED_NM_CONN_SUFFIX%22%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20connections%2B%3D(%22%24connection%22)%0A%20%20%20%20%20%20fi%0A%20%20%20%20done%20%3C%20%3C(nmcli%20-g%20NAME%20c)%0A%20%20%20%20connections%2B%3D(ovs-if-br-ex)%0A%20%20%20%20if%20%5B%20-f%20%22%24extra_bridge_file%22%20%5D%3B%20then%0A%20%20%20%20%20%20connections%2B%3D(ovs-if-br-ex1)%0A%20%20%20%20fi%0A%20%20%20%20activate_nm_connections%20%22%24%7Bconnections%5B%40%5D%7D%22%0A%20%20%20%20try_to_bind_ipv6_address%0A%20%20%20%20set_nm_conn_files%0A%20%20elif%20%5B%20%22%241%22%20%3D%3D%20%22OpenShiftSDN%22%20%5D%3B%20then%0A%20%20%20%20%23%20Revert%20changes%20made%20by%20%2Fusr%2Flocal%2Fbin%2Fconfigure-ovs.sh%20during%20SDN%20migration.%0A%20%20%20%20rollback_nm%0A%20%20%20%20%0A%20%20%20%20%23%20Remove%20bridges%20created%20by%20ovn-kubernetes%0A%20%20%20%20ovs-vsctl%20--timeout%3D30%20--if-exists%20del-br%20br-int%20--%20--if-exists%20del-br%20br-local%0A%20%20fi%0A%7D%0A%0A%23%20Retry%20configure_ovs%20until%20it%20succeeds.%0A%23%20By%20default%2C%20retry%20every%2015%20minutes%20to%20give%20enough%20time%20to%20gather%0A%23%20troubleshooting%20information%20in%20between.%20Note%20that%20configure_ovs%20has%20other%0A%23%20internal%20retry%20mechanisms.%20This%20retry%20is%20intended%20to%20give%20some%0A%23%20self-healing%20capabilities%20to%20temporary%20but%20not%20necessarily%20short-lived%0A%23%20infrastructure%20problems.%0ARETRY%3D%22%24%7BRETRY-15m%7D%22%0Awhile%20true%3B%20do%0A%0A%20%20%23%20Disable%20retries%20if%20termination%20signal%20is%20received.%20Note%20that%20systemd%0A%20%20%23%20sends%20the%20signals%20to%20all%20processes%20in%20the%20group%20by%20default%20so%20we%20expect%0A%20%20%23%20configure_ovs%20to%20get%20its%20own%20signals.%0A%20%20trap%20'echo%20%22WARNING%3A%20termination%20requested%2C%20disabling%20retries%22%3B%20RETRY%3D%22%22'%20INT%20TERM%0A%20%20%0A%20%20%23%20Run%20configure_ovs%20in%20a%20sub-shell.%20%0A%20%20(%20configure_ovs%20%22%24%40%22%20)%0A%20%20e%3D%24%3F%0A%0A%20%20%23%20Handle%20signals%20while%20we%20sleep%0A%20%20trap%20'handle_termination'%20INT%20TERM%0A%20%20%0A%20%20%23%20Exit%20if%20succesful%20and%20not%20configured%20to%20retry%0A%20%20%5B%20%22%24e%22%20-eq%200%20%5D%20%7C%7C%20%5B%20-z%20%22%24RETRY%22%20%5D%20%26%26%20exit%20%22%24e%22%0A%20%20%0A%20%20echo%20%22configure-ovs%20failed%2C%20will%20retry%20after%20%24RETRY%22%0A%20%20%23%20flag%20that%20a%20retry%20has%20happened%0A%20%20touch%20%2Ftmp%2Fconfigure-ovs-retry%0A%20%20sleep%20%22%24RETRY%22%0A%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/configure-ovs.sh
        - contents:
            source: data:,%23%20This%20file%20is%20generated%20by%20the%20Machine%20Config%20Operator's%20containerruntimeconfig%20controller.%0A%23%0A%23%20storage.conf%20is%20the%20configuration%20file%20for%20all%20tools%0A%23%20that%20share%20the%20containers%2Fstorage%20libraries%0A%23%20See%20man%205%20containers-storage.conf%20for%20more%20information%0A%23%20The%20%22container%20storage%22%20table%20contains%20all%20of%20the%20server%20options.%0A%5Bstorage%5D%0A%0A%23%20Default%20Storage%20Driver%0Adriver%20%3D%20%22overlay%22%0A%0A%23%20Temporary%20storage%20location%0Arunroot%20%3D%20%22%2Fvar%2Frun%2Fcontainers%2Fstorage%22%0A%0A%23%20Primary%20Read%2FWrite%20location%20of%20container%20storage%0Agraphroot%20%3D%20%22%2Fvar%2Flib%2Fcontainers%2Fstorage%22%0A%0A%5Bstorage.options%5D%0A%23%20Storage%20options%20to%20be%20passed%20to%20underlying%20storage%20drivers%0A%0A%23%20AdditionalImageStores%20is%20used%20to%20pass%20paths%20to%20additional%20Read%2FOnly%20image%20stores%0A%23%20Must%20be%20comma%20separated%20list.%0Aadditionalimagestores%20%3D%20%5B%0A%5D%0A%0A%23%20Size%20is%20used%20to%20set%20a%20maximum%20size%20of%20the%20container%20image.%20%20Only%20supported%20by%0A%23%20certain%20container%20storage%20drivers.%0Asize%20%3D%20%22%22%0A%0A%23%20Remap-UIDs%2FGIDs%20is%20the%20mapping%20from%20UIDs%2FGIDs%20as%20they%20should%20appear%20inside%20of%0A%23%20a%20container%2C%20to%20UIDs%2FGIDs%20as%20they%20should%20appear%20outside%20of%20the%20container%2C%20and%0A%23%20the%20length%20of%20the%20range%20of%20UIDs%2FGIDs.%20%20Additional%20mapped%20sets%20can%20be%20listed%0A%23%20and%20will%20be%20heeded%20by%20libraries%2C%20but%20there%20are%20limits%20to%20the%20number%20of%0A%23%20mappings%20which%20the%20kernel%20will%20allow%20when%20you%20later%20attempt%20to%20run%20a%0A%23%20container.%0A%23%0A%23%20remap-uids%20%3D%200%3A1668442479%3A65536%0A%23%20remap-gids%20%3D%200%3A1668442479%3A65536%0A%0A%23%20Remap-User%2FGroup%20is%20a%20name%20which%20can%20be%20used%20to%20look%20up%20one%20or%20more%20UID%2FGID%0A%23%20ranges%20in%20the%20%2Fetc%2Fsubuid%20or%20%2Fetc%2Fsubgid%20file.%20%20Mappings%20are%20set%20up%20starting%0A%23%20with%20an%20in-container%20ID%20of%200%20and%20the%20a%20host-level%20ID%20taken%20from%20the%20lowest%0A%23%20range%20that%20matches%20the%20specified%20name%2C%20and%20using%20the%20length%20of%20that%20range.%0A%23%20Additional%20ranges%20are%20then%20assigned%2C%20using%20the%20ranges%20which%20specify%20the%0A%23%20lowest%20host-level%20IDs%20first%2C%20to%20the%20lowest%20not-yet-mapped%20container-level%20ID%2C%0A%23%20until%20all%20of%20the%20entries%20have%20been%20used%20for%20maps.%0A%23%0A%23%20remap-user%20%3D%20%22storage%22%0A%23%20remap-group%20%3D%20%22storage%22%0A%0A%5Bstorage.options.overlay%5D%0A%23%20Storage%20Options%20for%20overlay%0A%0A%23%20Do%20not%20create%20a%20PRIVATE%20bind%20mount%20on%20the%20home%20directory.%0Askip_mount_home%20%3D%20%22true%22%0A%0A%5Bstorage.options.thinpool%5D%0A%23%20Storage%20Options%20for%20thinpool%0A%0A%23%20autoextend_percent%20determines%20the%20amount%20by%20which%20pool%20needs%20to%20be%0A%23%20grown.%20This%20is%20specified%20in%20terms%20of%20%25%20of%20pool%20size.%20So%20a%20value%20of%2020%20means%0A%23%20that%20when%20threshold%20is%20hit%2C%20pool%20will%20be%20grown%20by%2020%25%20of%20existing%0A%23%20pool%20size.%0A%23%20autoextend_percent%20%3D%20%2220%22%0A%0A%23%20autoextend_threshold%20determines%20the%20pool%20extension%20threshold%20in%20terms%0A%23%20of%20percentage%20of%20pool%20size.%20For%20example%2C%20if%20threshold%20is%2060%2C%20that%20means%20when%0A%23%20pool%20is%2060%25%20full%2C%20threshold%20has%20been%20hit.%0A%23%20autoextend_threshold%20%3D%20%2280%22%0A%0A%23%20basesize%20specifies%20the%20size%20to%20use%20when%20creating%20the%20base%20device%2C%20which%0A%23%20limits%20the%20size%20of%20images%20and%20containers.%0A%23%20basesize%20%3D%20%2210G%22%0A%0A%23%20blocksize%20specifies%20a%20custom%20blocksize%20to%20use%20for%20the%20thin%20pool.%0A%23%20blocksize%3D%2264k%22%0A%0A%23%20directlvm_device%20specifies%20a%20custom%20block%20storage%20device%20to%20use%20for%20the%0A%23%20thin%20pool.%20Required%20if%20you%20setup%20devicemapper%0A%23%20directlvm_device%20%3D%20%22%22%0A%0A%23%20directlvm_device_force%20wipes%20device%20even%20if%20device%20already%20has%20a%20filesystem%0A%23%20directlvm_device_force%20%3D%20%22True%22%0A%0A%23%20fs%20specifies%20the%20filesystem%20type%20to%20use%20for%20the%20base%20device.%0A%23%20fs%3D%22xfs%22%0A%0A%23%20log_level%20sets%20the%20log%20level%20of%20devicemapper.%0A%23%200%3A%20LogLevelSuppress%200%20(Default)%0A%23%202%3A%20LogLevelFatal%0A%23%203%3A%20LogLevelErr%0A%23%204%3A%20LogLevelWarn%0A%23%205%3A%20LogLevelNotice%0A%23%206%3A%20LogLevelInfo%0A%23%207%3A%20LogLevelDebug%0A%23%20log_level%20%3D%20%227%22%0A%0A%23%20min_free_space%20specifies%20the%20min%20free%20space%20percent%20in%20a%20thin%20pool%20require%20for%0A%23%20new%20device%20creation%20to%20succeed.%20Valid%20values%20are%20from%200%25%20-%2099%25.%0A%23%20Value%200%25%20disables%0A%23%20min_free_space%20%3D%20%2210%25%22%0A%0A%23%20mkfsarg%20specifies%20extra%20mkfs%20arguments%20to%20be%20used%20when%20creating%20the%20base%0A%23%20device.%0A%23%20mkfsarg%20%3D%20%22%22%0A%0A%23%20mountopt%20specifies%20extra%20mount%20options%20used%20when%20mounting%20the%20thin%20devices.%0A%23%20mountopt%20%3D%20%22%22%0A%0A%23%20use_deferred_removal%20Marking%20device%20for%20deferred%20removal%0A%23%20use_deferred_removal%20%3D%20%22True%22%0A%0A%23%20use_deferred_deletion%20Marking%20device%20for%20deferred%20deletion%0A%23%20use_deferred_deletion%20%3D%20%22True%22%0A%0A%23%20xfs_nospace_max_retries%20specifies%20the%20maximum%20number%20of%20retries%20XFS%20should%0A%23%20attempt%20to%20complete%20IO%20when%20ENOSPC%20(no%20space)%20error%20is%20returned%20by%0A%23%20underlying%20storage%20device.%0A%23%20xfs_nospace_max_retries%20%3D%20%220%22%0A
          mode: 420
          overwrite: true
          path: /etc/containers/storage.conf
        - contents:
            source: data:,apiVersion%3A%20kubelet.config.k8s.io%2Fv1%0Akind%3A%20CredentialProviderConfig%0Aproviders%3A%0A%20%20-%20name%3A%20ecr-credential-provider%0A%20%20%20%20matchImages%3A%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.*.amazonaws.com%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.*.amazonaws.com.cn%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr-fips.*.amazonaws.com%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.us-iso-east-1.c2s.ic.gov%22%0A%20%20%20%20%20%20-%20%22*.dkr.ecr.us-isob-east-1.sc2s.sgov.gov%22%0A%20%20%20%20defaultCacheDuration%3A%20%2212h%22%0A%20%20%20%20apiVersion%3A%20credentialprovider.kubelet.k8s.io%2Fv1%0A
          mode: 420
          overwrite: true
          path: /etc/kubernetes/credential-providers/ecr-credential-provider.yaml
        - contents:
            source: data:,%23%20Proxy%20environment%20variables%20will%20be%20populated%20in%20this%20file.%20Properly%0A%23%20url%20encoded%20passwords%20with%20special%20characters%20will%20use%20'%25%3CHEX%3E%3CHEX%3E'.%0A%23%20Systemd%20requires%20that%20any%20%25%20used%20in%20a%20password%20be%20represented%20as%0A%23%20%25%25%20in%20a%20unit%20file%20since%20%25%20is%20a%20prefix%20for%20macros%3B%20this%20restriction%20does%20not%0A%23%20apply%20for%20environment%20files.%20Templates%20that%20need%20the%20proxy%20set%20should%20use%0A%23%20'EnvironmentFile%3D%2Fetc%2Fmco%2Fproxy.env'.%0A
          mode: 420
          overwrite: true
          path: /etc/mco/proxy.env
        - contents:
            source: data:,%5BManager%5D%0ADefaultEnvironment%3DGODEBUG%3Dx509ignoreCN%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/10-default-env-godebug.conf
        - contents:
            source: data:,%23%20Force-load%20legacy%20iptables%20so%20it%20is%20usable%20from%20pod%20network%20namespaces%0Aip_tables%0A
          mode: 420
          overwrite: true
          path: /etc/modules-load.d/iptables.conf
        - contents:
            source: data:,NODE_SIZING_ENABLED%3Dfalse%0ASYSTEM_RESERVED_MEMORY%3D1Gi%0ASYSTEM_RESERVED_CPU%3D500m%0ASYSTEM_RESERVED_ES%3D1Gi
          mode: 420
          overwrite: true
          path: /etc/node-sizing-enabled.env
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%0ANODE_SIZES_ENV%3D%24%7BNODE_SIZES_ENV%3A-%2Fetc%2Fnode-sizing.env%7D%0AVERSION_1%3D1%0AVERSION_2%3D2%0ANODE_AUTO_SIZING_VERSION%3D%24%7BNODE_AUTO_SIZING_VERSION%3A-%24VERSION_2%7D%0ANODE_AUTO_SIZING_VERSION_FILE%3D%24%7BNODE_AUTO_SIZING_VERSION_FILE%3A-%2Fetc%2Fnode-sizing-version.json%7D%0Afunction%20dynamic_memory_sizing%20%7B%0A%20%20%20%20total_memory%3D%24(free%20-g%7Cawk%20'%2F%5EMem%3A%2F%7Bprint%20%242%7D')%0A%20%20%20%20%23%20total_memory%3D8%20test%20the%20recommended%20values%20by%20modifying%20this%20value%0A%20%20%20%20recommended_systemreserved_memory%3D0%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2025%25%20of%20the%20first%204GB%20of%20memory%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24total_memory%200.25%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D1%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%204))%3B%20then%20%23%2020%25%20of%20the%20next%204GB%20of%20memory%20(up%20to%208GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.20%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-4))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%208))%3B%20then%20%23%2010%25%20of%20the%20next%208GB%20of%20memory%20(up%20to%2016GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.10%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%200.80%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-8))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3C%3D%20112))%3B%20then%20%23%206%25%20of%20the%20next%20112GB%20of%20memory%20(up%20to%20128GB)%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D0%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%206.72%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20total_memory%3D%24((total_memory-112))%0A%20%20%20%20fi%0A%20%20%20%20if%20((%24total_memory%20%3E%3D%200))%3B%20then%20%23%202%25%20of%20any%20memory%20above%20128GB%0A%20%20%20%20%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%24(echo%20%24total_memory%200.02%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20fi%0A%20%20%20%20recommended_systemreserved_memory%3D%24(echo%20%24recommended_systemreserved_memory%20%7C%20awk%20'%7Bprintf(%22%25d%5Cn%22%2C%241%20%2B%200.5)%7D')%20%23%20Round%20off%20so%20we%20avoid%20float%20conversions%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7Brecommended_systemreserved_memory%7DGi%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_cpu_sizing%20%7B%0A%20%20%20%20total_cpu%3D%24(getconf%20_NPROCESSORS_ONLN)%0A%20%20%20%20if%20%5B%20%22%241%22%20-eq%20%22%24VERSION_1%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%206%25%20of%20the%20first%20core%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24total_cpu%200.06%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D0.06%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%201))%3B%20then%20%23%201%25%20of%20the%20next%20core%20(up%20to%202%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-1))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3C%3D%202))%3B%20then%20%23%200.5%25%20of%20the%20next%202%20cores%20(up%20to%204%20cores)%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.005%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D0%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%200.01%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20%20%20%20%20total_cpu%3D%24((total_cpu-2))%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20%20%20if%20((%24total_cpu%20%3E%3D%200))%3B%20then%20%23%200.25%25%20of%20any%20cores%20above%204%20cores%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(echo%20%24recommended_systemreserved_cpu%20%24(echo%20%24total_cpu%200.0025%20%7C%20awk%20'%7Bprint%20%241%20*%20%242%7D')%20%7C%20awk%20'%7Bprint%20%241%20%2B%20%242%7D')%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20else%0A%20%20%20%20%20%20%20%20%23%20Base%20allocation%20for%201%20CPU%20in%20fractions%20of%20a%20core%20(60%20millicores%20%3D%200.06%20CPU%20core)%0A%20%20%20%20%20%20%20%20base_allocation_fraction%3D0.06%0A%20%20%20%20%20%20%20%20%23%20Increment%20per%20additional%20CPU%20in%20fractions%20of%20a%20core%20(12%20millicores%20%3D%200.012%20CPU%20core)%0A%20%20%20%20%20%20%20%20increment_per_cpu_fraction%3D0.012%0A%20%20%20%20%20%20%20%20if%20((total_cpu%20%3E%201))%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20the%20total%20system-reserved%20CPU%20in%20fractions%2C%20starting%20with%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20and%20adding%20the%20incremental%20fraction%20for%20each%20additional%20CPU%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24(awk%20-v%20base%3D%22%24base_allocation_fraction%22%20-v%20increment%3D%22%24increment_per_cpu_fraction%22%20-v%20cpus%3D%22%24total_cpu%22%20'BEGIN%20%7Bprintf%20%22%25.2f%5Cn%22%2C%20base%20%2B%20increment%20*%20(cpus%20-%201)%7D')%0A%20%20%20%20%20%20%20%20else%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20For%20a%20single%20CPU%2C%20use%20the%20base%20allocation%0A%20%20%20%20%20%20%20%20%20%20%20%20recommended_systemreserved_cpu%3D%24base_allocation_fraction%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7Brecommended_systemreserved_cpu%7D%22%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_ephemeral_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20dynamic_pid_sizing%20%7B%0A%20%20%20%20echo%20%22Not%20implemented%20yet%22%0A%7D%0Afunction%20set_memory%20%7B%0A%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_MEMORY%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_MEMORY%3D%24%7BSYSTEM_RESERVED_MEMORY%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_cpu%20%7B%0A%20%20%20%20SYSTEM_RESERVED_CPU%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_CPU%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_CPU%3D%22500m%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_CPU%3D%24%7BSYSTEM_RESERVED_CPU%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20set_es%20%7B%0A%20%20%20%20SYSTEM_RESERVED_ES%3D%241%0A%20%20%20%20if%20%5B%20-z%20%22%24%7BSYSTEM_RESERVED_ES%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20SYSTEM_RESERVED_ES%3D%221Gi%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22SYSTEM_RESERVED_ES%3D%24%7BSYSTEM_RESERVED_ES%7D%22%20%3E%3E%20%24%7BNODE_SIZES_ENV%7D%0A%7D%0Afunction%20dynamic_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20dynamic_memory_sizing%0A%20%20%20%20dynamic_cpu_sizing%20%242%0A%20%20%20%20set_es%20%241%0A%20%20%20%20%23dynamic_ephemeral_sizing%0A%20%20%20%20%23dynamic_pid_sizing%0A%7D%0Afunction%20static_node_sizing%20%7B%0A%20%20%20%20rm%20-f%20%24%7BNODE_SIZES_ENV%7D%0A%20%20%20%20set_memory%20%241%0A%20%20%20%20set_cpu%20%242%0A%20%20%20%20set_es%20%243%0A%7D%0Afunction%20create_version_file%20%7B%0A%20%20%20%20echo%20%22%7B%5C%22version%5C%22%3A%20%241%7D%22%20%3E%20%242%0A%7D%0Aif%20!%20%5B%20-f%20%24NODE_AUTO_SIZING_VERSION_FILE%20%5D%3B%20then%0A%20%20%20%20create_version_file%20%24NODE_AUTO_SIZING_VERSION%20%24NODE_AUTO_SIZING_VERSION_FILE%0Afi%0Anew_version%3D%24(jq%20.version%20%24NODE_AUTO_SIZING_VERSION_FILE)%0Aif%20%5B%20%241%20%3D%3D%20%22true%22%20%5D%3B%20then%0A%20%20%20%20dynamic_node_sizing%20%244%20%24new_version%0Aelif%20%5B%20%241%20%3D%3D%20%22false%22%20%5D%3B%20then%0A%20%20%20%20static_node_sizing%20%242%20%243%20%244%0Aelse%0A%20%20%20%20echo%20%22Unrecognized%20command%20line%20option.%20Valid%20options%20are%20%5C%22true%5C%22%20or%20%5C%22false%5C%22%22%0Afi
          mode: 493
          overwrite: true
          path: /usr/local/sbin/dynamic-system-reserved-calc.sh
        - contents:
            source: data:,%23%20Turning%20on%20Accounting%20helps%20track%20down%20performance%20issues.%0A%5BManager%5D%0ADefaultCPUAccounting%3Dyes%0ADefaultMemoryAccounting%3Dyes%0ADefaultBlockIOAccounting%3Dyes%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system.conf.d/kubelet-cgroups.conf
        - contents:
            source: data:,%5BService%5D%0AEnvironment%3D%22KUBELET_LOG_LEVEL%3D2%22%0A
          mode: 420
          overwrite: true
          path: /etc/systemd/system/kubelet.service.d/20-logging.conf
        - contents:
            source: data:,%23%20ignore%20known%20SDN-managed%20devices%0A%5Bdevice%5D%0Amatch-device%3Dinterface-name%3Abr-int%3Binterface-name%3Abr-local%3Binterface-name%3Abr-nexthop%3Binterface-name%3Aovn-k8s-*%3Binterface-name%3Ak8s-*%3Binterface-name%3Atun0%3Binterface-name%3Abr0%3Binterface-name%3Apatch-br-*%3Binterface-name%3Abr-ext%3Binterface-name%3Aext-vxlan%3Binterface-name%3Aext%3Binterface-name%3Aint%3Binterface-name%3Avxlan_sys_*%3Binterface-name%3Agenev_sys_*%3Bdriver%3Aveth%0Amanaged%3D0%0A
          mode: 420
          overwrite: true
          path: /etc/NetworkManager/conf.d/sdn.conf
        - contents:
            source: data:,%5Bservice%5D%0Akeep_state_file_after_apply%20%3D%20true%0A
          mode: 420
          overwrite: true
          path: /etc/nmstate/nmstate.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Set%20interface%20ofport_request%20to%20guarantee%20stable%20ofport%20numbers.%20This%20is%20important%20for%20flow%20matches.%0A%23%20Otherwise%2C%20another%20ofport%20number%20is%20assigned%20to%20the%20interface%20on%20every%20restart%20of%20NetworkManager.%0A%23%20This%20script%20will%20build%20an%20associative%20array%20INTERFACE_NAME-%3Eofport_request%20and%20will%20save%20it%20to%20file%20CONFIGURATION_FILE.%0A%23%20When%20an%20interface%20is%20brought%20up%2C%20this%20will%20reuse%20the%20value%20from%20the%20associative%20array%20if%20such%20a%20value%20exists.%0A%23%20Otherwise%2C%20this%20will%20try%20to%20use%20the%20current%20ofport%20value.%20If%20the%20ofport%20value%20is%20already%20reserved%2C%20then%0A%23%20this%20uses%20the%20lowest%20available%20numerical%20value%2C%20instead.%0Aset%20-eux%20-o%20pipefail%0Aif%20%5B%5B%20%22OVNKubernetes%22%20!%3D%20%22OVNKubernetes%22%20%5D%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0AINTERFACE_NAME%3D%241%0AOPERATION%3D%242%0A%0A%23%20Only%20execute%20this%20on%20pre-up%0Aif%20%5B%20%22%24%7BOPERATION%7D%22%20!%3D%20%22pre-up%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0AINTERFACE_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%241%3D%3D%22'%24%7BINTERFACE_NAME%7D'%22%20%26%26%20%242!~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20slave-type.%20If%20this%20is%20not%20an%20ovs-port%2C%20then%20exit%0AINTERFACE_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BINTERFACE_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-port%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20This%20is%20not%20necessarily%20a%20UUID%20(can%20be%20a%20name%20in%20case%20of%20bonds)%20but%20this%20should%20be%20unique%0APORT%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BINTERFACE_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20interface's%20NM%20uuid%0APORT_CONNECTION_UUID%3D%24(nmcli%20-t%20-f%20device%2Ctype%2Cuuid%20conn%20%7C%20awk%20-F%20'%3A'%20'%7Bif(%20(%241%3D%3D%22'%24%7BPORT%7D'%22%20%7C%7C%20%243%3D%3D%22'%24%7BPORT%7D'%22)%20%26%26%20%242~%2F%5Eovs*%2F)%20print%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20slave-type.%20If%20this%20is%20not%20an%20ovs-bridge%2C%20then%20exit%0APORT_OVS_SLAVE_TYPE%3D%24(nmcli%20-t%20-f%20connection.slave-type%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BPORT_OVS_SLAVE_TYPE%7D%22%20!%3D%20%22ovs-bridge%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20port's%20master.%20If%20it%20doesn't%20have%20any%2C%20assume%20it's%20not%20our%20bridge%0ABRIDGE_ID%3D%24(nmcli%20-t%20-f%20connection.master%20conn%20show%20%22%24%7BPORT_CONNECTION_UUID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0Aif%20%5B%20%22%24%7BBRIDGE_ID%7D%22%20%3D%3D%20%22%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Get%20the%20bridge%20name%0ABRIDGE_NAME%3D%24(nmcli%20-t%20-f%20connection.interface-name%20conn%20show%20%22%24%7BBRIDGE_ID%7D%22%20%7C%20awk%20-F%20'%3A'%20'%7Bprint%20%24NF%7D')%0A%23%20Limit%20this%20to%20br-ex%20and%20br-ex1%20only.%20If%20one%20wanted%20to%20enable%20this%20for%20all%20OVS%20bridges%2C%0A%23%20the%20condition%20would%20be%3A%20if%20%5B%20%22%24BRIDGE_NAME%22%20%3D%3D%20%22%22%20%5D%3B%20then%0Aif%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex%22%20%5D%20%26%26%20%5B%20%22%24%7BBRIDGE_NAME%7D%22%20!%3D%20%22br-ex1%22%20%5D%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20Make%20sure%20that%20the%20interface%20is%20plugged%20into%20OVS%0A%23%20This%20should%20always%20be%20the%20case%20given%20that%20we%20are%20in%20pre-up%2C%20but%20exit%20gracefully%20in%20the%20odd%20case%20that%20it's%20not%0Aif%20!%20ovs-vsctl%20list%20interface%20%22%24%7BINTERFACE_NAME%7D%22%20%3E%2Fdev%2Fnull%202%3E%261%3B%20then%0A%20%20%20%20exit%200%0Afi%0A%0ACONFIGURATION_FILE%3D%22%2Frun%2Fofport_requests.%24%7BBRIDGE_NAME%7D%22%0A%0A%23%20Declare%20a%20new%20associative%20array.%20If%20CONFIGURATION_FILE%20exists%2C%20source%20entries%20from%20there%0Adeclare%20-A%20INTERFACES%0Aif%20%5B%20-f%20%22%24%7BCONFIGURATION_FILE%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Sourcing%20configuration%20file%20'%24%7BCONFIGURATION_FILE%7D'%20with%20contents%3A%22%0A%20%20%20%20cat%20%22%24%7BCONFIGURATION_FILE%7D%22%0A%20%20%20%20source%20%22%24%7BCONFIGURATION_FILE%7D%22%0Afi%0A%0A%23%20get_interface_ofport_request%20will%20return%0A%23%20*%20either%3A%20the%20current%20ofport%20assignment%20for%20the%20port%20if%20no%20interface%20has%20claimed%20this%20ofport%20number%2C%20yet%0A%23%20*%20or%3A%20%20%20%20%20the%20lowest%20available%20free%20ofport%20number%0Afunction%20get_interface_ofport_request()%20%7B%0A%20%20%20%20%23%20Build%20an%20array%20that%20only%20contains%20the%20currently%20reserved%20ofport_requests%0A%20%20%20%20declare%20-A%20ofport_requests%0A%20%20%20%20for%20interface_name%20in%20%22%24%7B!INTERFACES%5B%40%5D%7D%22%3B%20do%0A%20%20%20%20%20%20%20%20ofport_requests%5B%24%7BINTERFACES%5B%24interface_name%5D%7D%5D%3D%24%7BINTERFACES%5B%24interface_name%5D%7D%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20Get%20the%20current%20ofport%20number%20assignment%0A%20%20%20%20local%20current_ofport%3D%24(ovs-vsctl%20get%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport)%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20still%20free%2C%20use%20it%0A%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24current_ofport%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20echo%20%24current_ofport%0A%20%20%20%20%20%20%20%20return%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20If%20the%20current%20ofport%20number%20is%20not%20free%2C%20return%20the%20lowest%20free%20entry%0A%20%20%20%20i%3D0%0A%20%20%20%20for%20i%20in%20%7B1..65000%7D%3B%20do%0A%20%20%20%20%20%20%20%20if%20!%20%5B%20%22%24%7Bofport_requests%5B%24i%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%24i%0A%20%20%20%20%20%20%20%20%20%20%20%20return%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20done%0A%0A%20%20%20%20%23%20if%20we%20still%20cannot%20find%20an%20ID%2C%20exit%20with%20an%20error%0A%20%20%20%20echo%20%22Impossible%20to%20find%20an%20ofport%20ID%20for%20interface%20%24%7BINTERFACE_NAME%7D%22%20%3E%262%0A%20%20%20%20exit%201%0A%7D%0A%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20exists%2C%20use%20that%20value%0A%23%20If%20INTERFACES%5BINTERFACE_NAME%5D%20does%20not%20exists%2C%20use%20the%20value%20from%20get_interface_ofport_request%0Aif%20!%20%5B%20%22%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%2Ba%7D%22%20%5D%3B%20then%0A%20%20%20%20INTERFACES%5B%24INTERFACE_NAME%5D%3D%24(get_interface_ofport_request)%0Afi%0A%23%20Set%20ofport_request%20according%20to%20INTERFACES%5BINTERFACE_NAME%5D%0Aovs-vsctl%20set%20Interface%20%22%24%7BINTERFACE_NAME%7D%22%20ofport_request%3D%24%7BINTERFACES%5B%24INTERFACE_NAME%5D%7D%0A%0A%23%20Save%20current%20state%20of%20INTERFACES%20to%20CONFIGURATION_FILE%0Adeclare%20-p%20INTERFACES%20%3E%7C%20%22%24%7BCONFIGURATION_FILE%7D%22%0A
          mode: 493
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/pre-up.d/10-ofport-request.sh
        - contents:
            source: data:,%7B%22auths%22%3A%7B%22cloud.openshift.com%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfN2JmN2FjMTAyMDMxNDY1N2EwZjdiMDdiNDNjM2FiZDg6OE1YQ0gyTldMSktPVU9DQk5UNk9NSERPUzc2NkYxTURFTjlXQjhXN0xTTUtDNjk1NjI0N1c1OFUySzFDRUcwVw%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22quay.io%22%3A%7B%22auth%22%3A%22b3BlbnNoaWZ0LXJlbGVhc2UtZGV2K29jbV9hY2Nlc3NfN2JmN2FjMTAyMDMxNDY1N2EwZjdiMDdiNDNjM2FiZDg6OE1YQ0gyTldMSktPVU9DQk5UNk9NSERPUzc2NkYxTURFTjlXQjhXN0xTTUtDNjk1NjI0N1c1OFUySzFDRUcwVw%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22registry.ci.openshift.org%22%3A%7B%22auth%22%3A%22c2VydmljZWFjY291bnQ6ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNkluWjBaVmc1TVVkUlpGRjZRME5OWkVWa2JGOXNTSG90YlVSd2EwRlVPR2RzWjJoUVRtMVBkamxLUmpBaWZRLmV5SmhkV1FpT2xzaWFIUjBjSE02THk5amFTMWtkakp1Y0MxdmFXUmpMbk16TG1GdFlYcHZibUYzY3k1amIyMGlYU3dpWlhod0lqb3hOek0wTlRNd05EWXlMQ0pwWVhRaU9qRTNNekl4TVRFeU5qSXNJbWx6Y3lJNkltaDBkSEJ6T2k4dlkya3RaSFl5Ym5BdGIybGtZeTV6TXk1aGJXRjZiMjVoZDNNdVkyOXRJaXdpYTNWaVpYSnVaWFJsY3k1cGJ5STZleUp1WVcxbGMzQmhZMlVpT2lKamFTSXNJbk5sWTNKbGRDSTZleUp1WVcxbElqb2lkRzlyWlc0dFltOTFibVF0YjJKcVpXTjBMVEVpTENKMWFXUWlPaUkxWkRJd1pHUTBNQzFqT1RCaExUUXpNVFl0WVdNd05DMW1OVGczT0RFeVpUVTFZamdpZlN3aWMyVnlkbWxqWldGalkyOTFiblFpT25zaWJtRnRaU0k2SW1sdFlXZGxMWEIxYkd4bGNpSXNJblZwWkNJNkltRTNOMlk1TkdFeUxXVXdOelV0TkRGaU9DMDVPV1JoTFdRMlpEbGtNbUZpTlRGak9TSjlmU3dpYm1KbUlqb3hOek15TVRFeE1qWXlMQ0p6ZFdJaU9pSnplWE4wWlcwNmMyVnlkbWxqWldGalkyOTFiblE2WTJrNmFXMWhaMlV0Y0hWc2JHVnlJbjAuVGFqMktGY1JOV0FIRHJGT0NPQjBhWUJGUTUwVW9FUmdXMWFZYUNTVTQ0NF9jdnpCOFJDamNxR04xdV9jOFRRbFBDNXU0NG5JNklaYTdvU1RnMUh4dE9aQmEyYW5OS0JPMk5UNVF5WEhhX0R5cVJlaUUxb0YtcmphRms2TEJrNWllT1BSWXJHbklpWlJJNkQ2S0kxMmxJVFZQdFBPYUgtaXFuNV9LMXdOcmR4SDhYb2dCdlJ5UlJwRDBLTUxGNkJfeFBzbi1VeHVQQklIbjVRTFlXSkJtOVFMRVlIM0tzZDN2by03Uzc0anlZMkswMUF1OUpwYkFFR3k4Z2lyUDE1YlRnUXJReW1zS1NrbFN6U3BUbEM0MDJxVjNBanVPSjA4eGxrSE5VeXJROFk3dklJWDFBUUVmbHJaaC13ZVcyVy1aNWtnZjFOMXhNVVl6QnplZW5BZF9n%22%7D%2C%22registry.connect.redhat.com%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLWU3NDlmYWFiLTM0ZjktNDg0ZS1hNWQwLTJkNzFhMzgzMTg1MjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSXpORGszTURVMU5URTFObUkwTXpOaFltVmxNRGt5TVRJM09UZzNZV0V5WVNKOS50MUxtR0FhMTQzdnJIWG13RFZVVjNYaWhYa203Vk95bDFLek9kZm9QN0tTd3NqVFpKeUlSN1lKQjNyNGxGN3pVNWMwa0ZyOVYweUtwSFdPRU94clhJekVSaXlfOXkwQzRxbXRDOUhYNjJNVThsdmJtQW9GSXhZbHZXWnREVXVQZWgzSVFqS25CN2FJYlZ6MFJ3SWZWYVZucXFOUzhHbDNFcDRTUjVpNGZmUzE5akJCUnpxdmxBSjF6QkNVWWI3S1ZLTHVGRHJsNjdNNy1rWWwxTUhseTRBN2JVdjVISU5MaEhOdDVfRk5JX3RWbjdQM0RzQkVjcWxkWTd0Y0J4UlNoLTdQbWpzMGJEWm9ZZTZ6by1QY25TeEY0RV94QzF6aGZYYUNpdEU4UVZTUmk2MjhnM1c4WjVQQzc4VFBJWGtvaTBJWG9IX1E4QTd4SDlKaDhsWWhTTnBCaUxHODMyaFNhRUdtYkEtaU5kd3BrTGk0a0oyeTlYWE55ZlNUbU1mRUppUGwyWEI5VXRTT3lva05XU0ZqVk1kZ3l5WFlaUWtTNGh6Ql83VkpzTEh6RHpKaTJGcUZNNE56LW5Qd28zalZ3c3d3YXgzUUZZVUk2YzA5MVZnT0NUdEtpeEJXeTBaVEZyT3hEVDh4ZFRQOXcxY1JoR1N1UzU5WG55c2I2bndDLWQ5ZS11SWZpS2x4dDNZNkJaUkhRYmVUZlRtdGFoMUxOYWhRaXRzclVubVBjZXhnLVFXdzhCS3VENUFwbFc3eFVHcm9Lb1lkSEowVTJtc0ZWcjhZZ2FjVDl1UC1hWGUtTHd0dnJ3ZG1fWGtVdWRMRnFsRklxby1lWTdhVE03Xy1HRk8xWE8xTTIwQWVtSU5oUXJqUkN4TGRJeXlMSU9uOURBZUdYeGc5bUJiWQ%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%2C%22registry.redhat.io%22%3A%7B%22auth%22%3A%22fHVoYy1wb29sLWU3NDlmYWFiLTM0ZjktNDg0ZS1hNWQwLTJkNzFhMzgzMTg1MjpleUpoYkdjaU9pSlNVelV4TWlKOS5leUp6ZFdJaU9pSXpORGszTURVMU5URTFObUkwTXpOaFltVmxNRGt5TVRJM09UZzNZV0V5WVNKOS50MUxtR0FhMTQzdnJIWG13RFZVVjNYaWhYa203Vk95bDFLek9kZm9QN0tTd3NqVFpKeUlSN1lKQjNyNGxGN3pVNWMwa0ZyOVYweUtwSFdPRU94clhJekVSaXlfOXkwQzRxbXRDOUhYNjJNVThsdmJtQW9GSXhZbHZXWnREVXVQZWgzSVFqS25CN2FJYlZ6MFJ3SWZWYVZucXFOUzhHbDNFcDRTUjVpNGZmUzE5akJCUnpxdmxBSjF6QkNVWWI3S1ZLTHVGRHJsNjdNNy1rWWwxTUhseTRBN2JVdjVISU5MaEhOdDVfRk5JX3RWbjdQM0RzQkVjcWxkWTd0Y0J4UlNoLTdQbWpzMGJEWm9ZZTZ6by1QY25TeEY0RV94QzF6aGZYYUNpdEU4UVZTUmk2MjhnM1c4WjVQQzc4VFBJWGtvaTBJWG9IX1E4QTd4SDlKaDhsWWhTTnBCaUxHODMyaFNhRUdtYkEtaU5kd3BrTGk0a0oyeTlYWE55ZlNUbU1mRUppUGwyWEI5VXRTT3lva05XU0ZqVk1kZ3l5WFlaUWtTNGh6Ql83VkpzTEh6RHpKaTJGcUZNNE56LW5Qd28zalZ3c3d3YXgzUUZZVUk2YzA5MVZnT0NUdEtpeEJXeTBaVEZyT3hEVDh4ZFRQOXcxY1JoR1N1UzU5WG55c2I2bndDLWQ5ZS11SWZpS2x4dDNZNkJaUkhRYmVUZlRtdGFoMUxOYWhRaXRzclVubVBjZXhnLVFXdzhCS3VENUFwbFc3eFVHcm9Lb1lkSEowVTJtc0ZWcjhZZ2FjVDl1UC1hWGUtTHd0dnJ3ZG1fWGtVdWRMRnFsRklxby1lWTdhVE03Xy1HRk8xWE8xTTIwQWVtSU5oUXJqUkN4TGRJeXlMSU9uOURBZUdYeGc5bUJiWQ%3D%3D%22%2C%22email%22%3A%22aos-team-dp-testplatform%40redhat.com%22%7D%7D%7D%0A
          mode: 384
          overwrite: true
          path: /var/lib/kubelet/config.json
        - contents:
            source: data:,%23%20Needed%20by%20the%20OpenShift%20SDN.%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1758552%0Anet.ipv4.conf.all.arp_announce%20%3D%202%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/arp.conf
        - contents:
            source: data:,%23%20See%3A%20rhbz%231384746%2C%20OCPBUGS-24012%0Anet.ipv4.neigh.default.gc_thresh1%3D8192%0Anet.ipv4.neigh.default.gc_thresh2%3D32768%0Anet.ipv4.neigh.default.gc_thresh3%3D65536%0Anet.ipv6.neigh.default.gc_thresh1%3D8192%0Anet.ipv6.neigh.default.gc_thresh2%3D32768%0Anet.ipv6.neigh.default.gc_thresh3%3D65536%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/gc-thresh.conf
        - contents:
            source: data:,%0Afs.inotify.max_user_watches%20%3D%2065536%0Afs.inotify.max_user_instances%20%3D%208192%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/inotify.conf
        - contents:
            source: data:,vm.unprivileged_userfaultfd%20%3D%201
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/enable-userfaultfd.conf
        - contents:
            source: data:,%23%20Needed%20for%20OpenShift%20Logging%20(ElasticSearch).%20See%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1793714%0Avm.max_map_count%20%3D%20262144%0A
          mode: 420
          overwrite: true
          path: /etc/sysctl.d/vm-max-map.conf
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%20-o%20pipefail%0A%0ANODEENV%3D%2Fetc%2Fkubernetes%2Fnode.env%0A%0A%23%20This%20can%20be%20removed%201%20release%20after%20it%20merges%20because%20all%20affected%20nodes%0A%23%20will%20have%20upgraded%0ALEGACY_NODEENV%3D%2Fetc%2Fsystemd%2Fsystem%2Fkubelet.service.d%2F20-aws-node-name.conf%0Aif%20%5B%20-e%20%22%24%7BLEGACY_NODEENV%7D%22%20%5D%3B%20then%0A%20%20%20%20%23%20Legacy%20file%20was%20a%20systemd%20stanza%20with%20KUBELET_NODE_NAME%20specified%20in%0A%20%20%20%20%23%20a%20directive%20of%20the%20format%3A%0A%20%20%20%20%23%20%20%20Environment%3D%22KUBELET_NODE_NAME%3Dnode.example.com%22%0A%20%20%20%20%23%20New%20format%20is%20an%20environment%20file.%20The%20following%20extracts%20only%20the%0A%20%20%20%20%23%20contents%20of%20any%20Environment%20directives.%0A%20%20%20%20echo%20%22Migrating%20%24%7BLEGACY_NODEENV%7D%20to%20%24%7BNODEENV%7D%22%0A%20%20%20%20awk%20'match(%240%2C%20%2F%5E%5Cs*Environment%5Cs*%3D%5Cs*%22(.*)%22%5Cs*%24%2F%2C%20value)%20%7B%20print%20value%5B1%5D%20%7D'%20%3C%20%22%24%7BLEGACY_NODEENV%7D%22%20%3E%20%22%24%7BNODEENV%7D%22%0A%20%20%20%20rm%20%22%24%7BLEGACY_NODEENV%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0Aif%20%5B%20-e%20%22%24%7BNODEENV%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Not%20replacing%20existing%20%24%7BNODEENV%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20afterburn%20service%20is%20expected%20to%20be%20used%20for%20metadata%20retrival%2C%20see%20respective%20systemd%20unit.%0A%23%20However%2C%20on%20older%20OCP%20boot%20images%20does%20not%20contain%20afterburn%20service%2C%20check%20if%20afterburn%20variables%20are%20there%0A%23%20otherwise%20try%20to%20communicate%20IMDS%20here.%0A%23%20metadata%20related%20afterburn%20doc%3A%20https%3A%2F%2Fcoreos.github.io%2Fafterburn%2Fusage%2Fattributes%2F%0A%0AHOSTNAME%3D%24%7BAFTERBURN_AWS_HOSTNAME%3A-%7D%0Awhile%20%5B%5B%20-z%20%22%24%7BHOSTNAME%7D%22%20%5D%5D%3B%20do%0A%20%20HOSTNAME%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Flocal-hostname)%0A%20%20if%20%5B%5B%20-z%20%22%24%7BHOSTNAME%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Can%20not%20obtain%20hostname%20from%20the%20metadata%20service.%22%201%3E%262%0A%20%20%20%20sleep%205%0A%20%20fi%20%0Adone%0A%0A%23%20For%20compatibility%20with%20the%20AWS%20in-tree%20provider%0A%23%20Set%20node%20name%20to%20be%20instance%20FQDN%20instead%20of%20the%20default%20hostname%0Acat%20%3E%20%22%24%7BNODEENV%7D%22%20%3C%3CEOF%0AKUBELET_NODE_NAME%3D%24%7BHOSTNAME%25%25%20*%7D%0AEOF%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/aws-kubelet-nodename
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-e%20-o%20pipefail%0A%0ANODECONF%3D%2Fetc%2Fsystemd%2Fsystem%2Fkubelet.service.d%2F20-aws-providerid.conf%0A%0Aif%20%5B%20-e%20%22%24%7BNODECONF%7D%22%20%5D%3B%20then%0A%20%20%20%20echo%20%22Not%20replacing%20existing%20%24%7BNODECONF%7D%22%0A%20%20%20%20exit%200%0Afi%0A%0A%23%20afterburn%20service%20is%20expected%20to%20be%20used%20for%20metadata%20retrival%2C%20see%20respective%20systemd%20unit.%0A%23%20However%2C%20on%20older%20OCP%20boot%20images%20does%20not%20contain%20afterburn%20service%2C%20check%20if%20afterburn%20variables%20are%20there%0A%23%20otherwise%20try%20to%20communicate%20IMDS%20here.%0A%23%20metadata%20related%20afterburn%20doc%3A%20https%3A%2F%2Fcoreos.github.io%2Fafterburn%2Fusage%2Fattributes%2F%0A%0AINSTANCE_ID%3D%24%7BAFTERBURN_AWS_INSTANCE_ID%3A-%7D%0AAVAILABILITY_ZONE%3D%24%7BAFTERBURN_AWS_AVAILABILITY_ZONE%3A-%7D%0Aif%20%5B%5B%20-z%20%22%24%7BINSTANCE_ID%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20-z%20%22%24%7BAVAILABILITY_ZONE%7D%22%20%5D%5D%3B%20then%0A%20%20INSTANCE_ID%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Finstance-id)%0A%20%20AVAILABILITY_ZONE%3D%24(curl%20-fSs%20http%3A%2F%2F169.254.169.254%2F2022-09-24%2Fmeta-data%2Fplacement%2Favailability-zone)%0A%20%20if%20%5B%5B%20-z%20%22%24%7BINSTANCE_ID%7D%22%20%5D%5D%20%7C%7C%20%5B%5B%20-z%20%22%24%7BAVAILABILITY_ZONE%7D%22%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Can%20not%20obtain%20instance-id%20and%20availability%20zone%20info%20from%20the%20metadata%20service.%22%0A%20%20%20%20exit%201%0A%20%20fi%20%0Afi%0A%0A%23%20Due%20to%20a%20potential%20mismatch%20between%20Hostname%20and%20PrivateDNSName%20with%20clusters%20that%20use%20custom%20DHCP%20Option%20Sets%0A%23%20which%20can%20cause%20issues%20in%20cloud%20controller%20manager%20node%20syncing%0A%23%20(see%3A%20https%3A%2F%2Fgithub.com%2Fkubernetes%2Fcloud-provider-aws%2Fissues%2F384)%2C%0A%23%20set%20KUBELET_PROVIDERID%20to%20be%20a%20fully%20qualified%20AWS%20instace%20provider%20id.%0A%23%20This%20new%20variable%20is%20later%20used%20to%20populate%20the%20kubelet's%20%60provider-id%60%20flag%2C%20later%20set%20on%20the%20Node%20.spec%0A%23%20and%20used%20by%20the%20cloud%20controller%20manager's%20node%20controller%20to%20retrieve%20the%20Node's%20backing%20instance.%0Acat%20%3E%20%22%24%7BNODECONF%7D%22%20%3C%3CEOF%0A%5BService%5D%0AEnvironment%3D%22KUBELET_PROVIDERID%3Daws%3A%2F%2F%2F%24%7BAVAILABILITY_ZONE%7D%2F%24%7BINSTANCE_ID%7D%22%0AEOF%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/aws-kubelet-providerid
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20First%2C%20we%20need%20to%20wait%20until%20DHCP%20finishes%20and%20the%20node%20has%20a%20non-%60localhost%60%0A%23%20hostname%20before%20%60kubelet.service%60%20starts.%0A%23%20That's%20the%20%60--wait%60%20argument%20as%20used%20by%20%60node-valid-hostname.service%60.%0A%23%0A%23%20Second%2C%20on%20GCP%20specifically%20we%20truncate%20the%20hostname%20if%20it's%20%3E63%20characters.%0A%23%20That's%20%60gcp-hostname.service%60.%0A%0A%23%20Block%20indefinitely%20until%20the%20host%20gets%20a%20non-localhost%20name.%0A%23%20Note%20node-valid-hostname.service%20uses%20systemd%20to%20abort%20if%20this%20takes%20too%20long.%0Await_localhost()%20%7B%0A%20%20%20%20echo%20%22waiting%20for%20non-localhost%20hostname%20to%20be%20assigned%22%0A%20%20%20%20while%20%5B%5B%20%22%24(%3C%20%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%20%3D~%20(localhost%7Clocalhost.localdomain)%20%5D%5D%3B%0A%20%20%20%20do%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20done%0A%20%20%20%20echo%20%22node%20identified%20as%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%22%0A%20%20%20%20echo%20%22saving%20hostname%20to%20prevent%20NetworkManager%20from%20ever%20unsetting%20it%22%0A%20%20%20%20hostnamectl%20set-hostname%20--static%20--transient%20%24(%3C%2Fproc%2Fsys%2Fkernel%2Fhostname)%0A%20%20%20%20exit%200%0A%7D%0A%0Aset_gcp_hostname()%20%7B%0A%20%20%20%20%2Fusr%2Fbin%2Fafterburn%20--provider%20gcp%20--hostname%3D%2Frun%2Fafterburn.hostname%0A%0A%20%20%20%20local%20host_name%3D%24(cat%20%2Frun%2Fafterburn.hostname)%0A%20%20%20%20local%20type_arg%3D%22transient%22%0A%0A%20%20%20%20%23%20%2Fetc%2Fhostname%20is%20used%20for%20static%20hostnames%20and%20is%20authoritative.%0A%20%20%20%20%23%20This%20will%20check%20to%20make%20sure%20that%20the%20static%20hostname%20is%20the%0A%20%20%20%20%23%20less%20than%20or%20equal%20to%2063%20characters%20in%20length.%0A%20%20%20%20if%20%5B%20-f%20%2Fetc%2Fhostname%20%5D%20%26%26%20%5B%20%22%24(cat%20%2Fetc%2Fhostname%20%7C%20wc%20-m)%22%20-gt%200%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20etc_name%3D%22%24(%3C%20%2Fetc%2Fhostname)%22%0A%20%20%20%20%20%20%20%20type_arg%3D%22static%22%0A%20%20%20%20%20%20%20%20if%20%5B%20%22%24%7Betc_name%7D%22%20!%3D%20%22%24%7Bhost_name%7D%22%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22%2Fetc%2Fhostname%20is%20set%20to%20%24%7Betc_name%7D%20but%20does%20not%20match%20%24%7Bhost_name%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20echo%20%22using%20%2Fetc%2Fhostname%20as%20the%20authoritative%20name%22%0A%20%20%20%20%20%20%20%20%20%20%20%20host_name%3D%22%24%7Betc_name%7D%22%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20fi%0A%0A%20%20%20%20%23%20Only%20mutate%20the%20hostname%20if%20the%20length%20is%20longer%20than%2063%20characters.%20The%0A%20%20%20%20%23%20hostname%20will%20be%20the%20lesser%20of%2063%20characters%20after%20the%20first%20dot%20in%20the%0A%20%20%20%20%23%20FQDN.%20%20This%20algorithm%20is%20only%20known%20to%20work%20in%20GCP%2C%20and%20hence%20is%20only%0A%20%20%20%20%23%20executed%20in%20GCP.%0A%20%20%20%20if%20%5B%20%22%24%7B%23host_name%7D%22%20-gt%2063%20%5D%3B%20then%0A%20%20%20%20%20%20%20%20alt_name%3D%24(printf%20%22%24%7Bhost_name%7D%22%20%7C%20cut%20-f1%20-d'.'%20%7C%20cut%20-c%20-63)%0A%20%20%20%20%20%20%20%20echo%20%22%24%7Bhost_name%7D%20is%20longer%20than%2063%20characters%2C%20using%20truncated%20hostname%22%0A%20%20%20%20%20%20%20%20host_name%3D%22%24%7Balt_name%7D%22%0A%20%20%20%20fi%0A%20%20%20%20echo%20%22setting%20%24%7Btype_arg%7D%20hostname%20to%20%24%7Bhost_name%7D%22%0A%20%20%20%20%2Fbin%2Fhostnamectl%20%22--%24%7Btype_arg%7D%22%20set-hostname%20%22%24%7Bhost_name%7D%22%0A%20%20%20%20exit%200%0A%7D%0A%0Aarg%3D%24%7B1%7D%3B%20shift%3B%0Acase%20%22%24%7Barg%7D%22%20in%0A%20%20%20%20--wait)%20wait_localhost%3B%3B%0A%20%20%20%20--gcp)%20set_gcp_hostname%3B%3B%0A%20%20%20%20*)%20echo%20%22Unhandled%20arg%20%24arg%22%3B%20exit%201%0Aesac%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/mco-hostname
        - contents:
            source: data:,
          mode: 493
          overwrite: true
          path: /etc/kubernetes/kubelet-plugins/volume/exec/.dummy
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0A%23%20Workaround%3A%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1941714%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1935539%0A%23%20https%3A%2F%2Fbugzilla.redhat.com%2Fshow_bug.cgi%3Fid%3D1987108%0A%0Adriver%3D%24(nmcli%20-t%20-m%20tabular%20-f%20general.driver%20dev%20show%20%22%24%7BDEVICE_IFACE%7D%22)%0A%0Aif%20%5B%5B%20%22%242%22%20%3D%3D%20%22up%22%20%26%26%20%22%24%7Bdriver%7D%22%20%3D%3D%20%22vmxnet3%22%20%5D%5D%3B%20then%0A%20%20logger%20-s%20%2299-vsphere-disable-tx-udp-tnl%20triggered%20by%20%24%7B2%7D%20on%20device%20%24%7BDEVICE_IFACE%7D.%22%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-udp_tnl-csum-segmentation%20off%0A%20%20ethtool%20-K%20%24%7BDEVICE_IFACE%7D%20tx-checksum-ip-generic%20off%0Afi%0A
          mode: 484
          overwrite: true
          path: /etc/NetworkManager/dispatcher.d/99-vsphere-disable-tx-udp-tnl
        - contents:
            source: data:,%23!%2Fbin%2Fbash%0Aset%20-eux%0A%0Aif%20%5B%20!%20-e%20%2Fetc%2Fnmstate%2Fopenshift%2Fapplied%20%5D%3B%20then%0A%20%20%23%20No%20need%20to%20do%20this%20if%20no%20NMState%20configuration%20was%20applied%0A%20%20exit%200%0Afi%0A%0A%23%20This%20logic%20is%20borrowed%20from%20configure-ovs.sh%0A%23%20TODO%3A%20Find%20a%20platform-agnostic%20way%20to%20do%20this.%20It%20won't%20work%20on%20platforms%20where%0A%23%20nodeip-configuration%20is%20not%20used.%0Aip%3D%24(cat%20%2Frun%2Fnodeip-configuration%2Fprimary-ip)%0Aif%20%5B%5B%20%22%24%7Bip%7D%22%20%3D%3D%20%22%22%20%5D%5D%3B%20then%0A%20%20echo%20%22No%20ip%20to%20bind%20was%20found%22%0A%20%20exit%201%0Afi%0Awhile%20%3A%0Ado%0A%20%20random_port%3D%24(shuf%20-i%2050000-60000%20-n%201)%0A%20%20echo%20%22Trying%20to%20bind%20%24%7Bip%7D%20on%20port%20%24%7Brandom_port%7D%22%0A%20%20exit_code%3D%24(timeout%202s%20nc%20-l%20%22%24%7Bip%7D%22%20%24%7Brandom_port%7D%3B%20echo%20%24%3F)%0A%20%20if%20%5B%5B%20exit_code%20-eq%20124%20%5D%5D%3B%20then%0A%20%20%20%20echo%20%22Address%20bound%20successfully%22%0A%20%20%20%20exit%200%0A%20%20fi%0A%20%20sleep%2010%0Adone%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/wait-for-primary-ip.sh
        - contents:
            source: data:,unqualified-search-registries%20%3D%20%5B'registry.access.redhat.com'%2C%20'docker.io'%5D%0A
          mode: 420
          overwrite: true
          path: /etc/containers/registries.conf
        - contents:
            source: data:,%5Bcrio%5D%0Ainternal_wipe%20%3D%20true%0Ainternal_repair%20%3D%20true%0A%0A%5Bcrio.api%5D%0Astream_address%20%3D%20%22127.0.0.1%22%0Astream_port%20%3D%20%220%22%0A%0A%5Bcrio.runtime%5D%0Aselinux%20%3D%20true%0Aconmon%20%3D%20%22%22%0Aconmon_cgroup%20%3D%20%22pod%22%0Adefault_env%20%3D%20%5B%0A%20%20%20%20%22NSS_SDB_USE_CACHE%3Dno%22%2C%0A%5D%0Alog_level%20%3D%20%22info%22%0Acgroup_manager%20%3D%20%22systemd%22%0Adefault_sysctls%20%3D%20%5B%0A%20%20%20%20%22net.ipv4.ping_group_range%3D0%202147483647%22%2C%0A%5D%0Adefault_runtime%20%3D%20%22crun%22%0Ahooks_dir%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Frun%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%20%20%20%20%22%2Fusr%2Fshare%2Fcontainers%2Foci%2Fhooks.d%22%2C%0A%5D%0Amanage_ns_lifecycle%20%3D%20true%0Aabsent_mount_sources_to_reject%20%3D%20%5B%0A%20%20%20%20%22%2Fetc%2Fhostname%22%2C%0A%5D%0Adrop_infra_ctr%20%3D%20true%0A%0A%5Bcrio.runtime.runtimes.runc%5D%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%0A%5Bcrio.runtime.runtimes.crun%5D%0Aruntime_root%20%3D%20%22%2Frun%2Fcrun%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%20%20%22io.containers.trace-syscall%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.Devices%22%2C%0A%20%20%20%20%22io.kubernetes.cri-o.LinkLogs%22%2C%0A%5D%0A%23%20Based%20on%20https%3A%2F%2Fgithub.com%2Fcontainers%2Fcrun%2Fblob%2F27d7dd3a0%2FREADME.md%3Fplain%3D1%23L48%0Acontainer_min_memory%20%3D%20%22512KiB%22%0A%0A%5Bcrio.runtime.workloads.openshift-builder%5D%0Aactivation_annotation%20%3D%20%22io.openshift.builder%22%0Aallowed_annotations%20%3D%20%5B%0A%20%20%22io.kubernetes.cri-o.userns-mode%22%2C%0A%20%20%22io.kubernetes.cri-o.Devices%22%0A%5D%0A%5Bcrio.runtime.workloads.openshift-builder.resources%5D%0A%0A%5Bcrio.image%5D%0Aglobal_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_image%20%3D%20%22quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3A8c3c9719ba85ce692f2462e653d82d154bd958dc57c236d6bc0a8092bb6b2080%22%0Apause_image_auth_file%20%3D%20%22%2Fvar%2Flib%2Fkubelet%2Fconfig.json%22%0Apause_command%20%3D%20%22%2Fusr%2Fbin%2Fpod%22%0A%0A%5Bcrio.network%5D%0Anetwork_dir%20%3D%20%22%2Fetc%2Fkubernetes%2Fcni%2Fnet.d%2F%22%0Aplugin_dirs%20%3D%20%5B%0A%20%20%20%20%22%2Fvar%2Flib%2Fcni%2Fbin%22%2C%0A%20%20%20%20%22%2Fusr%2Flibexec%2Fcni%22%2C%0A%5D%0A%0A%5Bcrio.metrics%5D%0Aenable_metrics%20%3D%20true%0Ametrics_host%20%3D%20%22127.0.0.1%22%0Ametrics_port%20%3D%209537%0Ametrics_collectors%20%3D%20%5B%0A%20%20%22operations%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_total%22%0A%20%20%22operations_latency_microseconds_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds_total%22%0A%20%20%22operations_latency_microseconds%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_latency_seconds%22%0A%20%20%22operations_errors%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22operations_errors_total%22%0A%20%20%22image_pulls_layer_size%22%2C%0A%20%20%22containers_oom_total%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22containers_oom_count_total%22%0A%20%20%22containers_oom%22%2C%0A%20%20%23%20Drop%20metrics%20with%20excessive%20label%20cardinality.%0A%20%20%23%20%22image_pulls_by_digest%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_bytes_total%22%0A%20%20%23%20%22image_pulls_by_name_skipped%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_skipped_bytes_total%22%0A%20%20%23%20%22image_pulls_failures%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_failure_total%22%0A%20%20%23%20%22image_pulls_successes%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_pulls_success_total%22%0A%20%20%23%20%22image_layer_reuse%22%2C%20%23%20DEPRECATED%3A%20in%20favour%20of%20%22image_layer_reuse_total%22%0A%20%20%22operations_total%22%2C%0A%20%20%22operations_latency_seconds_total%22%2C%0A%20%20%22operations_latency_seconds%22%2C%0A%20%20%22operations_errors_total%22%2C%0A%20%20%22image_pulls_bytes_total%22%2C%0A%20%20%22image_pulls_skipped_bytes_total%22%2C%0A%20%20%22image_pulls_success_total%22%2C%0A%20%20%22image_pulls_failure_total%22%2C%0A%20%20%22image_layer_reuse_total%22%2C%0A%20%20%22containers_oom_count_total%22%2C%0A%20%20%22processes_defunct%22%0A%5D%0A
          mode: 420
          overwrite: true
          path: /etc/crio/crio.conf.d/00-default
        - contents:
            source: data:,%7B%0A%20%20%20%20%22default%22%3A%20%5B%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22type%22%3A%20%22insecureAcceptAnything%22%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%5D%2C%0A%20%20%20%20%22transports%22%3A%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22docker-daemon%22%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%3A%20%5B%7B%22type%22%3A%22insecureAcceptAnything%22%7D%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%7D
          mode: 420
          overwrite: true
          path: /etc/containers/policy.json
        - contents:
            source: data:,%5BGlobal%5D
          mode: 420
          overwrite: true
          path: /etc/kubernetes/cloud.conf
        - contents:
            source: data:,authorization%3A%0A%20%20static%3A%0A%20%20%20%20-%20resourceRequest%3A%20false%0A%20%20%20%20%20%20path%3A%20%2Fmetrics%0A%20%20%20%20%20%20verb%3A%20get%0A%20%20%20%20%20%20user%3A%0A%20%20%20%20%20%20%20%20name%3A%20system%3Aserviceaccount%3Aopenshift-monitoring%3Aprometheus-k8s
          mode: 420
          overwrite: true
          path: /etc/kubernetes/crio-metrics-proxy.cfg
        - contents:
            source: data:,apiVersion%3A%20v1%0Akind%3A%20Pod%0Ametadata%3A%0A%20%20name%3A%20kube-rbac-proxy-crio%0A%20%20namespace%3A%20openshift-machine-config-operator%0A%20%20annotations%3A%0A%20%20%20%20target.workload.openshift.io%2Fmanagement%3A%20'%7B%22effect%22%3A%20%22PreferredDuringScheduling%22%7D'%0Aspec%3A%0A%20%20volumes%3A%0A%20%20-%20name%3A%20etc-kube%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20hostPath%3A%0A%20%20%20%20%20%20path%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20hostNetwork%3A%20true%0A%20%20priorityClassName%3A%20system-cluster-critical%0A%20%20initContainers%3A%0A%20%20-%20name%3A%20setup%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ae6c78ecf5ff15391d335577ffca87563ddd533727e52cf08217038a579f70dd9%0A%20%20%20%20imagePullPolicy%3A%20IfNotPresent%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20command%3A%20%5B'%2Fbin%2Fbash'%2C%20'-ec'%5D%0A%20%20%20%20args%3A%0A%20%20%20%20-%20%7C%0A%20%20%20%20%20%20echo%20-n%20%22Waiting%20for%20kubelet%20key%20and%20certificate%20to%20be%20available%22%0A%20%20%20%20%20%20while%20%5B%20-n%20%22%24(test%20-e%20%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem)%22%20%5D%20%3B%20do%0A%20%20%20%20%20%20%20%20echo%20-n%20%22.%22%0A%20%20%20%20%20%20%20%20sleep%201%0A%20%20%20%20%20%20%20%20((%20tries%20%2B%3D%201%20))%0A%20%20%20%20%20%20%20%20if%20%5B%5B%20%22%24%7Btries%7D%22%20-gt%2010%20%5D%5D%3B%20then%0A%20%20%20%20%20%20%20%20%20%20echo%20%22Timed%20out%20waiting%20for%20kubelet%20key%20and%20cert.%22%0A%20%20%20%20%20%20%20%20%20%20exit%201%0A%20%20%20%20%20%20%20%20fi%0A%20%20%20%20%20%20done%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20%20%20%20%20cpu%3A%205m%0A%20%20containers%3A%0A%20%20-%20name%3A%20kube-rbac-proxy-crio%0A%20%20%20%20image%3A%20quay.io%2Fopenshift-release-dev%2Focp-v4.0-art-dev%40sha256%3Ae6c78ecf5ff15391d335577ffca87563ddd533727e52cf08217038a579f70dd9%0A%20%20%20%20securityContext%3A%0A%20%20%20%20%20%20privileged%3A%20true%0A%20%20%20%20ports%3A%0A%20%20%20%20-%20containerPort%3A%209637%0A%20%20%20%20args%3A%0A%20%20%20%20-%20--secure-listen-address%3D%3A9637%0A%20%20%20%20-%20--config-file%3D%2Fetc%2Fkubernetes%2Fcrio-metrics-proxy.cfg%0A%20%20%20%20-%20--client-ca-file%3D%2Fetc%2Fkubernetes%2Fkubelet-ca.crt%0A%20%20%20%20-%20--logtostderr%3Dtrue%0A%20%20%20%20-%20--kubeconfig%3D%2Fvar%2Flib%2Fkubelet%2Fkubeconfig%0A%20%20%20%20-%20--tls-cipher-suites%3DTLS_AES_128_GCM_SHA256%2CTLS_AES_256_GCM_SHA384%2CTLS_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256%2CTLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384%2CTLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256%2CTLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256%20%0A%20%20%20%20-%20--tls-min-version%3DVersionTLS12%0A%20%20%20%20-%20--upstream%3Dhttp%3A%2F%2F127.0.0.1%3A9537%0A%20%20%20%20-%20--tls-cert-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20-%20--tls-private-key-file%3D%2Fvar%2Flib%2Fkubelet%2Fpki%2Fkubelet-server-current.pem%0A%20%20%20%20resources%3A%0A%20%20%20%20%20%20requests%3A%0A%20%20%20%20%20%20%20%20cpu%3A%2020m%0A%20%20%20%20%20%20%20%20memory%3A%2050Mi%0A%20%20%20%20terminationMessagePolicy%3A%20FallbackToLogsOnError%0A%20%20%20%20volumeMounts%3A%0A%20%20%20%20-%20name%3A%20etc-kube%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fetc%2Fkubernetes%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer%0A%20%20%20%20-%20name%3A%20var-lib-kubelet%0A%20%20%20%20%20%20mountPath%3A%20%22%2Fvar%2Flib%2Fkubelet%22%0A%20%20%20%20%20%20mountPropagation%3A%20HostToContainer
          mode: 420
          overwrite: true
          path: /etc/kubernetes/manifests/criometricsproxy.yaml
        - contents:
            compression: ""
            source: data:text/plain;charset=utf-8;base64,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
          mode: 420
          overwrite: true
          path: /etc/kubernetes/kubelet.conf
        - contents:
            source: data:,%23!%2Fbin%2Fsh%0Aif%20%5B%20-x%20%2Fusr%2Fbin%2Fkubensenter%20%5D%3B%20then%0A%20%20exec%20%2Fusr%2Fbin%2Fkubensenter%20%22%24%40%22%0Aelse%0A%20%20exec%20%22%24%40%22%0Afi%0A
          mode: 493
          overwrite: true
          path: /usr/local/bin/kubenswrapper
      systemd:
        units:
        - contents: |
            [Unit]
            Description=Cleans NetworkManager state generated by dracut
            # Removal of this file signals firstboot completion
            ConditionPathExists=!/etc/ignition-machine-config-encapsulated.json
            # This is opt-in for some deployment types, and opt-out for others.
            ConditionPathExists=/var/lib/mco/nm-clean-initrd-state
            Wants=network-pre.target
            Before=network-pre.target

            [Service]
            Type=oneshot
            # Remove any existing state possibly generated NM run by dracut. We want NM to
            # consider all profiles autoconnect priority when it starts instead of
            # remembering which profile was a device activated with when NM is run by
            # dracut.
            ExecStart=/usr/local/bin/nm-clean-initrd-state.sh
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: NetworkManager-clean-initrd-state.service
        - contents: |
            [Unit]
            Description=Fetch kubelet node name from AWS Metadata

            # Run afterburn service for collect info from metadata server
            # see: https://coreos.github.io/afterburn/usage/attributes/
            # Not required due to OCP 4.1 boot image does not contain afterburn service
            # see: https://issues.redhat.com/browse/OCPBUGS-7559
            Wants=afterburn.service
            After=afterburn.service

            # Wait for NetworkManager to report it's online
            After=NetworkManager-wait-online.service
            # Run before kubelet
            Before=kubelet-dependencies.target

            [Service]
            # Mark afterburn environment file optional, due to it is possible that afterburn service was not executed
            EnvironmentFile=-/run/metadata/afterburn
            ExecStart=/usr/local/bin/aws-kubelet-nodename
            Type=oneshot

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: aws-kubelet-nodename.service
        - contents: |
            [Unit]
            Description=Fetch kubelet provider id from AWS Metadata

            # Run afterburn service for collect info from metadata server
            # see: https://coreos.github.io/afterburn/usage/attributes/
            # Not required due to OCP 4.1 boot image does not contain afterburn service
            # see: https://issues.redhat.com/browse/OCPBUGS-7559
            Wants=afterburn.service
            After=afterburn.service

            # Wait for NetworkManager to report it's online
            After=NetworkManager-wait-online.service
            # Run before kubelet
            Before=kubelet-dependencies.target

            [Service]
            # Mark afterburn environment file optional, due to it is possible that afterburn service was not executed
            EnvironmentFile=-/run/metadata/afterburn
            ExecStart=/usr/local/bin/aws-kubelet-providerid
            Type=oneshot

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: aws-kubelet-providerid.service
        - dropins:
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="ENABLE_PROFILE_UNIX_SOCKET=true"
            name: 10-mco-profile-unix-socket.conf
          - contents: |
              [Unit]
              After=kubelet-dependencies.target
              Requires=kubelet-dependencies.target
            name: 05-mco-ordering.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          name: crio.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: docker.socket
        - contents: |
            [Unit]
            Description=The firstboot OS update has completed
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target

            [Install]
            WantedBy=default.target
          enabled: true
          name: firstboot-osupdate.target
        - contents: |
            [Unit]
            Description=Dynamically sets the system reserved for the kubelet
            Wants=network-online.target
            After=network-online.target firstboot-osupdate.target
            Before=kubelet-dependencies.target

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            RemainAfterExit=yes
            EnvironmentFile=/etc/node-sizing-enabled.env
            ExecStart=/bin/bash /usr/local/sbin/dynamic-system-reserved-calc.sh ${NODE_SIZING_ENABLED} ${SYSTEM_RESERVED_MEMORY} ${SYSTEM_RESERVED_CPU} ${SYSTEM_RESERVED_ES}
            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: kubelet-auto-node-size.service
        - contents: |
            [Unit]
            Description=Dependencies necessary to run kubelet
            Documentation=https://github.com/openshift/machine-config-operator/
            Requires=basic.target network-online.target
            Wants=NetworkManager-wait-online.service crio-wipe.service
            Wants=rpc-statd.service chrony-wait.service
          name: kubelet-dependencies.target
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet
            Requires=crio.service kubelet-dependencies.target
            After=kubelet-dependencies.target
            After=ostree-finalize-staged.service

            [Service]
            Type=notify
            ExecStartPre=/bin/mkdir --parents /etc/kubernetes/manifests
            ExecStartPre=-/usr/sbin/restorecon -rv /var/lib/kubelet/ /usr/local/bin/kubenswrapper /usr/bin/kubensenter
            Environment="KUBELET_NODE_IP=0.0.0.0"
            EnvironmentFile=/etc/os-release
            EnvironmentFile=-/etc/kubernetes/kubelet-workaround
            EnvironmentFile=-/etc/kubernetes/kubelet-env
            EnvironmentFile=/etc/node-sizing.env

            ExecStart=/usr/local/bin/kubenswrapper \
                /usr/bin/kubelet \
                  --config=/etc/kubernetes/kubelet.conf \
                  --bootstrap-kubeconfig=/etc/kubernetes/kubeconfig \
                  --kubeconfig=/var/lib/kubelet/kubeconfig \
                  --container-runtime-endpoint=/var/run/crio/crio.sock \
                  --runtime-cgroups=/system.slice/crio.service \
                  --node-labels=node-role.kubernetes.io/worker,node.openshift.io/os_id=${ID} \
                  --node-ip=${KUBELET_NODE_IP} \
                  --minimum-container-ttl-duration=6m0s \
                  --volume-plugin-dir=/etc/kubernetes/kubelet-plugins/volume/exec \
                  --cloud-provider=external \
                  --image-credential-provider-bin-dir=/usr/libexec/kubelet-image-credential-provider-plugins --image-credential-provider-config=/etc/kubernetes/credential-providers/ecr-credential-provider.yaml \
                  --hostname-override=${KUBELET_NODE_NAME} \
                  --provider-id=${KUBELET_PROVIDERID} \
                  --pod-infra-container-image=quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8c3c9719ba85ce692f2462e653d82d154bd958dc57c236d6bc0a8092bb6b2080 \
                  --system-reserved=cpu=${SYSTEM_RESERVED_CPU},memory=${SYSTEM_RESERVED_MEMORY},ephemeral-storage=${SYSTEM_RESERVED_ES} \
                  --v=${KUBELET_LOG_LEVEL}

            Restart=always
            RestartSec=10

            [Install]
            WantedBy=multi-user.target
          dropins:
          - contents: |
              [Service]
              EnvironmentFile=/etc/kubernetes/node.env
            name: 20-node-env.conf
          - contents: |
              # vim:set ft=systemd :
              #
              # This drop-in will enable any service built with this
              # github.com/containers/kubemntns library to properly join the mount namespace
              # managed by kubens.service
              #

              [Unit]
              After=kubens.service

              [Service]
              EnvironmentFile=-/run/kubens/env
            name: 01-kubens.conf
          - contents: ""
            name: 10-mco-default-env.conf
          - contents: |
              [Service]
              Environment="GODEBUG=x509ignoreCN=0,madvdontneed=1"
            name: 10-mco-default-madv.conf
          enabled: true
          name: kubelet.service
        - contents: |
            [Unit]
            Description=Manages a mount namespace for kubernetes-specific mounts

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            RuntimeDirectory=kubens
            Environment=RUNTIME_DIRECTORY=%t/kubens
            Environment=BIND_POINT=%t/kubens/mnt
            Environment=ENVFILE=%t/kubens/env

            # Set up the runtime directory as an unbindable mountpoint
            ExecStartPre=bash -c "findmnt ${RUNTIME_DIRECTORY} || mount --make-unbindable --bind ${RUNTIME_DIRECTORY} ${RUNTIME_DIRECTORY}"
            # Ensure the bind point exists
            ExecStartPre=touch ${BIND_POINT}
            # Use 'unshare' to create the new mountpoint, then 'mount --make-rshared' so it cascades internally
            ExecStart=unshare --mount=${BIND_POINT} --propagation slave mount --make-rshared /
            # Finally, set an env pointer for ease-of-use
            ExecStartPost=bash -c 'echo "KUBENSMNT=${BIND_POINT}" > "${ENVFILE}"'

            # On stop, a recursive unmount cleans up the namespace and bind-mounted unbindable parent directory
            ExecStop=umount -R ${RUNTIME_DIRECTORY}

            [Install]
            WantedBy=multi-user.target
          enabled: false
          name: kubens.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Firstboot
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # Removal of this file signals firstboot completion
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            After=machine-config-daemon-pull.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            # Disable existing repos (if any) so that OS extensions would use embedded RPMs only
            ExecStartPre=-/usr/bin/sh -c "sed -i 's/enabled=1/enabled=0/' /etc/yum.repos.d/*.repo"
            # Run this via podman because we want to use the nmstatectl binary in our container
            ExecStart=/usr/bin/podman run --rm --privileged --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:787a505ca594b0a727549353c503dec9233a9d3c2dcd6b64e3de5f998892a1d5' firstboot-complete-machineconfig --persist-nics
            ExecStart=/usr/bin/podman run --rm --privileged --pid=host --net=host -v /:/rootfs  --entrypoint machine-config-daemon 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:787a505ca594b0a727549353c503dec9233a9d3c2dcd6b64e3de5f998892a1d5' firstboot-complete-machineconfig
            [Install]
            RequiredBy=firstboot-osupdate.target
          enabled: true
          name: machine-config-daemon-firstboot.service
        - contents: |
            [Unit]
            Description=Machine Config Daemon Pull
            # Make sure it runs only on OSTree booted system
            ConditionPathExists=/run/ostree-booted
            # This "stamp file" is unlinked when we complete
            # machine-config-daemon-firstboot.service
            ConditionPathExists=/etc/ignition-machine-config-encapsulated.json
            # Run after crio-wipe so the pulled MCD image is protected against a corrupted storage from a forced shutdown
            Wants=crio-wipe.service NetworkManager-wait-online.service
            After=crio-wipe.service NetworkManager-wait-online.service network.service

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            ExecStart=/bin/sh -c "while ! /usr/bin/podman pull --authfile=/var/lib/kubelet/config.json 'quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:787a505ca594b0a727549353c503dec9233a9d3c2dcd6b64e3de5f998892a1d5'; do sleep 1; done"
            [Install]
            RequiredBy=machine-config-daemon-firstboot.service
          enabled: true
          name: machine-config-daemon-pull.service
        - contents: |
            [Unit]
            Description=Wait for a non-localhost hostname
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            RemainAfterExit=yes
            User=root
            ExecStart=/usr/local/bin/mco-hostname --wait

            # Wait up to 5min for the node to get a non-localhost name
            TimeoutSec=300

            [Install]
            # TODO: Change this to RequiredBy after we fix https://github.com/openshift/machine-config-operator/pull/3865#issuecomment-1746963115
            WantedBy=kubelet-dependencies.target
          enabled: true
          name: node-valid-hostname.service
        - contents: |
            [Unit]
            Description=Writes IP address configuration so that kubelet and crio services select a valid node IP
            Wants=NetworkManager-wait-online.service
            After=NetworkManager-wait-online.service firstboot-osupdate.target
            Before=kubelet-dependencies.target ovs-configuration.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/bin/podman run --rm \
              --authfile /var/lib/kubelet/config.json \
              --net=host \
              --security-opt label=disable \
              --volume /etc/systemd/system:/etc/systemd/system \
              --volume /run/nodeip-configuration:/run/nodeip-configuration \
              quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:02a7419d80a103e656c25a8d7573106a62e8e4a41508c758387db7e13801d89c \
              node-ip \
              set \
              --retry-on-failure \
              --network-type OVNKubernetes \
              ${NODEIP_HINT:-${KUBELET_NODEIP_HINT:-}}; \
              do \
              sleep 5; \
              done"
            ExecStart=/bin/systemctl daemon-reload
            ExecStartPre=/bin/mkdir -p /run/nodeip-configuration
            StandardOutput=journal+console
            StandardError=journal+console

            EnvironmentFile=-/etc/default/nodeip-configuration

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: false
          name: nodeip-configuration.service
        - enabled: true
          name: openvswitch.service
        - contents: |
            [Unit]
            # Kdump will generate it's initramfs based on the running state when kdump.service run
            # If OVS has already run, the kdump fails to gather a working network config,
            # which prevent network log exports, sush as SSH.
            # See https://issues.redhat.com/browse/OCPBUGS-28239
            After=kdump.service
            Description=Configures OVS with proper host networking configuration
            # This service is used to move a physical NIC into OVS and reconfigure OVS to use the host IP
            Requires=openvswitch.service
            Wants=NetworkManager-wait-online.service
            After=firstboot-osupdate.target
            After=NetworkManager-wait-online.service openvswitch.service network.service nodeip-configuration.service nmstate.service
            Before=kubelet-dependencies.target node-valid-hostname.service

            [Service]
            # Need oneshot to delay kubelet
            Type=oneshot
            ExecStart=/usr/local/bin/configure-ovs.sh OVNKubernetes
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            RequiredBy=kubelet-dependencies.target
          enabled: true
          name: ovs-configuration.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /var/lib/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /etc/openvswitch'
              ExecStartPre=-/bin/sh -c '/usr/bin/chown -R :$${OVS_USER_ID##*:} /run/openvswitch'
              ExecStartPost=-/usr/bin/ovs-appctl vlog/set syslog:info
              ExecReload=-/usr/bin/ovs-appctl vlog/set syslog:info
            name: 10-ovs-vswitchd-restart.conf
          name: ovs-vswitchd.service
        - dropins:
          - contents: |
              [Service]
              Restart=always
            name: 10-ovsdb-restart.conf
          enabled: true
          name: ovsdb-server.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          name: pivot.service
        - dropins:
          - contents: ""
            name: 10-mco-default-env.conf
          name: rpm-ostreed.service
        - contents: |
            [Unit]
            Description=Ensure primary IP is assigned and usable
            Requires=nmstate.service
            After=nmstate.service
            Before=kubelet-dependencies.target

            [Service]
            Type=oneshot
            # Would prefer to do Restart=on-failure instead of this bash retry loop, but
            # the version of systemd we have right now doesn't support it. It should be
            # available in systemd v244 and higher.
            ExecStart=/bin/bash -c " \
              until \
              /usr/local/bin/wait-for-primary-ip.sh; \
              do \
              sleep 10; \
              done"
            StandardOutput=journal+console
            StandardError=journal+console

            [Install]
            WantedBy=network-online.target
          enabled: true
          name: wait-for-primary-ip.service
        - dropins:
          - contents: |
              [Unit]
              ConditionPathExists=/enoent
            name: mco-disabled.conf
          name: zincati.service
        - contents: |
            [Unit]
            Description=Kubernetes Kubelet After Reboot Cleanup
            Before=kubelet.service

            [Service]
            Type=oneshot
            ExecStart=/bin/rm -f /var/lib/kubelet/cpu_manager_state
            ExecStart=/bin/rm -f /var/lib/kubelet/memory_manager_state
            ExecStart=-/bin/rm -f /var/lib/kubelet/dra_manager_state

            [Install]
            WantedBy=multi-user.target
          enabled: true
          name: kubelet-cleanup.service
    extensions: []
    fips: false
    kernelArguments:
    - systemd.unified_cgroup_hierarchy=1
    - cgroup_no_v1="all"
    - psi=0
    kernelType: default
    osImageURL: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:ad394c1a0b0cc7d37e2bc632f795f9140ca3f68bc0f2ca2895b83125c61a7d2e
kind: List
metadata:
  resourceVersion: ""
